{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "gCHDAerPu9Yq",
    "outputId": "32dd50f2-8a42-4fdc-f1b9-b1ba09edff35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "upjtZ9uD4NHU"
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import os\n",
    "\n",
    "import lxml.etree\n",
    "import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Add,\n",
    "    Concatenate,\n",
    "    Conv2D,\n",
    "    Input,\n",
    "    Lambda,\n",
    "    LeakyReLU,\n",
    "    MaxPool2D,\n",
    "    UpSampling2D,\n",
    "    ZeroPadding2D,\n",
    "    BatchNormalization,\n",
    ")\n",
    "from tensorflow.keras.losses import (\n",
    "    binary_crossentropy,\n",
    "    sparse_categorical_crossentropy\n",
    ")\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import (\n",
    "    ReduceLROnPlateau,\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    TensorBoard\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dX4JxWHm4NHe"
   },
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for physical_device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(physical_device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "8wheYRzNwAut",
    "outputId": "d4dcb716-598c-42ad-b6bf-31bbdd9f4fe9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /content/drive/My Drive/ML/faceMaskDataset/dataset.zip\n",
      "  inflating: annotations/maksssksksss0.xml  \n",
      "  inflating: annotations/maksssksksss1.xml  \n",
      "  inflating: annotations/maksssksksss10.xml  \n",
      "  inflating: annotations/maksssksksss100.xml  \n",
      "  inflating: annotations/maksssksksss101.xml  \n",
      "  inflating: annotations/maksssksksss102.xml  \n",
      "  inflating: annotations/maksssksksss103.xml  \n",
      "  inflating: annotations/maksssksksss104.xml  \n",
      "  inflating: annotations/maksssksksss105.xml  \n",
      "  inflating: annotations/maksssksksss106.xml  \n",
      "  inflating: annotations/maksssksksss107.xml  \n",
      "  inflating: annotations/maksssksksss108.xml  \n",
      "  inflating: annotations/maksssksksss109.xml  \n",
      "  inflating: annotations/maksssksksss11.xml  \n",
      "  inflating: annotations/maksssksksss110.xml  \n",
      "  inflating: annotations/maksssksksss111.xml  \n",
      "  inflating: annotations/maksssksksss112.xml  \n",
      "  inflating: annotations/maksssksksss113.xml  \n",
      "  inflating: annotations/maksssksksss114.xml  \n",
      "  inflating: annotations/maksssksksss115.xml  \n",
      "  inflating: annotations/maksssksksss116.xml  \n",
      "  inflating: annotations/maksssksksss117.xml  \n",
      "  inflating: annotations/maksssksksss118.xml  \n",
      "  inflating: annotations/maksssksksss119.xml  \n",
      "  inflating: annotations/maksssksksss12.xml  \n",
      "  inflating: annotations/maksssksksss120.xml  \n",
      "  inflating: annotations/maksssksksss121.xml  \n",
      "  inflating: annotations/maksssksksss122.xml  \n",
      "  inflating: annotations/maksssksksss123.xml  \n",
      "  inflating: annotations/maksssksksss124.xml  \n",
      "  inflating: annotations/maksssksksss125.xml  \n",
      "  inflating: annotations/maksssksksss126.xml  \n",
      "  inflating: annotations/maksssksksss127.xml  \n",
      "  inflating: annotations/maksssksksss128.xml  \n",
      "  inflating: annotations/maksssksksss129.xml  \n",
      "  inflating: annotations/maksssksksss13.xml  \n",
      "  inflating: annotations/maksssksksss130.xml  \n",
      "  inflating: annotations/maksssksksss131.xml  \n",
      "  inflating: annotations/maksssksksss132.xml  \n",
      "  inflating: annotations/maksssksksss133.xml  \n",
      "  inflating: annotations/maksssksksss134.xml  \n",
      "  inflating: annotations/maksssksksss135.xml  \n",
      "  inflating: annotations/maksssksksss136.xml  \n",
      "  inflating: annotations/maksssksksss137.xml  \n",
      "  inflating: annotations/maksssksksss138.xml  \n",
      "  inflating: annotations/maksssksksss139.xml  \n",
      "  inflating: annotations/maksssksksss14.xml  \n",
      "  inflating: annotations/maksssksksss140.xml  \n",
      "  inflating: annotations/maksssksksss141.xml  \n",
      "  inflating: annotations/maksssksksss142.xml  \n",
      "  inflating: annotations/maksssksksss143.xml  \n",
      "  inflating: annotations/maksssksksss144.xml  \n",
      "  inflating: annotations/maksssksksss145.xml  \n",
      "  inflating: annotations/maksssksksss146.xml  \n",
      "  inflating: annotations/maksssksksss147.xml  \n",
      "  inflating: annotations/maksssksksss148.xml  \n",
      "  inflating: annotations/maksssksksss149.xml  \n",
      "  inflating: annotations/maksssksksss15.xml  \n",
      "  inflating: annotations/maksssksksss150.xml  \n",
      "  inflating: annotations/maksssksksss151.xml  \n",
      "  inflating: annotations/maksssksksss152.xml  \n",
      "  inflating: annotations/maksssksksss153.xml  \n",
      "  inflating: annotations/maksssksksss154.xml  \n",
      "  inflating: annotations/maksssksksss155.xml  \n",
      "  inflating: annotations/maksssksksss156.xml  \n",
      "  inflating: annotations/maksssksksss157.xml  \n",
      "  inflating: annotations/maksssksksss158.xml  \n",
      "  inflating: annotations/maksssksksss159.xml  \n",
      "  inflating: annotations/maksssksksss16.xml  \n",
      "  inflating: annotations/maksssksksss160.xml  \n",
      "  inflating: annotations/maksssksksss161.xml  \n",
      "  inflating: annotations/maksssksksss162.xml  \n",
      "  inflating: annotations/maksssksksss163.xml  \n",
      "  inflating: annotations/maksssksksss164.xml  \n",
      "  inflating: annotations/maksssksksss165.xml  \n",
      "  inflating: annotations/maksssksksss166.xml  \n",
      "  inflating: annotations/maksssksksss167.xml  \n",
      "  inflating: annotations/maksssksksss168.xml  \n",
      "  inflating: annotations/maksssksksss169.xml  \n",
      "  inflating: annotations/maksssksksss17.xml  \n",
      "  inflating: annotations/maksssksksss170.xml  \n",
      "  inflating: annotations/maksssksksss171.xml  \n",
      "  inflating: annotations/maksssksksss172.xml  \n",
      "  inflating: annotations/maksssksksss173.xml  \n",
      "  inflating: annotations/maksssksksss174.xml  \n",
      "  inflating: annotations/maksssksksss175.xml  \n",
      "  inflating: annotations/maksssksksss176.xml  \n",
      "  inflating: annotations/maksssksksss177.xml  \n",
      "  inflating: annotations/maksssksksss178.xml  \n",
      "  inflating: annotations/maksssksksss179.xml  \n",
      "  inflating: annotations/maksssksksss18.xml  \n",
      "  inflating: annotations/maksssksksss180.xml  \n",
      "  inflating: annotations/maksssksksss181.xml  \n",
      "  inflating: annotations/maksssksksss182.xml  \n",
      "  inflating: annotations/maksssksksss183.xml  \n",
      "  inflating: annotations/maksssksksss184.xml  \n",
      "  inflating: annotations/maksssksksss185.xml  \n",
      "  inflating: annotations/maksssksksss186.xml  \n",
      "  inflating: annotations/maksssksksss187.xml  \n",
      "  inflating: annotations/maksssksksss188.xml  \n",
      "  inflating: annotations/maksssksksss189.xml  \n",
      "  inflating: annotations/maksssksksss19.xml  \n",
      "  inflating: annotations/maksssksksss190.xml  \n",
      "  inflating: annotations/maksssksksss191.xml  \n",
      "  inflating: annotations/maksssksksss192.xml  \n",
      "  inflating: annotations/maksssksksss193.xml  \n",
      "  inflating: annotations/maksssksksss194.xml  \n",
      "  inflating: annotations/maksssksksss195.xml  \n",
      "  inflating: annotations/maksssksksss196.xml  \n",
      "  inflating: annotations/maksssksksss197.xml  \n",
      "  inflating: annotations/maksssksksss198.xml  \n",
      "  inflating: annotations/maksssksksss199.xml  \n",
      "  inflating: annotations/maksssksksss2.xml  \n",
      "  inflating: annotations/maksssksksss20.xml  \n",
      "  inflating: annotations/maksssksksss200.xml  \n",
      "  inflating: annotations/maksssksksss201.xml  \n",
      "  inflating: annotations/maksssksksss202.xml  \n",
      "  inflating: annotations/maksssksksss203.xml  \n",
      "  inflating: annotations/maksssksksss204.xml  \n",
      "  inflating: annotations/maksssksksss205.xml  \n",
      "  inflating: annotations/maksssksksss206.xml  \n",
      "  inflating: annotations/maksssksksss207.xml  \n",
      "  inflating: annotations/maksssksksss208.xml  \n",
      "  inflating: annotations/maksssksksss209.xml  \n",
      "  inflating: annotations/maksssksksss21.xml  \n",
      "  inflating: annotations/maksssksksss210.xml  \n",
      "  inflating: annotations/maksssksksss211.xml  \n",
      "  inflating: annotations/maksssksksss212.xml  \n",
      "  inflating: annotations/maksssksksss213.xml  \n",
      "  inflating: annotations/maksssksksss214.xml  \n",
      "  inflating: annotations/maksssksksss215.xml  \n",
      "  inflating: annotations/maksssksksss216.xml  \n",
      "  inflating: annotations/maksssksksss217.xml  \n",
      "  inflating: annotations/maksssksksss218.xml  \n",
      "  inflating: annotations/maksssksksss219.xml  \n",
      "  inflating: annotations/maksssksksss22.xml  \n",
      "  inflating: annotations/maksssksksss220.xml  \n",
      "  inflating: annotations/maksssksksss221.xml  \n",
      "  inflating: annotations/maksssksksss222.xml  \n",
      "  inflating: annotations/maksssksksss223.xml  \n",
      "  inflating: annotations/maksssksksss224.xml  \n",
      "  inflating: annotations/maksssksksss225.xml  \n",
      "  inflating: annotations/maksssksksss226.xml  \n",
      "  inflating: annotations/maksssksksss227.xml  \n",
      "  inflating: annotations/maksssksksss228.xml  \n",
      "  inflating: annotations/maksssksksss229.xml  \n",
      "  inflating: annotations/maksssksksss23.xml  \n",
      "  inflating: annotations/maksssksksss230.xml  \n",
      "  inflating: annotations/maksssksksss231.xml  \n",
      "  inflating: annotations/maksssksksss232.xml  \n",
      "  inflating: annotations/maksssksksss233.xml  \n",
      "  inflating: annotations/maksssksksss234.xml  \n",
      "  inflating: annotations/maksssksksss235.xml  \n",
      "  inflating: annotations/maksssksksss236.xml  \n",
      "  inflating: annotations/maksssksksss237.xml  \n",
      "  inflating: annotations/maksssksksss238.xml  \n",
      "  inflating: annotations/maksssksksss239.xml  \n",
      "  inflating: annotations/maksssksksss24.xml  \n",
      "  inflating: annotations/maksssksksss240.xml  \n",
      "  inflating: annotations/maksssksksss241.xml  \n",
      "  inflating: annotations/maksssksksss242.xml  \n",
      "  inflating: annotations/maksssksksss243.xml  \n",
      "  inflating: annotations/maksssksksss244.xml  \n",
      "  inflating: annotations/maksssksksss245.xml  \n",
      "  inflating: annotations/maksssksksss246.xml  \n",
      "  inflating: annotations/maksssksksss247.xml  \n",
      "  inflating: annotations/maksssksksss248.xml  \n",
      "  inflating: annotations/maksssksksss249.xml  \n",
      "  inflating: annotations/maksssksksss25.xml  \n",
      "  inflating: annotations/maksssksksss250.xml  \n",
      "  inflating: annotations/maksssksksss251.xml  \n",
      "  inflating: annotations/maksssksksss252.xml  \n",
      "  inflating: annotations/maksssksksss253.xml  \n",
      "  inflating: annotations/maksssksksss254.xml  \n",
      "  inflating: annotations/maksssksksss255.xml  \n",
      "  inflating: annotations/maksssksksss256.xml  \n",
      "  inflating: annotations/maksssksksss257.xml  \n",
      "  inflating: annotations/maksssksksss258.xml  \n",
      "  inflating: annotations/maksssksksss259.xml  \n",
      "  inflating: annotations/maksssksksss26.xml  \n",
      "  inflating: annotations/maksssksksss260.xml  \n",
      "  inflating: annotations/maksssksksss261.xml  \n",
      "  inflating: annotations/maksssksksss262.xml  \n",
      "  inflating: annotations/maksssksksss263.xml  \n",
      "  inflating: annotations/maksssksksss264.xml  \n",
      "  inflating: annotations/maksssksksss265.xml  \n",
      "  inflating: annotations/maksssksksss266.xml  \n",
      "  inflating: annotations/maksssksksss267.xml  \n",
      "  inflating: annotations/maksssksksss268.xml  \n",
      "  inflating: annotations/maksssksksss269.xml  \n",
      "  inflating: annotations/maksssksksss27.xml  \n",
      "  inflating: annotations/maksssksksss270.xml  \n",
      "  inflating: annotations/maksssksksss271.xml  \n",
      "  inflating: annotations/maksssksksss272.xml  \n",
      "  inflating: annotations/maksssksksss273.xml  \n",
      "  inflating: annotations/maksssksksss274.xml  \n",
      "  inflating: annotations/maksssksksss275.xml  \n",
      "  inflating: annotations/maksssksksss276.xml  \n",
      "  inflating: annotations/maksssksksss277.xml  \n",
      "  inflating: annotations/maksssksksss278.xml  \n",
      "  inflating: annotations/maksssksksss279.xml  \n",
      "  inflating: annotations/maksssksksss28.xml  \n",
      "  inflating: annotations/maksssksksss280.xml  \n",
      "  inflating: annotations/maksssksksss281.xml  \n",
      "  inflating: annotations/maksssksksss282.xml  \n",
      "  inflating: annotations/maksssksksss283.xml  \n",
      "  inflating: annotations/maksssksksss284.xml  \n",
      "  inflating: annotations/maksssksksss285.xml  \n",
      "  inflating: annotations/maksssksksss286.xml  \n",
      "  inflating: annotations/maksssksksss287.xml  \n",
      "  inflating: annotations/maksssksksss288.xml  \n",
      "  inflating: annotations/maksssksksss289.xml  \n",
      "  inflating: annotations/maksssksksss29.xml  \n",
      "  inflating: annotations/maksssksksss290.xml  \n",
      "  inflating: annotations/maksssksksss291.xml  \n",
      "  inflating: annotations/maksssksksss292.xml  \n",
      "  inflating: annotations/maksssksksss293.xml  \n",
      "  inflating: annotations/maksssksksss294.xml  \n",
      "  inflating: annotations/maksssksksss295.xml  \n",
      "  inflating: annotations/maksssksksss296.xml  \n",
      "  inflating: annotations/maksssksksss297.xml  \n",
      "  inflating: annotations/maksssksksss298.xml  \n",
      "  inflating: annotations/maksssksksss299.xml  \n",
      "  inflating: annotations/maksssksksss3.xml  \n",
      "  inflating: annotations/maksssksksss30.xml  \n",
      "  inflating: annotations/maksssksksss300.xml  \n",
      "  inflating: annotations/maksssksksss301.xml  \n",
      "  inflating: annotations/maksssksksss302.xml  \n",
      "  inflating: annotations/maksssksksss303.xml  \n",
      "  inflating: annotations/maksssksksss304.xml  \n",
      "  inflating: annotations/maksssksksss305.xml  \n",
      "  inflating: annotations/maksssksksss306.xml  \n",
      "  inflating: annotations/maksssksksss307.xml  \n",
      "  inflating: annotations/maksssksksss308.xml  \n",
      "  inflating: annotations/maksssksksss309.xml  \n",
      "  inflating: annotations/maksssksksss31.xml  \n",
      "  inflating: annotations/maksssksksss310.xml  \n",
      "  inflating: annotations/maksssksksss311.xml  \n",
      "  inflating: annotations/maksssksksss312.xml  \n",
      "  inflating: annotations/maksssksksss313.xml  \n",
      "  inflating: annotations/maksssksksss314.xml  \n",
      "  inflating: annotations/maksssksksss315.xml  \n",
      "  inflating: annotations/maksssksksss316.xml  \n",
      "  inflating: annotations/maksssksksss317.xml  \n",
      "  inflating: annotations/maksssksksss318.xml  \n",
      "  inflating: annotations/maksssksksss319.xml  \n",
      "  inflating: annotations/maksssksksss32.xml  \n",
      "  inflating: annotations/maksssksksss320.xml  \n",
      "  inflating: annotations/maksssksksss321.xml  \n",
      "  inflating: annotations/maksssksksss322.xml  \n",
      "  inflating: annotations/maksssksksss323.xml  \n",
      "  inflating: annotations/maksssksksss324.xml  \n",
      "  inflating: annotations/maksssksksss325.xml  \n",
      "  inflating: annotations/maksssksksss326.xml  \n",
      "  inflating: annotations/maksssksksss327.xml  \n",
      "  inflating: annotations/maksssksksss328.xml  \n",
      "  inflating: annotations/maksssksksss329.xml  \n",
      "  inflating: annotations/maksssksksss33.xml  \n",
      "  inflating: annotations/maksssksksss330.xml  \n",
      "  inflating: annotations/maksssksksss331.xml  \n",
      "  inflating: annotations/maksssksksss332.xml  \n",
      "  inflating: annotations/maksssksksss333.xml  \n",
      "  inflating: annotations/maksssksksss334.xml  \n",
      "  inflating: annotations/maksssksksss335.xml  \n",
      "  inflating: annotations/maksssksksss336.xml  \n",
      "  inflating: annotations/maksssksksss337.xml  \n",
      "  inflating: annotations/maksssksksss338.xml  \n",
      "  inflating: annotations/maksssksksss339.xml  \n",
      "  inflating: annotations/maksssksksss34.xml  \n",
      "  inflating: annotations/maksssksksss340.xml  \n",
      "  inflating: annotations/maksssksksss341.xml  \n",
      "  inflating: annotations/maksssksksss342.xml  \n",
      "  inflating: annotations/maksssksksss343.xml  \n",
      "  inflating: annotations/maksssksksss344.xml  \n",
      "  inflating: annotations/maksssksksss345.xml  \n",
      "  inflating: annotations/maksssksksss346.xml  \n",
      "  inflating: annotations/maksssksksss347.xml  \n",
      "  inflating: annotations/maksssksksss348.xml  \n",
      "  inflating: annotations/maksssksksss349.xml  \n",
      "  inflating: annotations/maksssksksss35.xml  \n",
      "  inflating: annotations/maksssksksss350.xml  \n",
      "  inflating: annotations/maksssksksss351.xml  \n",
      "  inflating: annotations/maksssksksss352.xml  \n",
      "  inflating: annotations/maksssksksss353.xml  \n",
      "  inflating: annotations/maksssksksss354.xml  \n",
      "  inflating: annotations/maksssksksss355.xml  \n",
      "  inflating: annotations/maksssksksss356.xml  \n",
      "  inflating: annotations/maksssksksss357.xml  \n",
      "  inflating: annotations/maksssksksss358.xml  \n",
      "  inflating: annotations/maksssksksss359.xml  \n",
      "  inflating: annotations/maksssksksss36.xml  \n",
      "  inflating: annotations/maksssksksss360.xml  \n",
      "  inflating: annotations/maksssksksss361.xml  \n",
      "  inflating: annotations/maksssksksss362.xml  \n",
      "  inflating: annotations/maksssksksss363.xml  \n",
      "  inflating: annotations/maksssksksss364.xml  \n",
      "  inflating: annotations/maksssksksss365.xml  \n",
      "  inflating: annotations/maksssksksss366.xml  \n",
      "  inflating: annotations/maksssksksss367.xml  \n",
      "  inflating: annotations/maksssksksss368.xml  \n",
      "  inflating: annotations/maksssksksss369.xml  \n",
      "  inflating: annotations/maksssksksss37.xml  \n",
      "  inflating: annotations/maksssksksss370.xml  \n",
      "  inflating: annotations/maksssksksss371.xml  \n",
      "  inflating: annotations/maksssksksss372.xml  \n",
      "  inflating: annotations/maksssksksss373.xml  \n",
      "  inflating: annotations/maksssksksss374.xml  \n",
      "  inflating: annotations/maksssksksss375.xml  \n",
      "  inflating: annotations/maksssksksss376.xml  \n",
      "  inflating: annotations/maksssksksss377.xml  \n",
      "  inflating: annotations/maksssksksss378.xml  \n",
      "  inflating: annotations/maksssksksss379.xml  \n",
      "  inflating: annotations/maksssksksss38.xml  \n",
      "  inflating: annotations/maksssksksss380.xml  \n",
      "  inflating: annotations/maksssksksss381.xml  \n",
      "  inflating: annotations/maksssksksss382.xml  \n",
      "  inflating: annotations/maksssksksss383.xml  \n",
      "  inflating: annotations/maksssksksss384.xml  \n",
      "  inflating: annotations/maksssksksss385.xml  \n",
      "  inflating: annotations/maksssksksss386.xml  \n",
      "  inflating: annotations/maksssksksss387.xml  \n",
      "  inflating: annotations/maksssksksss388.xml  \n",
      "  inflating: annotations/maksssksksss389.xml  \n",
      "  inflating: annotations/maksssksksss39.xml  \n",
      "  inflating: annotations/maksssksksss390.xml  \n",
      "  inflating: annotations/maksssksksss391.xml  \n",
      "  inflating: annotations/maksssksksss392.xml  \n",
      "  inflating: annotations/maksssksksss393.xml  \n",
      "  inflating: annotations/maksssksksss394.xml  \n",
      "  inflating: annotations/maksssksksss395.xml  \n",
      "  inflating: annotations/maksssksksss396.xml  \n",
      "  inflating: annotations/maksssksksss397.xml  \n",
      "  inflating: annotations/maksssksksss398.xml  \n",
      "  inflating: annotations/maksssksksss399.xml  \n",
      "  inflating: annotations/maksssksksss4.xml  \n",
      "  inflating: annotations/maksssksksss40.xml  \n",
      "  inflating: annotations/maksssksksss400.xml  \n",
      "  inflating: annotations/maksssksksss401.xml  \n",
      "  inflating: annotations/maksssksksss402.xml  \n",
      "  inflating: annotations/maksssksksss403.xml  \n",
      "  inflating: annotations/maksssksksss404.xml  \n",
      "  inflating: annotations/maksssksksss405.xml  \n",
      "  inflating: annotations/maksssksksss406.xml  \n",
      "  inflating: annotations/maksssksksss407.xml  \n",
      "  inflating: annotations/maksssksksss408.xml  \n",
      "  inflating: annotations/maksssksksss409.xml  \n",
      "  inflating: annotations/maksssksksss41.xml  \n",
      "  inflating: annotations/maksssksksss410.xml  \n",
      "  inflating: annotations/maksssksksss411.xml  \n",
      "  inflating: annotations/maksssksksss412.xml  \n",
      "  inflating: annotations/maksssksksss413.xml  \n",
      "  inflating: annotations/maksssksksss414.xml  \n",
      "  inflating: annotations/maksssksksss415.xml  \n",
      "  inflating: annotations/maksssksksss416.xml  \n",
      "  inflating: annotations/maksssksksss417.xml  \n",
      "  inflating: annotations/maksssksksss418.xml  \n",
      "  inflating: annotations/maksssksksss419.xml  \n",
      "  inflating: annotations/maksssksksss42.xml  \n",
      "  inflating: annotations/maksssksksss420.xml  \n",
      "  inflating: annotations/maksssksksss421.xml  \n",
      "  inflating: annotations/maksssksksss422.xml  \n",
      "  inflating: annotations/maksssksksss423.xml  \n",
      "  inflating: annotations/maksssksksss424.xml  \n",
      "  inflating: annotations/maksssksksss425.xml  \n",
      "  inflating: annotations/maksssksksss426.xml  \n",
      "  inflating: annotations/maksssksksss427.xml  \n",
      "  inflating: annotations/maksssksksss428.xml  \n",
      "  inflating: annotations/maksssksksss429.xml  \n",
      "  inflating: annotations/maksssksksss43.xml  \n",
      "  inflating: annotations/maksssksksss430.xml  \n",
      "  inflating: annotations/maksssksksss431.xml  \n",
      "  inflating: annotations/maksssksksss432.xml  \n",
      "  inflating: annotations/maksssksksss433.xml  \n",
      "  inflating: annotations/maksssksksss434.xml  \n",
      "  inflating: annotations/maksssksksss435.xml  \n",
      "  inflating: annotations/maksssksksss436.xml  \n",
      "  inflating: annotations/maksssksksss437.xml  \n",
      "  inflating: annotations/maksssksksss438.xml  \n",
      "  inflating: annotations/maksssksksss439.xml  \n",
      "  inflating: annotations/maksssksksss44.xml  \n",
      "  inflating: annotations/maksssksksss440.xml  \n",
      "  inflating: annotations/maksssksksss441.xml  \n",
      "  inflating: annotations/maksssksksss442.xml  \n",
      "  inflating: annotations/maksssksksss443.xml  \n",
      "  inflating: annotations/maksssksksss444.xml  \n",
      "  inflating: annotations/maksssksksss445.xml  \n",
      "  inflating: annotations/maksssksksss446.xml  \n",
      "  inflating: annotations/maksssksksss447.xml  \n",
      "  inflating: annotations/maksssksksss448.xml  \n",
      "  inflating: annotations/maksssksksss449.xml  \n",
      "  inflating: annotations/maksssksksss45.xml  \n",
      "  inflating: annotations/maksssksksss450.xml  \n",
      "  inflating: annotations/maksssksksss451.xml  \n",
      "  inflating: annotations/maksssksksss452.xml  \n",
      "  inflating: annotations/maksssksksss453.xml  \n",
      "  inflating: annotations/maksssksksss454.xml  \n",
      "  inflating: annotations/maksssksksss455.xml  \n",
      "  inflating: annotations/maksssksksss456.xml  \n",
      "  inflating: annotations/maksssksksss457.xml  \n",
      "  inflating: annotations/maksssksksss458.xml  \n",
      "  inflating: annotations/maksssksksss459.xml  \n",
      "  inflating: annotations/maksssksksss46.xml  \n",
      "  inflating: annotations/maksssksksss460.xml  \n",
      "  inflating: annotations/maksssksksss461.xml  \n",
      "  inflating: annotations/maksssksksss462.xml  \n",
      "  inflating: annotations/maksssksksss463.xml  \n",
      "  inflating: annotations/maksssksksss464.xml  \n",
      "  inflating: annotations/maksssksksss465.xml  \n",
      "  inflating: annotations/maksssksksss466.xml  \n",
      "  inflating: annotations/maksssksksss467.xml  \n",
      "  inflating: annotations/maksssksksss468.xml  \n",
      "  inflating: annotations/maksssksksss469.xml  \n",
      "  inflating: annotations/maksssksksss47.xml  \n",
      "  inflating: annotations/maksssksksss470.xml  \n",
      "  inflating: annotations/maksssksksss471.xml  \n",
      "  inflating: annotations/maksssksksss472.xml  \n",
      "  inflating: annotations/maksssksksss473.xml  \n",
      "  inflating: annotations/maksssksksss474.xml  \n",
      "  inflating: annotations/maksssksksss475.xml  \n",
      "  inflating: annotations/maksssksksss476.xml  \n",
      "  inflating: annotations/maksssksksss477.xml  \n",
      "  inflating: annotations/maksssksksss478.xml  \n",
      "  inflating: annotations/maksssksksss479.xml  \n",
      "  inflating: annotations/maksssksksss48.xml  \n",
      "  inflating: annotations/maksssksksss480.xml  \n",
      "  inflating: annotations/maksssksksss481.xml  \n",
      "  inflating: annotations/maksssksksss482.xml  \n",
      "  inflating: annotations/maksssksksss483.xml  \n",
      "  inflating: annotations/maksssksksss484.xml  \n",
      "  inflating: annotations/maksssksksss485.xml  \n",
      "  inflating: annotations/maksssksksss486.xml  \n",
      "  inflating: annotations/maksssksksss487.xml  \n",
      "  inflating: annotations/maksssksksss488.xml  \n",
      "  inflating: annotations/maksssksksss489.xml  \n",
      "  inflating: annotations/maksssksksss49.xml  \n",
      "  inflating: annotations/maksssksksss490.xml  \n",
      "  inflating: annotations/maksssksksss491.xml  \n",
      "  inflating: annotations/maksssksksss492.xml  \n",
      "  inflating: annotations/maksssksksss493.xml  \n",
      "  inflating: annotations/maksssksksss494.xml  \n",
      "  inflating: annotations/maksssksksss495.xml  \n",
      "  inflating: annotations/maksssksksss496.xml  \n",
      "  inflating: annotations/maksssksksss497.xml  \n",
      "  inflating: annotations/maksssksksss498.xml  \n",
      "  inflating: annotations/maksssksksss499.xml  \n",
      "  inflating: annotations/maksssksksss5.xml  \n",
      "  inflating: annotations/maksssksksss50.xml  \n",
      "  inflating: annotations/maksssksksss500.xml  \n",
      "  inflating: annotations/maksssksksss501.xml  \n",
      "  inflating: annotations/maksssksksss502.xml  \n",
      "  inflating: annotations/maksssksksss503.xml  \n",
      "  inflating: annotations/maksssksksss504.xml  \n",
      "  inflating: annotations/maksssksksss505.xml  \n",
      "  inflating: annotations/maksssksksss506.xml  \n",
      "  inflating: annotations/maksssksksss507.xml  \n",
      "  inflating: annotations/maksssksksss508.xml  \n",
      "  inflating: annotations/maksssksksss509.xml  \n",
      "  inflating: annotations/maksssksksss51.xml  \n",
      "  inflating: annotations/maksssksksss510.xml  \n",
      "  inflating: annotations/maksssksksss511.xml  \n",
      "  inflating: annotations/maksssksksss512.xml  \n",
      "  inflating: annotations/maksssksksss513.xml  \n",
      "  inflating: annotations/maksssksksss514.xml  \n",
      "  inflating: annotations/maksssksksss515.xml  \n",
      "  inflating: annotations/maksssksksss516.xml  \n",
      "  inflating: annotations/maksssksksss517.xml  \n",
      "  inflating: annotations/maksssksksss518.xml  \n",
      "  inflating: annotations/maksssksksss519.xml  \n",
      "  inflating: annotations/maksssksksss52.xml  \n",
      "  inflating: annotations/maksssksksss520.xml  \n",
      "  inflating: annotations/maksssksksss521.xml  \n",
      "  inflating: annotations/maksssksksss522.xml  \n",
      "  inflating: annotations/maksssksksss523.xml  \n",
      "  inflating: annotations/maksssksksss524.xml  \n",
      "  inflating: annotations/maksssksksss525.xml  \n",
      "  inflating: annotations/maksssksksss526.xml  \n",
      "  inflating: annotations/maksssksksss527.xml  \n",
      "  inflating: annotations/maksssksksss528.xml  \n",
      "  inflating: annotations/maksssksksss529.xml  \n",
      "  inflating: annotations/maksssksksss53.xml  \n",
      "  inflating: annotations/maksssksksss530.xml  \n",
      "  inflating: annotations/maksssksksss531.xml  \n",
      "  inflating: annotations/maksssksksss532.xml  \n",
      "  inflating: annotations/maksssksksss533.xml  \n",
      "  inflating: annotations/maksssksksss534.xml  \n",
      "  inflating: annotations/maksssksksss535.xml  \n",
      "  inflating: annotations/maksssksksss536.xml  \n",
      "  inflating: annotations/maksssksksss537.xml  \n",
      "  inflating: annotations/maksssksksss538.xml  \n",
      "  inflating: annotations/maksssksksss539.xml  \n",
      "  inflating: annotations/maksssksksss54.xml  \n",
      "  inflating: annotations/maksssksksss540.xml  \n",
      "  inflating: annotations/maksssksksss541.xml  \n",
      "  inflating: annotations/maksssksksss542.xml  \n",
      "  inflating: annotations/maksssksksss543.xml  \n",
      "  inflating: annotations/maksssksksss544.xml  \n",
      "  inflating: annotations/maksssksksss545.xml  \n",
      "  inflating: annotations/maksssksksss546.xml  \n",
      "  inflating: annotations/maksssksksss547.xml  \n",
      "  inflating: annotations/maksssksksss548.xml  \n",
      "  inflating: annotations/maksssksksss549.xml  \n",
      "  inflating: annotations/maksssksksss55.xml  \n",
      "  inflating: annotations/maksssksksss550.xml  \n",
      "  inflating: annotations/maksssksksss551.xml  \n",
      "  inflating: annotations/maksssksksss552.xml  \n",
      "  inflating: annotations/maksssksksss553.xml  \n",
      "  inflating: annotations/maksssksksss554.xml  \n",
      "  inflating: annotations/maksssksksss555.xml  \n",
      "  inflating: annotations/maksssksksss556.xml  \n",
      "  inflating: annotations/maksssksksss557.xml  \n",
      "  inflating: annotations/maksssksksss558.xml  \n",
      "  inflating: annotations/maksssksksss559.xml  \n",
      "  inflating: annotations/maksssksksss56.xml  \n",
      "  inflating: annotations/maksssksksss560.xml  \n",
      "  inflating: annotations/maksssksksss561.xml  \n",
      "  inflating: annotations/maksssksksss562.xml  \n",
      "  inflating: annotations/maksssksksss563.xml  \n",
      "  inflating: annotations/maksssksksss564.xml  \n",
      "  inflating: annotations/maksssksksss565.xml  \n",
      "  inflating: annotations/maksssksksss566.xml  \n",
      "  inflating: annotations/maksssksksss567.xml  \n",
      "  inflating: annotations/maksssksksss568.xml  \n",
      "  inflating: annotations/maksssksksss569.xml  \n",
      "  inflating: annotations/maksssksksss57.xml  \n",
      "  inflating: annotations/maksssksksss570.xml  \n",
      "  inflating: annotations/maksssksksss571.xml  \n",
      "  inflating: annotations/maksssksksss572.xml  \n",
      "  inflating: annotations/maksssksksss573.xml  \n",
      "  inflating: annotations/maksssksksss574.xml  \n",
      "  inflating: annotations/maksssksksss575.xml  \n",
      "  inflating: annotations/maksssksksss576.xml  \n",
      "  inflating: annotations/maksssksksss577.xml  \n",
      "  inflating: annotations/maksssksksss578.xml  \n",
      "  inflating: annotations/maksssksksss579.xml  \n",
      "  inflating: annotations/maksssksksss58.xml  \n",
      "  inflating: annotations/maksssksksss580.xml  \n",
      "  inflating: annotations/maksssksksss581.xml  \n",
      "  inflating: annotations/maksssksksss582.xml  \n",
      "  inflating: annotations/maksssksksss583.xml  \n",
      "  inflating: annotations/maksssksksss584.xml  \n",
      "  inflating: annotations/maksssksksss585.xml  \n",
      "  inflating: annotations/maksssksksss586.xml  \n",
      "  inflating: annotations/maksssksksss587.xml  \n",
      "  inflating: annotations/maksssksksss588.xml  \n",
      "  inflating: annotations/maksssksksss589.xml  \n",
      "  inflating: annotations/maksssksksss59.xml  \n",
      "  inflating: annotations/maksssksksss590.xml  \n",
      "  inflating: annotations/maksssksksss591.xml  \n",
      "  inflating: annotations/maksssksksss592.xml  \n",
      "  inflating: annotations/maksssksksss593.xml  \n",
      "  inflating: annotations/maksssksksss594.xml  \n",
      "  inflating: annotations/maksssksksss595.xml  \n",
      "  inflating: annotations/maksssksksss596.xml  \n",
      "  inflating: annotations/maksssksksss597.xml  \n",
      "  inflating: annotations/maksssksksss598.xml  \n",
      "  inflating: annotations/maksssksksss599.xml  \n",
      "  inflating: annotations/maksssksksss6.xml  \n",
      "  inflating: annotations/maksssksksss60.xml  \n",
      "  inflating: annotations/maksssksksss600.xml  \n",
      "  inflating: annotations/maksssksksss601.xml  \n",
      "  inflating: annotations/maksssksksss602.xml  \n",
      "  inflating: annotations/maksssksksss603.xml  \n",
      "  inflating: annotations/maksssksksss604.xml  \n",
      "  inflating: annotations/maksssksksss605.xml  \n",
      "  inflating: annotations/maksssksksss606.xml  \n",
      "  inflating: annotations/maksssksksss607.xml  \n",
      "  inflating: annotations/maksssksksss608.xml  \n",
      "  inflating: annotations/maksssksksss609.xml  \n",
      "  inflating: annotations/maksssksksss61.xml  \n",
      "  inflating: annotations/maksssksksss610.xml  \n",
      "  inflating: annotations/maksssksksss611.xml  \n",
      "  inflating: annotations/maksssksksss612.xml  \n",
      "  inflating: annotations/maksssksksss613.xml  \n",
      "  inflating: annotations/maksssksksss614.xml  \n",
      "  inflating: annotations/maksssksksss615.xml  \n",
      "  inflating: annotations/maksssksksss616.xml  \n",
      "  inflating: annotations/maksssksksss617.xml  \n",
      "  inflating: annotations/maksssksksss618.xml  \n",
      "  inflating: annotations/maksssksksss619.xml  \n",
      "  inflating: annotations/maksssksksss62.xml  \n",
      "  inflating: annotations/maksssksksss620.xml  \n",
      "  inflating: annotations/maksssksksss621.xml  \n",
      "  inflating: annotations/maksssksksss622.xml  \n",
      "  inflating: annotations/maksssksksss623.xml  \n",
      "  inflating: annotations/maksssksksss624.xml  \n",
      "  inflating: annotations/maksssksksss625.xml  \n",
      "  inflating: annotations/maksssksksss626.xml  \n",
      "  inflating: annotations/maksssksksss627.xml  \n",
      "  inflating: annotations/maksssksksss628.xml  \n",
      "  inflating: annotations/maksssksksss629.xml  \n",
      "  inflating: annotations/maksssksksss63.xml  \n",
      "  inflating: annotations/maksssksksss630.xml  \n",
      "  inflating: annotations/maksssksksss631.xml  \n",
      "  inflating: annotations/maksssksksss632.xml  \n",
      "  inflating: annotations/maksssksksss633.xml  \n",
      "  inflating: annotations/maksssksksss634.xml  \n",
      "  inflating: annotations/maksssksksss635.xml  \n",
      "  inflating: annotations/maksssksksss636.xml  \n",
      "  inflating: annotations/maksssksksss637.xml  \n",
      "  inflating: annotations/maksssksksss638.xml  \n",
      "  inflating: annotations/maksssksksss639.xml  \n",
      "  inflating: annotations/maksssksksss64.xml  \n",
      "  inflating: annotations/maksssksksss640.xml  \n",
      "  inflating: annotations/maksssksksss641.xml  \n",
      "  inflating: annotations/maksssksksss642.xml  \n",
      "  inflating: annotations/maksssksksss643.xml  \n",
      "  inflating: annotations/maksssksksss644.xml  \n",
      "  inflating: annotations/maksssksksss645.xml  \n",
      "  inflating: annotations/maksssksksss646.xml  \n",
      "  inflating: annotations/maksssksksss647.xml  \n",
      "  inflating: annotations/maksssksksss648.xml  \n",
      "  inflating: annotations/maksssksksss649.xml  \n",
      "  inflating: annotations/maksssksksss65.xml  \n",
      "  inflating: annotations/maksssksksss650.xml  \n",
      "  inflating: annotations/maksssksksss651.xml  \n",
      "  inflating: annotations/maksssksksss652.xml  \n",
      "  inflating: annotations/maksssksksss653.xml  \n",
      "  inflating: annotations/maksssksksss654.xml  \n",
      "  inflating: annotations/maksssksksss655.xml  \n",
      "  inflating: annotations/maksssksksss656.xml  \n",
      "  inflating: annotations/maksssksksss657.xml  \n",
      "  inflating: annotations/maksssksksss658.xml  \n",
      "  inflating: annotations/maksssksksss659.xml  \n",
      "  inflating: annotations/maksssksksss66.xml  \n",
      "  inflating: annotations/maksssksksss660.xml  \n",
      "  inflating: annotations/maksssksksss661.xml  \n",
      "  inflating: annotations/maksssksksss662.xml  \n",
      "  inflating: annotations/maksssksksss663.xml  \n",
      "  inflating: annotations/maksssksksss664.xml  \n",
      "  inflating: annotations/maksssksksss665.xml  \n",
      "  inflating: annotations/maksssksksss666.xml  \n",
      "  inflating: annotations/maksssksksss667.xml  \n",
      "  inflating: annotations/maksssksksss668.xml  \n",
      "  inflating: annotations/maksssksksss669.xml  \n",
      "  inflating: annotations/maksssksksss67.xml  \n",
      "  inflating: annotations/maksssksksss670.xml  \n",
      "  inflating: annotations/maksssksksss671.xml  \n",
      "  inflating: annotations/maksssksksss672.xml  \n",
      "  inflating: annotations/maksssksksss673.xml  \n",
      "  inflating: annotations/maksssksksss674.xml  \n",
      "  inflating: annotations/maksssksksss675.xml  \n",
      "  inflating: annotations/maksssksksss676.xml  \n",
      "  inflating: annotations/maksssksksss677.xml  \n",
      "  inflating: annotations/maksssksksss678.xml  \n",
      "  inflating: annotations/maksssksksss679.xml  \n",
      "  inflating: annotations/maksssksksss68.xml  \n",
      "  inflating: annotations/maksssksksss680.xml  \n",
      "  inflating: annotations/maksssksksss681.xml  \n",
      "  inflating: annotations/maksssksksss682.xml  \n",
      "  inflating: annotations/maksssksksss683.xml  \n",
      "  inflating: annotations/maksssksksss684.xml  \n",
      "  inflating: annotations/maksssksksss685.xml  \n",
      "  inflating: annotations/maksssksksss686.xml  \n",
      "  inflating: annotations/maksssksksss687.xml  \n",
      "  inflating: annotations/maksssksksss688.xml  \n",
      "  inflating: annotations/maksssksksss689.xml  \n",
      "  inflating: annotations/maksssksksss69.xml  \n",
      "  inflating: annotations/maksssksksss690.xml  \n",
      "  inflating: annotations/maksssksksss691.xml  \n",
      "  inflating: annotations/maksssksksss692.xml  \n",
      "  inflating: annotations/maksssksksss693.xml  \n",
      "  inflating: annotations/maksssksksss694.xml  \n",
      "  inflating: annotations/maksssksksss695.xml  \n",
      "  inflating: annotations/maksssksksss696.xml  \n",
      "  inflating: annotations/maksssksksss697.xml  \n",
      "  inflating: annotations/maksssksksss698.xml  \n",
      "  inflating: annotations/maksssksksss699.xml  \n",
      "  inflating: annotations/maksssksksss7.xml  \n",
      "  inflating: annotations/maksssksksss70.xml  \n",
      "  inflating: annotations/maksssksksss700.xml  \n",
      "  inflating: annotations/maksssksksss701.xml  \n",
      "  inflating: annotations/maksssksksss702.xml  \n",
      "  inflating: annotations/maksssksksss703.xml  \n",
      "  inflating: annotations/maksssksksss704.xml  \n",
      "  inflating: annotations/maksssksksss705.xml  \n",
      "  inflating: annotations/maksssksksss706.xml  \n",
      "  inflating: annotations/maksssksksss707.xml  \n",
      "  inflating: annotations/maksssksksss708.xml  \n",
      "  inflating: annotations/maksssksksss709.xml  \n",
      "  inflating: annotations/maksssksksss71.xml  \n",
      "  inflating: annotations/maksssksksss710.xml  \n",
      "  inflating: annotations/maksssksksss711.xml  \n",
      "  inflating: annotations/maksssksksss712.xml  \n",
      "  inflating: annotations/maksssksksss713.xml  \n",
      "  inflating: annotations/maksssksksss714.xml  \n",
      "  inflating: annotations/maksssksksss715.xml  \n",
      "  inflating: annotations/maksssksksss716.xml  \n",
      "  inflating: annotations/maksssksksss717.xml  \n",
      "  inflating: annotations/maksssksksss718.xml  \n",
      "  inflating: annotations/maksssksksss719.xml  \n",
      "  inflating: annotations/maksssksksss72.xml  \n",
      "  inflating: annotations/maksssksksss720.xml  \n",
      "  inflating: annotations/maksssksksss721.xml  \n",
      "  inflating: annotations/maksssksksss722.xml  \n",
      "  inflating: annotations/maksssksksss723.xml  \n",
      "  inflating: annotations/maksssksksss724.xml  \n",
      "  inflating: annotations/maksssksksss725.xml  \n",
      "  inflating: annotations/maksssksksss726.xml  \n",
      "  inflating: annotations/maksssksksss727.xml  \n",
      "  inflating: annotations/maksssksksss728.xml  \n",
      "  inflating: annotations/maksssksksss729.xml  \n",
      "  inflating: annotations/maksssksksss73.xml  \n",
      "  inflating: annotations/maksssksksss730.xml  \n",
      "  inflating: annotations/maksssksksss731.xml  \n",
      "  inflating: annotations/maksssksksss732.xml  \n",
      "  inflating: annotations/maksssksksss733.xml  \n",
      "  inflating: annotations/maksssksksss734.xml  \n",
      "  inflating: annotations/maksssksksss735.xml  \n",
      "  inflating: annotations/maksssksksss736.xml  \n",
      "  inflating: annotations/maksssksksss737.xml  \n",
      "  inflating: annotations/maksssksksss738.xml  \n",
      "  inflating: annotations/maksssksksss739.xml  \n",
      "  inflating: annotations/maksssksksss74.xml  \n",
      "  inflating: annotations/maksssksksss740.xml  \n",
      "  inflating: annotations/maksssksksss741.xml  \n",
      "  inflating: annotations/maksssksksss742.xml  \n",
      "  inflating: annotations/maksssksksss743.xml  \n",
      "  inflating: annotations/maksssksksss744.xml  \n",
      "  inflating: annotations/maksssksksss745.xml  \n",
      "  inflating: annotations/maksssksksss746.xml  \n",
      "  inflating: annotations/maksssksksss747.xml  \n",
      "  inflating: annotations/maksssksksss748.xml  \n",
      "  inflating: annotations/maksssksksss749.xml  \n",
      "  inflating: annotations/maksssksksss75.xml  \n",
      "  inflating: annotations/maksssksksss750.xml  \n",
      "  inflating: annotations/maksssksksss751.xml  \n",
      "  inflating: annotations/maksssksksss752.xml  \n",
      "  inflating: annotations/maksssksksss753.xml  \n",
      "  inflating: annotations/maksssksksss754.xml  \n",
      "  inflating: annotations/maksssksksss755.xml  \n",
      "  inflating: annotations/maksssksksss756.xml  \n",
      "  inflating: annotations/maksssksksss757.xml  \n",
      "  inflating: annotations/maksssksksss758.xml  \n",
      "  inflating: annotations/maksssksksss759.xml  \n",
      "  inflating: annotations/maksssksksss76.xml  \n",
      "  inflating: annotations/maksssksksss760.xml  \n",
      "  inflating: annotations/maksssksksss761.xml  \n",
      "  inflating: annotations/maksssksksss762.xml  \n",
      "  inflating: annotations/maksssksksss763.xml  \n",
      "  inflating: annotations/maksssksksss764.xml  \n",
      "  inflating: annotations/maksssksksss765.xml  \n",
      "  inflating: annotations/maksssksksss766.xml  \n",
      "  inflating: annotations/maksssksksss767.xml  \n",
      "  inflating: annotations/maksssksksss768.xml  \n",
      "  inflating: annotations/maksssksksss769.xml  \n",
      "  inflating: annotations/maksssksksss77.xml  \n",
      "  inflating: annotations/maksssksksss770.xml  \n",
      "  inflating: annotations/maksssksksss771.xml  \n",
      "  inflating: annotations/maksssksksss772.xml  \n",
      "  inflating: annotations/maksssksksss773.xml  \n",
      "  inflating: annotations/maksssksksss774.xml  \n",
      "  inflating: annotations/maksssksksss775.xml  \n",
      "  inflating: annotations/maksssksksss776.xml  \n",
      "  inflating: annotations/maksssksksss777.xml  \n",
      "  inflating: annotations/maksssksksss778.xml  \n",
      "  inflating: annotations/maksssksksss779.xml  \n",
      "  inflating: annotations/maksssksksss78.xml  \n",
      "  inflating: annotations/maksssksksss780.xml  \n",
      "  inflating: annotations/maksssksksss781.xml  \n",
      "  inflating: annotations/maksssksksss782.xml  \n",
      "  inflating: annotations/maksssksksss783.xml  \n",
      "  inflating: annotations/maksssksksss784.xml  \n",
      "  inflating: annotations/maksssksksss785.xml  \n",
      "  inflating: annotations/maksssksksss786.xml  \n",
      "  inflating: annotations/maksssksksss787.xml  \n",
      "  inflating: annotations/maksssksksss788.xml  \n",
      "  inflating: annotations/maksssksksss789.xml  \n",
      "  inflating: annotations/maksssksksss79.xml  \n",
      "  inflating: annotations/maksssksksss790.xml  \n",
      "  inflating: annotations/maksssksksss791.xml  \n",
      "  inflating: annotations/maksssksksss792.xml  \n",
      "  inflating: annotations/maksssksksss793.xml  \n",
      "  inflating: annotations/maksssksksss794.xml  \n",
      "  inflating: annotations/maksssksksss795.xml  \n",
      "  inflating: annotations/maksssksksss796.xml  \n",
      "  inflating: annotations/maksssksksss797.xml  \n",
      "  inflating: annotations/maksssksksss798.xml  \n",
      "  inflating: annotations/maksssksksss799.xml  \n",
      "  inflating: annotations/maksssksksss8.xml  \n",
      "  inflating: annotations/maksssksksss80.xml  \n",
      "  inflating: annotations/maksssksksss800.xml  \n",
      "  inflating: annotations/maksssksksss801.xml  \n",
      "  inflating: annotations/maksssksksss802.xml  \n",
      "  inflating: annotations/maksssksksss803.xml  \n",
      "  inflating: annotations/maksssksksss804.xml  \n",
      "  inflating: annotations/maksssksksss805.xml  \n",
      "  inflating: annotations/maksssksksss806.xml  \n",
      "  inflating: annotations/maksssksksss807.xml  \n",
      "  inflating: annotations/maksssksksss808.xml  \n",
      "  inflating: annotations/maksssksksss809.xml  \n",
      "  inflating: annotations/maksssksksss81.xml  \n",
      "  inflating: annotations/maksssksksss810.xml  \n",
      "  inflating: annotations/maksssksksss811.xml  \n",
      "  inflating: annotations/maksssksksss812.xml  \n",
      "  inflating: annotations/maksssksksss813.xml  \n",
      "  inflating: annotations/maksssksksss814.xml  \n",
      "  inflating: annotations/maksssksksss815.xml  \n",
      "  inflating: annotations/maksssksksss816.xml  \n",
      "  inflating: annotations/maksssksksss817.xml  \n",
      "  inflating: annotations/maksssksksss818.xml  \n",
      "  inflating: annotations/maksssksksss819.xml  \n",
      "  inflating: annotations/maksssksksss82.xml  \n",
      "  inflating: annotations/maksssksksss820.xml  \n",
      "  inflating: annotations/maksssksksss821.xml  \n",
      "  inflating: annotations/maksssksksss822.xml  \n",
      "  inflating: annotations/maksssksksss823.xml  \n",
      "  inflating: annotations/maksssksksss824.xml  \n",
      "  inflating: annotations/maksssksksss825.xml  \n",
      "  inflating: annotations/maksssksksss826.xml  \n",
      "  inflating: annotations/maksssksksss827.xml  \n",
      "  inflating: annotations/maksssksksss828.xml  \n",
      "  inflating: annotations/maksssksksss829.xml  \n",
      "  inflating: annotations/maksssksksss83.xml  \n",
      "  inflating: annotations/maksssksksss830.xml  \n",
      "  inflating: annotations/maksssksksss831.xml  \n",
      "  inflating: annotations/maksssksksss832.xml  \n",
      "  inflating: annotations/maksssksksss833.xml  \n",
      "  inflating: annotations/maksssksksss834.xml  \n",
      "  inflating: annotations/maksssksksss835.xml  \n",
      "  inflating: annotations/maksssksksss836.xml  \n",
      "  inflating: annotations/maksssksksss837.xml  \n",
      "  inflating: annotations/maksssksksss838.xml  \n",
      "  inflating: annotations/maksssksksss839.xml  \n",
      "  inflating: annotations/maksssksksss84.xml  \n",
      "  inflating: annotations/maksssksksss840.xml  \n",
      "  inflating: annotations/maksssksksss841.xml  \n",
      "  inflating: annotations/maksssksksss842.xml  \n",
      "  inflating: annotations/maksssksksss843.xml  \n",
      "  inflating: annotations/maksssksksss844.xml  \n",
      "  inflating: annotations/maksssksksss845.xml  \n",
      "  inflating: annotations/maksssksksss846.xml  \n",
      "  inflating: annotations/maksssksksss847.xml  \n",
      "  inflating: annotations/maksssksksss848.xml  \n",
      "  inflating: annotations/maksssksksss849.xml  \n",
      "  inflating: annotations/maksssksksss85.xml  \n",
      "  inflating: annotations/maksssksksss850.xml  \n",
      "  inflating: annotations/maksssksksss851.xml  \n",
      "  inflating: annotations/maksssksksss852.xml  \n",
      "  inflating: annotations/maksssksksss86.xml  \n",
      "  inflating: annotations/maksssksksss87.xml  \n",
      "  inflating: annotations/maksssksksss88.xml  \n",
      "  inflating: annotations/maksssksksss89.xml  \n",
      "  inflating: annotations/maksssksksss9.xml  \n",
      "  inflating: annotations/maksssksksss90.xml  \n",
      "  inflating: annotations/maksssksksss91.xml  \n",
      "  inflating: annotations/maksssksksss92.xml  \n",
      "  inflating: annotations/maksssksksss93.xml  \n",
      "  inflating: annotations/maksssksksss94.xml  \n",
      "  inflating: annotations/maksssksksss95.xml  \n",
      "  inflating: annotations/maksssksksss96.xml  \n",
      "  inflating: annotations/maksssksksss97.xml  \n",
      "  inflating: annotations/maksssksksss98.xml  \n",
      "  inflating: annotations/maksssksksss99.xml  \n",
      "  inflating: images/maksssksksss0.png  \n",
      "  inflating: images/maksssksksss1.png  \n",
      "  inflating: images/maksssksksss10.png  \n",
      "  inflating: images/maksssksksss100.png  \n",
      "  inflating: images/maksssksksss101.png  \n",
      "  inflating: images/maksssksksss102.png  \n",
      "  inflating: images/maksssksksss103.png  \n",
      "  inflating: images/maksssksksss104.png  \n",
      "  inflating: images/maksssksksss105.png  \n",
      "  inflating: images/maksssksksss106.png  \n",
      "  inflating: images/maksssksksss107.png  \n",
      "  inflating: images/maksssksksss108.png  \n",
      "  inflating: images/maksssksksss109.png  \n",
      "  inflating: images/maksssksksss11.png  \n",
      "  inflating: images/maksssksksss110.png  \n",
      "  inflating: images/maksssksksss111.png  \n",
      "  inflating: images/maksssksksss112.png  \n",
      "  inflating: images/maksssksksss113.png  \n",
      "  inflating: images/maksssksksss114.png  \n",
      "  inflating: images/maksssksksss115.png  \n",
      "  inflating: images/maksssksksss116.png  \n",
      "  inflating: images/maksssksksss117.png  \n",
      "  inflating: images/maksssksksss118.png  \n",
      "  inflating: images/maksssksksss119.png  \n",
      "  inflating: images/maksssksksss12.png  \n",
      "  inflating: images/maksssksksss120.png  \n",
      "  inflating: images/maksssksksss121.png  \n",
      "  inflating: images/maksssksksss122.png  \n",
      "  inflating: images/maksssksksss123.png  \n",
      "  inflating: images/maksssksksss124.png  \n",
      "  inflating: images/maksssksksss125.png  \n",
      "  inflating: images/maksssksksss126.png  \n",
      "  inflating: images/maksssksksss127.png  \n",
      "  inflating: images/maksssksksss128.png  \n",
      "  inflating: images/maksssksksss129.png  \n",
      "  inflating: images/maksssksksss13.png  \n",
      "  inflating: images/maksssksksss130.png  \n",
      "  inflating: images/maksssksksss131.png  \n",
      "  inflating: images/maksssksksss132.png  \n",
      "  inflating: images/maksssksksss133.png  \n",
      "  inflating: images/maksssksksss134.png  \n",
      "  inflating: images/maksssksksss135.png  \n",
      "  inflating: images/maksssksksss136.png  \n",
      "  inflating: images/maksssksksss137.png  \n",
      "  inflating: images/maksssksksss138.png  \n",
      "  inflating: images/maksssksksss139.png  \n",
      "  inflating: images/maksssksksss14.png  \n",
      "  inflating: images/maksssksksss140.png  \n",
      "  inflating: images/maksssksksss141.png  \n",
      "  inflating: images/maksssksksss142.png  \n",
      "  inflating: images/maksssksksss143.png  \n",
      "  inflating: images/maksssksksss144.png  \n",
      "  inflating: images/maksssksksss145.png  \n",
      "  inflating: images/maksssksksss146.png  \n",
      "  inflating: images/maksssksksss147.png  \n",
      "  inflating: images/maksssksksss148.png  \n",
      "  inflating: images/maksssksksss149.png  \n",
      "  inflating: images/maksssksksss15.png  \n",
      "  inflating: images/maksssksksss150.png  \n",
      "  inflating: images/maksssksksss151.png  \n",
      "  inflating: images/maksssksksss152.png  \n",
      "  inflating: images/maksssksksss153.png  \n",
      "  inflating: images/maksssksksss154.png  \n",
      "  inflating: images/maksssksksss155.png  \n",
      "  inflating: images/maksssksksss156.png  \n",
      "  inflating: images/maksssksksss157.png  \n",
      "  inflating: images/maksssksksss158.png  \n",
      "  inflating: images/maksssksksss159.png  \n",
      "  inflating: images/maksssksksss16.png  \n",
      "  inflating: images/maksssksksss160.png  \n",
      "  inflating: images/maksssksksss161.png  \n",
      "  inflating: images/maksssksksss162.png  \n",
      "  inflating: images/maksssksksss163.png  \n",
      "  inflating: images/maksssksksss164.png  \n",
      "  inflating: images/maksssksksss165.png  \n",
      "  inflating: images/maksssksksss166.png  \n",
      "  inflating: images/maksssksksss167.png  \n",
      "  inflating: images/maksssksksss168.png  \n",
      "  inflating: images/maksssksksss169.png  \n",
      "  inflating: images/maksssksksss17.png  \n",
      "  inflating: images/maksssksksss170.png  \n",
      "  inflating: images/maksssksksss171.png  \n",
      "  inflating: images/maksssksksss172.png  \n",
      "  inflating: images/maksssksksss173.png  \n",
      "  inflating: images/maksssksksss174.png  \n",
      "  inflating: images/maksssksksss175.png  \n",
      "  inflating: images/maksssksksss176.png  \n",
      "  inflating: images/maksssksksss177.png  \n",
      "  inflating: images/maksssksksss178.png  \n",
      "  inflating: images/maksssksksss179.png  \n",
      "  inflating: images/maksssksksss18.png  \n",
      "  inflating: images/maksssksksss180.png  \n",
      "  inflating: images/maksssksksss181.png  \n",
      "  inflating: images/maksssksksss182.png  \n",
      "  inflating: images/maksssksksss183.png  \n",
      "  inflating: images/maksssksksss184.png  \n",
      "  inflating: images/maksssksksss185.png  \n",
      "  inflating: images/maksssksksss186.png  \n",
      "  inflating: images/maksssksksss187.png  \n",
      "  inflating: images/maksssksksss188.png  \n",
      "  inflating: images/maksssksksss189.png  \n",
      "  inflating: images/maksssksksss19.png  \n",
      "  inflating: images/maksssksksss190.png  \n",
      "  inflating: images/maksssksksss191.png  \n",
      "  inflating: images/maksssksksss192.png  \n",
      "  inflating: images/maksssksksss193.png  \n",
      "  inflating: images/maksssksksss194.png  \n",
      "  inflating: images/maksssksksss195.png  \n",
      "  inflating: images/maksssksksss196.png  \n",
      "  inflating: images/maksssksksss197.png  \n",
      "  inflating: images/maksssksksss198.png  \n",
      "  inflating: images/maksssksksss199.png  \n",
      "  inflating: images/maksssksksss2.png  \n",
      "  inflating: images/maksssksksss20.png  \n",
      "  inflating: images/maksssksksss200.png  \n",
      "  inflating: images/maksssksksss201.png  \n",
      "  inflating: images/maksssksksss202.png  \n",
      "  inflating: images/maksssksksss203.png  \n",
      "  inflating: images/maksssksksss204.png  \n",
      "  inflating: images/maksssksksss205.png  \n",
      "  inflating: images/maksssksksss206.png  \n",
      "  inflating: images/maksssksksss207.png  \n",
      "  inflating: images/maksssksksss208.png  \n",
      "  inflating: images/maksssksksss209.png  \n",
      "  inflating: images/maksssksksss21.png  \n",
      "  inflating: images/maksssksksss210.png  \n",
      "  inflating: images/maksssksksss211.png  \n",
      "  inflating: images/maksssksksss212.png  \n",
      "  inflating: images/maksssksksss213.png  \n",
      "  inflating: images/maksssksksss214.png  \n",
      "  inflating: images/maksssksksss215.png  \n",
      "  inflating: images/maksssksksss216.png  \n",
      "  inflating: images/maksssksksss217.png  \n",
      "  inflating: images/maksssksksss218.png  \n",
      "  inflating: images/maksssksksss219.png  \n",
      "  inflating: images/maksssksksss22.png  \n",
      "  inflating: images/maksssksksss220.png  \n",
      "  inflating: images/maksssksksss221.png  \n",
      "  inflating: images/maksssksksss222.png  \n",
      "  inflating: images/maksssksksss223.png  \n",
      "  inflating: images/maksssksksss224.png  \n",
      "  inflating: images/maksssksksss225.png  \n",
      "  inflating: images/maksssksksss226.png  \n",
      "  inflating: images/maksssksksss227.png  \n",
      "  inflating: images/maksssksksss228.png  \n",
      "  inflating: images/maksssksksss229.png  \n",
      "  inflating: images/maksssksksss23.png  \n",
      "  inflating: images/maksssksksss230.png  \n",
      "  inflating: images/maksssksksss231.png  \n",
      "  inflating: images/maksssksksss232.png  \n",
      "  inflating: images/maksssksksss233.png  \n",
      "  inflating: images/maksssksksss234.png  \n",
      "  inflating: images/maksssksksss235.png  \n",
      "  inflating: images/maksssksksss236.png  \n",
      "  inflating: images/maksssksksss237.png  \n",
      "  inflating: images/maksssksksss238.png  \n",
      "  inflating: images/maksssksksss239.png  \n",
      "  inflating: images/maksssksksss24.png  \n",
      "  inflating: images/maksssksksss240.png  \n",
      "  inflating: images/maksssksksss241.png  \n",
      "  inflating: images/maksssksksss242.png  \n",
      "  inflating: images/maksssksksss243.png  \n",
      "  inflating: images/maksssksksss244.png  \n",
      "  inflating: images/maksssksksss245.png  \n",
      "  inflating: images/maksssksksss246.png  \n",
      "  inflating: images/maksssksksss247.png  \n",
      "  inflating: images/maksssksksss248.png  \n",
      "  inflating: images/maksssksksss249.png  \n",
      "  inflating: images/maksssksksss25.png  \n",
      "  inflating: images/maksssksksss250.png  \n",
      "  inflating: images/maksssksksss251.png  \n",
      "  inflating: images/maksssksksss252.png  \n",
      "  inflating: images/maksssksksss253.png  \n",
      "  inflating: images/maksssksksss254.png  \n",
      "  inflating: images/maksssksksss255.png  \n",
      "  inflating: images/maksssksksss256.png  \n",
      "  inflating: images/maksssksksss257.png  \n",
      "  inflating: images/maksssksksss258.png  \n",
      "  inflating: images/maksssksksss259.png  \n",
      "  inflating: images/maksssksksss26.png  \n",
      "  inflating: images/maksssksksss260.png  \n",
      "  inflating: images/maksssksksss261.png  \n",
      "  inflating: images/maksssksksss262.png  \n",
      "  inflating: images/maksssksksss263.png  \n",
      "  inflating: images/maksssksksss264.png  \n",
      "  inflating: images/maksssksksss265.png  \n",
      "  inflating: images/maksssksksss266.png  \n",
      "  inflating: images/maksssksksss267.png  \n",
      "  inflating: images/maksssksksss268.png  \n",
      "  inflating: images/maksssksksss269.png  \n",
      "  inflating: images/maksssksksss27.png  \n",
      "  inflating: images/maksssksksss270.png  \n",
      "  inflating: images/maksssksksss271.png  \n",
      "  inflating: images/maksssksksss272.png  \n",
      "  inflating: images/maksssksksss273.png  \n",
      "  inflating: images/maksssksksss274.png  \n",
      "  inflating: images/maksssksksss275.png  \n",
      "  inflating: images/maksssksksss276.png  \n",
      "  inflating: images/maksssksksss277.png  \n",
      "  inflating: images/maksssksksss278.png  \n",
      "  inflating: images/maksssksksss279.png  \n",
      "  inflating: images/maksssksksss28.png  \n",
      "  inflating: images/maksssksksss280.png  \n",
      "  inflating: images/maksssksksss281.png  \n",
      "  inflating: images/maksssksksss282.png  \n",
      "  inflating: images/maksssksksss283.png  \n",
      "  inflating: images/maksssksksss284.png  \n",
      "  inflating: images/maksssksksss285.png  \n",
      "  inflating: images/maksssksksss286.png  \n",
      "  inflating: images/maksssksksss287.png  \n",
      "  inflating: images/maksssksksss288.png  \n",
      "  inflating: images/maksssksksss289.png  \n",
      "  inflating: images/maksssksksss29.png  \n",
      "  inflating: images/maksssksksss290.png  \n",
      "  inflating: images/maksssksksss291.png  \n",
      "  inflating: images/maksssksksss292.png  \n",
      "  inflating: images/maksssksksss293.png  \n",
      "  inflating: images/maksssksksss294.png  \n",
      "  inflating: images/maksssksksss295.png  \n",
      "  inflating: images/maksssksksss296.png  \n",
      "  inflating: images/maksssksksss297.png  \n",
      "  inflating: images/maksssksksss298.png  \n",
      "  inflating: images/maksssksksss299.png  \n",
      "  inflating: images/maksssksksss3.png  \n",
      "  inflating: images/maksssksksss30.png  \n",
      "  inflating: images/maksssksksss300.png  \n",
      "  inflating: images/maksssksksss301.png  \n",
      "  inflating: images/maksssksksss302.png  \n",
      "  inflating: images/maksssksksss303.png  \n",
      "  inflating: images/maksssksksss304.png  \n",
      "  inflating: images/maksssksksss305.png  \n",
      "  inflating: images/maksssksksss306.png  \n",
      "  inflating: images/maksssksksss307.png  \n",
      "  inflating: images/maksssksksss308.png  \n",
      "  inflating: images/maksssksksss309.png  \n",
      "  inflating: images/maksssksksss31.png  \n",
      "  inflating: images/maksssksksss310.png  \n",
      "  inflating: images/maksssksksss311.png  \n",
      "  inflating: images/maksssksksss312.png  \n",
      "  inflating: images/maksssksksss313.png  \n",
      "  inflating: images/maksssksksss314.png  \n",
      "  inflating: images/maksssksksss315.png  \n",
      "  inflating: images/maksssksksss316.png  \n",
      "  inflating: images/maksssksksss317.png  \n",
      "  inflating: images/maksssksksss318.png  \n",
      "  inflating: images/maksssksksss319.png  \n",
      "  inflating: images/maksssksksss32.png  \n",
      "  inflating: images/maksssksksss320.png  \n",
      "  inflating: images/maksssksksss321.png  \n",
      "  inflating: images/maksssksksss322.png  \n",
      "  inflating: images/maksssksksss323.png  \n",
      "  inflating: images/maksssksksss324.png  \n",
      "  inflating: images/maksssksksss325.png  \n",
      "  inflating: images/maksssksksss326.png  \n",
      "  inflating: images/maksssksksss327.png  \n",
      "  inflating: images/maksssksksss328.png  \n",
      "  inflating: images/maksssksksss329.png  \n",
      "  inflating: images/maksssksksss33.png  \n",
      "  inflating: images/maksssksksss330.png  \n",
      "  inflating: images/maksssksksss331.png  \n",
      "  inflating: images/maksssksksss332.png  \n",
      "  inflating: images/maksssksksss333.png  \n",
      "  inflating: images/maksssksksss334.png  \n",
      "  inflating: images/maksssksksss335.png  \n",
      "  inflating: images/maksssksksss336.png  \n",
      "  inflating: images/maksssksksss337.png  \n",
      "  inflating: images/maksssksksss338.png  \n",
      "  inflating: images/maksssksksss339.png  \n",
      "  inflating: images/maksssksksss34.png  \n",
      "  inflating: images/maksssksksss340.png  \n",
      "  inflating: images/maksssksksss341.png  \n",
      "  inflating: images/maksssksksss342.png  \n",
      "  inflating: images/maksssksksss343.png  \n",
      "  inflating: images/maksssksksss344.png  \n",
      "  inflating: images/maksssksksss345.png  \n",
      "  inflating: images/maksssksksss346.png  \n",
      "  inflating: images/maksssksksss347.png  \n",
      "  inflating: images/maksssksksss348.png  \n",
      "  inflating: images/maksssksksss349.png  \n",
      "  inflating: images/maksssksksss35.png  \n",
      "  inflating: images/maksssksksss350.png  \n",
      "  inflating: images/maksssksksss351.png  \n",
      "  inflating: images/maksssksksss352.png  \n",
      "  inflating: images/maksssksksss353.png  \n",
      "  inflating: images/maksssksksss354.png  \n",
      "  inflating: images/maksssksksss355.png  \n",
      "  inflating: images/maksssksksss356.png  \n",
      "  inflating: images/maksssksksss357.png  \n",
      "  inflating: images/maksssksksss358.png  \n",
      "  inflating: images/maksssksksss359.png  \n",
      "  inflating: images/maksssksksss36.png  \n",
      "  inflating: images/maksssksksss360.png  \n",
      "  inflating: images/maksssksksss361.png  \n",
      "  inflating: images/maksssksksss362.png  \n",
      "  inflating: images/maksssksksss363.png  \n",
      "  inflating: images/maksssksksss364.png  \n",
      "  inflating: images/maksssksksss365.png  \n",
      "  inflating: images/maksssksksss366.png  \n",
      "  inflating: images/maksssksksss367.png  \n",
      "  inflating: images/maksssksksss368.png  \n",
      "  inflating: images/maksssksksss369.png  \n",
      "  inflating: images/maksssksksss37.png  \n",
      "  inflating: images/maksssksksss370.png  \n",
      "  inflating: images/maksssksksss371.png  \n",
      "  inflating: images/maksssksksss372.png  \n",
      "  inflating: images/maksssksksss373.png  \n",
      "  inflating: images/maksssksksss374.png  \n",
      "  inflating: images/maksssksksss375.png  \n",
      "  inflating: images/maksssksksss376.png  \n",
      "  inflating: images/maksssksksss377.png  \n",
      "  inflating: images/maksssksksss378.png  \n",
      "  inflating: images/maksssksksss379.png  \n",
      "  inflating: images/maksssksksss38.png  \n",
      "  inflating: images/maksssksksss380.png  \n",
      "  inflating: images/maksssksksss381.png  \n",
      "  inflating: images/maksssksksss382.png  \n",
      "  inflating: images/maksssksksss383.png  \n",
      "  inflating: images/maksssksksss384.png  \n",
      "  inflating: images/maksssksksss385.png  \n",
      "  inflating: images/maksssksksss386.png  \n",
      "  inflating: images/maksssksksss387.png  \n",
      "  inflating: images/maksssksksss388.png  \n",
      "  inflating: images/maksssksksss389.png  \n",
      "  inflating: images/maksssksksss39.png  \n",
      "  inflating: images/maksssksksss390.png  \n",
      "  inflating: images/maksssksksss391.png  \n",
      "  inflating: images/maksssksksss392.png  \n",
      "  inflating: images/maksssksksss393.png  \n",
      "  inflating: images/maksssksksss394.png  \n",
      "  inflating: images/maksssksksss395.png  \n",
      "  inflating: images/maksssksksss396.png  \n",
      "  inflating: images/maksssksksss397.png  \n",
      "  inflating: images/maksssksksss398.png  \n",
      "  inflating: images/maksssksksss399.png  \n",
      "  inflating: images/maksssksksss4.png  \n",
      "  inflating: images/maksssksksss40.png  \n",
      "  inflating: images/maksssksksss400.png  \n",
      "  inflating: images/maksssksksss401.png  \n",
      "  inflating: images/maksssksksss402.png  \n",
      "  inflating: images/maksssksksss403.png  \n",
      "  inflating: images/maksssksksss404.png  \n",
      "  inflating: images/maksssksksss405.png  \n",
      "  inflating: images/maksssksksss406.png  \n",
      "  inflating: images/maksssksksss407.png  \n",
      "  inflating: images/maksssksksss408.png  \n",
      "  inflating: images/maksssksksss409.png  \n",
      "  inflating: images/maksssksksss41.png  \n",
      "  inflating: images/maksssksksss410.png  \n",
      "  inflating: images/maksssksksss411.png  \n",
      "  inflating: images/maksssksksss412.png  \n",
      "  inflating: images/maksssksksss413.png  \n",
      "  inflating: images/maksssksksss414.png  \n",
      "  inflating: images/maksssksksss415.png  \n",
      "  inflating: images/maksssksksss416.png  \n",
      "  inflating: images/maksssksksss417.png  \n",
      "  inflating: images/maksssksksss418.png  \n",
      "  inflating: images/maksssksksss419.png  \n",
      "  inflating: images/maksssksksss42.png  \n",
      "  inflating: images/maksssksksss420.png  \n",
      "  inflating: images/maksssksksss421.png  \n",
      "  inflating: images/maksssksksss422.png  \n",
      "  inflating: images/maksssksksss423.png  \n",
      "  inflating: images/maksssksksss424.png  \n",
      "  inflating: images/maksssksksss425.png  \n",
      "  inflating: images/maksssksksss426.png  \n",
      "  inflating: images/maksssksksss427.png  \n",
      "  inflating: images/maksssksksss428.png  \n",
      "  inflating: images/maksssksksss429.png  \n",
      "  inflating: images/maksssksksss43.png  \n",
      "  inflating: images/maksssksksss430.png  \n",
      "  inflating: images/maksssksksss431.png  \n",
      "  inflating: images/maksssksksss432.png  \n",
      "  inflating: images/maksssksksss433.png  \n",
      "  inflating: images/maksssksksss434.png  \n",
      "  inflating: images/maksssksksss435.png  \n",
      "  inflating: images/maksssksksss436.png  \n",
      "  inflating: images/maksssksksss437.png  \n",
      "  inflating: images/maksssksksss438.png  \n",
      "  inflating: images/maksssksksss439.png  \n",
      "  inflating: images/maksssksksss44.png  \n",
      "  inflating: images/maksssksksss440.png  \n",
      "  inflating: images/maksssksksss441.png  \n",
      "  inflating: images/maksssksksss442.png  \n",
      "  inflating: images/maksssksksss443.png  \n",
      "  inflating: images/maksssksksss444.png  \n",
      "  inflating: images/maksssksksss445.png  \n",
      "  inflating: images/maksssksksss446.png  \n",
      "  inflating: images/maksssksksss447.png  \n",
      "  inflating: images/maksssksksss448.png  \n",
      "  inflating: images/maksssksksss449.png  \n",
      "  inflating: images/maksssksksss45.png  \n",
      "  inflating: images/maksssksksss450.png  \n",
      "  inflating: images/maksssksksss451.png  \n",
      "  inflating: images/maksssksksss452.png  \n",
      "  inflating: images/maksssksksss453.png  \n",
      "  inflating: images/maksssksksss454.png  \n",
      "  inflating: images/maksssksksss455.png  \n",
      "  inflating: images/maksssksksss456.png  \n",
      "  inflating: images/maksssksksss457.png  \n",
      "  inflating: images/maksssksksss458.png  \n",
      "  inflating: images/maksssksksss459.png  \n",
      "  inflating: images/maksssksksss46.png  \n",
      "  inflating: images/maksssksksss460.png  \n",
      "  inflating: images/maksssksksss461.png  \n",
      "  inflating: images/maksssksksss462.png  \n",
      "  inflating: images/maksssksksss463.png  \n",
      "  inflating: images/maksssksksss464.png  \n",
      "  inflating: images/maksssksksss465.png  \n",
      "  inflating: images/maksssksksss466.png  \n",
      "  inflating: images/maksssksksss467.png  \n",
      "  inflating: images/maksssksksss468.png  \n",
      "  inflating: images/maksssksksss469.png  \n",
      "  inflating: images/maksssksksss47.png  \n",
      "  inflating: images/maksssksksss470.png  \n",
      "  inflating: images/maksssksksss471.png  \n",
      "  inflating: images/maksssksksss472.png  \n",
      "  inflating: images/maksssksksss473.png  \n",
      "  inflating: images/maksssksksss474.png  \n",
      "  inflating: images/maksssksksss475.png  \n",
      "  inflating: images/maksssksksss476.png  \n",
      "  inflating: images/maksssksksss477.png  \n",
      "  inflating: images/maksssksksss478.png  \n",
      "  inflating: images/maksssksksss479.png  \n",
      "  inflating: images/maksssksksss48.png  \n",
      "  inflating: images/maksssksksss480.png  \n",
      "  inflating: images/maksssksksss481.png  \n",
      "  inflating: images/maksssksksss482.png  \n",
      "  inflating: images/maksssksksss483.png  \n",
      "  inflating: images/maksssksksss484.png  \n",
      "  inflating: images/maksssksksss485.png  \n",
      "  inflating: images/maksssksksss486.png  \n",
      "  inflating: images/maksssksksss487.png  \n",
      "  inflating: images/maksssksksss488.png  \n",
      "  inflating: images/maksssksksss489.png  \n",
      "  inflating: images/maksssksksss49.png  \n",
      "  inflating: images/maksssksksss490.png  \n",
      "  inflating: images/maksssksksss491.png  \n",
      "  inflating: images/maksssksksss492.png  \n",
      "  inflating: images/maksssksksss493.png  \n",
      "  inflating: images/maksssksksss494.png  \n",
      "  inflating: images/maksssksksss495.png  \n",
      "  inflating: images/maksssksksss496.png  \n",
      "  inflating: images/maksssksksss497.png  \n",
      "  inflating: images/maksssksksss498.png  \n",
      "  inflating: images/maksssksksss499.png  \n",
      "  inflating: images/maksssksksss5.png  \n",
      "  inflating: images/maksssksksss50.png  \n",
      "  inflating: images/maksssksksss500.png  \n",
      "  inflating: images/maksssksksss501.png  \n",
      "  inflating: images/maksssksksss502.png  \n",
      "  inflating: images/maksssksksss503.png  \n",
      "  inflating: images/maksssksksss504.png  \n",
      "  inflating: images/maksssksksss505.png  \n",
      "  inflating: images/maksssksksss506.png  \n",
      "  inflating: images/maksssksksss507.png  \n",
      "  inflating: images/maksssksksss508.png  \n",
      "  inflating: images/maksssksksss509.png  \n",
      "  inflating: images/maksssksksss51.png  \n",
      "  inflating: images/maksssksksss510.png  \n",
      "  inflating: images/maksssksksss511.png  \n",
      "  inflating: images/maksssksksss512.png  \n",
      "  inflating: images/maksssksksss513.png  \n",
      "  inflating: images/maksssksksss514.png  \n",
      "  inflating: images/maksssksksss515.png  \n",
      "  inflating: images/maksssksksss516.png  \n",
      "  inflating: images/maksssksksss517.png  \n",
      "  inflating: images/maksssksksss518.png  \n",
      "  inflating: images/maksssksksss519.png  \n",
      "  inflating: images/maksssksksss52.png  \n",
      "  inflating: images/maksssksksss520.png  \n",
      "  inflating: images/maksssksksss521.png  \n",
      "  inflating: images/maksssksksss522.png  \n",
      "  inflating: images/maksssksksss523.png  \n",
      "  inflating: images/maksssksksss524.png  \n",
      "  inflating: images/maksssksksss525.png  \n",
      "  inflating: images/maksssksksss526.png  \n",
      "  inflating: images/maksssksksss527.png  \n",
      "  inflating: images/maksssksksss528.png  \n",
      "  inflating: images/maksssksksss529.png  \n",
      "  inflating: images/maksssksksss53.png  \n",
      "  inflating: images/maksssksksss530.png  \n",
      "  inflating: images/maksssksksss531.png  \n",
      "  inflating: images/maksssksksss532.png  \n",
      "  inflating: images/maksssksksss533.png  \n",
      "  inflating: images/maksssksksss534.png  \n",
      "  inflating: images/maksssksksss535.png  \n",
      "  inflating: images/maksssksksss536.png  \n",
      "  inflating: images/maksssksksss537.png  \n",
      "  inflating: images/maksssksksss538.png  \n",
      "  inflating: images/maksssksksss539.png  \n",
      "  inflating: images/maksssksksss54.png  \n",
      "  inflating: images/maksssksksss540.png  \n",
      "  inflating: images/maksssksksss541.png  \n",
      "  inflating: images/maksssksksss542.png  \n",
      "  inflating: images/maksssksksss543.png  \n",
      "  inflating: images/maksssksksss544.png  \n",
      "  inflating: images/maksssksksss545.png  \n",
      "  inflating: images/maksssksksss546.png  \n",
      "  inflating: images/maksssksksss547.png  \n",
      "  inflating: images/maksssksksss548.png  \n",
      "  inflating: images/maksssksksss549.png  \n",
      "  inflating: images/maksssksksss55.png  \n",
      "  inflating: images/maksssksksss550.png  \n",
      "  inflating: images/maksssksksss551.png  \n",
      "  inflating: images/maksssksksss552.png  \n",
      "  inflating: images/maksssksksss553.png  \n",
      "  inflating: images/maksssksksss554.png  \n",
      "  inflating: images/maksssksksss555.png  \n",
      "  inflating: images/maksssksksss556.png  \n",
      "  inflating: images/maksssksksss557.png  \n",
      "  inflating: images/maksssksksss558.png  \n",
      "  inflating: images/maksssksksss559.png  \n",
      "  inflating: images/maksssksksss56.png  \n",
      "  inflating: images/maksssksksss560.png  \n",
      "  inflating: images/maksssksksss561.png  \n",
      "  inflating: images/maksssksksss562.png  \n",
      "  inflating: images/maksssksksss563.png  \n",
      "  inflating: images/maksssksksss564.png  \n",
      "  inflating: images/maksssksksss565.png  \n",
      "  inflating: images/maksssksksss566.png  \n",
      "  inflating: images/maksssksksss567.png  \n",
      "  inflating: images/maksssksksss568.png  \n",
      "  inflating: images/maksssksksss569.png  \n",
      "  inflating: images/maksssksksss57.png  \n",
      "  inflating: images/maksssksksss570.png  \n",
      "  inflating: images/maksssksksss571.png  \n",
      "  inflating: images/maksssksksss572.png  \n",
      "  inflating: images/maksssksksss573.png  \n",
      "  inflating: images/maksssksksss574.png  \n",
      "  inflating: images/maksssksksss575.png  \n",
      "  inflating: images/maksssksksss576.png  \n",
      "  inflating: images/maksssksksss577.png  \n",
      "  inflating: images/maksssksksss578.png  \n",
      "  inflating: images/maksssksksss579.png  \n",
      "  inflating: images/maksssksksss58.png  \n",
      "  inflating: images/maksssksksss580.png  \n",
      "  inflating: images/maksssksksss581.png  \n",
      "  inflating: images/maksssksksss582.png  \n",
      "  inflating: images/maksssksksss583.png  \n",
      "  inflating: images/maksssksksss584.png  \n",
      "  inflating: images/maksssksksss585.png  \n",
      "  inflating: images/maksssksksss586.png  \n",
      "  inflating: images/maksssksksss587.png  \n",
      "  inflating: images/maksssksksss588.png  \n",
      "  inflating: images/maksssksksss589.png  \n",
      "  inflating: images/maksssksksss59.png  \n",
      "  inflating: images/maksssksksss590.png  \n",
      "  inflating: images/maksssksksss591.png  \n",
      "  inflating: images/maksssksksss592.png  \n",
      "  inflating: images/maksssksksss593.png  \n",
      "  inflating: images/maksssksksss594.png  \n",
      "  inflating: images/maksssksksss595.png  \n",
      "  inflating: images/maksssksksss596.png  \n",
      "  inflating: images/maksssksksss597.png  \n",
      "  inflating: images/maksssksksss598.png  \n",
      "  inflating: images/maksssksksss599.png  \n",
      "  inflating: images/maksssksksss6.png  \n",
      "  inflating: images/maksssksksss60.png  \n",
      "  inflating: images/maksssksksss600.png  \n",
      "  inflating: images/maksssksksss601.png  \n",
      "  inflating: images/maksssksksss602.png  \n",
      "  inflating: images/maksssksksss603.png  \n",
      "  inflating: images/maksssksksss604.png  \n",
      "  inflating: images/maksssksksss605.png  \n",
      "  inflating: images/maksssksksss606.png  \n",
      "  inflating: images/maksssksksss607.png  \n",
      "  inflating: images/maksssksksss608.png  \n",
      "  inflating: images/maksssksksss609.png  \n",
      "  inflating: images/maksssksksss61.png  \n",
      "  inflating: images/maksssksksss610.png  \n",
      "  inflating: images/maksssksksss611.png  \n",
      "  inflating: images/maksssksksss612.png  \n",
      "  inflating: images/maksssksksss613.png  \n",
      "  inflating: images/maksssksksss614.png  \n",
      "  inflating: images/maksssksksss615.png  \n",
      "  inflating: images/maksssksksss616.png  \n",
      "  inflating: images/maksssksksss617.png  \n",
      "  inflating: images/maksssksksss618.png  \n",
      "  inflating: images/maksssksksss619.png  \n",
      "  inflating: images/maksssksksss62.png  \n",
      "  inflating: images/maksssksksss620.png  \n",
      "  inflating: images/maksssksksss621.png  \n",
      "  inflating: images/maksssksksss622.png  \n",
      "  inflating: images/maksssksksss623.png  \n",
      "  inflating: images/maksssksksss624.png  \n",
      "  inflating: images/maksssksksss625.png  \n",
      "  inflating: images/maksssksksss626.png  \n",
      "  inflating: images/maksssksksss627.png  \n",
      "  inflating: images/maksssksksss628.png  \n",
      "  inflating: images/maksssksksss629.png  \n",
      "  inflating: images/maksssksksss63.png  \n",
      "  inflating: images/maksssksksss630.png  \n",
      "  inflating: images/maksssksksss631.png  \n",
      "  inflating: images/maksssksksss632.png  \n",
      "  inflating: images/maksssksksss633.png  \n",
      "  inflating: images/maksssksksss634.png  \n",
      "  inflating: images/maksssksksss635.png  \n",
      "  inflating: images/maksssksksss636.png  \n",
      "  inflating: images/maksssksksss637.png  \n",
      "  inflating: images/maksssksksss638.png  \n",
      "  inflating: images/maksssksksss639.png  \n",
      "  inflating: images/maksssksksss64.png  \n",
      "  inflating: images/maksssksksss640.png  \n",
      "  inflating: images/maksssksksss641.png  \n",
      "  inflating: images/maksssksksss642.png  \n",
      "  inflating: images/maksssksksss643.png  \n",
      "  inflating: images/maksssksksss644.png  \n",
      "  inflating: images/maksssksksss645.png  \n",
      "  inflating: images/maksssksksss646.png  \n",
      "  inflating: images/maksssksksss647.png  \n",
      "  inflating: images/maksssksksss648.png  \n",
      "  inflating: images/maksssksksss649.png  \n",
      "  inflating: images/maksssksksss65.png  \n",
      "  inflating: images/maksssksksss650.png  \n",
      "  inflating: images/maksssksksss651.png  \n",
      "  inflating: images/maksssksksss652.png  \n",
      "  inflating: images/maksssksksss653.png  \n",
      "  inflating: images/maksssksksss654.png  \n",
      "  inflating: images/maksssksksss655.png  \n",
      "  inflating: images/maksssksksss656.png  \n",
      "  inflating: images/maksssksksss657.png  \n",
      "  inflating: images/maksssksksss658.png  \n",
      "  inflating: images/maksssksksss659.png  \n",
      "  inflating: images/maksssksksss66.png  \n",
      "  inflating: images/maksssksksss660.png  \n",
      "  inflating: images/maksssksksss661.png  \n",
      "  inflating: images/maksssksksss662.png  \n",
      "  inflating: images/maksssksksss663.png  \n",
      "  inflating: images/maksssksksss664.png  \n",
      "  inflating: images/maksssksksss665.png  \n",
      "  inflating: images/maksssksksss666.png  \n",
      "  inflating: images/maksssksksss667.png  \n",
      "  inflating: images/maksssksksss668.png  \n",
      "  inflating: images/maksssksksss669.png  \n",
      "  inflating: images/maksssksksss67.png  \n",
      "  inflating: images/maksssksksss670.png  \n",
      "  inflating: images/maksssksksss671.png  \n",
      "  inflating: images/maksssksksss672.png  \n",
      "  inflating: images/maksssksksss673.png  \n",
      "  inflating: images/maksssksksss674.png  \n",
      "  inflating: images/maksssksksss675.png  \n",
      "  inflating: images/maksssksksss676.png  \n",
      "  inflating: images/maksssksksss677.png  \n",
      "  inflating: images/maksssksksss678.png  \n",
      "  inflating: images/maksssksksss679.png  \n",
      "  inflating: images/maksssksksss68.png  \n",
      "  inflating: images/maksssksksss680.png  \n",
      "  inflating: images/maksssksksss681.png  \n",
      "  inflating: images/maksssksksss682.png  \n",
      "  inflating: images/maksssksksss683.png  \n",
      "  inflating: images/maksssksksss684.png  \n",
      "  inflating: images/maksssksksss685.png  \n",
      "  inflating: images/maksssksksss686.png  \n",
      "  inflating: images/maksssksksss687.png  \n",
      "  inflating: images/maksssksksss688.png  \n",
      "  inflating: images/maksssksksss689.png  \n",
      "  inflating: images/maksssksksss69.png  \n",
      "  inflating: images/maksssksksss690.png  \n",
      "  inflating: images/maksssksksss691.png  \n",
      "  inflating: images/maksssksksss692.png  \n",
      "  inflating: images/maksssksksss693.png  \n",
      "  inflating: images/maksssksksss694.png  \n",
      "  inflating: images/maksssksksss695.png  \n",
      "  inflating: images/maksssksksss696.png  \n",
      "  inflating: images/maksssksksss697.png  \n",
      "  inflating: images/maksssksksss698.png  \n",
      "  inflating: images/maksssksksss699.png  \n",
      "  inflating: images/maksssksksss7.png  \n",
      "  inflating: images/maksssksksss70.png  \n",
      "  inflating: images/maksssksksss700.png  \n",
      "  inflating: images/maksssksksss701.png  \n",
      "  inflating: images/maksssksksss702.png  \n",
      "  inflating: images/maksssksksss703.png  \n",
      "  inflating: images/maksssksksss704.png  \n",
      "  inflating: images/maksssksksss705.png  \n",
      "  inflating: images/maksssksksss706.png  \n",
      "  inflating: images/maksssksksss707.png  \n",
      "  inflating: images/maksssksksss708.png  \n",
      "  inflating: images/maksssksksss709.png  \n",
      "  inflating: images/maksssksksss71.png  \n",
      "  inflating: images/maksssksksss710.png  \n",
      "  inflating: images/maksssksksss711.png  \n",
      "  inflating: images/maksssksksss712.png  \n",
      "  inflating: images/maksssksksss713.png  \n",
      "  inflating: images/maksssksksss714.png  \n",
      "  inflating: images/maksssksksss715.png  \n",
      "  inflating: images/maksssksksss716.png  \n",
      "  inflating: images/maksssksksss717.png  \n",
      "  inflating: images/maksssksksss718.png  \n",
      "  inflating: images/maksssksksss719.png  \n",
      "  inflating: images/maksssksksss72.png  \n",
      "  inflating: images/maksssksksss720.png  \n",
      "  inflating: images/maksssksksss721.png  \n",
      "  inflating: images/maksssksksss722.png  \n",
      "  inflating: images/maksssksksss723.png  \n",
      "  inflating: images/maksssksksss724.png  \n",
      "  inflating: images/maksssksksss725.png  \n",
      "  inflating: images/maksssksksss726.png  \n",
      "  inflating: images/maksssksksss727.png  \n",
      "  inflating: images/maksssksksss728.png  \n",
      "  inflating: images/maksssksksss729.png  \n",
      "  inflating: images/maksssksksss73.png  \n",
      "  inflating: images/maksssksksss730.png  \n",
      "  inflating: images/maksssksksss731.png  \n",
      "  inflating: images/maksssksksss732.png  \n",
      "  inflating: images/maksssksksss733.png  \n",
      "  inflating: images/maksssksksss734.png  \n",
      "  inflating: images/maksssksksss735.png  \n",
      "  inflating: images/maksssksksss736.png  \n",
      "  inflating: images/maksssksksss737.png  \n",
      "  inflating: images/maksssksksss738.png  \n",
      "  inflating: images/maksssksksss739.png  \n",
      "  inflating: images/maksssksksss74.png  \n",
      "  inflating: images/maksssksksss740.png  \n",
      "  inflating: images/maksssksksss741.png  \n",
      "  inflating: images/maksssksksss742.png  \n",
      "  inflating: images/maksssksksss743.png  \n",
      "  inflating: images/maksssksksss744.png  \n",
      "  inflating: images/maksssksksss745.png  \n",
      "  inflating: images/maksssksksss746.png  \n",
      "  inflating: images/maksssksksss747.png  \n",
      "  inflating: images/maksssksksss748.png  \n",
      "  inflating: images/maksssksksss749.png  \n",
      "  inflating: images/maksssksksss75.png  \n",
      "  inflating: images/maksssksksss750.png  \n",
      "  inflating: images/maksssksksss751.png  \n",
      "  inflating: images/maksssksksss752.png  \n",
      "  inflating: images/maksssksksss753.png  \n",
      "  inflating: images/maksssksksss754.png  \n",
      "  inflating: images/maksssksksss755.png  \n",
      "  inflating: images/maksssksksss756.png  \n",
      "  inflating: images/maksssksksss757.png  \n",
      "  inflating: images/maksssksksss758.png  \n",
      "  inflating: images/maksssksksss759.png  \n",
      "  inflating: images/maksssksksss76.png  \n",
      "  inflating: images/maksssksksss760.png  \n",
      "  inflating: images/maksssksksss761.png  \n",
      "  inflating: images/maksssksksss762.png  \n",
      "  inflating: images/maksssksksss763.png  \n",
      "  inflating: images/maksssksksss764.png  \n",
      "  inflating: images/maksssksksss765.png  \n",
      "  inflating: images/maksssksksss766.png  \n",
      "  inflating: images/maksssksksss767.png  \n",
      "  inflating: images/maksssksksss768.png  \n",
      "  inflating: images/maksssksksss769.png  \n",
      "  inflating: images/maksssksksss77.png  \n",
      "  inflating: images/maksssksksss770.png  \n",
      "  inflating: images/maksssksksss771.png  \n",
      "  inflating: images/maksssksksss772.png  \n",
      "  inflating: images/maksssksksss773.png  \n",
      "  inflating: images/maksssksksss774.png  \n",
      "  inflating: images/maksssksksss775.png  \n",
      "  inflating: images/maksssksksss776.png  \n",
      "  inflating: images/maksssksksss777.png  \n",
      "  inflating: images/maksssksksss778.png  \n",
      "  inflating: images/maksssksksss779.png  \n",
      "  inflating: images/maksssksksss78.png  \n",
      "  inflating: images/maksssksksss780.png  \n",
      "  inflating: images/maksssksksss781.png  \n",
      "  inflating: images/maksssksksss782.png  \n",
      "  inflating: images/maksssksksss783.png  \n",
      "  inflating: images/maksssksksss784.png  \n",
      "  inflating: images/maksssksksss785.png  \n",
      "  inflating: images/maksssksksss786.png  \n",
      "  inflating: images/maksssksksss787.png  \n",
      "  inflating: images/maksssksksss788.png  \n",
      "  inflating: images/maksssksksss789.png  \n",
      "  inflating: images/maksssksksss79.png  \n",
      "  inflating: images/maksssksksss790.png  \n",
      "  inflating: images/maksssksksss791.png  \n",
      "  inflating: images/maksssksksss792.png  \n",
      "  inflating: images/maksssksksss793.png  \n",
      "  inflating: images/maksssksksss794.png  \n",
      "  inflating: images/maksssksksss795.png  \n",
      "  inflating: images/maksssksksss796.png  \n",
      "  inflating: images/maksssksksss797.png  \n",
      "  inflating: images/maksssksksss798.png  \n",
      "  inflating: images/maksssksksss799.png  \n",
      "  inflating: images/maksssksksss8.png  \n",
      "  inflating: images/maksssksksss80.png  \n",
      "  inflating: images/maksssksksss800.png  \n",
      "  inflating: images/maksssksksss801.png  \n",
      "  inflating: images/maksssksksss802.png  \n",
      "  inflating: images/maksssksksss803.png  \n",
      "  inflating: images/maksssksksss804.png  \n",
      "  inflating: images/maksssksksss805.png  \n",
      "  inflating: images/maksssksksss806.png  \n",
      "  inflating: images/maksssksksss807.png  \n",
      "  inflating: images/maksssksksss808.png  \n",
      "  inflating: images/maksssksksss809.png  \n",
      "  inflating: images/maksssksksss81.png  \n",
      "  inflating: images/maksssksksss810.png  \n",
      "  inflating: images/maksssksksss811.png  \n",
      "  inflating: images/maksssksksss812.png  \n",
      "  inflating: images/maksssksksss813.png  \n",
      "  inflating: images/maksssksksss814.png  \n",
      "  inflating: images/maksssksksss815.png  \n",
      "  inflating: images/maksssksksss816.png  \n",
      "  inflating: images/maksssksksss817.png  \n",
      "  inflating: images/maksssksksss818.png  \n",
      "  inflating: images/maksssksksss819.png  \n",
      "  inflating: images/maksssksksss82.png  \n",
      "  inflating: images/maksssksksss820.png  \n",
      "  inflating: images/maksssksksss821.png  \n",
      "  inflating: images/maksssksksss822.png  \n",
      "  inflating: images/maksssksksss823.png  \n",
      "  inflating: images/maksssksksss824.png  \n",
      "  inflating: images/maksssksksss825.png  \n",
      "  inflating: images/maksssksksss826.png  \n",
      "  inflating: images/maksssksksss827.png  \n",
      "  inflating: images/maksssksksss828.png  \n",
      "  inflating: images/maksssksksss829.png  \n",
      "  inflating: images/maksssksksss83.png  \n",
      "  inflating: images/maksssksksss830.png  \n",
      "  inflating: images/maksssksksss831.png  \n",
      "  inflating: images/maksssksksss832.png  \n",
      "  inflating: images/maksssksksss833.png  \n",
      "  inflating: images/maksssksksss834.png  \n",
      "  inflating: images/maksssksksss835.png  \n",
      "  inflating: images/maksssksksss836.png  \n",
      "  inflating: images/maksssksksss837.png  \n",
      "  inflating: images/maksssksksss838.png  \n",
      "  inflating: images/maksssksksss839.png  \n",
      "  inflating: images/maksssksksss84.png  \n",
      "  inflating: images/maksssksksss840.png  \n",
      "  inflating: images/maksssksksss841.png  \n",
      "  inflating: images/maksssksksss842.png  \n",
      "  inflating: images/maksssksksss843.png  \n",
      "  inflating: images/maksssksksss844.png  \n",
      "  inflating: images/maksssksksss845.png  \n",
      "  inflating: images/maksssksksss846.png  \n",
      "  inflating: images/maksssksksss847.png  \n",
      "  inflating: images/maksssksksss848.png  \n",
      "  inflating: images/maksssksksss849.png  \n",
      "  inflating: images/maksssksksss85.png  \n",
      "  inflating: images/maksssksksss850.png  \n",
      "  inflating: images/maksssksksss851.png  \n",
      "  inflating: images/maksssksksss852.png  \n",
      "  inflating: images/maksssksksss86.png  \n",
      "  inflating: images/maksssksksss87.png  \n",
      "  inflating: images/maksssksksss88.png  \n",
      "  inflating: images/maksssksksss89.png  \n",
      "  inflating: images/maksssksksss9.png  \n",
      "  inflating: images/maksssksksss90.png  \n",
      "  inflating: images/maksssksksss91.png  \n",
      "  inflating: images/maksssksksss92.png  \n",
      "  inflating: images/maksssksksss93.png  \n",
      "  inflating: images/maksssksksss94.png  \n",
      "  inflating: images/maksssksksss95.png  \n",
      "  inflating: images/maksssksksss96.png  \n",
      "  inflating: images/maksssksksss97.png  \n",
      "  inflating: images/maksssksksss98.png  \n",
      "  inflating: images/maksssksksss99.png  \n"
     ]
    }
   ],
   "source": [
    "!unzip /content/drive/My\\ Drive/ML/faceMaskDataset/dataset.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JPcuym5eww4j"
   },
   "outputs": [],
   "source": [
    "!cp /content/drive/My\\ Drive/ML/Weights/yolov3.weights ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1z8pIaxT4NHo",
    "outputId": "2058ec0f-7649-494c-bcdf-74e41c055783"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JqKmzBNk4NHw",
    "outputId": "98bd26d6-c694-4513-ced5-8d023f73344f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-07-27 14:53:38--  https://pjreddie.com/media/files/yolov3.weights\n",
      "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
      "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 248007048 (237M) [application/octet-stream]\n",
      "Saving to: ‘./yolov3.weights’\n",
      "\n",
      "./yolov3.weights    100%[===================>] 236.52M   210KB/s    in 13m 31s \n",
      "\n",
      "2020-07-27 15:07:11 (299 KB/s) - ‘./yolov3.weights’ saved [248007048/248007048]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://pjreddie.com/media/files/yolov3.weights -O ./yolov3.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s_BQ0YXf4NH1"
   },
   "outputs": [],
   "source": [
    "YOLOV3_LAYER_LIST = [\n",
    "    'yolo_darknet',\n",
    "    'yolo_conv_0',\n",
    "    'yolo_output_0',\n",
    "    'yolo_conv_1',\n",
    "    'yolo_output_1',\n",
    "    'yolo_conv_2',\n",
    "    'yolo_output_2',\n",
    "]\n",
    "\n",
    "\n",
    "def load_darknet_weights(model, weights_file, tiny=False):\n",
    "    wf = open(weights_file, 'rb')\n",
    "    major, minor, revision, seen, _ = np.fromfile(wf, dtype=np.int32, count=5)\n",
    "\n",
    "    layers = YOLOV3_LAYER_LIST\n",
    "\n",
    "    for layer_name in layers:\n",
    "        sub_model = model.get_layer(layer_name)\n",
    "        for i, layer in enumerate(sub_model.layers):\n",
    "            if not layer.name.startswith('conv2d'):\n",
    "                continue\n",
    "            batch_norm = None\n",
    "            if i + 1 < len(sub_model.layers) and \\\n",
    "                    sub_model.layers[i + 1].name.startswith('batch_norm'):\n",
    "                batch_norm = sub_model.layers[i + 1]\n",
    "\n",
    "            print(\"{}/{} {}\".format(\n",
    "                sub_model.name, layer.name, 'bn' if batch_norm else 'bias'))\n",
    "\n",
    "            filters = layer.filters\n",
    "            size = layer.kernel_size[0]\n",
    "            in_dim = layer.input_shape[-1]\n",
    "\n",
    "            if batch_norm is None:\n",
    "                conv_bias = np.fromfile(wf, dtype=np.float32, count=filters)\n",
    "            else:\n",
    "                # darknet [beta, gamma, mean, variance]\n",
    "                bn_weights = np.fromfile(\n",
    "                    wf, dtype=np.float32, count=4 * filters)\n",
    "                # tf [gamma, beta, mean, variance]\n",
    "                bn_weights = bn_weights.reshape((4, filters))[[1, 0, 2, 3]]\n",
    "\n",
    "            # darknet shape (out_dim, in_dim, height, width)\n",
    "            conv_shape = (filters, in_dim, size, size)\n",
    "            conv_weights = np.fromfile(\n",
    "                wf, dtype=np.float32, count=np.product(conv_shape))\n",
    "            # tf shape (height, width, in_dim, out_dim)\n",
    "            conv_weights = conv_weights.reshape(\n",
    "                conv_shape).transpose([2, 3, 1, 0])\n",
    "\n",
    "            if batch_norm is None:\n",
    "                layer.set_weights([conv_weights, conv_bias])\n",
    "            else:\n",
    "                layer.set_weights([conv_weights])\n",
    "                batch_norm.set_weights(bn_weights)\n",
    "\n",
    "    assert len(wf.read()) == 0, 'failed to read all data'\n",
    "    wf.close()\n",
    "\n",
    "\n",
    "def broadcast_iou(box_1, box_2):\n",
    "    # box_1: (..., (x1, y1, x2, y2))\n",
    "    # box_2: (N, (x1, y1, x2, y2))\n",
    "\n",
    "    # broadcast boxes\n",
    "    box_1 = tf.expand_dims(box_1, -2)\n",
    "    box_2 = tf.expand_dims(box_2, 0)\n",
    "    # new_shape: (..., N, (x1, y1, x2, y2))\n",
    "    new_shape = tf.broadcast_dynamic_shape(tf.shape(box_1), tf.shape(box_2))\n",
    "    box_1 = tf.broadcast_to(box_1, new_shape)\n",
    "    box_2 = tf.broadcast_to(box_2, new_shape)\n",
    "\n",
    "    int_w = tf.maximum(tf.minimum(box_1[..., 2], box_2[..., 2]) -\n",
    "                       tf.maximum(box_1[..., 0], box_2[..., 0]), 0)\n",
    "    int_h = tf.maximum(tf.minimum(box_1[..., 3], box_2[..., 3]) -\n",
    "                       tf.maximum(box_1[..., 1], box_2[..., 1]), 0)\n",
    "    int_area = int_w * int_h\n",
    "    box_1_area = (box_1[..., 2] - box_1[..., 0]) * \\\n",
    "                 (box_1[..., 3] - box_1[..., 1])\n",
    "    box_2_area = (box_2[..., 2] - box_2[..., 0]) * \\\n",
    "                 (box_2[..., 3] - box_2[..., 1])\n",
    "    return int_area / (box_1_area + box_2_area - int_area)\n",
    "\n",
    "\n",
    "def draw_outputs(img, outputs, class_names):\n",
    "    boxes, objectness, classes, nums = outputs\n",
    "    boxes, objectness, classes, nums = boxes[0], objectness[0], classes[0], nums[0]\n",
    "    wh = np.flip(img.shape[0:2])\n",
    "    for i in range(nums):\n",
    "        x1y1 = tuple((np.array(boxes[i][0:2]) * wh).astype(np.int32))\n",
    "        x2y2 = tuple((np.array(boxes[i][2:4]) * wh).astype(np.int32))\n",
    "        img = cv2.rectangle(img, x1y1, x2y2, (255, 0, 0), 2)\n",
    "        img = cv2.putText(img, '{} {:.4f}'.format(\n",
    "            class_names[int(classes[i])], objectness[i]),\n",
    "                          x1y1, cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 2)\n",
    "    return img\n",
    "\n",
    "\n",
    "def draw_labels(x, y, class_names):\n",
    "    img = x.numpy()\n",
    "    boxes, classes = tf.split(y, (4, 1), axis=-1)\n",
    "    classes = classes[..., 0]\n",
    "    wh = np.flip(img.shape[0:2])\n",
    "    for i in range(len(boxes)):\n",
    "        x1y1 = tuple((np.array(boxes[i][0:2]) * wh).astype(np.int32))\n",
    "        x2y2 = tuple((np.array(boxes[i][2:4]) * wh).astype(np.int32))\n",
    "        img = cv2.rectangle(img, x1y1, x2y2, (255, 0, 0), 2)\n",
    "        img = cv2.putText(img, class_names[classes[i]],\n",
    "                          x1y1, cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
    "                          1, (0, 0, 255), 2)\n",
    "    return img\n",
    "\n",
    "\n",
    "def freeze_all(model, frozen=True):\n",
    "    \n",
    "    model.trainable = not frozen\n",
    "    if isinstance(model, tf.keras.Model):\n",
    "        for l in model.layers:\n",
    "            \n",
    "            freeze_all(l, frozen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UjDoblHs4NH5"
   },
   "outputs": [],
   "source": [
    "\n",
    "# flags.DEFINE_integer('yolo_max_boxes', 100, 'maximum number of boxes per image')\n",
    "# flags.DEFINE_float('yolo_iou_threshold', 0.5, 'iou threshold')\n",
    "# flags.DEFINE_float('yolo_score_threshold', 0.5, 'score threshold')\n",
    "yolo_max_boxes = 150\n",
    "yolo_iou_threshold = 0.5\n",
    "yolo_score_threshold = 0.5\n",
    "\n",
    "yolo_anchors = np.array([(10, 13), (16, 30), (33, 23), (30, 61), (62, 45),\n",
    "                         (59, 119), (116, 90), (156, 198), (373, 326)],\n",
    "                        np.float32) / 416\n",
    "yolo_anchor_masks = np.array([[6, 7, 8], [3, 4, 5], [0, 1, 2]])\n",
    "\n",
    "\n",
    "def DarknetConv(x, filters, size, strides=1, batch_norm=True):\n",
    "    if strides == 1:\n",
    "        padding = 'same'\n",
    "    else:\n",
    "        x = ZeroPadding2D(((1, 0), (1, 0)))(x)  # top left half-padding\n",
    "        padding = 'valid'\n",
    "    x = Conv2D(filters=filters, kernel_size=size,\n",
    "               strides=strides, padding=padding,\n",
    "               use_bias=not batch_norm, kernel_regularizer=l2(0.0005))(x)\n",
    "    if batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(alpha=0.1)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def DarknetResidual(x, filters):\n",
    "    prev = x\n",
    "    x = DarknetConv(x, filters // 2, 1)\n",
    "    x = DarknetConv(x, filters, 3)\n",
    "    x = Add()([prev, x])\n",
    "    return x\n",
    "\n",
    "\n",
    "def DarknetBlock(x, filters, blocks):\n",
    "    x = DarknetConv(x, filters, 3, strides=2)\n",
    "    for _ in range(blocks):\n",
    "        x = DarknetResidual(x, filters)\n",
    "    return x\n",
    "\n",
    "\n",
    "def Darknet(name=None):\n",
    "    x = inputs = Input([None, None, 3])\n",
    "    x = DarknetConv(x, 32, 3)\n",
    "    x = DarknetBlock(x, 64, 1)\n",
    "    x = DarknetBlock(x, 128, 2)  # skip connection\n",
    "    x = x_36 = DarknetBlock(x, 256, 8)  # skip connection\n",
    "    x = x_61 = DarknetBlock(x, 512, 8)\n",
    "    x = DarknetBlock(x, 1024, 4)\n",
    "    return tf.keras.Model(inputs, (x_36, x_61, x), name=name)\n",
    "\n",
    "\n",
    "def DarknetTiny(name=None):\n",
    "    x = inputs = Input([None, None, 3])\n",
    "    x = DarknetConv(x, 16, 3)\n",
    "    x = MaxPool2D(2, 2, 'same')(x)\n",
    "    x = DarknetConv(x, 32, 3)\n",
    "    x = MaxPool2D(2, 2, 'same')(x)\n",
    "    x = DarknetConv(x, 64, 3)\n",
    "    x = MaxPool2D(2, 2, 'same')(x)\n",
    "    x = DarknetConv(x, 128, 3)\n",
    "    x = MaxPool2D(2, 2, 'same')(x)\n",
    "    x = x_8 = DarknetConv(x, 256, 3)  # skip connection\n",
    "    x = MaxPool2D(2, 2, 'same')(x)\n",
    "    x = DarknetConv(x, 512, 3)\n",
    "    x = MaxPool2D(2, 1, 'same')(x)\n",
    "    x = DarknetConv(x, 1024, 3)\n",
    "    return tf.keras.Model(inputs, (x_8, x), name=name)\n",
    "\n",
    "\n",
    "def YoloConv(filters, name=None):\n",
    "    def yolo_conv(x_in):\n",
    "        if isinstance(x_in, tuple):\n",
    "            inputs = Input(x_in[0].shape[1:]), Input(x_in[1].shape[1:])\n",
    "            x, x_skip = inputs\n",
    "\n",
    "            # concat with skip connection\n",
    "            x = DarknetConv(x, filters, 1)\n",
    "            x = UpSampling2D(2)(x)\n",
    "            x = Concatenate()([x, x_skip])\n",
    "        else:\n",
    "            x = inputs = Input(x_in.shape[1:])\n",
    "\n",
    "        x = DarknetConv(x, filters, 1)\n",
    "        x = DarknetConv(x, filters * 2, 3)\n",
    "        x = DarknetConv(x, filters, 1)\n",
    "        x = DarknetConv(x, filters * 2, 3)\n",
    "        x = DarknetConv(x, filters, 1)\n",
    "        return Model(inputs, x, name=name)(x_in)\n",
    "\n",
    "    return yolo_conv\n",
    "\n",
    "\n",
    "# def YoloConvTiny(filters, name=None):\n",
    "#     def yolo_conv(x_in):\n",
    "#         if isinstance(x_in, tuple):\n",
    "#             inputs = Input(x_in[0].shape[1:]), Input(x_in[1].shape[1:])\n",
    "#             x, x_skip = inputs\n",
    "#\n",
    "#             # concat with skip connection\n",
    "#             x = DarknetConv(x, filters, 1)\n",
    "#             x = UpSampling2D(2)(x)\n",
    "#             x = Concatenate()([x, x_skip])\n",
    "#         else:\n",
    "#             x = inputs = Input(x_in.shape[1:])\n",
    "#             x = DarknetConv(x, filters, 1)\n",
    "#         return Model(inputs, x, name=name)(x_in)\n",
    "#\n",
    "#     return yolo_conv\n",
    "\n",
    "\n",
    "def YoloOutput(filters, anchors, classes, name=None):\n",
    "    def yolo_output(x_in):\n",
    "        x = inputs = Input(x_in.shape[1:])\n",
    "        x = DarknetConv(x, filters * 2, 3)\n",
    "        x = DarknetConv(x, anchors * (classes + 5), 1, batch_norm=False)\n",
    "        x = Lambda(lambda x: tf.reshape(x, (-1, tf.shape(x)[1], tf.shape(x)[2],\n",
    "                                            anchors, classes + 5)))(x)\n",
    "        return tf.keras.Model(inputs, x, name=name)(x_in)\n",
    "\n",
    "    return yolo_output\n",
    "\n",
    "\n",
    "def yolo_boxes(pred, anchors, classes):\n",
    "    # pred: (batch_size, grid, grid, anchors, (x, y, w, h, obj, ...classes))\n",
    "    grid_size = tf.shape(pred)[1]\n",
    "    box_xy, box_wh, objectness, class_probs = tf.split(\n",
    "        pred, (2, 2, 1, classes), axis=-1)\n",
    "\n",
    "    box_xy = tf.sigmoid(box_xy)\n",
    "    objectness = tf.sigmoid(objectness)\n",
    "    class_probs = tf.sigmoid(class_probs)\n",
    "    pred_box = tf.concat((box_xy, box_wh), axis=-1)  # original xywh for loss\n",
    "\n",
    "    # !!! grid[x][y] == (y, x)\n",
    "    grid = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))\n",
    "    grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)  # [gx, gy, 1, 2]\n",
    "\n",
    "    box_xy = (box_xy + tf.cast(grid, tf.float32)) / tf.cast(grid_size, tf.float32)\n",
    "    box_wh = tf.exp(box_wh) * anchors\n",
    "\n",
    "    box_x1y1 = box_xy - box_wh / 2\n",
    "    box_x2y2 = box_xy + box_wh / 2\n",
    "    bbox = tf.concat([box_x1y1, box_x2y2], axis=-1)\n",
    "\n",
    "    return bbox, objectness, class_probs, pred_box\n",
    "\n",
    "\n",
    "def yolo_nms(outputs, anchors, masks, classes):\n",
    "    # boxes, conf, type\n",
    "    b, c, t = [], [], []\n",
    "\n",
    "    for o in outputs:\n",
    "        b.append(tf.reshape(o[0], (tf.shape(o[0])[0], -1, tf.shape(o[0])[-1])))\n",
    "        c.append(tf.reshape(o[1], (tf.shape(o[1])[0], -1, tf.shape(o[1])[-1])))\n",
    "        t.append(tf.reshape(o[2], (tf.shape(o[2])[0], -1, tf.shape(o[2])[-1])))\n",
    "\n",
    "    bbox = tf.concat(b, axis=1)\n",
    "    confidence = tf.concat(c, axis=1)\n",
    "    class_probs = tf.concat(t, axis=1)\n",
    "\n",
    "    scores = confidence * class_probs\n",
    "    boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(\n",
    "        boxes=tf.reshape(bbox, (tf.shape(bbox)[0], -1, 1, 4)),\n",
    "        scores=tf.reshape(\n",
    "            scores, (tf.shape(scores)[0], -1, tf.shape(scores)[-1])),\n",
    "        max_output_size_per_class=100,\n",
    "        max_total_size=100,\n",
    "        iou_threshold=0.5,\n",
    "        score_threshold=0.5\n",
    "    )\n",
    "    return boxes, scores, classes, valid_detections\n",
    "\n",
    "\n",
    "def YoloV3(size=None, channels=3, anchors=yolo_anchors, masks=yolo_anchor_masks, classes=80, training=False):\n",
    "    x = inputs = Input([size, size, channels], name='input')\n",
    "\n",
    "    x_36, x_61, x = Darknet(name='yolo_darknet')(x)\n",
    "\n",
    "    x = YoloConv(512, name='yolo_conv_0')(x)\n",
    "    output_0 = YoloOutput(512, len(masks[0]), classes, name='yolo_output_0')(x)\n",
    "\n",
    "    x = YoloConv(256, name='yolo_conv_1')((x, x_61))\n",
    "    output_1 = YoloOutput(256, len(masks[1]), classes, name='yolo_output_1')(x)\n",
    "\n",
    "    x = YoloConv(128, name='yolo_conv_2')((x, x_36))\n",
    "    output_2 = YoloOutput(128, len(masks[2]), classes, name='yolo_output_2')(x)\n",
    "\n",
    "    if training:\n",
    "        return Model(inputs, (output_0, output_1, output_2), name='yolov3')\n",
    "\n",
    "    boxes_0 = Lambda(lambda x: yolo_boxes(x, anchors[masks[0]], classes),\n",
    "                     name='yolo_boxes_0')(output_0)\n",
    "    boxes_1 = Lambda(lambda x: yolo_boxes(x, anchors[masks[1]], classes),\n",
    "                     name='yolo_boxes_1')(output_1)\n",
    "    boxes_2 = Lambda(lambda x: yolo_boxes(x, anchors[masks[2]], classes),\n",
    "                     name='yolo_boxes_2')(output_2)\n",
    "\n",
    "    outputs = Lambda(lambda x: yolo_nms(x, anchors, masks, classes),\n",
    "                     name='yolo_nms')((boxes_0[:3], boxes_1[:3], boxes_2[:3]))\n",
    "    return Model(inputs, outputs, name='yolov3')\n",
    "\n",
    "\n",
    "def YoloLoss(anchors, classes=80, ignore_thresh=0.5):\n",
    "    def yolo_loss(y_true, y_pred):\n",
    "        # 1. transform all pred outputs\n",
    "        # y_pred: (batch_size, grid, grid, anchors, (x, y, w, h, obj, ...cls))\n",
    "        pred_box, pred_obj, pred_class, pred_xywh = yolo_boxes(y_pred, anchors, classes)\n",
    "        pred_xy = pred_xywh[..., 0:2]\n",
    "        pred_wh = pred_xywh[..., 2:4]\n",
    "\n",
    "        # 2. transform all true outputs\n",
    "        # y_true: (batch_size, grid, grid, anchors, (x1, y1, x2, y2, obj, cls))\n",
    "        true_box, true_obj, true_class_idx = tf.split(y_true, (4, 1, 1), axis=-1)\n",
    "        true_xy = (true_box[..., 0:2] + true_box[..., 2:4]) / 2\n",
    "        true_wh = true_box[..., 2:4] - true_box[..., 0:2]\n",
    "\n",
    "        # give higher weights to small boxes\n",
    "        box_loss_scale = 2 - true_wh[..., 0] * true_wh[..., 1]\n",
    "\n",
    "        # 3. inverting the pred box equations\n",
    "        grid_size = tf.shape(y_true)[1]\n",
    "        grid = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))\n",
    "        grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)\n",
    "        true_xy = true_xy * tf.cast(grid_size, tf.float32) - tf.cast(grid, tf.float32)\n",
    "        true_wh = tf.math.log(true_wh / anchors)\n",
    "        true_wh = tf.where(tf.math.is_inf(true_wh), tf.zeros_like(true_wh), true_wh)\n",
    "\n",
    "        # 4. calculate all masks\n",
    "        obj_mask = tf.squeeze(true_obj, -1)\n",
    "        # ignore false positive when iou is over threshold\n",
    "        best_iou = tf.map_fn(\n",
    "            lambda x: tf.reduce_max(broadcast_iou(x[0], tf.boolean_mask(x[1], tf.cast(x[2], tf.bool))), axis=-1),\n",
    "            (pred_box, true_box, obj_mask),\n",
    "            tf.float32)\n",
    "        ignore_mask = tf.cast(best_iou < ignore_thresh, tf.float32)\n",
    "\n",
    "        # 5. calculate all losses\n",
    "        xy_loss = obj_mask * box_loss_scale * tf.reduce_sum(tf.square(true_xy - pred_xy), axis=-1)\n",
    "        wh_loss = obj_mask * box_loss_scale * tf.reduce_sum(tf.square(true_wh - pred_wh), axis=-1)\n",
    "        obj_loss = binary_crossentropy(true_obj, pred_obj)\n",
    "        obj_loss = obj_mask * obj_loss + (1 - obj_mask) * ignore_mask * obj_loss\n",
    "        # TODO: use binary_crossentropy instead\n",
    "        class_loss = obj_mask * sparse_categorical_crossentropy(true_class_idx, pred_class)\n",
    "\n",
    "        # 6. sum over (batch, gridx, gridy, anchors) => (batch, 1)\n",
    "        xy_loss = tf.reduce_sum(xy_loss, axis=(1, 2, 3))\n",
    "        wh_loss = tf.reduce_sum(wh_loss, axis=(1, 2, 3))\n",
    "        obj_loss = tf.reduce_sum(obj_loss, axis=(1, 2, 3))\n",
    "        class_loss = tf.reduce_sum(class_loss, axis=(1, 2, 3))\n",
    "\n",
    "        return xy_loss + wh_loss + obj_loss + class_loss\n",
    "\n",
    "    return yolo_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Q6B3IRLQ4NH9",
    "outputId": "53617893-b1c9-4920-b249-ecc111cd3d81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"yolov3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "yolo_darknet (Model)            ((None, None, None,  40620640    input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "yolo_conv_0 (Model)             (None, None, None, 5 11024384    yolo_darknet[1][2]               \n",
      "__________________________________________________________________________________________________\n",
      "yolo_conv_1 (Model)             (None, None, None, 2 2957312     yolo_conv_0[1][0]                \n",
      "                                                                 yolo_darknet[1][1]               \n",
      "__________________________________________________________________________________________________\n",
      "yolo_conv_2 (Model)             (None, None, None, 1 741376      yolo_conv_1[1][0]                \n",
      "                                                                 yolo_darknet[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "yolo_output_0 (Model)           (None, None, None, 3 4984063     yolo_conv_0[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "yolo_output_1 (Model)           (None, None, None, 3 1312511     yolo_conv_1[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "yolo_output_2 (Model)           (None, None, None, 3 361471      yolo_conv_2[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "yolo_boxes_0 (Lambda)           ((None, None, None,  0           yolo_output_0[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "yolo_boxes_1 (Lambda)           ((None, None, None,  0           yolo_output_1[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "yolo_boxes_2 (Lambda)           ((None, None, None,  0           yolo_output_2[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "yolo_nms (Lambda)               ((None, 100, 4), (No 0           yolo_boxes_0[0][0]               \n",
      "                                                                 yolo_boxes_0[0][1]               \n",
      "                                                                 yolo_boxes_0[0][2]               \n",
      "                                                                 yolo_boxes_1[0][0]               \n",
      "                                                                 yolo_boxes_1[0][1]               \n",
      "                                                                 yolo_boxes_1[0][2]               \n",
      "                                                                 yolo_boxes_2[0][0]               \n",
      "                                                                 yolo_boxes_2[0][1]               \n",
      "                                                                 yolo_boxes_2[0][2]               \n",
      "==================================================================================================\n",
      "Total params: 62,001,757\n",
      "Trainable params: 61,949,149\n",
      "Non-trainable params: 52,608\n",
      "__________________________________________________________________________________________________\n",
      "model created\n",
      "yolo_darknet/conv2d bn\n",
      "yolo_darknet/conv2d_1 bn\n",
      "yolo_darknet/conv2d_2 bn\n",
      "yolo_darknet/conv2d_3 bn\n",
      "yolo_darknet/conv2d_4 bn\n",
      "yolo_darknet/conv2d_5 bn\n",
      "yolo_darknet/conv2d_6 bn\n",
      "yolo_darknet/conv2d_7 bn\n",
      "yolo_darknet/conv2d_8 bn\n",
      "yolo_darknet/conv2d_9 bn\n",
      "yolo_darknet/conv2d_10 bn\n",
      "yolo_darknet/conv2d_11 bn\n",
      "yolo_darknet/conv2d_12 bn\n",
      "yolo_darknet/conv2d_13 bn\n",
      "yolo_darknet/conv2d_14 bn\n",
      "yolo_darknet/conv2d_15 bn\n",
      "yolo_darknet/conv2d_16 bn\n",
      "yolo_darknet/conv2d_17 bn\n",
      "yolo_darknet/conv2d_18 bn\n",
      "yolo_darknet/conv2d_19 bn\n",
      "yolo_darknet/conv2d_20 bn\n",
      "yolo_darknet/conv2d_21 bn\n",
      "yolo_darknet/conv2d_22 bn\n",
      "yolo_darknet/conv2d_23 bn\n",
      "yolo_darknet/conv2d_24 bn\n",
      "yolo_darknet/conv2d_25 bn\n",
      "yolo_darknet/conv2d_26 bn\n",
      "yolo_darknet/conv2d_27 bn\n",
      "yolo_darknet/conv2d_28 bn\n",
      "yolo_darknet/conv2d_29 bn\n",
      "yolo_darknet/conv2d_30 bn\n",
      "yolo_darknet/conv2d_31 bn\n",
      "yolo_darknet/conv2d_32 bn\n",
      "yolo_darknet/conv2d_33 bn\n",
      "yolo_darknet/conv2d_34 bn\n",
      "yolo_darknet/conv2d_35 bn\n",
      "yolo_darknet/conv2d_36 bn\n",
      "yolo_darknet/conv2d_37 bn\n",
      "yolo_darknet/conv2d_38 bn\n",
      "yolo_darknet/conv2d_39 bn\n",
      "yolo_darknet/conv2d_40 bn\n",
      "yolo_darknet/conv2d_41 bn\n",
      "yolo_darknet/conv2d_42 bn\n",
      "yolo_darknet/conv2d_43 bn\n",
      "yolo_darknet/conv2d_44 bn\n",
      "yolo_darknet/conv2d_45 bn\n",
      "yolo_darknet/conv2d_46 bn\n",
      "yolo_darknet/conv2d_47 bn\n",
      "yolo_darknet/conv2d_48 bn\n",
      "yolo_darknet/conv2d_49 bn\n",
      "yolo_darknet/conv2d_50 bn\n",
      "yolo_darknet/conv2d_51 bn\n",
      "yolo_conv_0/conv2d_52 bn\n",
      "yolo_conv_0/conv2d_53 bn\n",
      "yolo_conv_0/conv2d_54 bn\n",
      "yolo_conv_0/conv2d_55 bn\n",
      "yolo_conv_0/conv2d_56 bn\n",
      "yolo_output_0/conv2d_57 bn\n",
      "yolo_output_0/conv2d_58 bias\n",
      "yolo_conv_1/conv2d_59 bn\n",
      "yolo_conv_1/conv2d_60 bn\n",
      "yolo_conv_1/conv2d_61 bn\n",
      "yolo_conv_1/conv2d_62 bn\n",
      "yolo_conv_1/conv2d_63 bn\n",
      "yolo_conv_1/conv2d_64 bn\n",
      "yolo_output_1/conv2d_65 bn\n",
      "yolo_output_1/conv2d_66 bias\n",
      "yolo_conv_2/conv2d_67 bn\n",
      "yolo_conv_2/conv2d_68 bn\n",
      "yolo_conv_2/conv2d_69 bn\n",
      "yolo_conv_2/conv2d_70 bn\n",
      "yolo_conv_2/conv2d_71 bn\n",
      "yolo_conv_2/conv2d_72 bn\n",
      "yolo_output_2/conv2d_73 bn\n",
      "yolo_output_2/conv2d_74 bias\n",
      "weights loaded\n",
      "sanity check passed\n",
      "weights saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load():\n",
    "    yolo = YoloV3(classes=80)\n",
    "    yolo.summary()\n",
    "    print('model created')\n",
    "    load_darknet_weights(yolo, './yolov3.weights')\n",
    "    print('weights loaded')\n",
    "    img = np.random.random((1, 320, 320, 3)).astype(np.float32)\n",
    "    output = yolo(img)\n",
    "    print('sanity check passed')\n",
    "    yolo.save_weights('./checkpoints/yolov3.tf')\n",
    "    print('weights saved')\n",
    "\n",
    "\n",
    "load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2d1a27f2-726b-40cd-ad15-ee6ca3249084",
    "_uuid": "ec12b90b-23fa-4f55-b332-8cc53423f548",
    "colab": {},
    "colab_type": "code",
    "id": "OaN2UmVv4NID"
   },
   "outputs": [],
   "source": [
    "# from absl import app, flags, logging\n",
    "# from absl.flags import FLAGS\n",
    "\n",
    "# flags.DEFINE_string('data_dir', './input/face-mask-detection/',\n",
    "#                     'path to raw dataset')\n",
    "# flags.DEFINE_enum('split', 'train', [\n",
    "#     'train', 'val'], 'specify train or val spit')\n",
    "# flags.DEFINE_string('output_file', './data/mask_detection.tfrecord', 'output dataset')\n",
    "# flags.DEFINE_string('classes', './input/classnames/faceMasks.names', 'classes file')\n",
    "data_dir = './'\n",
    "train_output_file = './maskdetection.tfrecord'\n",
    "valid_output_file = './maskdetection_val.tfrecord'\n",
    "classes = './faceMask.names'\n",
    "\n",
    "\n",
    "\n",
    "def build_example(annotation, class_map):\n",
    "    img_path = os.path.join(data_dir,'images', annotation['filename'])\n",
    "    img_raw = open(img_path, 'rb').read()\n",
    "    key = hashlib.sha256(img_raw).hexdigest()\n",
    "\n",
    "    width = int(annotation['size']['width'])\n",
    "    height = int(annotation['size']['height'])\n",
    "\n",
    "    xmin = []\n",
    "    ymin = []\n",
    "    xmax = []\n",
    "    ymax = []\n",
    "    classes = []\n",
    "    classes_text = []\n",
    "    truncated = []\n",
    "    views = []\n",
    "    difficult_obj = []\n",
    "    if 'object' in annotation:\n",
    "        for obj in annotation['object']:\n",
    "            difficult = bool(int(obj['difficult']))\n",
    "            difficult_obj.append(int(difficult))\n",
    "\n",
    "            xmin.append(float(obj['bndbox']['xmin']) / width)\n",
    "            ymin.append(float(obj['bndbox']['ymin']) / height)\n",
    "            xmax.append(float(obj['bndbox']['xmax']) / width)\n",
    "            ymax.append(float(obj['bndbox']['ymax']) / height)\n",
    "            classes_text.append(obj['name'].encode('utf8'))\n",
    "            classes.append(class_map[obj['name']])\n",
    "            truncated.append(int(obj['truncated']))\n",
    "            views.append(obj['pose'].encode('utf8'))\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n",
    "        'image/width': tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n",
    "        'image/filename': tf.train.Feature(bytes_list=tf.train.BytesList(value=[\n",
    "            annotation['filename'].encode('utf8')])),\n",
    "        'image/source_id': tf.train.Feature(bytes_list=tf.train.BytesList(value=[\n",
    "            annotation['filename'].encode('utf8')])),\n",
    "        'image/key/sha256': tf.train.Feature(bytes_list=tf.train.BytesList(value=[key.encode('utf8')])),\n",
    "        'image/encoded': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw])),\n",
    "        'image/format': tf.train.Feature(bytes_list=tf.train.BytesList(value=['jpeg'.encode('utf8')])),\n",
    "        'image/object/bbox/xmin': tf.train.Feature(float_list=tf.train.FloatList(value=xmin)),\n",
    "        'image/object/bbox/xmax': tf.train.Feature(float_list=tf.train.FloatList(value=xmax)),\n",
    "        'image/object/bbox/ymin': tf.train.Feature(float_list=tf.train.FloatList(value=ymin)),\n",
    "        'image/object/bbox/ymax': tf.train.Feature(float_list=tf.train.FloatList(value=ymax)),\n",
    "        'image/object/class/text': tf.train.Feature(bytes_list=tf.train.BytesList(value=classes_text)),\n",
    "        'image/object/class/label': tf.train.Feature(int64_list=tf.train.Int64List(value=classes)),\n",
    "        'image/object/difficult': tf.train.Feature(int64_list=tf.train.Int64List(value=difficult_obj)),\n",
    "        'image/object/truncated': tf.train.Feature(int64_list=tf.train.Int64List(value=truncated)),\n",
    "        'image/object/view': tf.train.Feature(bytes_list=tf.train.BytesList(value=views)),\n",
    "    }))\n",
    "    return example\n",
    "\n",
    "\n",
    "def parse_xml(xml):\n",
    "    if not len(xml):\n",
    "        return {xml.tag: xml.text}\n",
    "    result = {}\n",
    "    for child in xml:\n",
    "        child_result = parse_xml(child)\n",
    "        if child.tag != 'object':\n",
    "            result[child.tag] = child_result[child.tag]\n",
    "        else:\n",
    "            if child.tag not in result:\n",
    "                result[child.tag] = []\n",
    "            result[child.tag].append(child_result[child.tag])\n",
    "    return {xml.tag: result}\n",
    "\n",
    "\n",
    "def create_train():\n",
    "    class_map = {name: idx for idx, name in enumerate(open(classes).read().splitlines())}\n",
    "    print(\"Class mapping loaded: \", class_map)\n",
    "\n",
    "    writer = tf.io.TFRecordWriter(train_output_file)\n",
    "    image_list = os.listdir(os.path.join(data_dir, 'images'))\n",
    "#     image_list = open(os.path.join(\n",
    "#         FLAGS.data_dir, 'aeroplane_%s.txt' % FLAGS.split)).read().splitlines()\n",
    "    print(f\"Image list loaded: {len(image_list)}\")\n",
    "    for image in tqdm.tqdm(image_list[0: 700]):\n",
    "        name, _ = image.split('.')\n",
    "        annotation_xml = os.path.join(data_dir, 'annotations', name + '.xml')\n",
    "        annotation_xml = lxml.etree.fromstring(open(annotation_xml).read())\n",
    "        annotation = parse_xml(annotation_xml)['annotation']\n",
    "        tf_example = build_example(annotation, class_map)\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "    writer.close()\n",
    "    print(\"Done\")\n",
    "    \n",
    "    \n",
    "def create_valid():\n",
    "    class_map = {name: idx for idx, name in enumerate(open(classes).read().splitlines())}\n",
    "    print(\"Class mapping loaded: \", class_map)\n",
    "\n",
    "    writer = tf.io.TFRecordWriter(valid_output_file)\n",
    "    image_list = os.listdir(os.path.join(data_dir, 'images'))\n",
    "#     image_list = open(os.path.join(\n",
    "#         FLAGS.data_dir, 'aeroplane_%s.txt' % FLAGS.split)).read().splitlines()\n",
    "    print(f\"Image list loaded: {len(image_list)}\")\n",
    "    for image in tqdm.tqdm(image_list[701: ]):\n",
    "        name, _ = image.split('.')\n",
    "        annotation_xml = os.path.join(data_dir, 'annotations', name + '.xml')\n",
    "        annotation_xml = lxml.etree.fromstring(open(annotation_xml).read())\n",
    "        annotation = parse_xml(annotation_xml)['annotation']\n",
    "        tf_example = build_example(annotation, class_map)\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "    writer.close()\n",
    "    print(\"Done\")\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     app.run(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "8zZcx0ki4NIG",
    "outputId": "34c44e29-e543-4c07-ec28-dd6be9d1f932"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 39/700 [00:00<00:01, 389.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class mapping loaded:  {'with_mask': 0, 'without_mask': 1, 'mask_weared_incorrect': 2}\n",
      "Image list loaded: 853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [00:01<00:00, 355.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "create_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "ko4yPURh4NIJ",
    "outputId": "b29bca10-6e2d-4fe3-fd45-1dbbfe485f68"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 39/152 [00:00<00:00, 388.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class mapping loaded:  {'with_mask': 0, 'without_mask': 1, 'mask_weared_incorrect': 2}\n",
      "Image list loaded: 853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [00:00<00:00, 330.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "create_valid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j_3a5Zkq4NIL"
   },
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SdB0f88X4NIM"
   },
   "outputs": [],
   "source": [
    "\n",
    "@tf.function\n",
    "def transform_targets_for_output(y_true, grid_size, anchor_idxs):\n",
    "    # y_true: (N, boxes, (x1, y1, x2, y2, class, best_anchor))\n",
    "    N = tf.shape(y_true)[0]\n",
    "\n",
    "    # y_true_out: (N, grid, grid, anchors, [x, y, w, h, obj, class])\n",
    "    y_true_out = tf.zeros(\n",
    "        (N, grid_size, grid_size, tf.shape(anchor_idxs)[0], 6))\n",
    "\n",
    "    anchor_idxs = tf.cast(anchor_idxs, tf.int32)\n",
    "\n",
    "    indexes = tf.TensorArray(tf.int32, 1, dynamic_size=True)\n",
    "    updates = tf.TensorArray(tf.float32, 1, dynamic_size=True)\n",
    "    idx = 0\n",
    "    for i in tf.range(N):\n",
    "        for j in tf.range(tf.shape(y_true)[1]):\n",
    "            if tf.equal(y_true[i][j][2], 0):\n",
    "                continue\n",
    "            anchor_eq = tf.equal(\n",
    "                anchor_idxs, tf.cast(y_true[i][j][5], tf.int32))\n",
    "\n",
    "            if tf.reduce_any(anchor_eq):\n",
    "                box = y_true[i][j][0:4]\n",
    "                box_xy = (y_true[i][j][0:2] + y_true[i][j][2:4]) / 2\n",
    "\n",
    "                anchor_idx = tf.cast(tf.where(anchor_eq), tf.int32)\n",
    "                grid_xy = tf.cast(box_xy // (1 / grid_size), tf.int32)\n",
    "\n",
    "                # grid[y][x][anchor] = (tx, ty, bw, bh, obj, class)\n",
    "                indexes = indexes.write(\n",
    "                    idx, [i, grid_xy[1], grid_xy[0], anchor_idx[0][0]])\n",
    "                updates = updates.write(\n",
    "                    idx, [box[0], box[1], box[2], box[3], 1, y_true[i][j][4]])\n",
    "                idx += 1\n",
    "\n",
    "    # tf.print(indexes.stack())\n",
    "    # tf.print(updates.stack())\n",
    "\n",
    "    return tf.tensor_scatter_nd_update(\n",
    "        y_true_out, indexes.stack(), updates.stack())\n",
    "\n",
    "\n",
    "def transform_targets(y_train, anchors, anchor_masks, size):\n",
    "    y_outs = []\n",
    "    grid_size = size // 32\n",
    "\n",
    "    # calculate anchor index for true boxes\n",
    "    anchors = tf.cast(anchors, tf.float32)\n",
    "    anchor_area = anchors[..., 0] * anchors[..., 1]\n",
    "    box_wh = y_train[..., 2:4] - y_train[..., 0:2]\n",
    "    box_wh = tf.tile(tf.expand_dims(box_wh, -2),\n",
    "                     (1, 1, tf.shape(anchors)[0], 1))\n",
    "    box_area = box_wh[..., 0] * box_wh[..., 1]\n",
    "    intersection = tf.minimum(box_wh[..., 0], anchors[..., 0]) * \\\n",
    "                   tf.minimum(box_wh[..., 1], anchors[..., 1])\n",
    "    iou = intersection / (box_area + anchor_area - intersection)\n",
    "    anchor_idx = tf.cast(tf.argmax(iou, axis=-1), tf.float32)\n",
    "    anchor_idx = tf.expand_dims(anchor_idx, axis=-1)\n",
    "\n",
    "    y_train = tf.concat([y_train, anchor_idx], axis=-1)\n",
    "\n",
    "    for anchor_idxs in anchor_masks:\n",
    "        y_outs.append(transform_targets_for_output(\n",
    "            y_train, grid_size, anchor_idxs))\n",
    "        grid_size *= 2\n",
    "\n",
    "    return tuple(y_outs)\n",
    "\n",
    "\n",
    "def transform_images(x_train, size):\n",
    "    x_train = tf.image.resize(x_train, (size, size))\n",
    "    x_train = x_train / 255\n",
    "    return x_train\n",
    "\n",
    "\n",
    "IMAGE_FEATURE_MAP = {\n",
    "    # 'image/width': tf.io.FixedLenFeature([], tf.int64),\n",
    "    # 'image/height': tf.io.FixedLenFeature([], tf.int64),\n",
    "    # 'image/filename': tf.io.FixedLenFeature([], tf.string),\n",
    "    # 'image/source_id': tf.io.FixedLenFeature([], tf.string),\n",
    "    # 'image/key/sha256': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "    # 'image/format': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/object/bbox/xmin': tf.io.VarLenFeature(tf.float32),\n",
    "    'image/object/bbox/ymin': tf.io.VarLenFeature(tf.float32),\n",
    "    'image/object/bbox/xmax': tf.io.VarLenFeature(tf.float32),\n",
    "    'image/object/bbox/ymax': tf.io.VarLenFeature(tf.float32),\n",
    "    'image/object/class/text': tf.io.VarLenFeature(tf.string),\n",
    "    # 'image/object/class/label': tf.io.VarLenFeature(tf.int64),\n",
    "    # 'image/object/difficult': tf.io.VarLenFeature(tf.int64),\n",
    "    # 'image/object/truncated': tf.io.VarLenFeature(tf.int64),\n",
    "    # 'image/object/view': tf.io.VarLenFeature(tf.string),\n",
    "}\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def parse_tfrecord(tfrecord, class_table, size):\n",
    "    x = tf.io.parse_single_example(tfrecord, IMAGE_FEATURE_MAP)\n",
    "    x_train = tf.image.decode_png(x['image/encoded'], channels=3)\n",
    "    x_train = tf.image.resize(x_train, (size, size))\n",
    "    \n",
    "    class_text = tf.sparse.to_dense(\n",
    "        x['image/object/class/text'], default_value='')\n",
    "    \n",
    "    labels = tf.cast(class_table.lookup(class_text), tf.float32)\n",
    "    y_train = tf.stack([tf.sparse.to_dense(x['image/object/bbox/xmin']),\n",
    "                        tf.sparse.to_dense(x['image/object/bbox/ymin']),\n",
    "                        tf.sparse.to_dense(x['image/object/bbox/xmax']),\n",
    "                        tf.sparse.to_dense(x['image/object/bbox/ymax']),\n",
    "                        labels], axis=1)\n",
    "    \n",
    "    \n",
    "\n",
    "    paddings = [[0, yolo_max_boxes - tf.shape(y_train)[0]], [0, 0]]\n",
    "    y_train = tf.pad(y_train, paddings)\n",
    "\n",
    "    return x_train, y_train\n",
    "\n",
    "\n",
    "def load_tfrecord_dataset(file_pattern, class_file, size=416):\n",
    "    LINE_NUMBER = -1 #tf.lookup.TextFileIndex.LINE_NUMBER\n",
    "    class_table = tf.lookup.StaticHashTable(tf.lookup.TextFileInitializer(\n",
    "        class_file, tf.string, 0, tf.int64, LINE_NUMBER, delimiter=\"\\n\"), -1)\n",
    "\n",
    "    files = tf.data.Dataset.list_files(file_pattern)\n",
    "    dataset = files.flat_map(tf.data.TFRecordDataset)\n",
    "    return dataset.map(lambda x: parse_tfrecord(x, class_table, size))\n",
    "\n",
    "\n",
    "def load_fake_dataset():\n",
    "    x_train = tf.image.decode_jpeg(\n",
    "        open('./data/girl.png', 'rb').read(), channels=3)\n",
    "    x_train = tf.expand_dims(x_train, axis=0)\n",
    "\n",
    "    labels = [\n",
    "                 [0.18494931, 0.03049111, 0.9435849, 0.96302897, 0],\n",
    "                 [0.01586703, 0.35938117, 0.17582396, 0.6069674, 56],\n",
    "                 [0.09158827, 0.48252046, 0.26967454, 0.6403017, 67]\n",
    "             ] + [[0, 0, 0, 0, 0]] * 5\n",
    "    y_train = tf.convert_to_tensor(labels, tf.float32)\n",
    "    y_train = tf.expand_dims(y_train, axis=0)\n",
    "\n",
    "    return tf.data.Dataset.from_tensor_slices((x_train, y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "id": "vk0V0USJ4NIO",
    "outputId": "aabdbd37-4b40-407e-c087-568f5d232e32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Aug  2 10:49:38 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   55C    P0    29W /  70W |   8797MiB / 15079MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3PXcoh-X4NIZ"
   },
   "outputs": [],
   "source": [
    "dataset = './maskdetection.tfrecord'\n",
    "valid_dataset = './maskdetection_val.tfrecord'\n",
    "weights = './checkpoints/yolov3.tf'\n",
    "size = 416\n",
    "epochs = 100\n",
    "batch_size = 8\n",
    "learning_rate = 1e-3\n",
    "num_classes = 80\n",
    "weights_num_classes = 3\n",
    "classes = './data/faceMask.names'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qy1resxx4NIb"
   },
   "outputs": [],
   "source": [
    "train_dataset = load_tfrecord_dataset(dataset, classes, size)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=512)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "train_dataset = train_dataset.map(lambda x, y: (transform_images(x, size),transform_targets(y, yolo_anchors, yolo_anchor_masks, size)))\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "val_dataset = load_tfrecord_dataset(valid_dataset, classes, size)\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "val_dataset = val_dataset.map(lambda x, y: (transform_images(x, size),transform_targets(y, yolo_anchors, yolo_anchor_masks, size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nh6bxUxI4NIh",
    "outputId": "564424f1-b853-4e5a-9a36-50a4bc571ee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;30;43mStreaming output truncated to the last 5000 lines.\u001B[0m\n",
      "epoch=55_train_batch=15, total_loss=47.890567779541016, pred_loss=[0.09458425, 3.3880534, 32.973553]\n",
      "epoch=55_train_batch=16, total_loss=22.300418853759766, pred_loss=[2.8834703, 1.2638919, 6.7173533]\n",
      "epoch=55_train_batch=17, total_loss=35.065528869628906, pred_loss=[0.592169, 1.5847391, 21.451578]\n",
      "epoch=55_train_batch=18, total_loss=93.72885131835938, pred_loss=[0.84392726, 5.300004, 76.14656]\n",
      "epoch=55_train_batch=19, total_loss=28.29515266418457, pred_loss=[0.9478702, 5.7761936, 10.131464]\n",
      "epoch=55_train_batch=20, total_loss=22.98080062866211, pred_loss=[0.50957155, 1.5605499, 9.469805]\n",
      "epoch=55_train_batch=21, total_loss=16.212730407714844, pred_loss=[0.69437045, 2.3701475, 1.7061177]\n",
      "epoch=55_train_batch=22, total_loss=94.90412139892578, pred_loss=[1.7930624, 3.9480991, 77.71968]\n",
      "epoch=55_train_batch=23, total_loss=99.97195434570312, pred_loss=[0.53911066, 3.649131, 84.3393]\n",
      "epoch=55_train_batch=24, total_loss=26.05355453491211, pred_loss=[1.5903556, 2.9578798, 10.059742]\n",
      "epoch=55_train_batch=25, total_loss=30.496353149414062, pred_loss=[3.2556925, 12.251439, 3.542452]\n",
      "epoch=55_train_batch=26, total_loss=33.71588134765625, pred_loss=[3.5092392, 10.898279, 7.860396]\n",
      "epoch=55_train_batch=27, total_loss=59.995811462402344, pred_loss=[1.0751536, 3.6650393, 43.806488]\n",
      "epoch=55_train_batch=28, total_loss=43.71978759765625, pred_loss=[0.25429246, 9.614963, 22.40025]\n",
      "epoch=55_train_batch=29, total_loss=39.443817138671875, pred_loss=[5.088649, 0.98567235, 21.918072]\n",
      "epoch=55_train_batch=30, total_loss=27.81008529663086, pred_loss=[5.118001, 7.139398, 4.100127]\n",
      "epoch=55_train_batch=31, total_loss=42.976444244384766, pred_loss=[1.5966389, 8.7653475, 21.160757]\n",
      "epoch=55_train_batch=32, total_loss=23.414379119873047, pred_loss=[0.45336425, 9.011422, 2.4947774]\n",
      "epoch=55_train_batch=33, total_loss=24.436630249023438, pred_loss=[2.7644076, 3.2283306, 6.9879847]\n",
      "epoch=55_train_batch=34, total_loss=101.75591278076172, pred_loss=[0.18869501, 8.467757, 81.642494]\n",
      "epoch=55_train_batch=35, total_loss=23.403362274169922, pred_loss=[1.4064846, 4.5725656, 5.966315]\n",
      "epoch=55_train_batch=36, total_loss=23.625717163085938, pred_loss=[1.019151, 3.4114347, 7.736091]\n",
      "epoch=55_train_batch=37, total_loss=24.74609375, pred_loss=[0.22789268, 2.30435, 10.753774]\n",
      "epoch=55_train_batch=38, total_loss=17.458351135253906, pred_loss=[2.3743544, 0.91254675, 2.7103722]\n",
      "epoch=55_train_batch=39, total_loss=21.22933578491211, pred_loss=[0.9899746, 1.6791339, 7.0981874]\n",
      "epoch=55_train_batch=40, total_loss=20.81014060974121, pred_loss=[1.8823196, 4.3807955, 3.08408]\n",
      "epoch=55_train_batch=41, total_loss=26.865253448486328, pred_loss=[0.7740265, 10.006835, 4.620599]\n",
      "epoch=55_train_batch=42, total_loss=35.63605880737305, pred_loss=[0.646374, 10.359638, 13.165473]\n",
      "epoch=55_train_batch=43, total_loss=45.237850189208984, pred_loss=[0.27151948, 3.461578, 30.039469]\n",
      "epoch=55_train_batch=44, total_loss=43.64558410644531, pred_loss=[0.6127209, 9.342476, 22.224428]\n",
      "epoch=55_train_batch=45, total_loss=41.468814849853516, pred_loss=[0.6573602, 3.475434, 25.869427]\n",
      "epoch=55_train_batch=46, total_loss=62.949039459228516, pred_loss=[0.3695778, 9.298982, 41.813263]\n",
      "epoch=55_train_batch=47, total_loss=31.69007110595703, pred_loss=[2.385532, 3.457672, 14.379021]\n",
      "epoch=55_train_batch=48, total_loss=79.67007446289062, pred_loss=[0.13263983, 5.7106404, 62.358307]\n",
      "epoch=55_train_batch=49, total_loss=76.36601257324219, pred_loss=[0.3480614, 6.373351, 58.175472]\n",
      "epoch=55_train_batch=50, total_loss=17.85045623779297, pred_loss=[1.1614568, 3.7863626, 1.4328604]\n",
      "epoch=55_train_batch=51, total_loss=30.593826293945312, pred_loss=[1.4792246, 1.7427261, 15.901438]\n",
      "epoch=55_train_batch=52, total_loss=41.50434112548828, pred_loss=[0.19568737, 1.4556077, 28.381956]\n",
      "epoch=55_train_batch=53, total_loss=32.164886474609375, pred_loss=[1.3621581, 3.2856114, 16.04538]\n",
      "epoch=55_train_batch=54, total_loss=29.848020553588867, pred_loss=[0.54133034, 2.3766356, 15.457663]\n",
      "epoch=55_train_batch=55, total_loss=46.15222930908203, pred_loss=[0.75669885, 3.6585233, 30.263973]\n",
      "epoch=55_train_batch=56, total_loss=46.64222717285156, pred_loss=[0.55363137, 3.6409345, 30.973997]\n",
      "epoch=55_train_batch=57, total_loss=19.926395416259766, pred_loss=[0.9462753, 3.9894106, 3.5164313]\n",
      "epoch=55_train_batch=58, total_loss=27.455698013305664, pred_loss=[0.8639305, 5.9615355, 9.155355]\n",
      "epoch=55_train_batch=59, total_loss=19.567127227783203, pred_loss=[0.7851492, 2.872538, 4.433982]\n",
      "epoch=55_train_batch=60, total_loss=27.32449722290039, pred_loss=[0.8664607, 7.450531, 7.531474]\n",
      "epoch=55_train_batch=61, total_loss=21.259477615356445, pred_loss=[0.8068892, 2.4043522, 6.5716605]\n",
      "epoch=55_train_batch=62, total_loss=50.30333709716797, pred_loss=[0.26105654, 5.605241, 32.959927]\n",
      "epoch=55_train_batch=63, total_loss=50.3880729675293, pred_loss=[3.3808916, 6.2111855, 29.31835]\n",
      "epoch=55_train_batch=64, total_loss=46.04549789428711, pred_loss=[0.3856893, 6.2432594, 27.93836]\n",
      "epoch=55_train_batch=65, total_loss=17.8682918548584, pred_loss=[1.1755958, 4.134883, 1.0791006]\n",
      "epoch=55_train_batch=66, total_loss=37.68998718261719, pred_loss=[0.3899324, 7.952075, 17.868755]\n",
      "epoch=55_train_batch=67, total_loss=38.37737274169922, pred_loss=[0.18535821, 14.383491, 12.328794]\n",
      "epoch=55_train_batch=68, total_loss=69.08515167236328, pred_loss=[1.0782869, 32.679382, 23.84722]\n",
      "epoch=55_train_batch=69, total_loss=18.950714111328125, pred_loss=[0.1219953, 0.9168167, 6.4310246]\n",
      "epoch=55_train_batch=70, total_loss=42.61227798461914, pred_loss=[1.6395645, 17.553925, 11.937239]\n",
      "epoch=55_train_batch=71, total_loss=32.73776626586914, pred_loss=[0.7438079, 7.3770223, 13.134688]\n",
      "epoch=55_train_batch=72, total_loss=32.27301788330078, pred_loss=[0.7255168, 6.275768, 13.788783]\n",
      "epoch=55_train_batch=73, total_loss=26.66863250732422, pred_loss=[0.074672535, 8.4933, 6.6170125]\n",
      "epoch=55_train_batch=74, total_loss=27.679542541503906, pred_loss=[0.46765465, 12.447548, 3.2799993]\n",
      "epoch=55_train_batch=75, total_loss=26.91277313232422, pred_loss=[0.30709293, 2.5702558, 12.550399]\n",
      "epoch=55_train_batch=76, total_loss=56.124366760253906, pred_loss=[0.47769177, 17.617638, 26.54334]\n",
      "epoch=55_train_batch=77, total_loss=17.1689453125, pred_loss=[0.89978427, 1.3639791, 3.418838]\n",
      "epoch=55_train_batch=78, total_loss=45.76213073730469, pred_loss=[0.23246703, 13.539616, 20.503063]\n",
      "epoch=55_train_batch=79, total_loss=34.625587463378906, pred_loss=[0.8562236, 13.426001, 8.85575]\n",
      "epoch=55_train_batch=80, total_loss=22.35102081298828, pred_loss=[1.1713979, 4.3700047, 5.321339]\n",
      "epoch=55_train_batch=81, total_loss=40.72901153564453, pred_loss=[0.12141324, 17.50621, 11.612415]\n",
      "epoch=55_train_batch=82, total_loss=18.997455596923828, pred_loss=[1.3883352, 2.62742, 3.492023]\n",
      "epoch=55_train_batch=83, total_loss=21.716163635253906, pred_loss=[0.39965183, 5.918807, 3.9073339]\n",
      "epoch=55_train_batch=84, total_loss=26.812332153320312, pred_loss=[1.4268366, 4.4601097, 9.434338]\n",
      "epoch=55_train_batch=85, total_loss=19.34174156188965, pred_loss=[2.3069358, 3.8113146, 1.7317901]\n",
      "epoch=55_train_batch=86, total_loss=37.34211730957031, pred_loss=[0.7203953, 20.33213, 4.7972517]\n",
      "epoch=55_train_batch=87, total_loss=17.710899353027344, pred_loss=[0.21120568, 0.7798976, 5.2268515]\n",
      "epoch=55_val_batch=0, total_val_loss=838.70556640625, pred_val_loss[0.25208184, 65.77627, 761.18365]\n",
      "epoch=55_val_batch=1, total_val_loss=268.1002197265625, pred_val_loss[0.45665368, 162.12839, 94.021645]\n",
      "epoch=55_val_batch=2, total_val_loss=84.65457153320312, pred_val_loss[8.552014, 16.92823, 47.68081]\n",
      "epoch=55_val_batch=3, total_val_loss=132.90916442871094, pred_val_loss[4.9025574, 29.313917, 87.19917]\n",
      "epoch=55_val_batch=4, total_val_loss=137.906494140625, pred_val_loss[5.964596, 43.767757, 76.68063]\n",
      "epoch=55_val_batch=5, total_val_loss=70.78842163085938, pred_val_loss[8.009616, 20.212658, 31.072628]\n",
      "epoch=55_val_batch=6, total_val_loss=249.0071258544922, pred_val_loss[21.331234, 12.277659, 203.90471]\n",
      "epoch=55_val_batch=7, total_val_loss=159.0338134765625, pred_val_loss[1.3221893, 56.493916, 89.7242]\n",
      "epoch=55_val_batch=8, total_val_loss=70.43578338623047, pred_val_loss[0.7194573, 48.348904, 9.873911]\n",
      "epoch=55_val_batch=9, total_val_loss=150.27455139160156, pred_val_loss[5.755266, 74.559006, 58.46677]\n",
      "epoch=55_val_batch=10, total_val_loss=135.43832397460938, pred_val_loss[24.47616, 11.108338, 88.360306]\n",
      "epoch=55_val_batch=11, total_val_loss=166.9163055419922, pred_val_loss[13.392997, 69.28004, 72.74976]\n",
      "epoch=55_val_batch=12, total_val_loss=36.03046798706055, pred_val_loss[3.1928458, 10.32937, 11.014738]\n",
      "epoch=55_val_batch=13, total_val_loss=96.29679870605469, pred_val_loss[0.5530789, 40.464977, 43.785225]\n",
      "epoch=55_val_batch=14, total_val_loss=111.80948638916016, pred_val_loss[13.285566, 42.180294, 44.850113]\n",
      "epoch=55_val_batch=15, total_val_loss=95.42881774902344, pred_val_loss[24.201097, 5.5725036, 54.161697]\n",
      "epoch=55_val_batch=16, total_val_loss=216.12062072753906, pred_val_loss[6.058085, 71.330505, 127.238525]\n",
      "epoch=55_val_batch=17, total_val_loss=190.95965576171875, pred_val_loss[18.553904, 17.799639, 143.1126]\n",
      "epoch=55_val_batch=18, total_val_loss=189.8131561279297, pred_val_loss[5.1403484, 46.5287, 126.6506]\n",
      "epoch=55, train: avg_loss=37.805355072021484, val: avg_val_loss=178.98049926757812\n",
      "Saved checkpoint for step 66: ./tf_ckpts/ckpt-65\n",
      "epoch=56_train_batch=0, total_loss=18.61166763305664, pred_loss=[0.9365766, 4.6933455, 1.4882299]\n",
      "epoch=56_train_batch=1, total_loss=17.5577392578125, pred_loss=[1.1677505, 3.0544503, 1.841489]\n",
      "epoch=56_train_batch=2, total_loss=21.86823844909668, pred_loss=[0.12784055, 4.9945126, 5.2513437]\n",
      "epoch=56_train_batch=3, total_loss=20.49676513671875, pred_loss=[0.3017282, 4.7982855, 3.9017613]\n",
      "epoch=56_train_batch=4, total_loss=43.00487518310547, pred_loss=[0.97682947, 2.225162, 28.307493]\n",
      "epoch=56_train_batch=5, total_loss=17.726062774658203, pred_loss=[0.44777012, 1.3003571, 4.48219]\n",
      "epoch=56_train_batch=6, total_loss=21.106658935546875, pred_loss=[0.3209035, 1.1166694, 8.173004]\n",
      "epoch=56_train_batch=7, total_loss=20.558780670166016, pred_loss=[0.93056417, 2.4145682, 5.717251]\n",
      "epoch=56_train_batch=8, total_loss=32.21726608276367, pred_loss=[0.21460316, 4.4629292, 16.043043]\n",
      "epoch=56_train_batch=9, total_loss=20.41094398498535, pred_loss=[0.2600901, 1.7501628, 6.9037294]\n",
      "epoch=56_train_batch=10, total_loss=16.201412200927734, pred_loss=[1.1130009, 1.1156838, 2.4755118]\n",
      "epoch=56_train_batch=11, total_loss=17.654741287231445, pred_loss=[0.89541674, 2.8391528, 2.4227204]\n",
      "epoch=56_train_batch=12, total_loss=15.644424438476562, pred_loss=[0.49329942, 0.8656991, 2.7877598]\n",
      "epoch=56_train_batch=13, total_loss=14.638887405395508, pred_loss=[0.13522427, 1.5349405, 1.4708602]\n",
      "epoch=56_train_batch=14, total_loss=19.86899185180664, pred_loss=[0.7147455, 6.292623, 1.3635836]\n",
      "epoch=56_train_batch=15, total_loss=25.870033264160156, pred_loss=[0.028712524, 5.334485, 9.00865]\n",
      "epoch=56_train_batch=16, total_loss=19.435152053833008, pred_loss=[0.13334164, 3.2712955, 4.5321875]\n",
      "epoch=56_train_batch=17, total_loss=20.417327880859375, pred_loss=[3.8213544, 1.0055877, 4.0919275]\n",
      "epoch=56_train_batch=18, total_loss=21.034626007080078, pred_loss=[1.1877223, 1.557443, 6.7908955]\n",
      "epoch=56_train_batch=19, total_loss=28.868389129638672, pred_loss=[3.9021518, 2.7128797, 10.75469]\n",
      "epoch=56_train_batch=20, total_loss=18.74807357788086, pred_loss=[0.34257954, 2.4287097, 4.4780097]\n",
      "epoch=56_train_batch=21, total_loss=22.33306884765625, pred_loss=[0.65365815, 4.9544516, 5.2260795]\n",
      "epoch=56_train_batch=22, total_loss=18.02255630493164, pred_loss=[0.38704655, 2.762401, 3.3741212]\n",
      "epoch=56_train_batch=23, total_loss=25.3282527923584, pred_loss=[0.20065375, 1.8463666, 11.782148]\n",
      "epoch=56_train_batch=24, total_loss=17.793331146240234, pred_loss=[0.6313285, 2.94016, 2.722678]\n",
      "epoch=56_train_batch=25, total_loss=51.9406852722168, pred_loss=[0.7509335, 28.61369, 11.076829]\n",
      "epoch=56_train_batch=26, total_loss=16.330718994140625, pred_loss=[1.8438113, 1.0009449, 1.9866681]\n",
      "epoch=56_train_batch=27, total_loss=34.02305603027344, pred_loss=[0.5953563, 7.485564, 14.442765]\n",
      "epoch=56_train_batch=28, total_loss=19.337507247924805, pred_loss=[2.9377778, 2.9911606, 1.9090976]\n",
      "epoch=56_train_batch=29, total_loss=22.744277954101562, pred_loss=[0.18020461, 6.2486115, 4.815853]\n",
      "epoch=56_train_batch=30, total_loss=45.5329475402832, pred_loss=[0.69508934, 5.0661087, 28.271984]\n",
      "epoch=56_train_batch=31, total_loss=15.9586181640625, pred_loss=[1.0298347, 1.389333, 2.0395331]\n",
      "epoch=56_train_batch=32, total_loss=16.724132537841797, pred_loss=[0.81647265, 2.6837974, 1.7237947]\n",
      "epoch=56_train_batch=33, total_loss=22.617267608642578, pred_loss=[0.33663383, 5.324155, 5.456259]\n",
      "epoch=56_train_batch=34, total_loss=15.195707321166992, pred_loss=[0.89310914, 2.0436163, 0.75860375]\n",
      "epoch=56_train_batch=35, total_loss=21.479671478271484, pred_loss=[0.8960856, 3.4102664, 5.6727805]\n",
      "epoch=56_train_batch=36, total_loss=19.325942993164062, pred_loss=[0.9354957, 1.1393523, 5.750404]\n",
      "epoch=56_train_batch=37, total_loss=25.534727096557617, pred_loss=[0.33658051, 4.2631984, 9.434113]\n",
      "epoch=56_train_batch=38, total_loss=16.18119239807129, pred_loss=[0.9828702, 2.5765011, 1.120856]\n",
      "epoch=56_train_batch=39, total_loss=34.50338363647461, pred_loss=[0.4772718, 4.719465, 17.805565]\n",
      "epoch=56_train_batch=40, total_loss=20.02098846435547, pred_loss=[1.4065353, 3.165784, 3.9474807]\n",
      "epoch=56_train_batch=41, total_loss=38.59856414794922, pred_loss=[0.46617305, 1.9523734, 24.678722]\n",
      "epoch=56_train_batch=42, total_loss=15.349737167358398, pred_loss=[0.8824369, 1.5381558, 1.427756]\n",
      "epoch=56_train_batch=43, total_loss=26.684223175048828, pred_loss=[1.0700533, 4.2012835, 9.911402]\n",
      "epoch=56_train_batch=44, total_loss=20.618465423583984, pred_loss=[0.14245696, 1.3330295, 7.641409]\n",
      "epoch=56_train_batch=45, total_loss=16.928918838500977, pred_loss=[0.35300806, 0.8741033, 4.2001467]\n",
      "epoch=56_train_batch=46, total_loss=45.01604461669922, pred_loss=[0.02281608, 23.677036, 9.814447]\n",
      "epoch=56_train_batch=47, total_loss=19.545913696289062, pred_loss=[0.21170288, 0.9552621, 6.8771296]\n",
      "epoch=56_train_batch=48, total_loss=15.984503746032715, pred_loss=[0.3829702, 1.4158896, 2.6837413]\n",
      "epoch=56_train_batch=49, total_loss=15.938435554504395, pred_loss=[1.3804387, 1.1893407, 1.8666688]\n",
      "epoch=56_train_batch=50, total_loss=17.804433822631836, pred_loss=[0.20956849, 2.4761548, 3.6166425]\n",
      "epoch=56_train_batch=51, total_loss=15.017638206481934, pred_loss=[0.7804705, 2.0972338, 0.6377834]\n",
      "epoch=56_train_batch=52, total_loss=39.48784255981445, pred_loss=[4.9736657, 5.9461274, 17.065826]\n",
      "epoch=56_train_batch=53, total_loss=22.890094757080078, pred_loss=[0.36621982, 4.910637, 6.1109476]\n",
      "epoch=56_train_batch=54, total_loss=21.689849853515625, pred_loss=[0.29710072, 4.538787, 5.3515534]\n",
      "epoch=56_train_batch=55, total_loss=16.961315155029297, pred_loss=[0.4473554, 2.893502, 2.1178937]\n",
      "epoch=56_train_batch=56, total_loss=16.268970489501953, pred_loss=[0.41673577, 3.8274643, 0.52203584]\n",
      "epoch=56_train_batch=57, total_loss=21.889522552490234, pred_loss=[0.4832592, 3.6910357, 6.212309]\n",
      "epoch=56_train_batch=58, total_loss=19.49117660522461, pred_loss=[1.4996552, 4.555688, 1.9327157]\n",
      "epoch=56_train_batch=59, total_loss=28.627471923828125, pred_loss=[0.3600487, 9.687624, 7.076485]\n",
      "epoch=56_train_batch=60, total_loss=21.397079467773438, pred_loss=[1.031136, 2.1616726, 6.7007523]\n",
      "epoch=56_train_batch=61, total_loss=18.77994155883789, pred_loss=[0.6439541, 4.0575256, 2.5747337]\n",
      "epoch=56_train_batch=62, total_loss=19.36825180053711, pred_loss=[0.15252674, 3.915183, 3.796605]\n",
      "epoch=56_train_batch=63, total_loss=19.44569969177246, pred_loss=[0.49690512, 4.390446, 3.054209]\n",
      "epoch=56_train_batch=64, total_loss=24.378829956054688, pred_loss=[0.68304175, 1.3872514, 10.804199]\n",
      "epoch=56_train_batch=65, total_loss=28.527667999267578, pred_loss=[10.480387, 2.257081, 4.2856836]\n",
      "epoch=56_train_batch=66, total_loss=18.945045471191406, pred_loss=[0.4600935, 2.0065541, 4.9737015]\n",
      "epoch=56_train_batch=67, total_loss=31.604557037353516, pred_loss=[0.25586888, 10.703317, 9.140438]\n",
      "epoch=56_train_batch=68, total_loss=23.64128875732422, pred_loss=[0.12311039, 7.3862057, 4.626773]\n",
      "epoch=56_train_batch=69, total_loss=17.384424209594727, pred_loss=[1.2960145, 1.6837412, 2.8991833]\n",
      "epoch=56_train_batch=70, total_loss=21.020431518554688, pred_loss=[1.1147966, 2.4257119, 5.974129]\n",
      "epoch=56_train_batch=71, total_loss=14.585223197937012, pred_loss=[0.14398864, 1.5652895, 1.3698361]\n",
      "epoch=56_train_batch=72, total_loss=20.60862922668457, pred_loss=[0.24774022, 3.0672889, 5.787184]\n",
      "epoch=56_train_batch=73, total_loss=21.35552215576172, pred_loss=[0.7757783, 2.781769, 6.291268]\n",
      "epoch=56_train_batch=74, total_loss=17.209352493286133, pred_loss=[0.9788834, 2.0807767, 2.6427221]\n",
      "epoch=56_train_batch=75, total_loss=20.27001190185547, pred_loss=[1.0731463, 5.5391593, 2.1504948]\n",
      "epoch=56_train_batch=76, total_loss=23.041091918945312, pred_loss=[0.11609671, 3.6870017, 7.7305436]\n",
      "epoch=56_train_batch=77, total_loss=16.617694854736328, pred_loss=[1.9634224, 0.9896418, 2.1569543]\n",
      "epoch=56_train_batch=78, total_loss=19.639863967895508, pred_loss=[0.23521458, 1.2985338, 6.59824]\n",
      "epoch=56_train_batch=79, total_loss=16.0771427154541, pred_loss=[0.43570334, 2.1205618, 2.0128176]\n",
      "epoch=56_train_batch=80, total_loss=24.959365844726562, pred_loss=[0.82490516, 5.7868066, 6.839431]\n",
      "epoch=56_train_batch=81, total_loss=19.049158096313477, pred_loss=[1.4821186, 2.1741147, 3.8845472]\n",
      "epoch=56_train_batch=82, total_loss=18.70531463623047, pred_loss=[0.8512985, 1.1064692, 5.2390227]\n",
      "epoch=56_train_batch=83, total_loss=16.23765754699707, pred_loss=[0.6286525, 1.9471653, 2.1531808]\n",
      "epoch=56_train_batch=84, total_loss=20.060314178466797, pred_loss=[0.20313172, 1.9894786, 6.358929]\n",
      "epoch=56_train_batch=85, total_loss=17.11314582824707, pred_loss=[0.21344686, 2.6258538, 2.7649763]\n",
      "epoch=56_train_batch=86, total_loss=21.298683166503906, pred_loss=[0.4025826, 4.4704933, 4.9166584]\n",
      "epoch=56_train_batch=87, total_loss=15.471766471862793, pred_loss=[0.10147504, 1.456348, 2.4049332]\n",
      "epoch=56_val_batch=0, total_val_loss=684.968505859375, pred_val_loss[0.24781023, 63.355038, 609.8566]\n",
      "epoch=56_val_batch=1, total_val_loss=208.72076416015625, pred_val_loss[0.058734655, 117.00854, 80.14443]\n",
      "epoch=56_val_batch=2, total_val_loss=78.85582733154297, pred_val_loss[9.434637, 11.289743, 46.622395]\n",
      "epoch=56_val_batch=3, total_val_loss=123.2305679321289, pred_val_loss[5.8679733, 29.553493, 76.30005]\n",
      "epoch=56_val_batch=4, total_val_loss=92.44526672363281, pred_val_loss[6.007422, 22.839317, 52.08947]\n",
      "epoch=56_val_batch=5, total_val_loss=70.7448959350586, pred_val_loss[14.471018, 15.690027, 29.074791]\n",
      "epoch=56_val_batch=6, total_val_loss=224.55792236328125, pred_val_loss[23.819885, 8.0817585, 181.14722]\n",
      "epoch=56_val_batch=7, total_val_loss=143.29336547851562, pred_val_loss[0.86441517, 52.449905, 78.46998]\n",
      "epoch=56_val_batch=8, total_val_loss=53.989112854003906, pred_val_loss[0.44656375, 31.374908, 10.658585]\n",
      "epoch=56_val_batch=9, total_val_loss=125.48319244384766, pred_val_loss[9.009909, 48.73661, 56.22762]\n",
      "epoch=56_val_batch=10, total_val_loss=132.3818817138672, pred_val_loss[31.790613, 13.525881, 75.55633]\n",
      "epoch=56_val_batch=11, total_val_loss=158.1938934326172, pred_val_loss[13.698112, 58.212803, 74.77392]\n",
      "epoch=56_val_batch=12, total_val_loss=26.480194091796875, pred_val_loss[1.9845117, 3.7203674, 9.266258]\n",
      "epoch=56_val_batch=13, total_val_loss=107.85049438476562, pred_val_loss[0.24351326, 38.729805, 57.36812]\n",
      "epoch=56_val_batch=14, total_val_loss=98.8710708618164, pred_val_loss[14.26959, 28.715761, 44.37666]\n",
      "epoch=56_val_batch=15, total_val_loss=92.27507781982422, pred_val_loss[27.446154, 3.9587247, 49.361145]\n",
      "epoch=56_val_batch=16, total_val_loss=205.75, pred_val_loss[12.51305, 60.490437, 121.23746]\n",
      "epoch=56_val_batch=17, total_val_loss=176.895263671875, pred_val_loss[19.595903, 21.687868, 124.102425]\n",
      "epoch=56_val_batch=18, total_val_loss=135.25123596191406, pred_val_loss[1.6643728, 26.178274, 95.89953]\n",
      "epoch=56, train: avg_loss=21.982444763183594, val: avg_val_loss=154.7493896484375\n",
      "Saved checkpoint for step 67: ./tf_ckpts/ckpt-66\n",
      "epoch=57_train_batch=0, total_loss=20.14287567138672, pred_loss=[1.6676714, 1.7795758, 5.186572]\n",
      "epoch=57_train_batch=1, total_loss=22.100351333618164, pred_loss=[0.6937562, 4.164419, 5.7330747]\n",
      "epoch=57_train_batch=2, total_loss=17.34006118774414, pred_loss=[0.23803689, 3.6524377, 1.9404584]\n",
      "epoch=57_train_batch=3, total_loss=16.008878707885742, pred_loss=[0.076648295, 2.9603572, 1.462728]\n",
      "epoch=57_train_batch=4, total_loss=15.180262565612793, pred_loss=[0.074719995, 1.6614314, 1.9349685]\n",
      "epoch=57_train_batch=5, total_loss=16.058359146118164, pred_loss=[0.4190579, 3.697823, 0.4323519]\n",
      "epoch=57_train_batch=6, total_loss=14.739184379577637, pred_loss=[0.28287423, 1.1421818, 1.8050342]\n",
      "epoch=57_train_batch=7, total_loss=17.937658309936523, pred_loss=[0.33893806, 0.85956633, 5.2301016]\n",
      "epoch=57_train_batch=8, total_loss=20.95815658569336, pred_loss=[0.52523947, 3.1104825, 5.813436]\n",
      "epoch=57_train_batch=9, total_loss=15.205414772033691, pred_loss=[0.4396729, 1.2483351, 2.008481]\n",
      "epoch=57_train_batch=10, total_loss=18.995018005371094, pred_loss=[0.48082507, 3.208982, 3.7963624]\n",
      "epoch=57_train_batch=11, total_loss=17.1962890625, pred_loss=[0.5210518, 1.0603304, 4.1061435]\n",
      "epoch=57_train_batch=12, total_loss=16.163389205932617, pred_loss=[0.523795, 2.4528747, 1.678049]\n",
      "epoch=57_train_batch=13, total_loss=13.670538902282715, pred_loss=[0.6590476, 0.79361856, 0.70929635]\n",
      "epoch=57_train_batch=14, total_loss=29.24066925048828, pred_loss=[16.411303, 0.51529425, 0.8055953]\n",
      "epoch=57_train_batch=15, total_loss=31.15709686279297, pred_loss=[12.959378, 3.3904607, 3.29879]\n",
      "epoch=57_train_batch=16, total_loss=27.495800018310547, pred_loss=[0.17686154, 1.7437193, 14.066562]\n",
      "epoch=57_train_batch=17, total_loss=16.65740966796875, pred_loss=[0.27788278, 2.9483824, 1.9221306]\n",
      "epoch=57_train_batch=18, total_loss=17.165233612060547, pred_loss=[3.6037524, 1.3464127, 0.7055931]\n",
      "epoch=57_train_batch=19, total_loss=18.844982147216797, pred_loss=[2.591441, 1.4338396, 3.3097148]\n",
      "epoch=57_train_batch=20, total_loss=25.905813217163086, pred_loss=[5.361512, 1.2258165, 7.807972]\n",
      "epoch=57_train_batch=21, total_loss=24.000808715820312, pred_loss=[7.349653, 2.6473322, 2.4927733]\n",
      "epoch=57_train_batch=22, total_loss=18.135988235473633, pred_loss=[0.35155472, 3.4040704, 2.8687558]\n",
      "epoch=57_train_batch=23, total_loss=18.226316452026367, pred_loss=[1.7595727, 3.1890874, 1.7654692]\n",
      "epoch=57_train_batch=24, total_loss=16.485492706298828, pred_loss=[0.073338896, 3.856125, 1.0432651]\n",
      "epoch=57_train_batch=25, total_loss=18.926136016845703, pred_loss=[0.7840638, 1.8206117, 4.808119]\n",
      "epoch=57_train_batch=26, total_loss=17.154972076416016, pred_loss=[0.91487, 1.0063912, 3.7198076]\n",
      "epoch=57_train_batch=27, total_loss=18.980453491210938, pred_loss=[2.035929, 1.3410299, 4.0890584]\n",
      "epoch=57_train_batch=28, total_loss=18.215057373046875, pred_loss=[3.697598, 0.18725571, 2.815266]\n",
      "epoch=57_train_batch=29, total_loss=17.120567321777344, pred_loss=[1.1447345, 2.3151774, 2.1452472]\n",
      "epoch=57_train_batch=30, total_loss=16.946828842163086, pred_loss=[1.7803564, 1.1382139, 2.5124125]\n",
      "epoch=57_train_batch=31, total_loss=15.417571067810059, pred_loss=[1.5880485, 0.9006978, 1.4125686]\n",
      "epoch=57_train_batch=32, total_loss=34.61307144165039, pred_loss=[2.902201, 3.7211866, 16.47305]\n",
      "epoch=57_train_batch=33, total_loss=24.613800048828125, pred_loss=[0.77934825, 1.467863, 10.849573]\n",
      "epoch=57_train_batch=34, total_loss=17.023462295532227, pred_loss=[2.1509552, 1.0373528, 2.3177648]\n",
      "epoch=57_train_batch=35, total_loss=24.041337966918945, pred_loss=[5.2664533, 2.3124878, 4.944656]\n",
      "epoch=57_train_batch=36, total_loss=16.155319213867188, pred_loss=[0.99874157, 1.1802016, 2.4582927]\n",
      "epoch=57_train_batch=37, total_loss=26.375438690185547, pred_loss=[5.872991, 0.9996526, 7.984377]\n",
      "epoch=57_train_batch=38, total_loss=22.817039489746094, pred_loss=[0.67615163, 0.8114298, 9.810739]\n",
      "epoch=57_train_batch=39, total_loss=18.415918350219727, pred_loss=[1.3096316, 0.39281923, 5.194466]\n",
      "epoch=57_train_batch=40, total_loss=14.801517486572266, pred_loss=[1.2940104, 1.022635, 0.96562165]\n",
      "epoch=57_train_batch=41, total_loss=14.452672958374023, pred_loss=[0.93100595, 1.3427012, 0.65948933]\n",
      "epoch=57_train_batch=42, total_loss=17.28021240234375, pred_loss=[0.66669846, 1.8675511, 3.226284]\n",
      "epoch=57_train_batch=43, total_loss=15.364065170288086, pred_loss=[0.11740804, 0.96721077, 2.7595928]\n",
      "epoch=57_train_batch=44, total_loss=15.918816566467285, pred_loss=[0.4978503, 1.714291, 2.1866698]\n",
      "epoch=57_train_batch=45, total_loss=16.881032943725586, pred_loss=[1.4030964, 2.7197628, 1.2380426]\n",
      "epoch=57_train_batch=46, total_loss=23.1079044342041, pred_loss=[3.3944235, 0.6753807, 7.5178747]\n",
      "epoch=57_train_batch=47, total_loss=15.50269889831543, pred_loss=[0.8389447, 1.1279949, 2.0154567]\n",
      "epoch=57_train_batch=48, total_loss=15.41876220703125, pred_loss=[0.897686, 0.9933846, 2.007329]\n",
      "epoch=57_train_batch=49, total_loss=16.48775291442871, pred_loss=[2.142112, 1.3408213, 1.4844154]\n",
      "epoch=57_train_batch=50, total_loss=15.604394912719727, pred_loss=[0.60443306, 1.2529578, 2.2265797]\n",
      "epoch=57_train_batch=51, total_loss=23.30181121826172, pred_loss=[0.4177879, 1.9077548, 9.455837]\n",
      "epoch=57_train_batch=52, total_loss=17.226001739501953, pred_loss=[1.473168, 1.2630031, 2.9693985]\n",
      "epoch=57_train_batch=53, total_loss=16.658658981323242, pred_loss=[0.99845046, 1.3424524, 2.797338]\n",
      "epoch=57_train_batch=54, total_loss=15.495677947998047, pred_loss=[1.0387871, 0.20286994, 2.733631]\n",
      "epoch=57_train_batch=55, total_loss=16.381237030029297, pred_loss=[0.23588589, 1.7366185, 2.8883805]\n",
      "epoch=57_train_batch=56, total_loss=14.968034744262695, pred_loss=[0.4644208, 0.9564689, 2.0268404]\n",
      "epoch=57_train_batch=57, total_loss=14.131338119506836, pred_loss=[0.7518796, 0.45733485, 1.4018767]\n",
      "epoch=57_train_batch=58, total_loss=15.1460542678833, pred_loss=[0.5282099, 1.2370765, 1.860596]\n",
      "epoch=57_train_batch=59, total_loss=25.594758987426758, pred_loss=[7.5648866, 1.1810827, 5.328703]\n",
      "epoch=57_train_batch=60, total_loss=14.931083679199219, pred_loss=[1.1597718, 0.22136472, 2.0298722]\n",
      "epoch=57_train_batch=61, total_loss=18.236656188964844, pred_loss=[0.24178848, 1.345366, 5.1294193]\n",
      "epoch=57_train_batch=62, total_loss=14.100274085998535, pred_loss=[0.17630282, 0.49997067, 1.9038992]\n",
      "epoch=57_train_batch=63, total_loss=14.328693389892578, pred_loss=[0.45524123, 0.9410151, 1.4123158]\n",
      "epoch=57_train_batch=64, total_loss=16.003738403320312, pred_loss=[0.035066754, 1.9971887, 2.4513426]\n",
      "epoch=57_train_batch=65, total_loss=13.952583312988281, pred_loss=[0.31168365, 1.1862586, 0.93448794]\n",
      "epoch=57_train_batch=66, total_loss=16.80429458618164, pred_loss=[0.46395618, 0.5109832, 4.3092003]\n",
      "epoch=57_train_batch=67, total_loss=15.8112211227417, pred_loss=[0.22126803, 1.8158492, 2.2539606]\n",
      "epoch=57_train_batch=68, total_loss=15.973109245300293, pred_loss=[0.479406, 0.7150574, 3.2585235]\n",
      "epoch=57_train_batch=69, total_loss=17.579635620117188, pred_loss=[0.91956425, 1.4771888, 3.662794]\n",
      "epoch=57_train_batch=70, total_loss=12.669007301330566, pred_loss=[0.19686602, 0.42072028, 0.5313874]\n",
      "epoch=57_train_batch=71, total_loss=17.293865203857422, pred_loss=[0.98932487, 1.2461519, 3.5384212]\n",
      "epoch=57_train_batch=72, total_loss=25.105880737304688, pred_loss=[1.7640963, 2.49187, 9.330032]\n",
      "epoch=57_train_batch=73, total_loss=15.105145454406738, pred_loss=[0.30363232, 1.2741032, 2.0076063]\n",
      "epoch=57_train_batch=74, total_loss=14.304681777954102, pred_loss=[1.8300354, 0.6073051, 0.34762257]\n",
      "epoch=57_train_batch=75, total_loss=14.738895416259766, pred_loss=[0.27072862, 1.3785818, 1.5699694]\n",
      "epoch=57_train_batch=76, total_loss=15.047471046447754, pred_loss=[0.8593275, 0.5999938, 2.0686436]\n",
      "epoch=57_train_batch=77, total_loss=33.58291244506836, pred_loss=[0.07003774, 2.075267, 19.91821]\n",
      "epoch=57_train_batch=78, total_loss=15.949735641479492, pred_loss=[1.3295364, 1.3836223, 1.7172911]\n",
      "epoch=57_train_batch=79, total_loss=15.176166534423828, pred_loss=[0.77417713, 1.2116733, 1.6711528]\n",
      "epoch=57_train_batch=80, total_loss=18.9608211517334, pred_loss=[0.28238487, 1.1288826, 6.0305147]\n",
      "epoch=57_train_batch=81, total_loss=16.154560089111328, pred_loss=[0.67504436, 0.8095554, 3.151045]\n",
      "epoch=57_train_batch=82, total_loss=13.357645034790039, pred_loss=[0.9068952, 0.34119558, 0.5907724]\n",
      "epoch=57_train_batch=83, total_loss=47.83748245239258, pred_loss=[0.515712, 0.669008, 35.134117]\n",
      "epoch=57_train_batch=84, total_loss=15.275789260864258, pred_loss=[0.46185076, 2.623361, 0.6720767]\n",
      "epoch=57_train_batch=85, total_loss=14.288676261901855, pred_loss=[1.1901764, 1.0546261, 0.52551275]\n",
      "epoch=57_train_batch=86, total_loss=16.036880493164062, pred_loss=[0.18502155, 1.4537725, 2.8798637]\n",
      "epoch=57_train_batch=87, total_loss=12.828910827636719, pred_loss=[0.033247914, 0.58464324, 0.69293964]\n",
      "epoch=57_val_batch=0, total_val_loss=661.6499633789062, pred_val_loss[0.3695056, 55.45928, 594.3032]\n",
      "epoch=57_val_batch=1, total_val_loss=203.0514678955078, pred_val_loss[0.19820304, 112.15982, 79.17551]\n",
      "epoch=57_val_batch=2, total_val_loss=77.83058166503906, pred_val_loss[11.8659, 11.582214, 42.86454]\n",
      "epoch=57_val_batch=3, total_val_loss=124.61358642578125, pred_val_loss[5.358392, 22.617397, 85.119865]\n",
      "epoch=57_val_batch=4, total_val_loss=94.86622619628906, pred_val_loss[6.9984975, 23.035938, 53.313866]\n",
      "epoch=57_val_batch=5, total_val_loss=55.14533233642578, pred_val_loss[10.092166, 8.424207, 25.111027]\n",
      "epoch=57_val_batch=6, total_val_loss=212.6947479248047, pred_val_loss[24.98358, 7.737737, 168.4555]\n",
      "epoch=57_val_batch=7, total_val_loss=142.2681121826172, pred_val_loss[0.8797711, 47.683533, 82.186874]\n",
      "epoch=57_val_batch=8, total_val_loss=46.13885498046875, pred_val_loss[0.22470605, 27.3965, 6.9997168]\n",
      "epoch=57_val_batch=9, total_val_loss=116.71131896972656, pred_val_loss[3.5307007, 46.8949, 54.767788]\n",
      "epoch=57_val_batch=10, total_val_loss=124.72383117675781, pred_val_loss[31.344368, 7.2037635, 74.657776]\n",
      "epoch=57_val_batch=11, total_val_loss=148.9451141357422, pred_val_loss[14.910402, 54.46764, 68.04915]\n",
      "epoch=57_val_batch=12, total_val_loss=27.85373306274414, pred_val_loss[0.59982014, 6.055917, 9.680063]\n",
      "epoch=57_val_batch=13, total_val_loss=92.97377014160156, pred_val_loss[0.3275293, 34.719193, 46.40912]\n",
      "epoch=57_val_batch=14, total_val_loss=98.599365234375, pred_val_loss[17.15157, 29.788586, 40.14128]\n",
      "epoch=57_val_batch=15, total_val_loss=84.43032836914062, pred_val_loss[29.18428, 2.2729063, 41.45521]\n",
      "epoch=57_val_batch=16, total_val_loss=198.4980010986328, pred_val_loss[2.7654119, 61.728462, 122.48619]\n",
      "epoch=57_val_batch=17, total_val_loss=154.58270263671875, pred_val_loss[11.542607, 16.704124, 114.81804]\n",
      "epoch=57_val_batch=18, total_val_loss=146.5977325439453, pred_val_loss[4.8591547, 28.438911, 101.78174]\n",
      "epoch=57, train: avg_loss=18.44304656982422, val: avg_val_loss=148.0092010498047\n",
      "Saved checkpoint for step 68: ./tf_ckpts/ckpt-67\n",
      "epoch=58_train_batch=0, total_loss=18.60045623779297, pred_loss=[0.9755193, 0.7606516, 5.346353]\n",
      "epoch=58_train_batch=1, total_loss=14.026689529418945, pred_loss=[0.4989382, 0.78697026, 1.2229956]\n",
      "epoch=58_train_batch=2, total_loss=15.024160385131836, pred_loss=[0.761534, 0.8182537, 1.9267349]\n",
      "epoch=58_train_batch=3, total_loss=13.24191665649414, pred_loss=[0.69019437, 0.38824362, 0.6459952]\n",
      "epoch=58_train_batch=4, total_loss=75.56017303466797, pred_loss=[62.205177, 0.55554676, 1.282127]\n",
      "epoch=58_train_batch=5, total_loss=14.533740997314453, pred_loss=[0.7071253, 0.32532787, 1.9839478]\n",
      "epoch=58_train_batch=6, total_loss=14.44062328338623, pred_loss=[0.7885838, 0.9871882, 1.1469545]\n",
      "epoch=58_train_batch=7, total_loss=14.47456169128418, pred_loss=[0.52546895, 1.6397023, 0.79055566]\n",
      "epoch=58_train_batch=8, total_loss=16.038381576538086, pred_loss=[0.79598373, 1.0350182, 2.687355]\n",
      "epoch=58_train_batch=9, total_loss=14.217384338378906, pred_loss=[1.8736671, 0.42243958, 0.39990258]\n",
      "epoch=58_train_batch=10, total_loss=24.860530853271484, pred_loss=[1.3603388, 0.6095257, 11.3678465]\n",
      "epoch=58_train_batch=11, total_loss=21.250152587890625, pred_loss=[8.214493, 0.7651979, 0.7461602]\n",
      "epoch=58_train_batch=12, total_loss=15.195890426635742, pred_loss=[0.55239874, 2.626267, 0.49143228]\n",
      "epoch=58_train_batch=13, total_loss=14.950864791870117, pred_loss=[1.0864377, 0.58224714, 1.7549143]\n",
      "epoch=58_train_batch=14, total_loss=17.990896224975586, pred_loss=[4.7018223, 0.41351587, 1.3468584]\n",
      "epoch=58_train_batch=15, total_loss=15.993160247802734, pred_loss=[1.451315, 1.0601199, 1.9516344]\n",
      "epoch=58_train_batch=16, total_loss=18.790828704833984, pred_loss=[0.5081362, 1.6598958, 5.0913672]\n",
      "epoch=58_train_batch=17, total_loss=14.019796371459961, pred_loss=[0.9160573, 0.94802165, 0.6230126]\n",
      "epoch=58_train_batch=18, total_loss=17.656240463256836, pred_loss=[1.4918193, 1.4796188, 3.1508884]\n",
      "epoch=58_train_batch=19, total_loss=15.422979354858398, pred_loss=[1.8879352, 0.53225565, 1.4677482]\n",
      "epoch=58_train_batch=20, total_loss=16.639503479003906, pred_loss=[3.737905, 0.49932584, 0.8661818]\n",
      "epoch=58_train_batch=21, total_loss=17.45713996887207, pred_loss=[1.2358834, 1.259168, 3.4250345]\n",
      "epoch=58_train_batch=22, total_loss=14.836883544921875, pred_loss=[1.2447593, 0.4802343, 1.573944]\n",
      "epoch=58_train_batch=23, total_loss=15.177666664123535, pred_loss=[0.37933058, 0.71308076, 2.5464854]\n",
      "epoch=58_train_batch=24, total_loss=16.532155990600586, pred_loss=[2.6889768, 1.8204628, 0.48319352]\n",
      "epoch=58_train_batch=25, total_loss=13.091544151306152, pred_loss=[0.9036258, 0.32079718, 0.3269025]\n",
      "epoch=58_train_batch=26, total_loss=21.809284210205078, pred_loss=[0.70441246, 2.8759198, 6.688092]\n",
      "epoch=58_train_batch=27, total_loss=13.772177696228027, pred_loss=[0.6806989, 0.41954708, 1.1304891]\n",
      "epoch=58_train_batch=28, total_loss=17.273426055908203, pred_loss=[1.5458874, 1.8388354, 2.3467362]\n",
      "epoch=58_train_batch=29, total_loss=16.098628997802734, pred_loss=[1.8744036, 0.43186525, 2.2499251]\n",
      "epoch=58_train_batch=30, total_loss=13.699058532714844, pred_loss=[0.2894159, 1.108869, 0.7579132]\n",
      "epoch=58_train_batch=31, total_loss=15.791847229003906, pred_loss=[1.0431451, 1.0574881, 2.1479635]\n",
      "epoch=58_train_batch=32, total_loss=17.921653747558594, pred_loss=[0.9960952, 1.166983, 4.2149734]\n",
      "epoch=58_train_batch=33, total_loss=14.339395523071289, pred_loss=[0.6956397, 0.5525744, 1.5472682]\n",
      "epoch=58_train_batch=34, total_loss=13.695204734802246, pred_loss=[1.1292012, 0.41561776, 0.60620093]\n",
      "epoch=58_train_batch=35, total_loss=16.9573974609375, pred_loss=[0.07131996, 2.0514348, 3.2902226]\n",
      "epoch=58_train_batch=36, total_loss=18.363075256347656, pred_loss=[1.0292931, 0.72066027, 5.0685005]\n",
      "epoch=58_train_batch=37, total_loss=14.539460182189941, pred_loss=[0.24362504, 1.2201638, 1.5308887]\n",
      "epoch=58_train_batch=38, total_loss=15.216415405273438, pred_loss=[2.3230066, 0.28017658, 1.0683213]\n",
      "epoch=58_train_batch=39, total_loss=22.531753540039062, pred_loss=[0.8755882, 3.6015227, 6.5096345]\n",
      "epoch=58_train_batch=40, total_loss=16.761852264404297, pred_loss=[1.1244725, 0.6120754, 3.4802213]\n",
      "epoch=58_train_batch=41, total_loss=16.181055068969727, pred_loss=[3.062546, 0.68404186, 0.88932306]\n",
      "epoch=58_train_batch=42, total_loss=18.132694244384766, pred_loss=[1.4964869, 2.4323583, 2.6586545]\n",
      "epoch=58_train_batch=43, total_loss=13.790332794189453, pred_loss=[0.5813353, 0.24825692, 1.4154928]\n",
      "epoch=58_train_batch=44, total_loss=18.353069305419922, pred_loss=[0.61552894, 0.7068991, 5.4853454]\n",
      "epoch=58_train_batch=45, total_loss=14.927579879760742, pred_loss=[0.83822066, 1.5370525, 1.0069705]\n",
      "epoch=58_train_batch=46, total_loss=15.248026847839355, pred_loss=[0.5228409, 2.5012126, 0.678606]\n",
      "epoch=58_train_batch=47, total_loss=15.586599349975586, pred_loss=[1.2388958, 0.81071556, 1.9916015]\n",
      "epoch=58_train_batch=48, total_loss=15.712301254272461, pred_loss=[0.12670998, 0.5652956, 3.474903]\n",
      "epoch=58_train_batch=49, total_loss=15.93344783782959, pred_loss=[0.57651615, 0.7216331, 3.089914]\n",
      "epoch=58_train_batch=50, total_loss=17.9798583984375, pred_loss=[0.57356423, 0.5813343, 5.2796]\n",
      "epoch=58_train_batch=51, total_loss=19.28624153137207, pred_loss=[4.3362274, 1.0213876, 2.3833065]\n",
      "epoch=58_train_batch=52, total_loss=18.839679718017578, pred_loss=[5.802583, 0.8381705, 0.65364474]\n",
      "epoch=58_train_batch=53, total_loss=22.01592254638672, pred_loss=[0.11515181, 3.171548, 7.183976]\n",
      "epoch=58_train_batch=54, total_loss=16.02949333190918, pred_loss=[0.29929495, 1.327475, 2.85751]\n",
      "epoch=58_train_batch=55, total_loss=15.11803150177002, pred_loss=[0.10651293, 0.5257766, 2.9405618]\n",
      "epoch=58_train_batch=56, total_loss=19.645248413085938, pred_loss=[0.6027013, 0.6419422, 6.855463]\n",
      "epoch=58_train_batch=57, total_loss=32.5091438293457, pred_loss=[19.395823, 0.20202625, 1.3661993]\n",
      "epoch=58_train_batch=58, total_loss=17.96895980834961, pred_loss=[0.30654883, 1.9121081, 4.2050867]\n",
      "epoch=58_train_batch=59, total_loss=14.329802513122559, pred_loss=[0.20247144, 1.391592, 1.190064]\n",
      "epoch=58_train_batch=60, total_loss=15.227540969848633, pred_loss=[0.7689785, 0.43988448, 2.47231]\n",
      "epoch=58_train_batch=61, total_loss=16.857269287109375, pred_loss=[0.91048414, 0.5547024, 3.8448677]\n",
      "epoch=58_train_batch=62, total_loss=14.586455345153809, pred_loss=[0.63841873, 1.0028625, 1.3970243]\n",
      "epoch=58_train_batch=63, total_loss=24.698667526245117, pred_loss=[7.7216806, 1.2177802, 4.2100763]\n",
      "epoch=58_train_batch=64, total_loss=13.088863372802734, pred_loss=[0.37464347, 0.7991707, 0.36493057]\n",
      "epoch=58_train_batch=65, total_loss=16.1702823638916, pred_loss=[0.08419479, 0.40887794, 4.1260867]\n",
      "epoch=58_train_batch=66, total_loss=16.997360229492188, pred_loss=[3.3925269, 0.8411644, 1.2115575]\n",
      "epoch=58_train_batch=67, total_loss=17.695432662963867, pred_loss=[1.0391021, 1.9437474, 3.1595156]\n",
      "epoch=58_train_batch=68, total_loss=26.34894561767578, pred_loss=[6.799818, 0.72078854, 7.2743497]\n",
      "epoch=58_train_batch=69, total_loss=22.77012062072754, pred_loss=[0.028762247, 1.2223544, 9.964138]\n",
      "epoch=58_train_batch=70, total_loss=19.731040954589844, pred_loss=[3.0123982, 0.6525608, 4.5103717]\n",
      "epoch=58_train_batch=71, total_loss=135.39202880859375, pred_loss=[95.692696, 0.74495006, 27.397873]\n",
      "epoch=58_train_batch=72, total_loss=15.078165054321289, pred_loss=[0.47914132, 0.6237252, 2.417258]\n",
      "epoch=58_train_batch=73, total_loss=14.71595573425293, pred_loss=[1.5986457, 0.5993732, 0.9570129]\n",
      "epoch=58_train_batch=74, total_loss=19.932870864868164, pred_loss=[4.735628, 0.3992598, 3.23326]\n",
      "epoch=58_train_batch=75, total_loss=24.396583557128906, pred_loss=[11.89241, 0.5160484, 0.41898033]\n",
      "epoch=58_train_batch=76, total_loss=19.29903793334961, pred_loss=[6.4443464, 0.48842794, 0.79235756]\n",
      "epoch=58_train_batch=77, total_loss=17.490732192993164, pred_loss=[3.4673026, 0.6856132, 1.7589157]\n",
      "epoch=58_train_batch=78, total_loss=16.519332885742188, pred_loss=[2.7635622, 0.48802757, 1.6837583]\n",
      "epoch=58_train_batch=79, total_loss=28.9814453125, pred_loss=[7.080606, 0.74949074, 9.562296]\n",
      "epoch=58_train_batch=80, total_loss=18.655059814453125, pred_loss=[4.2550263, 1.7852919, 1.0206473]\n",
      "epoch=58_train_batch=81, total_loss=14.95130729675293, pred_loss=[0.36930293, 1.3998617, 1.5830202]\n",
      "epoch=58_train_batch=82, total_loss=26.134775161743164, pred_loss=[12.5004425, 0.5026868, 1.5275865]\n",
      "epoch=58_train_batch=83, total_loss=20.98377227783203, pred_loss=[5.093419, 0.8606998, 3.4206936]\n",
      "epoch=58_train_batch=84, total_loss=18.206308364868164, pred_loss=[2.1624722, 1.8679755, 2.5619915]\n",
      "epoch=58_train_batch=85, total_loss=30.571617126464844, pred_loss=[16.853018, 0.7937733, 1.3061287]\n",
      "epoch=58_train_batch=86, total_loss=18.45927619934082, pred_loss=[2.341421, 0.9612629, 3.5332532]\n",
      "epoch=58_train_batch=87, total_loss=13.812556266784668, pred_loss=[0.65254235, 0.23024008, 1.3019148]\n",
      "epoch=58_val_batch=0, total_val_loss=580.8895874023438, pred_val_loss[1.4341071, 57.910164, 509.9131]\n",
      "epoch=58_val_batch=1, total_val_loss=204.8492431640625, pred_val_loss[1.0525279, 115.08328, 77.08123]\n",
      "epoch=58_val_batch=2, total_val_loss=77.9163589477539, pred_val_loss[16.611551, 10.154657, 39.51795]\n",
      "epoch=58_val_batch=3, total_val_loss=112.18318939208984, pred_val_loss[4.997408, 22.921192, 72.632385]\n",
      "epoch=58_val_batch=4, total_val_loss=90.76753234863281, pred_val_loss[5.9421725, 24.88852, 48.304634]\n",
      "epoch=58_val_batch=5, total_val_loss=66.41736602783203, pred_val_loss[21.448755, 9.141056, 24.195349]\n",
      "epoch=58_val_batch=6, total_val_loss=214.81765747070312, pred_val_loss[35.48247, 8.271556, 159.43143]\n",
      "epoch=58_val_batch=7, total_val_loss=136.9886016845703, pred_val_loss[3.2245903, 49.996548, 72.13526]\n",
      "epoch=58_val_batch=8, total_val_loss=58.07082748413086, pred_val_loss[3.5986366, 33.035057, 9.80493]\n",
      "epoch=58_val_batch=9, total_val_loss=128.84800720214844, pred_val_loss[16.494036, 50.129715, 50.59205]\n",
      "epoch=58_val_batch=10, total_val_loss=140.2070770263672, pred_val_loss[52.73597, 7.4046564, 68.43425]\n",
      "epoch=58_val_batch=11, total_val_loss=167.07058715820312, pred_val_loss[26.991493, 56.813038, 71.63385]\n",
      "epoch=58_val_batch=12, total_val_loss=28.64519500732422, pred_val_loss[2.7675047, 5.789481, 8.456004]\n",
      "epoch=58_val_batch=13, total_val_loss=94.58407592773438, pred_val_loss[0.65903854, 39.200954, 43.09188]\n",
      "epoch=58_val_batch=14, total_val_loss=111.44406127929688, pred_val_loss[26.27565, 29.455194, 44.081013]\n",
      "epoch=58_val_batch=15, total_val_loss=89.32365417480469, pred_val_loss[38.26407, 2.6108856, 36.816494]\n",
      "epoch=58_val_batch=16, total_val_loss=183.5195770263672, pred_val_loss[12.346301, 61.97164, 97.569435]\n",
      "epoch=58_val_batch=17, total_val_loss=158.53887939453125, pred_val_loss[32.51082, 11.472724, 102.92314]\n",
      "epoch=58_val_batch=18, total_val_loss=141.72581481933594, pred_val_loss[7.2973027, 35.58574, 87.21057]\n",
      "epoch=58, train: avg_loss=19.592445373535156, val: avg_val_loss=146.67405700683594\n",
      "Saved checkpoint for step 69: ./tf_ckpts/ckpt-68\n",
      "epoch=59_train_batch=0, total_loss=15.731077194213867, pred_loss=[1.9288805, 0.7412749, 1.4287164]\n",
      "epoch=59_train_batch=1, total_loss=19.08995246887207, pred_loss=[3.4664202, 1.7220957, 2.2651029]\n",
      "epoch=59_train_batch=2, total_loss=17.540132522583008, pred_loss=[4.5225058, 0.4871907, 0.8901819]\n",
      "epoch=59_train_batch=3, total_loss=28.462621688842773, pred_loss=[6.4846854, 0.4032815, 9.930721]\n",
      "epoch=59_train_batch=4, total_loss=16.139362335205078, pred_loss=[2.699208, 0.47236562, 1.3203988]\n",
      "epoch=59_train_batch=5, total_loss=18.765336990356445, pred_loss=[4.607882, 0.8499601, 1.6568707]\n",
      "epoch=59_train_batch=6, total_loss=38.45935821533203, pred_loss=[13.436312, 1.0021803, 12.367201]\n",
      "epoch=59_train_batch=7, total_loss=25.804794311523438, pred_loss=[11.578127, 0.34435838, 2.2257555]\n",
      "epoch=59_train_batch=8, total_loss=14.794973373413086, pred_loss=[0.723299, 1.276108, 1.1363217]\n",
      "epoch=59_train_batch=9, total_loss=18.18617820739746, pred_loss=[2.8320842, 0.61629975, 3.0760345]\n",
      "epoch=59_train_batch=10, total_loss=18.480009078979492, pred_loss=[0.037071474, 2.3470533, 4.4317894]\n",
      "epoch=59_train_batch=11, total_loss=16.011289596557617, pred_loss=[2.541963, 0.7082932, 1.0947859]\n",
      "epoch=59_train_batch=12, total_loss=17.87602996826172, pred_loss=[4.5951996, 0.5113001, 1.1013012]\n",
      "epoch=59_train_batch=13, total_loss=25.760570526123047, pred_loss=[3.653346, 1.00265, 9.43453]\n",
      "epoch=59_train_batch=14, total_loss=27.518253326416016, pred_loss=[14.540216, 0.55163974, 0.75469613]\n",
      "epoch=59_train_batch=15, total_loss=15.183164596557617, pred_loss=[1.467089, 0.31510392, 1.7277716]\n",
      "epoch=59_train_batch=16, total_loss=21.661216735839844, pred_loss=[3.966154, 0.86886334, 5.1516013]\n",
      "epoch=59_train_batch=17, total_loss=18.34178352355957, pred_loss=[1.621774, 0.4856197, 4.5584955]\n",
      "epoch=59_train_batch=18, total_loss=24.899517059326172, pred_loss=[10.752979, 1.2359598, 1.2334882]\n",
      "epoch=59_train_batch=19, total_loss=19.853458404541016, pred_loss=[3.116201, 0.5817725, 4.4772916]\n",
      "epoch=59_train_batch=20, total_loss=18.326004028320312, pred_loss=[3.8635507, 0.43165717, 2.3515859]\n",
      "epoch=59_train_batch=21, total_loss=18.067441940307617, pred_loss=[3.8229969, 0.39086825, 2.1734366]\n",
      "epoch=59_train_batch=22, total_loss=15.410215377807617, pred_loss=[1.5787733, 1.190524, 0.95993596]\n",
      "epoch=59_train_batch=23, total_loss=20.266998291015625, pred_loss=[4.7031803, 0.68383193, 3.198233]\n",
      "epoch=59_train_batch=24, total_loss=25.181119918823242, pred_loss=[1.1748972, 0.73811436, 11.585641]\n",
      "epoch=59_train_batch=25, total_loss=14.778803825378418, pred_loss=[2.141453, 0.4651503, 0.48908168]\n",
      "epoch=59_train_batch=26, total_loss=13.837699890136719, pred_loss=[0.38859183, 0.70719826, 1.0582018]\n",
      "epoch=59_train_batch=27, total_loss=13.57443618774414, pred_loss=[0.6738873, 0.43746305, 0.7788507]\n",
      "epoch=59_train_batch=28, total_loss=15.19433307647705, pred_loss=[1.3396882, 0.59003365, 1.5799093]\n",
      "epoch=59_train_batch=29, total_loss=16.828983306884766, pred_loss=[1.6012377, 0.5637723, 2.978864]\n",
      "epoch=59_train_batch=30, total_loss=16.233396530151367, pred_loss=[3.2692614, 0.804087, 0.47459012]\n",
      "epoch=59_train_batch=31, total_loss=18.245372772216797, pred_loss=[3.9594944, 0.1714536, 2.4286737]\n",
      "epoch=59_train_batch=32, total_loss=17.65262222290039, pred_loss=[3.9085543, 0.70804733, 1.3500254]\n",
      "epoch=59_train_batch=33, total_loss=18.64635467529297, pred_loss=[2.543923, 0.30442303, 4.1118035]\n",
      "epoch=59_train_batch=34, total_loss=16.520265579223633, pred_loss=[3.1063268, 0.39600724, 1.3315365]\n",
      "epoch=59_train_batch=35, total_loss=18.67184829711914, pred_loss=[3.1378932, 1.6380595, 2.2093391]\n",
      "epoch=59_train_batch=36, total_loss=14.345346450805664, pred_loss=[0.7249285, 0.52020663, 1.4135163]\n",
      "epoch=59_train_batch=37, total_loss=15.55845832824707, pred_loss=[1.5903126, 0.8697014, 1.4116278]\n",
      "epoch=59_train_batch=38, total_loss=14.463569641113281, pred_loss=[1.0573318, 0.2954682, 1.4238484]\n",
      "epoch=59_train_batch=39, total_loss=15.709298133850098, pred_loss=[1.0619003, 1.6171539, 1.3432329]\n",
      "epoch=59_train_batch=40, total_loss=15.231422424316406, pred_loss=[0.41063902, 0.5752388, 2.5584674]\n",
      "epoch=59_train_batch=41, total_loss=14.080037117004395, pred_loss=[0.7491817, 0.24437849, 1.3993524]\n",
      "epoch=59_train_batch=42, total_loss=15.530925750732422, pred_loss=[2.0930104, 0.72165513, 1.0291114]\n",
      "epoch=59_train_batch=43, total_loss=14.170943260192871, pred_loss=[0.7974714, 1.1477301, 0.5385834]\n",
      "epoch=59_train_batch=44, total_loss=13.569095611572266, pred_loss=[0.4392045, 0.91260886, 0.53013104]\n",
      "epoch=59_train_batch=45, total_loss=17.594058990478516, pred_loss=[4.0952578, 0.62925607, 1.1824175]\n",
      "epoch=59_train_batch=46, total_loss=22.868003845214844, pred_loss=[3.6746013, 0.1911372, 7.315186]\n",
      "epoch=59_train_batch=47, total_loss=26.493389129638672, pred_loss=[1.2173824, 8.002276, 5.5866976]\n",
      "epoch=59_train_batch=48, total_loss=16.32554054260254, pred_loss=[0.021952715, 0.77291334, 3.843683]\n",
      "epoch=59_train_batch=49, total_loss=16.756502151489258, pred_loss=[3.1343408, 0.3644335, 1.5707823]\n",
      "epoch=59_train_batch=50, total_loss=14.37081527709961, pred_loss=[0.44058183, 0.9503165, 1.2930033]\n",
      "epoch=59_train_batch=51, total_loss=16.728845596313477, pred_loss=[1.4097291, 0.9420595, 2.6901813]\n",
      "epoch=59_train_batch=52, total_loss=17.524560928344727, pred_loss=[3.5358415, 0.79718554, 1.5047076]\n",
      "epoch=59_train_batch=53, total_loss=15.094731330871582, pred_loss=[1.1589775, 0.9476649, 1.3013206]\n",
      "epoch=59_train_batch=54, total_loss=14.562395095825195, pred_loss=[1.0719676, 0.79586244, 1.007859]\n",
      "epoch=59_train_batch=55, total_loss=13.982170104980469, pred_loss=[0.37753567, 0.9362792, 0.9817194]\n",
      "epoch=59_train_batch=56, total_loss=22.871742248535156, pred_loss=[0.33495712, 4.872074, 5.978149]\n",
      "epoch=59_train_batch=57, total_loss=36.032501220703125, pred_loss=[0.5144025, 0.4454221, 23.386204]\n",
      "epoch=59_train_batch=58, total_loss=13.826510429382324, pred_loss=[0.9274735, 0.102598846, 1.1100637]\n",
      "epoch=59_train_batch=59, total_loss=14.785415649414062, pred_loss=[1.0926529, 0.6117161, 1.394777]\n",
      "epoch=59_train_batch=60, total_loss=13.873969078063965, pred_loss=[1.3718312, 0.50021255, 0.31577218]\n",
      "epoch=59_train_batch=61, total_loss=25.656238555908203, pred_loss=[12.257975, 0.727456, 0.9847827]\n",
      "epoch=59_train_batch=62, total_loss=19.911245346069336, pred_loss=[0.03227633, 1.4351203, 6.7579317]\n",
      "epoch=59_train_batch=63, total_loss=17.468090057373047, pred_loss=[0.08755399, 0.8002068, 4.8944306]\n",
      "epoch=59_train_batch=64, total_loss=15.48991584777832, pred_loss=[2.7534292, 0.5583832, 0.49215645]\n",
      "epoch=59_train_batch=65, total_loss=15.955446243286133, pred_loss=[0.64588857, 1.1535821, 2.4699402]\n",
      "epoch=59_train_batch=66, total_loss=14.599893569946289, pred_loss=[1.7106488, 0.30653912, 0.8965528]\n",
      "epoch=59_train_batch=67, total_loss=13.640809059143066, pred_loss=[1.0477164, 0.45198524, 0.45482403]\n",
      "epoch=59_train_batch=68, total_loss=18.027362823486328, pred_loss=[3.642662, 0.28218204, 2.416102]\n",
      "epoch=59_train_batch=69, total_loss=14.446809768676758, pred_loss=[0.4835148, 0.61689365, 1.6598363]\n",
      "epoch=59_train_batch=70, total_loss=15.862277030944824, pred_loss=[0.31739727, 1.6186205, 2.2395535]\n",
      "epoch=59_train_batch=71, total_loss=15.490110397338867, pred_loss=[0.34088585, 0.73079, 2.7315989]\n",
      "epoch=59_train_batch=72, total_loss=16.923503875732422, pred_loss=[1.1215398, 1.0865926, 3.0284173]\n",
      "epoch=59_train_batch=73, total_loss=19.66823387145996, pred_loss=[0.5914341, 2.3775997, 5.0121436]\n",
      "epoch=59_train_batch=74, total_loss=15.788409233093262, pred_loss=[0.95590943, 0.6489227, 2.4964395]\n",
      "epoch=59_train_batch=75, total_loss=17.635631561279297, pred_loss=[1.357559, 1.2187283, 3.3721452]\n",
      "epoch=59_train_batch=76, total_loss=20.703907012939453, pred_loss=[6.478819, 1.0732362, 1.4646153]\n",
      "epoch=59_train_batch=77, total_loss=13.998380661010742, pred_loss=[0.23702031, 1.0727987, 1.0013114]\n",
      "epoch=59_train_batch=78, total_loss=14.163196563720703, pred_loss=[1.1708769, 0.5999966, 0.70507157]\n",
      "epoch=59_train_batch=79, total_loss=15.015437126159668, pred_loss=[2.2773297, 0.5721593, 0.47870475]\n",
      "epoch=59_train_batch=80, total_loss=15.496999740600586, pred_loss=[0.23687035, 1.7317178, 1.8411953]\n",
      "epoch=59_train_batch=81, total_loss=17.134504318237305, pred_loss=[1.4070139, 0.35339192, 3.6869166]\n",
      "epoch=59_train_batch=82, total_loss=18.401565551757812, pred_loss=[5.52069, 0.8901335, 0.3036074]\n",
      "epoch=59_train_batch=83, total_loss=36.09538269042969, pred_loss=[23.320854, 0.49829602, 0.5891639]\n",
      "epoch=59_train_batch=84, total_loss=15.641592025756836, pred_loss=[0.3641991, 0.83828986, 2.7520497]\n",
      "epoch=59_train_batch=85, total_loss=15.754064559936523, pred_loss=[1.0917823, 0.29571652, 2.6794496]\n",
      "epoch=59_train_batch=86, total_loss=14.23678970336914, pred_loss=[1.3760704, 0.4313825, 0.742112]\n",
      "epoch=59_train_batch=87, total_loss=17.526885986328125, pred_loss=[4.7600737, 0.20862359, 0.87082636]\n",
      "epoch=59_val_batch=0, total_val_loss=633.6336669921875, pred_val_loss[0.38605064, 52.76218, 568.7979]\n",
      "epoch=59_val_batch=1, total_val_loss=204.78805541992188, pred_val_loss[0.5871746, 109.671875, 82.84148]\n",
      "epoch=59_val_batch=2, total_val_loss=81.31066131591797, pred_val_loss[9.049521, 13.573923, 46.999687]\n",
      "epoch=59_val_batch=3, total_val_loss=118.63079833984375, pred_val_loss[4.7839465, 25.93672, 76.2226]\n",
      "epoch=59_val_batch=4, total_val_loss=95.54627990722656, pred_val_loss[6.6601076, 23.952557, 53.246086]\n",
      "epoch=59_val_batch=5, total_val_loss=54.10333251953125, pred_val_loss[10.513197, 7.168812, 24.733791]\n",
      "epoch=59_val_batch=6, total_val_loss=214.34375, pred_val_loss[25.662952, 6.22289, 170.77039]\n",
      "epoch=59_val_batch=7, total_val_loss=157.39852905273438, pred_val_loss[4.1681776, 49.833122, 91.7097]\n",
      "epoch=59_val_batch=8, total_val_loss=55.08917999267578, pred_val_loss[2.198814, 31.949408, 9.253433]\n",
      "epoch=59_val_batch=9, total_val_loss=127.66663360595703, pred_val_loss[6.731379, 52.461395, 56.786327]\n",
      "epoch=59_val_batch=10, total_val_loss=129.64663696289062, pred_val_loss[27.568542, 7.900139, 82.49043]\n",
      "epoch=59_val_batch=11, total_val_loss=137.10385131835938, pred_val_loss[5.787827, 53.21811, 66.41039]\n",
      "epoch=59_val_batch=12, total_val_loss=31.284038543701172, pred_val_loss[3.5162854, 6.052081, 10.028143]\n",
      "epoch=59_val_batch=13, total_val_loss=93.36796569824219, pred_val_loss[1.2138554, 34.04377, 46.422813]\n",
      "epoch=59_val_batch=14, total_val_loss=91.06715393066406, pred_val_loss[10.532858, 27.017513, 41.82925]\n",
      "epoch=59_val_batch=15, total_val_loss=78.67317962646484, pred_val_loss[21.833122, 1.0789814, 44.073544]\n",
      "epoch=59_val_batch=16, total_val_loss=197.62603759765625, pred_val_loss[5.809804, 60.63855, 119.49014]\n",
      "epoch=59_val_batch=17, total_val_loss=168.2748565673828, pred_val_loss[18.391401, 15.893314, 122.30261]\n",
      "epoch=59_val_batch=18, total_val_loss=137.16107177734375, pred_val_loss[6.1369843, 27.234602, 92.10196]\n",
      "epoch=59, train: avg_loss=18.10315704345703, val: avg_val_loss=147.7218780517578\n",
      "Saved checkpoint for step 70: ./tf_ckpts/ckpt-69\n",
      "epoch=60_train_batch=0, total_loss=15.870523452758789, pred_loss=[0.01879466, 0.78877234, 3.3754282]\n",
      "epoch=60_train_batch=1, total_loss=14.391914367675781, pred_loss=[0.59390795, 0.8251964, 1.2851187]\n",
      "epoch=60_train_batch=2, total_loss=13.634671211242676, pred_loss=[0.8464594, 0.38994145, 0.7104262]\n",
      "epoch=60_train_batch=3, total_loss=14.309682846069336, pred_loss=[0.46199846, 0.29370832, 1.8659978]\n",
      "epoch=60_train_batch=4, total_loss=15.44416332244873, pred_loss=[2.8098326, 0.38602084, 0.5602187]\n",
      "epoch=60_train_batch=5, total_loss=13.506926536560059, pred_loss=[1.0119644, 0.4483207, 0.35847014]\n",
      "epoch=60_train_batch=6, total_loss=13.50092887878418, pred_loss=[0.49931976, 0.9387442, 0.37463477]\n",
      "epoch=60_train_batch=7, total_loss=14.119478225708008, pred_loss=[0.3583004, 0.5665849, 1.5063248]\n",
      "epoch=60_train_batch=8, total_loss=14.63998794555664, pred_loss=[0.20472482, 0.7233772, 2.0236037]\n",
      "epoch=60_train_batch=9, total_loss=14.080747604370117, pred_loss=[1.7084618, 0.19336592, 0.49064285]\n",
      "epoch=60_train_batch=10, total_loss=13.70576286315918, pred_loss=[1.5195525, 0.19773047, 0.30022842]\n",
      "epoch=60_train_batch=11, total_loss=16.224937438964844, pred_loss=[0.14328808, 0.5168889, 3.876555]\n",
      "epoch=60_train_batch=12, total_loss=13.73071002960205, pred_loss=[0.82802564, 0.3738998, 0.84064204]\n",
      "epoch=60_train_batch=13, total_loss=14.664891242980957, pred_loss=[0.30453086, 0.75003433, 1.9222634]\n",
      "epoch=60_train_batch=14, total_loss=15.108474731445312, pred_loss=[2.076422, 0.5272411, 0.816846]\n",
      "epoch=60_train_batch=15, total_loss=14.214138984680176, pred_loss=[0.6680194, 0.30006272, 1.5582087]\n",
      "epoch=60_train_batch=16, total_loss=14.806626319885254, pred_loss=[1.5802041, 0.67357534, 0.865119]\n",
      "epoch=60_train_batch=17, total_loss=14.343993186950684, pred_loss=[0.9492773, 0.20550942, 1.5016034]\n",
      "epoch=60_train_batch=18, total_loss=13.387295722961426, pred_loss=[0.6345032, 0.45181763, 0.6135041]\n",
      "epoch=60_train_batch=19, total_loss=13.971921920776367, pred_loss=[1.1223991, 0.56347096, 0.5987226]\n",
      "epoch=60_train_batch=20, total_loss=15.182843208312988, pred_loss=[2.0593195, 0.47803032, 0.9583081]\n",
      "epoch=60_train_batch=21, total_loss=15.904930114746094, pred_loss=[1.8608309, 0.21370253, 2.143362]\n",
      "epoch=60_train_batch=22, total_loss=13.934825897216797, pred_loss=[0.71497357, 0.88373196, 0.6492275]\n",
      "epoch=60_train_batch=23, total_loss=13.717771530151367, pred_loss=[0.64462286, 0.7019479, 0.68446195]\n",
      "epoch=60_train_batch=24, total_loss=20.242820739746094, pred_loss=[6.2239285, 0.4267812, 1.9055262]\n",
      "epoch=60_train_batch=25, total_loss=14.090234756469727, pred_loss=[1.514581, 0.22425233, 0.6649858]\n",
      "epoch=60_train_batch=26, total_loss=15.337645530700684, pred_loss=[1.0523763, 0.23687787, 2.3621304]\n",
      "epoch=60_train_batch=27, total_loss=19.597877502441406, pred_loss=[0.5410186, 1.1706562, 6.2000904]\n",
      "epoch=60_train_batch=28, total_loss=20.989524841308594, pred_loss=[1.3270081, 0.40126067, 7.575282]\n",
      "epoch=60_train_batch=29, total_loss=14.917929649353027, pred_loss=[1.3942273, 0.7479138, 1.0899491]\n",
      "epoch=60_train_batch=30, total_loss=15.73345947265625, pred_loss=[1.0997373, 0.62877226, 2.3192418]\n",
      "epoch=60_train_batch=31, total_loss=14.736343383789062, pred_loss=[0.5221133, 1.3496771, 1.1789789]\n",
      "epoch=60_train_batch=32, total_loss=14.120089530944824, pred_loss=[1.2027109, 0.4777616, 0.7541796]\n",
      "epoch=60_train_batch=33, total_loss=13.86548900604248, pred_loss=[1.1921833, 0.5505085, 0.4375013]\n",
      "epoch=60_train_batch=34, total_loss=13.243633270263672, pred_loss=[0.8343025, 0.39844087, 0.32572898]\n",
      "epoch=60_train_batch=35, total_loss=13.462480545043945, pred_loss=[0.6772325, 0.23255804, 0.86766833]\n",
      "epoch=60_train_batch=36, total_loss=14.838401794433594, pred_loss=[1.0854785, 0.5584517, 1.5095967]\n",
      "epoch=60_train_batch=37, total_loss=20.263439178466797, pred_loss=[0.6597994, 0.59230244, 7.3266068]\n",
      "epoch=60_train_batch=38, total_loss=13.039507865905762, pred_loss=[0.56406665, 0.295891, 0.49496847]\n",
      "epoch=60_train_batch=39, total_loss=13.117208480834961, pred_loss=[0.6486308, 0.3895902, 0.39456147]\n",
      "epoch=60_train_batch=40, total_loss=15.06513786315918, pred_loss=[2.1781788, 0.25140432, 0.951293]\n",
      "epoch=60_train_batch=41, total_loss=13.743515014648438, pred_loss=[0.42967206, 0.5583424, 1.0714217]\n",
      "epoch=60_train_batch=42, total_loss=13.895609855651855, pred_loss=[0.72632086, 0.680941, 0.8044584]\n",
      "epoch=60_train_batch=43, total_loss=13.245698928833008, pred_loss=[0.37238634, 0.28873453, 0.900885]\n",
      "epoch=60_train_batch=44, total_loss=44.237770080566406, pred_loss=[31.555399, 0.46633047, 0.5325495]\n",
      "epoch=60_train_batch=45, total_loss=13.463150978088379, pred_loss=[0.47754532, 0.63437855, 0.66787016]\n",
      "epoch=60_train_batch=46, total_loss=14.504655838012695, pred_loss=[1.1670523, 0.12463654, 1.5294247]\n",
      "epoch=60_train_batch=47, total_loss=15.926412582397461, pred_loss=[1.3237059, 0.23540205, 2.683348]\n",
      "epoch=60_train_batch=48, total_loss=17.59156036376953, pred_loss=[4.362405, 0.4455649, 1.0990561]\n",
      "epoch=60_train_batch=49, total_loss=14.756354331970215, pred_loss=[1.8325937, 0.48870274, 0.7498229]\n",
      "epoch=60_train_batch=50, total_loss=15.32379150390625, pred_loss=[2.338367, 0.55198103, 0.7474585]\n",
      "epoch=60_train_batch=51, total_loss=15.806922912597656, pred_loss=[2.273126, 0.49779218, 1.3492379]\n",
      "epoch=60_train_batch=52, total_loss=13.729497909545898, pred_loss=[1.4240298, 0.30354446, 0.31437427]\n",
      "epoch=60_train_batch=53, total_loss=15.795930862426758, pred_loss=[3.356989, 0.30579537, 0.4448289]\n",
      "epoch=60_train_batch=54, total_loss=14.889320373535156, pred_loss=[1.8411735, 0.5872556, 0.7718149]\n",
      "epoch=60_train_batch=55, total_loss=15.66777229309082, pred_loss=[0.2140547, 0.5321659, 3.2317474]\n",
      "epoch=60_train_batch=56, total_loss=30.33208465576172, pred_loss=[1.0957199, 0.66315556, 16.882729]\n",
      "epoch=60_train_batch=57, total_loss=14.765690803527832, pred_loss=[1.3300685, 0.35832703, 1.3861749]\n",
      "epoch=60_train_batch=58, total_loss=13.983905792236328, pred_loss=[0.25171274, 0.42447022, 1.6160185]\n",
      "epoch=60_train_batch=59, total_loss=15.504110336303711, pred_loss=[2.0683756, 0.5790515, 1.1644416]\n",
      "epoch=60_train_batch=60, total_loss=14.842026710510254, pred_loss=[1.4881316, 0.36896414, 1.2922108]\n",
      "epoch=60_train_batch=61, total_loss=14.169145584106445, pred_loss=[0.45861113, 0.54535997, 1.4720367]\n",
      "epoch=60_train_batch=62, total_loss=15.04013729095459, pred_loss=[1.1493204, 0.29853493, 1.8987767]\n",
      "epoch=60_train_batch=63, total_loss=26.830509185791016, pred_loss=[0.364771, 0.6316908, 14.140222]\n",
      "epoch=60_train_batch=64, total_loss=16.607986450195312, pred_loss=[3.2957125, 0.3473368, 1.2708331]\n",
      "epoch=60_train_batch=65, total_loss=13.569751739501953, pred_loss=[0.4350524, 0.5705043, 0.86987317]\n",
      "epoch=60_train_batch=66, total_loss=15.768303871154785, pred_loss=[1.3266004, 0.83629715, 1.9109006]\n",
      "epoch=60_train_batch=67, total_loss=15.821512222290039, pred_loss=[0.5189621, 0.7574402, 2.850469]\n",
      "epoch=60_train_batch=68, total_loss=40.60541915893555, pred_loss=[16.081135, 3.4151053, 9.4144335]\n",
      "epoch=60_train_batch=69, total_loss=13.140649795532227, pred_loss=[0.43362662, 0.4923254, 0.51986086]\n",
      "epoch=60_train_batch=70, total_loss=15.468382835388184, pred_loss=[0.67372674, 0.5111358, 2.5885968]\n",
      "epoch=60_train_batch=71, total_loss=14.07604694366455, pred_loss=[1.8129473, 0.29781973, 0.2702848]\n",
      "epoch=60_train_batch=72, total_loss=13.568963050842285, pred_loss=[0.32795873, 0.9644113, 0.5815476]\n",
      "epoch=60_train_batch=73, total_loss=22.167587280273438, pred_loss=[0.90015244, 0.2567404, 9.315617]\n",
      "epoch=60_train_batch=74, total_loss=15.375814437866211, pred_loss=[1.0041186, 1.1493838, 1.5272138]\n",
      "epoch=60_train_batch=75, total_loss=18.548919677734375, pred_loss=[0.5316802, 2.030784, 4.2913446]\n",
      "epoch=60_train_batch=76, total_loss=13.775564193725586, pred_loss=[0.76807743, 0.28188133, 1.0304996]\n",
      "epoch=60_train_batch=77, total_loss=21.638578414916992, pred_loss=[9.328368, 0.2534489, 0.361678]\n",
      "epoch=60_train_batch=78, total_loss=14.958868026733398, pred_loss=[2.08309, 0.6228241, 0.55793464]\n",
      "epoch=60_train_batch=79, total_loss=14.302797317504883, pred_loss=[0.06283997, 0.5011226, 2.0438561]\n",
      "epoch=60_train_batch=80, total_loss=15.383157730102539, pred_loss=[0.23248795, 0.49345744, 2.9622607]\n",
      "epoch=60_train_batch=81, total_loss=30.54387092590332, pred_loss=[0.41268495, 0.5716995, 17.864557]\n",
      "epoch=60_train_batch=82, total_loss=15.903829574584961, pred_loss=[0.44557533, 1.0990947, 2.6642375]\n",
      "epoch=60_train_batch=83, total_loss=15.45721435546875, pred_loss=[0.4375274, 0.9658469, 2.3589244]\n",
      "epoch=60_train_batch=84, total_loss=13.774575233459473, pred_loss=[0.7136899, 0.87839186, 0.48758593]\n",
      "epoch=60_train_batch=85, total_loss=16.863718032836914, pred_loss=[0.7931149, 1.9097097, 2.466001]\n",
      "epoch=60_train_batch=86, total_loss=27.369487762451172, pred_loss=[0.76966554, 0.976557, 13.928403]\n",
      "epoch=60_train_batch=87, total_loss=12.251497268676758, pred_loss=[0.12341596, 0.29973266, 0.13352518]\n",
      "epoch=60_val_batch=0, total_val_loss=790.8509521484375, pred_val_loss[0.2839276, 55.83482, 723.0374]\n",
      "epoch=60_val_batch=1, total_val_loss=213.0382537841797, pred_val_loss[0.2473821, 117.54014, 83.55595]\n",
      "epoch=60_val_batch=2, total_val_loss=77.38563537597656, pred_val_loss[12.872454, 11.784552, 41.03386]\n",
      "epoch=60_val_batch=3, total_val_loss=117.3650131225586, pred_val_loss[1.9777889, 24.536808, 79.15565]\n",
      "epoch=60_val_batch=4, total_val_loss=89.8316421508789, pred_val_loss[2.674659, 22.93615, 52.52606]\n",
      "epoch=60_val_batch=5, total_val_loss=49.51804733276367, pred_val_loss[11.076861, 7.85625, 18.890165]\n",
      "epoch=60_val_batch=6, total_val_loss=230.83255004882812, pred_val_loss[19.861042, 7.39239, 191.88434]\n",
      "epoch=60_val_batch=7, total_val_loss=147.54689025878906, pred_val_loss[1.5431701, 54.558105, 79.75084]\n",
      "epoch=60_val_batch=8, total_val_loss=52.93412780761719, pred_val_loss[0.39862671, 32.379036, 8.461694]\n",
      "epoch=60_val_batch=9, total_val_loss=122.4657211303711, pred_val_loss[5.7545066, 53.014076, 52.002373]\n",
      "epoch=60_val_batch=10, total_val_loss=127.50750732421875, pred_val_loss[33.984108, 10.951036, 70.877594]\n",
      "epoch=60_val_batch=11, total_val_loss=157.77000427246094, pred_val_loss[12.299973, 61.99823, 71.777016]\n",
      "epoch=60_val_batch=12, total_val_loss=28.078109741210938, pred_val_loss[1.2686758, 4.9218397, 10.192824]\n",
      "epoch=60_val_batch=13, total_val_loss=98.3143539428711, pred_val_loss[0.411169, 39.061996, 47.146416]\n",
      "epoch=60_val_batch=14, total_val_loss=87.70092010498047, pred_val_loss[7.05477, 28.094065, 40.85731]\n",
      "epoch=60_val_batch=15, total_val_loss=70.76786804199219, pred_val_loss[20.324291, 1.493925, 37.25488]\n",
      "epoch=60_val_batch=16, total_val_loss=197.33761596679688, pred_val_loss[7.2012057, 60.336853, 118.10478]\n",
      "epoch=60_val_batch=17, total_val_loss=168.5319366455078, pred_val_loss[18.53064, 15.919731, 122.386795]\n",
      "epoch=60_val_batch=18, total_val_loss=148.20652770996094, pred_val_loss[2.523256, 27.590467, 106.39802]\n",
      "epoch=60, train: avg_loss=16.341447830200195, val: avg_val_loss=156.6307373046875\n",
      "Saved checkpoint for step 71: ./tf_ckpts/ckpt-70\n",
      "epoch=61_train_batch=0, total_loss=14.687353134155273, pred_loss=[2.4260833, 0.14809752, 0.4184004]\n",
      "epoch=61_train_batch=1, total_loss=13.578221321105957, pred_loss=[1.0335128, 0.2864269, 0.5635573]\n",
      "epoch=61_train_batch=2, total_loss=13.359395027160645, pred_loss=[0.3089912, 0.6236058, 0.73213327]\n",
      "epoch=61_train_batch=3, total_loss=21.62933349609375, pred_loss=[0.05481953, 0.72021025, 9.159713]\n",
      "epoch=61_train_batch=4, total_loss=16.842979431152344, pred_loss=[0.5304134, 0.7758226, 3.8422358]\n",
      "epoch=61_train_batch=5, total_loss=15.26910400390625, pred_loss=[0.33849993, 1.7643992, 1.4718019]\n",
      "epoch=61_train_batch=6, total_loss=16.546859741210938, pred_loss=[1.6960006, 0.23838373, 2.9181883]\n",
      "epoch=61_train_batch=7, total_loss=13.49209976196289, pred_loss=[0.7188392, 0.2615585, 0.81753945]\n",
      "epoch=61_train_batch=8, total_loss=15.969979286193848, pred_loss=[1.5137622, 1.0153733, 1.7468157]\n",
      "epoch=61_train_batch=9, total_loss=14.253957748413086, pred_loss=[0.62472284, 0.5742713, 1.361085]\n",
      "epoch=61_train_batch=10, total_loss=13.538227081298828, pred_loss=[1.2300702, 0.15330991, 0.46112832]\n",
      "epoch=61_train_batch=11, total_loss=14.465697288513184, pred_loss=[0.29459038, 0.4128762, 2.0646796]\n",
      "epoch=61_train_batch=12, total_loss=15.847190856933594, pred_loss=[2.689405, 1.2083498, 0.25606605]\n",
      "epoch=61_train_batch=13, total_loss=16.36395835876465, pred_loss=[0.2638796, 3.4029913, 1.0039066]\n",
      "epoch=61_train_batch=14, total_loss=21.784812927246094, pred_loss=[0.2603867, 1.9904696, 7.8409734]\n",
      "epoch=61_train_batch=15, total_loss=14.021636962890625, pred_loss=[0.56987274, 1.0676911, 0.69130135]\n",
      "epoch=61_train_batch=16, total_loss=13.666099548339844, pred_loss=[1.0098609, 0.55295193, 0.41072991]\n",
      "epoch=61_train_batch=17, total_loss=14.489301681518555, pred_loss=[0.8080325, 0.6191634, 1.3697654]\n",
      "epoch=61_train_batch=18, total_loss=14.274415016174316, pred_loss=[1.3351111, 0.47537822, 0.7718059]\n",
      "epoch=61_train_batch=19, total_loss=16.42094612121582, pred_loss=[0.5310614, 0.9793651, 3.2186303]\n",
      "epoch=61_train_batch=20, total_loss=13.825422286987305, pred_loss=[1.0559402, 0.2157661, 0.8620557]\n",
      "epoch=61_train_batch=21, total_loss=14.275788307189941, pred_loss=[0.5473972, 1.285547, 0.7514091]\n",
      "epoch=61_train_batch=22, total_loss=13.367789268493652, pred_loss=[1.1223788, 0.27984822, 0.27435213]\n",
      "epoch=61_train_batch=23, total_loss=13.764883041381836, pred_loss=[0.23231198, 0.5336759, 1.3079082]\n",
      "epoch=61_train_batch=24, total_loss=18.840896606445312, pred_loss=[0.28777412, 0.96108335, 5.9012823]\n",
      "epoch=61_train_batch=25, total_loss=22.1087646484375, pred_loss=[8.480003, 0.5204567, 1.4177839]\n",
      "epoch=61_train_batch=26, total_loss=16.80323028564453, pred_loss=[0.56572056, 1.2196082, 3.3276196]\n",
      "epoch=61_train_batch=27, total_loss=14.530416488647461, pred_loss=[1.7276341, 0.3903574, 0.7223789]\n",
      "epoch=61_train_batch=28, total_loss=13.58706283569336, pred_loss=[0.32945636, 0.830133, 0.73766506]\n",
      "epoch=61_train_batch=29, total_loss=14.10156536102295, pred_loss=[0.4403758, 0.25469908, 1.7169131]\n",
      "epoch=61_train_batch=30, total_loss=15.200719833374023, pred_loss=[0.16521344, 0.40712303, 2.9390316]\n",
      "epoch=61_train_batch=31, total_loss=14.524124145507812, pred_loss=[0.55815315, 0.32487762, 1.951964]\n",
      "epoch=61_train_batch=32, total_loss=13.704601287841797, pred_loss=[0.8839956, 0.76021194, 0.37148523]\n",
      "epoch=61_train_batch=33, total_loss=13.275468826293945, pred_loss=[0.35859925, 0.6354594, 0.59272105]\n",
      "epoch=61_train_batch=34, total_loss=14.217567443847656, pred_loss=[0.2902179, 0.6984403, 1.5404398]\n",
      "epoch=61_train_batch=35, total_loss=19.96287727355957, pred_loss=[6.518063, 0.40314785, 1.3534245]\n",
      "epoch=61_train_batch=36, total_loss=13.362290382385254, pred_loss=[0.77968764, 0.4320806, 0.46248153]\n",
      "epoch=61_train_batch=37, total_loss=13.96650505065918, pred_loss=[0.99140453, 0.1849038, 1.1023555]\n",
      "epoch=61_train_batch=38, total_loss=21.537260055541992, pred_loss=[0.06573885, 0.4657343, 9.318149]\n",
      "epoch=61_train_batch=39, total_loss=13.57365894317627, pred_loss=[0.9198236, 0.5452115, 0.42118713]\n",
      "epoch=61_train_batch=40, total_loss=14.593843460083008, pred_loss=[1.8261815, 0.7956439, 0.2847895]\n",
      "epoch=61_train_batch=41, total_loss=16.088783264160156, pred_loss=[0.7810915, 0.8341329, 2.786558]\n",
      "epoch=61_train_batch=42, total_loss=18.650421142578125, pred_loss=[0.2987219, 0.2589302, 6.405999]\n",
      "epoch=61_train_batch=43, total_loss=13.359806060791016, pred_loss=[0.31264758, 0.6226399, 0.7379812]\n",
      "epoch=61_train_batch=44, total_loss=14.547792434692383, pred_loss=[1.4797589, 0.122852445, 1.2588766]\n",
      "epoch=61_train_batch=45, total_loss=13.647851943969727, pred_loss=[0.7062732, 0.48982948, 0.76567125]\n",
      "epoch=61_train_batch=46, total_loss=13.323348999023438, pred_loss=[0.3370282, 0.50142723, 0.7990463]\n",
      "epoch=61_train_batch=47, total_loss=13.066509246826172, pred_loss=[0.14747801, 0.80568695, 0.42773265]\n",
      "epoch=61_train_batch=48, total_loss=14.210125923156738, pred_loss=[0.034158915, 0.55216897, 1.9384239]\n",
      "epoch=61_train_batch=49, total_loss=19.73586654663086, pred_loss=[0.4797262, 2.357601, 5.2134104]\n",
      "epoch=61_train_batch=50, total_loss=15.889155387878418, pred_loss=[0.6754464, 1.3269362, 2.2018952]\n",
      "epoch=61_train_batch=51, total_loss=14.719781875610352, pred_loss=[1.7228079, 0.33418116, 0.9781708]\n",
      "epoch=61_train_batch=52, total_loss=14.412517547607422, pred_loss=[0.14869612, 0.70048255, 1.8789661]\n",
      "epoch=61_train_batch=53, total_loss=13.773449897766113, pred_loss=[0.78681415, 0.16019033, 1.1423241]\n",
      "epoch=61_train_batch=54, total_loss=14.083619117736816, pred_loss=[0.86674297, 0.36335558, 1.1696529]\n",
      "epoch=61_train_batch=55, total_loss=14.086228370666504, pred_loss=[0.065489024, 0.6421417, 1.6949859]\n",
      "epoch=61_train_batch=56, total_loss=13.549613952636719, pred_loss=[0.38252923, 0.47497758, 1.0087554]\n",
      "epoch=61_train_batch=57, total_loss=26.775047302246094, pred_loss=[0.20143458, 2.0531902, 12.837334]\n",
      "epoch=61_train_batch=58, total_loss=15.128042221069336, pred_loss=[0.08519484, 0.7455963, 2.6144328]\n",
      "epoch=61_train_batch=59, total_loss=14.260540962219238, pred_loss=[0.48737675, 0.47350198, 1.6171136]\n",
      "epoch=61_train_batch=60, total_loss=13.861957550048828, pred_loss=[0.12329757, 0.6133488, 1.4430344]\n",
      "epoch=61_train_batch=61, total_loss=14.107178688049316, pred_loss=[1.2481594, 0.31205964, 0.8649576]\n",
      "epoch=61_train_batch=62, total_loss=16.31589126586914, pred_loss=[2.9791226, 0.50676125, 1.1482854]\n",
      "epoch=61_train_batch=63, total_loss=13.41107177734375, pred_loss=[0.09203106, 0.8504696, 0.78712356]\n",
      "epoch=61_train_batch=64, total_loss=13.277542114257812, pred_loss=[0.8812803, 0.39936244, 0.31572503]\n",
      "epoch=61_train_batch=65, total_loss=27.954124450683594, pred_loss=[0.015738491, 0.6431114, 15.614372]\n",
      "epoch=61_train_batch=66, total_loss=13.190401077270508, pred_loss=[0.45437562, 0.5334822, 0.52191424]\n",
      "epoch=61_train_batch=67, total_loss=15.003973007202148, pred_loss=[0.57543504, 0.5292483, 2.2189276]\n",
      "epoch=61_train_batch=68, total_loss=13.831823348999023, pred_loss=[0.4162826, 0.9711037, 0.76434255]\n",
      "epoch=61_train_batch=69, total_loss=13.28232479095459, pred_loss=[0.18699439, 0.5192429, 0.8962558]\n",
      "epoch=61_train_batch=70, total_loss=20.22777557373047, pred_loss=[0.28721595, 0.4624762, 7.7985163]\n",
      "epoch=61_train_batch=71, total_loss=15.782461166381836, pred_loss=[0.86417377, 0.22067346, 3.018315]\n",
      "epoch=61_train_batch=72, total_loss=17.501182556152344, pred_loss=[0.52945656, 0.31598276, 4.9767156]\n",
      "epoch=61_train_batch=73, total_loss=16.512842178344727, pred_loss=[0.15643004, 2.0363884, 2.6412647]\n",
      "epoch=61_train_batch=74, total_loss=17.42261505126953, pred_loss=[0.11526557, 0.6783578, 4.9505024]\n",
      "epoch=61_train_batch=75, total_loss=14.15871810913086, pred_loss=[0.2736707, 1.1052529, 1.1015716]\n",
      "epoch=61_train_batch=76, total_loss=16.820528030395508, pred_loss=[0.2932164, 0.33041003, 4.518949]\n",
      "epoch=61_train_batch=77, total_loss=14.585250854492188, pred_loss=[0.29725963, 1.7762547, 0.8340503]\n",
      "epoch=61_train_batch=78, total_loss=13.511418342590332, pred_loss=[0.43731767, 0.8942244, 0.5024563]\n",
      "epoch=61_train_batch=79, total_loss=15.270670890808105, pred_loss=[0.23442423, 0.39714238, 2.9619536]\n",
      "epoch=61_train_batch=80, total_loss=15.134393692016602, pred_loss=[0.6545798, 0.19521596, 2.6077182]\n",
      "epoch=61_train_batch=81, total_loss=13.722127914428711, pred_loss=[0.2957908, 1.0722357, 0.67749465]\n",
      "epoch=61_train_batch=82, total_loss=13.312254905700684, pred_loss=[0.48795635, 0.6045233, 0.5434415]\n",
      "epoch=61_train_batch=83, total_loss=14.919042587280273, pred_loss=[1.5790656, 0.5132105, 1.1507101]\n",
      "epoch=61_train_batch=84, total_loss=13.578893661499023, pred_loss=[0.43995982, 0.82820386, 0.6349545]\n",
      "epoch=61_train_batch=85, total_loss=13.036138534545898, pred_loss=[0.31260365, 0.30086628, 0.74717337]\n",
      "epoch=61_train_batch=86, total_loss=13.25326919555664, pred_loss=[0.16738676, 0.5771597, 0.8335094]\n",
      "epoch=61_train_batch=87, total_loss=13.02534294128418, pred_loss=[0.60576195, 0.38148892, 0.3631607]\n",
      "epoch=61_val_batch=0, total_val_loss=679.0906372070312, pred_val_loss[0.38113752, 54.1161, 612.91876]\n",
      "epoch=61_val_batch=1, total_val_loss=208.1766815185547, pred_val_loss[0.34123, 116.00455, 80.15625]\n",
      "epoch=61_val_batch=2, total_val_loss=74.38906860351562, pred_val_loss[11.279611, 11.108875, 40.32593]\n",
      "epoch=61_val_batch=3, total_val_loss=112.79254150390625, pred_val_loss[2.6150389, 23.470028, 75.03282]\n",
      "epoch=61_val_batch=4, total_val_loss=86.01097869873047, pred_val_loss[3.9373267, 23.80677, 46.59223]\n",
      "epoch=61_val_batch=5, total_val_loss=52.537261962890625, pred_val_loss[11.625156, 8.553009, 20.684446]\n",
      "epoch=61_val_batch=6, total_val_loss=211.7252960205078, pred_val_loss[18.456728, 7.8607287, 173.73318]\n",
      "epoch=61_val_batch=7, total_val_loss=145.69471740722656, pred_val_loss[1.6144302, 51.57235, 80.83328]\n",
      "epoch=61_val_batch=8, total_val_loss=55.70167541503906, pred_val_loss[0.66206026, 35.451107, 7.9138556]\n",
      "epoch=61_val_batch=9, total_val_loss=117.85626983642578, pred_val_loss[4.6412344, 52.31288, 49.2275]\n",
      "epoch=61_val_batch=10, total_val_loss=119.53994750976562, pred_val_loss[24.670391, 8.617065, 74.577835]\n",
      "epoch=61_val_batch=11, total_val_loss=160.90866088867188, pred_val_loss[9.092801, 66.46662, 73.67458]\n",
      "epoch=61_val_batch=12, total_val_loss=28.627147674560547, pred_val_loss[0.8478663, 6.0512176, 10.0534115]\n",
      "epoch=61_val_batch=13, total_val_loss=98.88388061523438, pred_val_loss[0.91699135, 40.929638, 45.362595]\n",
      "epoch=61_val_batch=14, total_val_loss=93.01657104492188, pred_val_loss[11.239938, 28.927418, 41.17457]\n",
      "epoch=61_val_batch=15, total_val_loss=72.81315612792969, pred_val_loss[18.304241, 2.4157307, 40.418533]\n",
      "epoch=61_val_batch=16, total_val_loss=197.17019653320312, pred_val_loss[5.5996103, 58.550667, 121.34526]\n",
      "epoch=61_val_batch=17, total_val_loss=157.48529052734375, pred_val_loss[12.738759, 16.433231, 116.63866]\n",
      "epoch=61_val_batch=18, total_val_loss=147.19337463378906, pred_val_loss[4.760833, 29.32133, 101.43656]\n",
      "epoch=61, train: avg_loss=15.3743896484375, val: avg_val_loss=148.4007110595703\n",
      "Saved checkpoint for step 72: ./tf_ckpts/ckpt-71\n",
      "epoch=62_train_batch=0, total_loss=14.768691062927246, pred_loss=[0.27972162, 1.4234202, 1.390898]\n",
      "epoch=62_train_batch=1, total_loss=13.725716590881348, pred_loss=[0.20977269, 0.9751862, 0.86638796]\n",
      "epoch=62_train_batch=2, total_loss=13.844236373901367, pred_loss=[0.43825144, 1.1531031, 0.5787967]\n",
      "epoch=62_train_batch=3, total_loss=15.530008316040039, pred_loss=[0.65597415, 1.2518828, 1.9483514]\n",
      "epoch=62_train_batch=4, total_loss=13.159194946289062, pred_loss=[0.26258177, 0.41202036, 0.81108177]\n",
      "epoch=62_train_batch=5, total_loss=13.620000839233398, pred_loss=[0.3458105, 0.50906825, 1.0919038]\n",
      "epoch=62_train_batch=6, total_loss=12.989546775817871, pred_loss=[0.08672193, 0.7412312, 0.48866907]\n",
      "epoch=62_train_batch=7, total_loss=14.212760925292969, pred_loss=[0.46907273, 1.3934395, 0.67761683]\n",
      "epoch=62_train_batch=8, total_loss=13.390475273132324, pred_loss=[0.10655005, 0.6397882, 0.971803]\n",
      "epoch=62_train_batch=9, total_loss=14.123578071594238, pred_loss=[0.7515998, 0.2678714, 1.4320679]\n",
      "epoch=62_train_batch=10, total_loss=18.36529541015625, pred_loss=[0.46298212, 1.8583428, 4.37223]\n",
      "epoch=62_train_batch=11, total_loss=14.03720474243164, pred_loss=[1.0744507, 0.36759818, 0.9237157]\n",
      "epoch=62_train_batch=12, total_loss=14.563580513000488, pred_loss=[0.3711007, 2.139612, 0.38172042]\n",
      "epoch=62_train_batch=13, total_loss=13.519604682922363, pred_loss=[0.6649703, 0.27784783, 0.905933]\n",
      "epoch=62_train_batch=14, total_loss=13.268695831298828, pred_loss=[0.37634274, 0.1793724, 1.042423]\n",
      "epoch=62_train_batch=15, total_loss=16.36919593811035, pred_loss=[0.45756105, 0.38483375, 3.8565364]\n",
      "epoch=62_train_batch=16, total_loss=13.512432098388672, pred_loss=[0.1558967, 0.770947, 0.91562223]\n",
      "epoch=62_train_batch=17, total_loss=14.139774322509766, pred_loss=[0.06393225, 1.9295659, 0.47660953]\n",
      "epoch=62_train_batch=18, total_loss=14.274101257324219, pred_loss=[0.039861858, 1.0488241, 1.5160491]\n",
      "epoch=62_train_batch=19, total_loss=13.78103256225586, pred_loss=[0.43771288, 0.30918467, 1.3650665]\n",
      "epoch=62_train_batch=20, total_loss=12.985953330993652, pred_loss=[0.16188875, 0.7003088, 0.45498753]\n",
      "epoch=62_train_batch=21, total_loss=14.575416564941406, pred_loss=[1.1868696, 0.8930457, 0.82703227]\n",
      "epoch=62_train_batch=22, total_loss=17.966384887695312, pred_loss=[0.639144, 0.83704716, 4.8220296]\n",
      "epoch=62_train_batch=23, total_loss=13.93250846862793, pred_loss=[0.5267296, 0.7242679, 1.0136509]\n",
      "epoch=62_train_batch=24, total_loss=13.052452087402344, pred_loss=[0.14014444, 0.8527487, 0.39200303]\n",
      "epoch=62_train_batch=25, total_loss=12.926549911499023, pred_loss=[0.34545437, 0.3301351, 0.5837091]\n",
      "epoch=62_train_batch=26, total_loss=15.089605331420898, pred_loss=[0.121941105, 1.0543797, 2.2463393]\n",
      "epoch=62_train_batch=27, total_loss=16.01593780517578, pred_loss=[0.63097894, 0.6061406, 3.1121795]\n",
      "epoch=62_train_batch=28, total_loss=13.330820083618164, pred_loss=[0.4806264, 0.8399325, 0.34392658]\n",
      "epoch=62_train_batch=29, total_loss=14.510510444641113, pred_loss=[0.2723035, 0.41922215, 2.1529555]\n",
      "epoch=62_train_batch=30, total_loss=21.651941299438477, pred_loss=[9.020436, 0.48697257, 0.47880965]\n",
      "epoch=62_train_batch=31, total_loss=13.5762939453125, pred_loss=[0.026102971, 0.8631079, 1.0216442]\n",
      "epoch=62_train_batch=32, total_loss=14.01896858215332, pred_loss=[0.45890486, 0.58948565, 1.3054186]\n",
      "epoch=62_train_batch=33, total_loss=13.744304656982422, pred_loss=[0.39801988, 0.5589637, 1.1224376]\n",
      "epoch=62_train_batch=34, total_loss=18.186203002929688, pred_loss=[0.3097841, 2.2263336, 3.9854774]\n",
      "epoch=62_train_batch=35, total_loss=14.249330520629883, pred_loss=[0.87746686, 0.9679343, 0.739594]\n",
      "epoch=62_train_batch=36, total_loss=13.825325012207031, pred_loss=[0.44098398, 0.26333576, 1.4569509]\n",
      "epoch=62_train_batch=37, total_loss=16.840085983276367, pred_loss=[0.40090126, 1.4527161, 3.3226936]\n",
      "epoch=62_train_batch=38, total_loss=13.155112266540527, pred_loss=[0.47579, 0.55982435, 0.4560055]\n",
      "epoch=62_train_batch=39, total_loss=13.941871643066406, pred_loss=[1.359478, 0.6439981, 0.27518797]\n",
      "epoch=62_train_batch=40, total_loss=15.404346466064453, pred_loss=[0.13816313, 1.8009053, 1.8023583]\n",
      "epoch=62_train_batch=41, total_loss=12.80484676361084, pred_loss=[0.22150551, 0.4930777, 0.42762846]\n",
      "epoch=62_train_batch=42, total_loss=13.10838508605957, pred_loss=[0.6548761, 0.2257093, 0.56545335]\n",
      "epoch=62_train_batch=43, total_loss=13.068073272705078, pred_loss=[0.3531882, 0.6541195, 0.3987062]\n",
      "epoch=62_train_batch=44, total_loss=13.210226058959961, pred_loss=[0.1964335, 1.1073179, 0.24470474]\n",
      "epoch=62_train_batch=45, total_loss=13.506438255310059, pred_loss=[0.419304, 0.8011687, 0.6244873]\n",
      "epoch=62_train_batch=46, total_loss=13.390299797058105, pred_loss=[0.34134477, 0.79354143, 0.5942321]\n",
      "epoch=62_train_batch=47, total_loss=13.167387008666992, pred_loss=[0.25429788, 0.28556547, 0.96664095]\n",
      "epoch=62_train_batch=48, total_loss=13.298286437988281, pred_loss=[0.33812615, 0.4640037, 0.8355736]\n",
      "epoch=62_train_batch=49, total_loss=12.671348571777344, pred_loss=[0.41225243, 0.1946742, 0.40414408]\n",
      "epoch=62_train_batch=50, total_loss=13.345680236816406, pred_loss=[0.15614165, 0.7209229, 0.808645]\n",
      "epoch=62_train_batch=51, total_loss=13.06630802154541, pred_loss=[0.45533773, 0.4053393, 0.5459687]\n",
      "epoch=62_train_batch=52, total_loss=14.34705924987793, pred_loss=[0.03738822, 1.456298, 1.1940222]\n",
      "epoch=62_train_batch=53, total_loss=12.987606048583984, pred_loss=[0.29749116, 0.5419214, 0.48915693]\n",
      "epoch=62_train_batch=54, total_loss=12.729557037353516, pred_loss=[0.3761716, 0.3151309, 0.379534]\n",
      "epoch=62_train_batch=55, total_loss=13.148422241210938, pred_loss=[0.12306715, 0.31189102, 1.0550604]\n",
      "epoch=62_train_batch=56, total_loss=16.68216896057129, pred_loss=[0.26224467, 1.1819594, 3.5798786]\n",
      "epoch=62_train_batch=57, total_loss=13.30176830291748, pred_loss=[0.2524801, 0.100884296, 1.2906392]\n",
      "epoch=62_train_batch=58, total_loss=14.656118392944336, pred_loss=[0.3342709, 0.35810965, 2.3062952]\n",
      "epoch=62_train_batch=59, total_loss=12.642741203308105, pred_loss=[0.11379014, 0.3205842, 0.55124205]\n",
      "epoch=62_train_batch=60, total_loss=13.389482498168945, pred_loss=[0.26403698, 0.59015894, 0.87848175]\n",
      "epoch=62_train_batch=61, total_loss=12.85350513458252, pred_loss=[0.24333853, 0.45770195, 0.4959799]\n",
      "epoch=62_train_batch=62, total_loss=15.303348541259766, pred_loss=[2.493266, 0.3631098, 0.7908083]\n",
      "epoch=62_train_batch=63, total_loss=13.51998519897461, pred_loss=[0.109718315, 0.40065992, 1.3537693]\n",
      "epoch=62_train_batch=64, total_loss=13.615360260009766, pred_loss=[0.07234155, 1.0327579, 0.8547448]\n",
      "epoch=62_train_batch=65, total_loss=13.3302640914917, pred_loss=[0.4838483, 0.82942694, 0.36179733]\n",
      "epoch=62_train_batch=66, total_loss=13.135713577270508, pred_loss=[0.11683448, 0.78011394, 0.58389616]\n",
      "epoch=62_train_batch=67, total_loss=17.944339752197266, pred_loss=[0.28638506, 0.41995502, 5.5834517]\n",
      "epoch=62_train_batch=68, total_loss=12.997642517089844, pred_loss=[0.7059828, 0.32125258, 0.31618547]\n",
      "epoch=62_train_batch=69, total_loss=13.505035400390625, pred_loss=[0.08819129, 0.43938044, 1.3235631]\n",
      "epoch=62_train_batch=70, total_loss=13.621257781982422, pred_loss=[0.6631945, 0.37905002, 0.9254315]\n",
      "epoch=62_train_batch=71, total_loss=13.168099403381348, pred_loss=[0.22707348, 0.3797968, 0.907964]\n",
      "epoch=62_train_batch=72, total_loss=13.310111999511719, pred_loss=[0.23350702, 0.32265288, 1.101003]\n",
      "epoch=62_train_batch=73, total_loss=15.874338150024414, pred_loss=[0.20596923, 1.090451, 2.9252844]\n",
      "epoch=62_train_batch=74, total_loss=13.722886085510254, pred_loss=[0.26633024, 0.43863848, 1.3655993]\n",
      "epoch=62_train_batch=75, total_loss=13.150062561035156, pred_loss=[0.42100263, 0.1645484, 0.91251004]\n",
      "epoch=62_train_batch=76, total_loss=13.455000877380371, pred_loss=[0.5740566, 0.662951, 0.5663096]\n",
      "epoch=62_train_batch=77, total_loss=12.802434921264648, pred_loss=[0.48073164, 0.32165462, 0.34868306]\n",
      "epoch=62_train_batch=78, total_loss=13.494367599487305, pred_loss=[0.19278562, 0.20370224, 1.4468342]\n",
      "epoch=62_train_batch=79, total_loss=12.875730514526367, pred_loss=[0.31559438, 0.11755966, 0.79185236]\n",
      "epoch=62_train_batch=80, total_loss=14.159265518188477, pred_loss=[0.08170324, 0.29081374, 2.1363442]\n",
      "epoch=62_train_batch=81, total_loss=12.826374053955078, pred_loss=[0.2469194, 0.19490732, 0.73446536]\n",
      "epoch=62_train_batch=82, total_loss=12.452102661132812, pred_loss=[0.32655156, 0.25976455, 0.21602961]\n",
      "epoch=62_train_batch=83, total_loss=14.009859085083008, pred_loss=[0.14911968, 1.7734752, 0.43783212]\n",
      "epoch=62_train_batch=84, total_loss=13.5643949508667, pred_loss=[0.053921677, 0.43513075, 1.4262366]\n",
      "epoch=62_train_batch=85, total_loss=14.538347244262695, pred_loss=[0.4918643, 0.09181893, 2.305883]\n",
      "epoch=62_train_batch=86, total_loss=13.216743469238281, pred_loss=[0.60449934, 0.5791849, 0.38460323]\n",
      "epoch=62_train_batch=87, total_loss=12.70045280456543, pred_loss=[0.46534255, 0.3080423, 0.2789381]\n",
      "epoch=62_val_batch=0, total_val_loss=694.4421997070312, pred_val_loss[0.3115235, 53.158302, 629.3245]\n",
      "epoch=62_val_batch=1, total_val_loss=201.66664123535156, pred_val_loss[0.24877384, 109.37752, 80.39255]\n",
      "epoch=62_val_batch=2, total_val_loss=75.43730163574219, pred_val_loss[9.855874, 11.636741, 42.29688]\n",
      "epoch=62_val_batch=3, total_val_loss=116.67247009277344, pred_val_loss[2.1781592, 21.608072, 81.238434]\n",
      "epoch=62_val_batch=4, total_val_loss=89.63216400146484, pred_val_loss[3.784678, 25.693129, 48.50655]\n",
      "epoch=62_val_batch=5, total_val_loss=54.99723434448242, pred_val_loss[13.000408, 8.372912, 21.976103]\n",
      "epoch=62_val_batch=6, total_val_loss=209.52394104003906, pred_val_loss[17.271347, 7.780605, 172.82417]\n",
      "epoch=62_val_batch=7, total_val_loss=149.6566619873047, pred_val_loss[0.78965116, 49.25978, 87.95942]\n",
      "epoch=62_val_batch=8, total_val_loss=52.00247573852539, pred_val_loss[0.33391988, 30.773031, 9.247716]\n",
      "epoch=62_val_batch=9, total_val_loss=122.18048858642578, pred_val_loss[4.3930736, 51.888367, 54.25124]\n",
      "epoch=62_val_batch=10, total_val_loss=130.01495361328125, pred_val_loss[29.601038, 8.14794, 80.61817]\n",
      "epoch=62_val_batch=11, total_val_loss=145.04351806640625, pred_val_loss[7.6168113, 60.490303, 65.28859]\n",
      "epoch=62_val_batch=12, total_val_loss=26.714385986328125, pred_val_loss[0.72427803, 5.832993, 8.509308]\n",
      "epoch=62_val_batch=13, total_val_loss=92.47493743896484, pred_val_loss[0.22193176, 37.00543, 43.59977]\n",
      "epoch=62_val_batch=14, total_val_loss=96.80970001220703, pred_val_loss[12.527444, 27.332012, 45.302444]\n",
      "epoch=62_val_batch=15, total_val_loss=73.4029769897461, pred_val_loss[18.268715, 1.3634903, 42.122963]\n",
      "epoch=62_val_batch=16, total_val_loss=199.9742889404297, pred_val_loss[6.670727, 60.02922, 121.62652]\n",
      "epoch=62_val_batch=17, total_val_loss=155.94422912597656, pred_val_loss[11.507286, 14.396877, 118.39225]\n",
      "epoch=62_val_batch=18, total_val_loss=148.72286987304688, pred_val_loss[3.4969726, 31.51256, 102.06553]\n",
      "epoch=62, train: avg_loss=14.043686866760254, val: avg_val_loss=149.22703552246094\n",
      "Saved checkpoint for step 73: ./tf_ckpts/ckpt-72\n",
      "epoch=63_train_batch=0, total_loss=12.996357917785645, pred_loss=[0.35999665, 0.65248203, 0.3360722]\n",
      "epoch=63_train_batch=1, total_loss=12.966817855834961, pred_loss=[0.5337173, 0.5114412, 0.27417988]\n",
      "epoch=63_train_batch=2, total_loss=14.841581344604492, pred_loss=[0.35098553, 1.404762, 1.4386773]\n",
      "epoch=63_train_batch=3, total_loss=13.199254989624023, pred_loss=[0.48359352, 0.41765308, 0.6511754]\n",
      "epoch=63_train_batch=4, total_loss=13.739309310913086, pred_loss=[0.2383349, 0.4103852, 1.4440795]\n",
      "epoch=63_train_batch=5, total_loss=12.797959327697754, pred_loss=[0.21728858, 0.48386383, 0.4506213]\n",
      "epoch=63_train_batch=6, total_loss=13.114221572875977, pred_loss=[0.18514672, 0.83020264, 0.45300728]\n",
      "epoch=63_train_batch=7, total_loss=12.662938117980957, pred_loss=[0.42650896, 0.06942397, 0.5214659]\n",
      "epoch=63_train_batch=8, total_loss=14.241395950317383, pred_loss=[0.25956306, 1.5194556, 0.81716293]\n",
      "epoch=63_train_batch=9, total_loss=13.741259574890137, pred_loss=[0.09485186, 0.7781722, 1.223347]\n",
      "epoch=63_train_batch=10, total_loss=14.262585639953613, pred_loss=[0.24897745, 1.107753, 1.2612927]\n",
      "epoch=63_train_batch=11, total_loss=12.823294639587402, pred_loss=[0.11107375, 0.5514365, 0.516548]\n",
      "epoch=63_train_batch=12, total_loss=13.18212604522705, pred_loss=[0.14986968, 0.28509927, 1.1032486]\n",
      "epoch=63_train_batch=13, total_loss=12.86572551727295, pred_loss=[0.1751757, 0.5581939, 0.48877537]\n",
      "epoch=63_train_batch=14, total_loss=12.581053733825684, pred_loss=[0.25835326, 0.32267794, 0.35677093]\n",
      "epoch=63_train_batch=15, total_loss=13.30663776397705, pred_loss=[0.0690473, 1.1878046, 0.40686345]\n",
      "epoch=63_train_batch=16, total_loss=13.270493507385254, pred_loss=[0.12013386, 0.48110348, 1.0266657]\n",
      "epoch=63_train_batch=17, total_loss=12.603801727294922, pred_loss=[0.1996395, 0.18585947, 0.57604367]\n",
      "epoch=63_train_batch=18, total_loss=12.825108528137207, pred_loss=[0.114167176, 0.1505102, 0.9185028]\n",
      "epoch=63_train_batch=19, total_loss=12.978195190429688, pred_loss=[0.13103753, 0.26748896, 0.93807447]\n",
      "epoch=63_train_batch=20, total_loss=13.112074851989746, pred_loss=[0.24978761, 0.75797415, 0.4630512]\n",
      "epoch=63_train_batch=21, total_loss=12.954038619995117, pred_loss=[0.14523587, 0.5283081, 0.63956547]\n",
      "epoch=63_train_batch=22, total_loss=13.710615158081055, pred_loss=[0.36148652, 0.38347992, 1.3250564]\n",
      "epoch=63_train_batch=23, total_loss=12.767251014709473, pred_loss=[0.047857627, 0.2441482, 0.8349875]\n",
      "epoch=63_train_batch=24, total_loss=12.588841438293457, pred_loss=[0.17201272, 0.30147856, 0.4754297]\n",
      "epoch=63_train_batch=25, total_loss=13.942157745361328, pred_loss=[0.29503992, 0.6808811, 1.3266529]\n",
      "epoch=63_train_batch=26, total_loss=12.488680839538574, pred_loss=[0.09115746, 0.41473714, 0.34353822]\n",
      "epoch=63_train_batch=27, total_loss=13.070427894592285, pred_loss=[0.2250295, 0.8292788, 0.37720758]\n",
      "epoch=63_train_batch=28, total_loss=12.719074249267578, pred_loss=[0.438513, 0.34213448, 0.29985]\n",
      "epoch=63_train_batch=29, total_loss=12.538159370422363, pred_loss=[0.11538498, 0.25963032, 0.5249036]\n",
      "epoch=63_train_batch=30, total_loss=12.593822479248047, pred_loss=[0.17671667, 0.39469093, 0.384512]\n",
      "epoch=63_train_batch=31, total_loss=13.1105375289917, pred_loss=[0.121218696, 0.5801268, 0.77162725]\n",
      "epoch=63_train_batch=32, total_loss=15.178749084472656, pred_loss=[0.21705882, 0.30377644, 3.0206883]\n",
      "epoch=63_train_batch=33, total_loss=13.156045913696289, pred_loss=[0.5278844, 0.41102248, 0.5802486]\n",
      "epoch=63_train_batch=34, total_loss=14.048172950744629, pred_loss=[0.19430093, 0.51950306, 1.6978164]\n",
      "epoch=63_train_batch=35, total_loss=12.998332977294922, pred_loss=[0.18470776, 0.71921825, 0.45819283]\n",
      "epoch=63_train_batch=36, total_loss=12.497808456420898, pred_loss=[0.1556501, 0.18551496, 0.5207683]\n",
      "epoch=63_train_batch=37, total_loss=12.982885360717773, pred_loss=[0.15832256, 0.1764096, 1.0126193]\n",
      "epoch=63_train_batch=38, total_loss=13.13200855255127, pred_loss=[0.2329636, 0.26033443, 1.0035163]\n",
      "epoch=63_train_batch=39, total_loss=13.464879035949707, pred_loss=[0.1198132, 0.90334135, 0.8068714]\n",
      "epoch=63_train_batch=40, total_loss=14.997424125671387, pred_loss=[0.013257512, 0.47680342, 2.8728514]\n",
      "epoch=63_train_batch=41, total_loss=13.242439270019531, pred_loss=[0.7956775, 0.18542439, 0.62716675]\n",
      "epoch=63_train_batch=42, total_loss=14.5222806930542, pred_loss=[0.46047986, 0.25687414, 2.1710966]\n",
      "epoch=63_train_batch=43, total_loss=13.24026870727539, pred_loss=[0.069803834, 0.680593, 0.85638225]\n",
      "epoch=63_train_batch=44, total_loss=12.786478996276855, pred_loss=[0.12884808, 0.4654067, 0.5590749]\n",
      "epoch=63_train_batch=45, total_loss=12.963394165039062, pred_loss=[0.014080744, 0.48288986, 0.8336139]\n",
      "epoch=63_train_batch=46, total_loss=12.926291465759277, pred_loss=[0.18517509, 0.40198, 0.70666647]\n",
      "epoch=63_train_batch=47, total_loss=12.480283737182617, pred_loss=[0.014195994, 0.21190621, 0.622049]\n",
      "epoch=63_train_batch=48, total_loss=12.713322639465332, pred_loss=[0.39252856, 0.25403938, 0.43496102]\n",
      "epoch=63_train_batch=49, total_loss=14.544827461242676, pred_loss=[0.3937798, 0.2377551, 2.281838]\n",
      "epoch=63_train_batch=50, total_loss=14.945612907409668, pred_loss=[0.5382919, 0.06706367, 2.7091413]\n",
      "epoch=63_train_batch=51, total_loss=13.52031421661377, pred_loss=[0.00943435, 0.44523382, 1.4348664]\n",
      "epoch=63_train_batch=52, total_loss=18.708967208862305, pred_loss=[6.315156, 0.25700793, 0.5063583]\n",
      "epoch=63_train_batch=53, total_loss=13.21207046508789, pred_loss=[0.10089795, 0.14823425, 1.3327863]\n",
      "epoch=63_train_batch=54, total_loss=17.615432739257812, pred_loss=[0.42714915, 1.9250833, 3.6333146]\n",
      "epoch=63_train_batch=55, total_loss=12.828165054321289, pred_loss=[0.2686646, 0.43184802, 0.49801368]\n",
      "epoch=63_train_batch=56, total_loss=13.291370391845703, pred_loss=[0.44515958, 0.47434473, 0.74246186]\n",
      "epoch=63_train_batch=57, total_loss=13.980592727661133, pred_loss=[0.3683768, 0.106002964, 1.8770369]\n",
      "epoch=63_train_batch=58, total_loss=18.64928436279297, pred_loss=[0.5451547, 0.20264058, 6.2725406]\n",
      "epoch=63_train_batch=59, total_loss=13.323821067810059, pred_loss=[0.521184, 0.37461978, 0.7992971]\n",
      "epoch=63_train_batch=60, total_loss=12.924870491027832, pred_loss=[0.31439602, 0.42233008, 0.5596519]\n",
      "epoch=63_train_batch=61, total_loss=12.605161666870117, pred_loss=[0.23617236, 0.3915763, 0.34915227]\n",
      "epoch=63_train_batch=62, total_loss=13.36198616027832, pred_loss=[0.2656835, 0.10167198, 1.3666047]\n",
      "epoch=63_train_batch=63, total_loss=13.650053977966309, pred_loss=[0.17365275, 0.35574555, 1.4928691]\n",
      "epoch=63_train_batch=64, total_loss=12.884159088134766, pred_loss=[0.3349593, 0.3860373, 0.53562415]\n",
      "epoch=63_train_batch=65, total_loss=13.856475830078125, pred_loss=[0.42267627, 0.21809524, 1.588419]\n",
      "epoch=63_train_batch=66, total_loss=14.854710578918457, pred_loss=[0.44427297, 1.964344, 0.81906784]\n",
      "epoch=63_train_batch=67, total_loss=12.811492919921875, pred_loss=[0.3311985, 0.2283386, 0.6251881]\n",
      "epoch=63_train_batch=68, total_loss=12.766180038452148, pred_loss=[0.14192109, 0.27905726, 0.71869326]\n",
      "epoch=63_train_batch=69, total_loss=12.842046737670898, pred_loss=[0.061970476, 0.38960123, 0.76423]\n",
      "epoch=63_train_batch=70, total_loss=12.34469223022461, pred_loss=[0.35859078, 0.1259188, 0.23420726]\n",
      "epoch=63_train_batch=71, total_loss=12.957198143005371, pred_loss=[0.8250878, 0.1936161, 0.3127916]\n",
      "epoch=63_train_batch=72, total_loss=13.820165634155273, pred_loss=[0.15590434, 1.1715037, 0.86733466]\n",
      "epoch=63_train_batch=73, total_loss=12.361498832702637, pred_loss=[0.35907733, 0.12119116, 0.25609112]\n",
      "epoch=63_train_batch=74, total_loss=12.876863479614258, pred_loss=[0.316503, 0.3195299, 0.6159781]\n",
      "epoch=63_train_batch=75, total_loss=12.331002235412598, pred_loss=[0.11025606, 0.26252994, 0.33365676]\n",
      "epoch=63_train_batch=76, total_loss=14.018082618713379, pred_loss=[0.27388352, 0.6606556, 1.4592817]\n",
      "epoch=63_train_batch=77, total_loss=12.7401123046875, pred_loss=[0.093187876, 0.3750776, 0.6478878]\n",
      "epoch=63_train_batch=78, total_loss=13.783306121826172, pred_loss=[0.3262303, 0.8998807, 0.9335424]\n",
      "epoch=63_train_batch=79, total_loss=13.063971519470215, pred_loss=[0.45864505, 0.6107477, 0.3712374]\n",
      "epoch=63_train_batch=80, total_loss=15.921440124511719, pred_loss=[3.7890463, 0.075963594, 0.433403]\n",
      "epoch=63_train_batch=81, total_loss=12.583322525024414, pred_loss=[0.29740962, 0.29560673, 0.36759186]\n",
      "epoch=63_train_batch=82, total_loss=17.419729232788086, pred_loss=[0.119382344, 0.5201076, 5.1578403]\n",
      "epoch=63_train_batch=83, total_loss=14.015533447265625, pred_loss=[0.15753713, 0.19664752, 2.0392618]\n",
      "epoch=63_train_batch=84, total_loss=17.228557586669922, pred_loss=[0.42006737, 2.2093875, 2.9773285]\n",
      "epoch=63_train_batch=85, total_loss=12.90834903717041, pred_loss=[0.42176563, 0.56779075, 0.29733437]\n",
      "epoch=63_train_batch=86, total_loss=12.530927658081055, pred_loss=[0.5922847, 0.11808176, 0.19941828]\n",
      "epoch=63_train_batch=87, total_loss=12.58354663848877, pred_loss=[0.0035410863, 0.19096118, 0.7682133]\n",
      "epoch=63_val_batch=0, total_val_loss=794.721435546875, pred_val_loss[0.24130453, 63.263382, 719.5962]\n",
      "epoch=63_val_batch=1, total_val_loss=224.083984375, pred_val_loss[0.12476942, 124.94525, 87.39344]\n",
      "epoch=63_val_batch=2, total_val_loss=77.51575469970703, pred_val_loss[10.326978, 11.366155, 44.202106]\n",
      "epoch=63_val_batch=3, total_val_loss=125.79196166992188, pred_val_loss[3.048533, 29.341164, 81.78175]\n",
      "epoch=63_val_batch=4, total_val_loss=99.7943344116211, pred_val_loss[3.7435822, 25.563675, 58.866566]\n",
      "epoch=63_val_batch=5, total_val_loss=60.627532958984375, pred_val_loss[12.847784, 10.410667, 25.748564]\n",
      "epoch=63_val_batch=6, total_val_loss=225.8422088623047, pred_val_loss[17.65371, 7.1708026, 189.39719]\n",
      "epoch=63_val_batch=7, total_val_loss=164.8218231201172, pred_val_loss[0.89930433, 60.956078, 91.345924]\n",
      "epoch=63_val_batch=8, total_val_loss=65.31743621826172, pred_val_loss[0.463157, 40.437477, 12.796284]\n",
      "epoch=63_val_batch=9, total_val_loss=129.8434600830078, pred_val_loss[4.5661182, 56.00881, 57.648018]\n",
      "epoch=63_val_batch=10, total_val_loss=132.64735412597656, pred_val_loss[26.786987, 8.764911, 85.474945]\n",
      "epoch=63_val_batch=11, total_val_loss=158.3091583251953, pred_val_loss[8.956875, 66.97876, 70.753006]\n",
      "epoch=63_val_batch=12, total_val_loss=28.709720611572266, pred_val_loss[0.810778, 5.7342734, 10.544151]\n",
      "epoch=63_val_batch=13, total_val_loss=99.98338317871094, pred_val_loss[0.23151138, 40.712967, 47.418396]\n",
      "epoch=63_val_batch=14, total_val_loss=104.01212310791016, pred_val_loss[11.411115, 31.77512, 49.205376]\n",
      "epoch=63_val_batch=15, total_val_loss=81.17396545410156, pred_val_loss[18.246777, 2.129054, 49.177624]\n",
      "epoch=63_val_batch=16, total_val_loss=208.7501220703125, pred_val_loss[6.8125696, 64.061264, 126.25578]\n",
      "epoch=63_val_batch=17, total_val_loss=169.2332305908203, pred_val_loss[14.192395, 16.40228, 127.018036]\n",
      "epoch=63_val_batch=18, total_val_loss=159.70941162109375, pred_val_loss[3.3618987, 32.43106, 112.29593]\n",
      "epoch=63, train: avg_loss=13.529460906982422, val: avg_val_loss=163.73097229003906\n",
      "Saved checkpoint for step 74: ./tf_ckpts/ckpt-73\n",
      "epoch=64_train_batch=0, total_loss=13.377045631408691, pred_loss=[0.091811135, 0.36384332, 1.3008747]\n",
      "epoch=64_train_batch=1, total_loss=13.870016098022461, pred_loss=[0.039749503, 0.3633233, 1.8467418]\n",
      "epoch=64_train_batch=2, total_loss=12.846230506896973, pred_loss=[0.13361077, 0.21810907, 0.87462795]\n",
      "epoch=64_train_batch=3, total_loss=12.883604049682617, pred_loss=[0.38659155, 0.475672, 0.40177768]\n",
      "epoch=64_train_batch=4, total_loss=12.689950942993164, pred_loss=[0.13669387, 0.13108926, 0.80292666]\n",
      "epoch=64_train_batch=5, total_loss=13.10895824432373, pred_loss=[0.10439857, 0.4572426, 0.92839926]\n",
      "epoch=64_train_batch=6, total_loss=13.460348129272461, pred_loss=[0.14909089, 0.4675604, 1.2251055]\n",
      "epoch=64_train_batch=7, total_loss=13.823709487915039, pred_loss=[0.31407103, 0.41874802, 1.4726276]\n",
      "epoch=64_train_batch=8, total_loss=21.574424743652344, pred_loss=[4.891114, 0.19784892, 4.8675275]\n",
      "epoch=64_train_batch=9, total_loss=12.920080184936523, pred_loss=[0.14495175, 0.08894573, 1.0685627]\n",
      "epoch=64_train_batch=10, total_loss=13.260526657104492, pred_loss=[0.1530483, 0.6502577, 0.83990985]\n",
      "epoch=64_train_batch=11, total_loss=12.936279296875, pred_loss=[0.058459613, 0.3635091, 0.89730465]\n",
      "epoch=64_train_batch=12, total_loss=12.304254531860352, pred_loss=[0.079823755, 0.35319316, 0.2545349]\n",
      "epoch=64_train_batch=13, total_loss=12.29228401184082, pred_loss=[0.21132347, 0.11067107, 0.35388955]\n",
      "epoch=64_train_batch=14, total_loss=15.542802810668945, pred_loss=[0.34770778, 0.15392944, 3.4250712]\n",
      "epoch=64_train_batch=15, total_loss=12.621748924255371, pred_loss=[0.22299822, 0.4712452, 0.31171593]\n",
      "epoch=64_train_batch=16, total_loss=12.616058349609375, pred_loss=[0.37966982, 0.40930122, 0.2116074]\n",
      "epoch=64_train_batch=17, total_loss=14.7669677734375, pred_loss=[0.103344575, 0.429941, 2.618511]\n",
      "epoch=64_train_batch=18, total_loss=12.34628677368164, pred_loss=[0.11638773, 0.29519564, 0.31984234]\n",
      "epoch=64_train_batch=19, total_loss=24.327606201171875, pred_loss=[0.0874831, 0.25795904, 12.367618]\n",
      "epoch=64_train_batch=20, total_loss=12.841194152832031, pred_loss=[0.22207971, 0.41799095, 0.5868899]\n",
      "epoch=64_train_batch=21, total_loss=12.907783508300781, pred_loss=[0.34133923, 0.46098602, 0.49153623]\n",
      "epoch=64_train_batch=22, total_loss=13.054339408874512, pred_loss=[0.15998583, 0.5089896, 0.77175456]\n",
      "epoch=64_train_batch=23, total_loss=13.130453109741211, pred_loss=[0.32719854, 0.29308867, 0.8968727]\n",
      "epoch=64_train_batch=24, total_loss=12.47506332397461, pred_loss=[0.22313353, 0.27492413, 0.3640287]\n",
      "epoch=64_train_batch=25, total_loss=13.327667236328125, pred_loss=[0.12546872, 0.2572687, 1.3322709]\n",
      "epoch=64_train_batch=26, total_loss=13.884973526000977, pred_loss=[0.34832814, 0.3664406, 1.5578644]\n",
      "epoch=64_train_batch=27, total_loss=16.64273452758789, pred_loss=[0.31053728, 0.391074, 4.3291035]\n",
      "epoch=64_train_batch=28, total_loss=14.344383239746094, pred_loss=[0.07948902, 0.55523205, 2.0979643]\n",
      "epoch=64_train_batch=29, total_loss=14.666746139526367, pred_loss=[0.17598566, 0.49031955, 2.3890648]\n",
      "epoch=64_train_batch=30, total_loss=14.606520652770996, pred_loss=[0.87538576, 0.1155438, 2.0045376]\n",
      "epoch=64_train_batch=31, total_loss=12.683414459228516, pred_loss=[0.42719275, 0.10931616, 0.5361819]\n",
      "epoch=64_train_batch=32, total_loss=12.93972396850586, pred_loss=[0.4165535, 0.50205123, 0.41072428]\n",
      "epoch=64_train_batch=33, total_loss=13.534544944763184, pred_loss=[0.34971586, 0.6561657, 0.9185987]\n",
      "epoch=64_train_batch=34, total_loss=14.748258590698242, pred_loss=[0.35979187, 0.21114635, 2.567589]\n",
      "epoch=64_train_batch=35, total_loss=15.127138137817383, pred_loss=[0.10495619, 1.1576993, 2.2550836]\n",
      "epoch=64_train_batch=36, total_loss=12.57211685180664, pred_loss=[0.32327333, 0.3183958, 0.3213857]\n",
      "epoch=64_train_batch=37, total_loss=12.937503814697266, pred_loss=[0.015414607, 0.66105306, 0.6523094]\n",
      "epoch=64_train_batch=38, total_loss=13.161914825439453, pred_loss=[0.19140893, 0.35517594, 1.0069454]\n",
      "epoch=64_train_batch=39, total_loss=12.89454174041748, pred_loss=[0.3375191, 0.25502524, 0.6939515]\n",
      "epoch=64_train_batch=40, total_loss=12.486559867858887, pred_loss=[0.094858505, 0.29611567, 0.4878831]\n",
      "epoch=64_train_batch=41, total_loss=12.815788269042969, pred_loss=[0.32114348, 0.18964916, 0.69763446]\n",
      "epoch=64_train_batch=42, total_loss=13.654609680175781, pred_loss=[0.8095057, 0.21457541, 1.0235116]\n",
      "epoch=64_train_batch=43, total_loss=12.856721878051758, pred_loss=[0.17846, 0.19311401, 0.8784734]\n",
      "epoch=64_train_batch=44, total_loss=12.737358093261719, pred_loss=[0.5555465, 0.25565547, 0.31982446]\n",
      "epoch=64_train_batch=45, total_loss=12.440658569335938, pred_loss=[0.48592862, 0.123253286, 0.22548582]\n",
      "epoch=64_train_batch=46, total_loss=14.83542537689209, pred_loss=[0.24417241, 0.7836093, 2.2019963]\n",
      "epoch=64_train_batch=47, total_loss=13.298413276672363, pred_loss=[0.44666374, 0.25366414, 0.9927844]\n",
      "epoch=64_train_batch=48, total_loss=15.716007232666016, pred_loss=[0.23863089, 0.36745936, 3.5049624]\n",
      "epoch=64_train_batch=49, total_loss=12.29925537109375, pred_loss=[0.13919355, 0.18877709, 0.36668104]\n",
      "epoch=64_train_batch=50, total_loss=15.051937103271484, pred_loss=[0.042604353, 0.19134836, 3.21373]\n",
      "epoch=64_train_batch=51, total_loss=13.331512451171875, pred_loss=[0.11339352, 0.23991452, 1.3742973]\n",
      "epoch=64_train_batch=52, total_loss=12.818918228149414, pred_loss=[0.0912505, 0.20234558, 0.9217633]\n",
      "epoch=64_train_batch=53, total_loss=14.794880867004395, pred_loss=[0.11693287, 0.49367952, 2.5810583]\n",
      "epoch=64_train_batch=54, total_loss=13.996795654296875, pred_loss=[1.228361, 0.23812363, 0.92744803]\n",
      "epoch=64_train_batch=55, total_loss=12.774467468261719, pred_loss=[0.45269954, 0.21409939, 0.5051535]\n",
      "epoch=64_train_batch=56, total_loss=28.357757568359375, pred_loss=[0.25513205, 0.49418312, 16.006273]\n",
      "epoch=64_train_batch=57, total_loss=14.020149230957031, pred_loss=[0.07594264, 0.37144005, 1.9709467]\n",
      "epoch=64_train_batch=58, total_loss=12.182921409606934, pred_loss=[0.15025896, 0.19961399, 0.23156962]\n",
      "epoch=64_train_batch=59, total_loss=13.319145202636719, pred_loss=[0.121353224, 1.3605969, 0.236052]\n",
      "epoch=64_train_batch=60, total_loss=12.654995918273926, pred_loss=[0.07625306, 0.460724, 0.5172132]\n",
      "epoch=64_train_batch=61, total_loss=14.66785717010498, pred_loss=[0.1019672, 0.29012573, 2.6752927]\n",
      "epoch=64_train_batch=62, total_loss=14.107131958007812, pred_loss=[0.19749263, 0.3535238, 1.9559731]\n",
      "epoch=64_train_batch=63, total_loss=13.15106201171875, pred_loss=[0.6344029, 0.38699418, 0.5298482]\n",
      "epoch=64_train_batch=64, total_loss=18.641178131103516, pred_loss=[0.1547996, 1.258719, 5.628174]\n",
      "epoch=64_train_batch=65, total_loss=13.341521263122559, pred_loss=[0.13738512, 0.6142353, 0.9907416]\n",
      "epoch=64_train_batch=66, total_loss=13.03811264038086, pred_loss=[0.18182403, 0.8475579, 0.40989584]\n",
      "epoch=64_train_batch=67, total_loss=12.854909896850586, pred_loss=[0.32400844, 0.40897772, 0.5234153]\n",
      "epoch=64_train_batch=68, total_loss=16.876684188842773, pred_loss=[0.27661702, 1.6050447, 3.3968422]\n",
      "epoch=64_train_batch=69, total_loss=13.489931106567383, pred_loss=[0.1527185, 0.25608298, 1.4832757]\n",
      "epoch=64_train_batch=70, total_loss=17.354427337646484, pred_loss=[0.047390573, 2.6891549, 3.0203533]\n",
      "epoch=64_train_batch=71, total_loss=12.57055950164795, pred_loss=[0.30196333, 0.21932669, 0.45206937]\n",
      "epoch=64_train_batch=72, total_loss=12.77851390838623, pred_loss=[0.22180383, 0.2926198, 0.66721725]\n",
      "epoch=64_train_batch=73, total_loss=12.685434341430664, pred_loss=[0.2254761, 0.23455039, 0.62886405]\n",
      "epoch=64_train_batch=74, total_loss=17.951854705810547, pred_loss=[0.15163475, 0.38887665, 5.8151293]\n",
      "epoch=64_train_batch=75, total_loss=12.515432357788086, pred_loss=[0.40339935, 0.22185881, 0.29429206]\n",
      "epoch=64_train_batch=76, total_loss=12.402170181274414, pred_loss=[0.31646144, 0.26040483, 0.22975112]\n",
      "epoch=64_train_batch=77, total_loss=13.166744232177734, pred_loss=[0.20110144, 0.1694848, 1.2009361]\n",
      "epoch=64_train_batch=78, total_loss=13.498407363891602, pred_loss=[0.20531395, 1.0866827, 0.61152124]\n",
      "epoch=64_train_batch=79, total_loss=13.00622844696045, pred_loss=[0.14726368, 0.34282762, 0.92158]\n",
      "epoch=64_train_batch=80, total_loss=13.56321907043457, pred_loss=[0.12217124, 0.5946865, 1.2521366]\n",
      "epoch=64_train_batch=81, total_loss=12.538164138793945, pred_loss=[0.32407808, 0.31023103, 0.30996498]\n",
      "epoch=64_train_batch=82, total_loss=13.04510498046875, pred_loss=[0.14873207, 0.3658586, 0.9369584]\n",
      "epoch=64_train_batch=83, total_loss=12.552762031555176, pred_loss=[0.12466517, 0.5276581, 0.30722123]\n",
      "epoch=64_train_batch=84, total_loss=12.972051620483398, pred_loss=[0.1265705, 0.22155975, 1.0310428]\n",
      "epoch=64_train_batch=85, total_loss=13.945850372314453, pred_loss=[0.15935232, 1.1453748, 1.0485874]\n",
      "epoch=64_train_batch=86, total_loss=13.500560760498047, pred_loss=[0.023412, 0.6150682, 1.269889]\n",
      "epoch=64_train_batch=87, total_loss=11.932291030883789, pred_loss=[0.04910307, 0.20032807, 0.09101394]\n",
      "epoch=64_val_batch=0, total_val_loss=684.0614013671875, pred_val_loss[0.3813101, 59.099194, 612.9894]\n",
      "epoch=64_val_batch=1, total_val_loss=209.15943908691406, pred_val_loss[0.076775685, 113.84313, 83.648026]\n",
      "epoch=64_val_batch=2, total_val_loss=78.99518585205078, pred_val_loss[9.100677, 13.656525, 44.64648]\n",
      "epoch=64_val_batch=3, total_val_loss=125.0427474975586, pred_val_loss[3.2775803, 27.72852, 82.445145]\n",
      "epoch=64_val_batch=4, total_val_loss=90.72421264648438, pred_val_loss[4.8012013, 24.721247, 49.610264]\n",
      "epoch=64_val_batch=5, total_val_loss=59.60347366333008, pred_val_loss[13.816444, 9.423978, 24.771553]\n",
      "epoch=64_val_batch=6, total_val_loss=200.45054626464844, pred_val_loss[17.6006, 6.1038985, 165.15454]\n",
      "epoch=64_val_batch=7, total_val_loss=157.12930297851562, pred_val_loss[0.673367, 55.45148, 89.41295]\n",
      "epoch=64_val_batch=8, total_val_loss=53.526458740234375, pred_val_loss[0.24129409, 31.984745, 9.708918]\n",
      "epoch=64_val_batch=9, total_val_loss=121.40470886230469, pred_val_loss[4.364205, 50.40046, 55.048546]\n",
      "epoch=64_val_batch=10, total_val_loss=128.55368041992188, pred_val_loss[24.557903, 8.38093, 84.023346]\n",
      "epoch=64_val_batch=11, total_val_loss=142.2212677001953, pred_val_loss[7.523129, 57.173702, 65.93293]\n",
      "epoch=64_val_batch=12, total_val_loss=30.312889099121094, pred_val_loss[0.7020114, 7.401328, 10.618049]\n",
      "epoch=64_val_batch=13, total_val_loss=90.9741439819336, pred_val_loss[0.14617093, 36.507526, 42.728943]\n",
      "epoch=64_val_batch=14, total_val_loss=91.98200988769531, pred_val_loss[12.208632, 25.402885, 42.77899]\n",
      "epoch=64_val_batch=15, total_val_loss=71.44194030761719, pred_val_loss[18.72348, 0.6999013, 40.42706]\n",
      "epoch=64_val_batch=16, total_val_loss=200.04757690429688, pred_val_loss[6.426903, 68.2171, 113.812065]\n",
      "epoch=64_val_batch=17, total_val_loss=158.99899291992188, pred_val_loss[12.922426, 13.929489, 120.555565]\n",
      "epoch=64_val_batch=18, total_val_loss=146.154052734375, pred_val_loss[4.0676656, 31.49947, 98.99541]\n",
      "epoch=64, train: avg_loss=13.916394233703613, val: avg_val_loss=149.51495361328125\n",
      "Saved checkpoint for step 75: ./tf_ckpts/ckpt-74\n",
      "epoch=65_train_batch=0, total_loss=12.15603256225586, pred_loss=[0.21126932, 0.056570087, 0.29669338]\n",
      "epoch=65_train_batch=1, total_loss=13.423785209655762, pred_loss=[0.21079752, 1.3459966, 0.2758388]\n",
      "epoch=65_train_batch=2, total_loss=16.161827087402344, pred_loss=[0.38188434, 0.5673984, 3.6217384]\n",
      "epoch=65_train_batch=3, total_loss=15.500155448913574, pred_loss=[0.15796906, 3.4655597, 0.2861688]\n",
      "epoch=65_train_batch=4, total_loss=12.274471282958984, pred_loss=[0.12682474, 0.21185517, 0.34567034]\n",
      "epoch=65_train_batch=5, total_loss=13.109046936035156, pred_loss=[0.02385864, 0.9421849, 0.5532089]\n",
      "epoch=65_train_batch=6, total_loss=13.339926719665527, pred_loss=[0.20181195, 0.44476452, 1.1038803]\n",
      "epoch=65_train_batch=7, total_loss=13.618557929992676, pred_loss=[0.100491814, 0.8432192, 1.0856962]\n",
      "epoch=65_train_batch=8, total_loss=12.78773021697998, pred_loss=[0.27318582, 0.39042196, 0.53528976]\n",
      "epoch=65_train_batch=9, total_loss=12.647666931152344, pred_loss=[0.40824366, 0.3013133, 0.34959388]\n",
      "epoch=65_train_batch=10, total_loss=12.715062141418457, pred_loss=[0.16224957, 0.5877147, 0.3768989]\n",
      "epoch=65_train_batch=11, total_loss=12.639121055603027, pred_loss=[0.13558334, 0.21192893, 0.7037293]\n",
      "epoch=65_train_batch=12, total_loss=13.849311828613281, pred_loss=[0.15305257, 0.4321671, 1.6765339]\n",
      "epoch=65_train_batch=13, total_loss=12.969104766845703, pred_loss=[0.07119846, 0.426771, 0.8839018]\n",
      "epoch=65_train_batch=14, total_loss=12.454619407653809, pred_loss=[0.3640179, 0.23589592, 0.26779664]\n",
      "epoch=65_train_batch=15, total_loss=12.387882232666016, pred_loss=[0.20755547, 0.25522134, 0.33852553]\n",
      "epoch=65_train_batch=16, total_loss=12.250544548034668, pred_loss=[0.052031133, 0.2982548, 0.31400824]\n",
      "epoch=65_train_batch=17, total_loss=18.26608657836914, pred_loss=[0.3361946, 0.72601783, 5.6179566]\n",
      "epoch=65_train_batch=18, total_loss=14.995305061340332, pred_loss=[0.10215445, 0.29978305, 3.007789]\n",
      "epoch=65_train_batch=19, total_loss=13.19352912902832, pred_loss=[0.08560736, 0.43742558, 1.0852568]\n",
      "epoch=65_train_batch=20, total_loss=12.590384483337402, pred_loss=[0.13640551, 0.20844741, 0.6606318]\n",
      "epoch=65_train_batch=21, total_loss=14.547615051269531, pred_loss=[0.12966505, 0.8115409, 2.0218508]\n",
      "epoch=65_train_batch=22, total_loss=13.599921226501465, pred_loss=[0.19176984, 0.32860607, 1.4953274]\n",
      "epoch=65_train_batch=23, total_loss=13.444580078125, pred_loss=[0.17179073, 0.2524215, 1.4364918]\n",
      "epoch=65_train_batch=24, total_loss=13.695456504821777, pred_loss=[0.3032983, 0.10047859, 1.708148]\n",
      "epoch=65_train_batch=25, total_loss=13.562028884887695, pred_loss=[0.33664113, 0.74087226, 0.9013297]\n",
      "epoch=65_train_batch=26, total_loss=13.129743576049805, pred_loss=[0.2708278, 0.48600206, 0.79007804]\n",
      "epoch=65_train_batch=27, total_loss=13.0757417678833, pred_loss=[0.12669122, 0.31909674, 1.047468]\n",
      "epoch=65_train_batch=28, total_loss=17.684154510498047, pred_loss=[0.02677482, 2.2487428, 3.8264995]\n",
      "epoch=65_train_batch=29, total_loss=12.936861991882324, pred_loss=[0.11877447, 0.14929274, 1.0870018]\n",
      "epoch=65_train_batch=30, total_loss=12.898674964904785, pred_loss=[0.10548855, 0.5553981, 0.6563409]\n",
      "epoch=65_train_batch=31, total_loss=14.402164459228516, pred_loss=[0.05282354, 0.32903275, 2.4392052]\n",
      "epoch=65_train_batch=32, total_loss=13.016729354858398, pred_loss=[0.011117965, 0.5298386, 0.8950136]\n",
      "epoch=65_train_batch=33, total_loss=12.965396881103516, pred_loss=[0.24049243, 0.5094643, 0.6350262]\n",
      "epoch=65_train_batch=34, total_loss=14.58438777923584, pred_loss=[0.38729933, 0.63601744, 1.9810032]\n",
      "epoch=65_train_batch=35, total_loss=12.72996997833252, pred_loss=[0.278135, 0.3842304, 0.48788112]\n",
      "epoch=65_train_batch=36, total_loss=13.675335884094238, pred_loss=[0.058739204, 0.38887376, 1.648345]\n",
      "epoch=65_train_batch=37, total_loss=12.954096794128418, pred_loss=[0.21143095, 0.4257341, 0.73789716]\n",
      "epoch=65_train_batch=38, total_loss=14.778868675231934, pred_loss=[0.11407482, 0.41571033, 2.6703904]\n",
      "epoch=65_train_batch=39, total_loss=13.473163604736328, pred_loss=[0.35720915, 0.20907122, 1.3285326]\n",
      "epoch=65_train_batch=40, total_loss=13.499568939208984, pred_loss=[0.71250224, 0.19954446, 1.0095159]\n",
      "epoch=65_train_batch=41, total_loss=12.558930397033691, pred_loss=[0.37126666, 0.23912627, 0.37087458]\n",
      "epoch=65_train_batch=42, total_loss=15.546038627624512, pred_loss=[0.27811918, 0.81985646, 2.8707469]\n",
      "epoch=65_train_batch=43, total_loss=12.376412391662598, pred_loss=[0.13686724, 0.47697264, 0.185599]\n",
      "epoch=65_train_batch=44, total_loss=16.70718765258789, pred_loss=[0.1554129, 0.25006422, 4.725081]\n",
      "epoch=65_train_batch=45, total_loss=12.866470336914062, pred_loss=[0.32426888, 0.17026085, 0.79565454]\n",
      "epoch=65_train_batch=46, total_loss=13.39565658569336, pred_loss=[0.17741527, 0.2714673, 1.3708372]\n",
      "epoch=65_train_batch=47, total_loss=12.853194236755371, pred_loss=[0.3152995, 0.15415058, 0.8081568]\n",
      "epoch=65_train_batch=48, total_loss=13.213041305541992, pred_loss=[0.17483997, 0.5097477, 0.95321786]\n",
      "epoch=65_train_batch=49, total_loss=13.262426376342773, pred_loss=[0.8431334, 0.25754416, 0.58686846]\n",
      "epoch=65_train_batch=50, total_loss=12.397810935974121, pred_loss=[0.24964744, 0.26693022, 0.3067177]\n",
      "epoch=65_train_batch=51, total_loss=12.512641906738281, pred_loss=[0.20559046, 0.26605898, 0.46684068]\n",
      "epoch=65_train_batch=52, total_loss=12.487581253051758, pred_loss=[0.28146005, 0.29989246, 0.33244064]\n",
      "epoch=65_train_batch=53, total_loss=12.812186241149902, pred_loss=[0.21974057, 0.22410578, 0.79491454]\n",
      "epoch=65_train_batch=54, total_loss=13.539386749267578, pred_loss=[0.037809134, 0.086783305, 1.8417312]\n",
      "epoch=65_train_batch=55, total_loss=12.624185562133789, pred_loss=[0.44327652, 0.08761916, 0.5205884]\n",
      "epoch=65_train_batch=56, total_loss=13.369245529174805, pred_loss=[0.086119495, 0.52531815, 1.1854647]\n",
      "epoch=65_train_batch=57, total_loss=12.57906723022461, pred_loss=[0.08271214, 0.26221132, 0.6621598]\n",
      "epoch=65_train_batch=58, total_loss=12.505494117736816, pred_loss=[0.2261056, 0.27328068, 0.43448156]\n",
      "epoch=65_train_batch=59, total_loss=12.9454345703125, pred_loss=[0.13091305, 0.3106091, 0.93264645]\n",
      "epoch=65_train_batch=60, total_loss=12.472949981689453, pred_loss=[0.4858084, 0.24263704, 0.17359938]\n",
      "epoch=65_train_batch=61, total_loss=13.269488334655762, pred_loss=[0.32819897, 0.18576775, 1.1849792]\n",
      "epoch=65_train_batch=62, total_loss=13.665421485900879, pred_loss=[0.054901224, 0.30631244, 1.7340305]\n",
      "epoch=65_train_batch=63, total_loss=12.911561965942383, pred_loss=[0.22794242, 0.6785526, 0.43525165]\n",
      "epoch=65_train_batch=64, total_loss=15.90522575378418, pred_loss=[0.05467993, 3.1669962, 1.1140999]\n",
      "epoch=65_train_batch=65, total_loss=12.961589813232422, pred_loss=[0.21839373, 0.16981335, 1.004293]\n",
      "epoch=65_train_batch=66, total_loss=13.138340950012207, pred_loss=[0.10887008, 0.23021251, 1.2305293]\n",
      "epoch=65_train_batch=67, total_loss=18.554594039916992, pred_loss=[0.105721846, 2.4020274, 4.478474]\n",
      "epoch=65_train_batch=68, total_loss=13.072915077209473, pred_loss=[0.2614091, 0.27224714, 0.97124934]\n",
      "epoch=65_train_batch=69, total_loss=17.414810180664062, pred_loss=[0.33628803, 3.7756145, 1.7352557]\n",
      "epoch=65_train_batch=70, total_loss=12.695297241210938, pred_loss=[0.19227189, 0.16651759, 0.7691568]\n",
      "epoch=65_train_batch=71, total_loss=12.532563209533691, pred_loss=[0.14522658, 0.39082825, 0.42933658]\n",
      "epoch=65_train_batch=72, total_loss=12.465752601623535, pred_loss=[0.08081334, 0.253765, 0.564101]\n",
      "epoch=65_train_batch=73, total_loss=13.381842613220215, pred_loss=[0.07327797, 0.3399924, 1.40154]\n",
      "epoch=65_train_batch=74, total_loss=12.512252807617188, pred_loss=[0.2844272, 0.17776173, 0.48303974]\n",
      "epoch=65_train_batch=75, total_loss=13.874229431152344, pred_loss=[0.16478753, 0.24759589, 1.89481]\n",
      "epoch=65_train_batch=76, total_loss=12.537602424621582, pred_loss=[0.34995785, 0.4073908, 0.21320295]\n",
      "epoch=65_train_batch=77, total_loss=13.811683654785156, pred_loss=[0.22054933, 0.7297758, 1.2942926]\n",
      "epoch=65_train_batch=78, total_loss=13.508227348327637, pred_loss=[0.28346074, 0.46935034, 1.1883441]\n",
      "epoch=65_train_batch=79, total_loss=13.148004531860352, pred_loss=[0.14807603, 0.27631193, 1.1565527]\n",
      "epoch=65_train_batch=80, total_loss=13.47584342956543, pred_loss=[0.06899495, 0.23492359, 1.6048839]\n",
      "epoch=65_train_batch=81, total_loss=13.594385147094727, pred_loss=[0.106936276, 0.9529433, 0.9675063]\n",
      "epoch=65_train_batch=82, total_loss=12.942872047424316, pred_loss=[0.15258044, 0.32310253, 0.90025157]\n",
      "epoch=65_train_batch=83, total_loss=12.746644020080566, pred_loss=[0.1652519, 0.5284848, 0.48604995]\n",
      "epoch=65_train_batch=84, total_loss=13.83368968963623, pred_loss=[0.31127197, 0.5244413, 1.4312199]\n",
      "epoch=65_train_batch=85, total_loss=13.532170295715332, pred_loss=[0.054566115, 0.7876772, 1.1232898]\n",
      "epoch=65_train_batch=86, total_loss=12.393047332763672, pred_loss=[0.23246963, 0.13692367, 0.45715714]\n",
      "epoch=65_train_batch=87, total_loss=13.121224403381348, pred_loss=[1.1911601, 0.25648317, 0.10724029]\n",
      "epoch=65_val_batch=0, total_val_loss=723.444580078125, pred_val_loss[0.28298974, 55.99243, 655.60297]\n",
      "epoch=65_val_batch=1, total_val_loss=221.67759704589844, pred_val_loss[0.15278408, 126.58983, 83.368805]\n",
      "epoch=65_val_batch=2, total_val_loss=76.08934020996094, pred_val_loss[10.56795, 10.931336, 43.023872]\n",
      "epoch=65_val_batch=3, total_val_loss=123.58915710449219, pred_val_loss[3.6671846, 26.107273, 82.24852]\n",
      "epoch=65_val_batch=4, total_val_loss=96.24825286865234, pred_val_loss[5.556635, 26.292168, 52.83327]\n",
      "epoch=65_val_batch=5, total_val_loss=59.71454620361328, pred_val_loss[15.183094, 7.684957, 25.280315]\n",
      "epoch=65_val_batch=6, total_val_loss=221.78062438964844, pred_val_loss[19.901802, 7.0772595, 183.23538]\n",
      "epoch=65_val_batch=7, total_val_loss=167.30479431152344, pred_val_loss[0.8026282, 63.128403, 91.80759]\n",
      "epoch=65_val_batch=8, total_val_loss=61.199134826660156, pred_val_loss[0.2704573, 41.36685, 7.9956493]\n",
      "epoch=65_val_batch=9, total_val_loss=117.72879028320312, pred_val_loss[4.943655, 51.119854, 50.099106]\n",
      "epoch=65_val_batch=10, total_val_loss=125.7720718383789, pred_val_loss[23.89252, 10.787268, 79.52611]\n",
      "epoch=65_val_batch=11, total_val_loss=162.01861572265625, pred_val_loss[8.207374, 72.51561, 69.729454]\n",
      "epoch=65_val_batch=12, total_val_loss=25.39712905883789, pred_val_loss[0.9388687, 5.5235434, 7.3685393]\n",
      "epoch=65_val_batch=13, total_val_loss=92.89067077636719, pred_val_loss[0.27649474, 40.488777, 40.55922]\n",
      "epoch=65_val_batch=14, total_val_loss=98.77934265136719, pred_val_loss[9.455302, 32.204487, 45.553375]\n",
      "epoch=65_val_batch=15, total_val_loss=77.6228256225586, pred_val_loss[21.483631, 2.4658263, 42.10719]\n",
      "epoch=65_val_batch=16, total_val_loss=190.6969451904297, pred_val_loss[6.6431403, 60.103508, 112.38411]\n",
      "epoch=65_val_batch=17, total_val_loss=165.08489990234375, pred_val_loss[13.831253, 17.354242, 122.33322]\n",
      "epoch=65_val_batch=18, total_val_loss=146.7941436767578, pred_val_loss[2.1539817, 29.262554, 103.81143]\n",
      "epoch=65, train: avg_loss=13.500127792358398, val: avg_val_loss=155.46493530273438\n",
      "Saved checkpoint for step 76: ./tf_ckpts/ckpt-75\n",
      "epoch=66_train_batch=0, total_loss=12.419157028198242, pred_loss=[0.097935624, 0.3428106, 0.41223273]\n",
      "epoch=66_train_batch=1, total_loss=12.62468433380127, pred_loss=[0.193943, 0.15418214, 0.7105562]\n",
      "epoch=66_train_batch=2, total_loss=12.84055233001709, pred_loss=[0.21725002, 0.5969934, 0.46049565]\n",
      "epoch=66_train_batch=3, total_loss=12.998980522155762, pred_loss=[0.0938009, 0.87385446, 0.46571714]\n",
      "epoch=66_train_batch=4, total_loss=12.362831115722656, pred_loss=[0.120692275, 0.28084728, 0.3958997]\n",
      "epoch=66_train_batch=5, total_loss=13.305669784545898, pred_loss=[0.11202517, 0.19214913, 1.4363322]\n",
      "epoch=66_train_batch=6, total_loss=12.82534122467041, pred_loss=[0.4398396, 0.21946512, 0.6011134]\n",
      "epoch=66_train_batch=7, total_loss=12.832589149475098, pred_loss=[0.29038274, 0.6138748, 0.36366096]\n",
      "epoch=66_train_batch=8, total_loss=12.873086929321289, pred_loss=[0.27071223, 0.4621548, 0.57581294]\n",
      "epoch=66_train_batch=9, total_loss=13.329269409179688, pred_loss=[0.591676, 0.6263876, 0.5470717]\n",
      "epoch=66_train_batch=10, total_loss=14.050765991210938, pred_loss=[0.064235166, 1.1883318, 1.2343491]\n",
      "epoch=66_train_batch=11, total_loss=12.369682312011719, pred_loss=[0.13379736, 0.2653673, 0.4069624]\n",
      "epoch=66_train_batch=12, total_loss=14.996833801269531, pred_loss=[0.08159991, 0.81388336, 2.5380945]\n",
      "epoch=66_train_batch=13, total_loss=15.959945678710938, pred_loss=[0.1273509, 1.7986677, 2.4709752]\n",
      "epoch=66_train_batch=14, total_loss=13.289816856384277, pred_loss=[0.20715639, 0.88696605, 0.6330495]\n",
      "epoch=66_train_batch=15, total_loss=12.35894775390625, pred_loss=[0.289538, 0.308642, 0.19843654]\n",
      "epoch=66_train_batch=16, total_loss=16.71873664855957, pred_loss=[0.4200905, 1.3027331, 3.433897]\n",
      "epoch=66_train_batch=17, total_loss=13.013909339904785, pred_loss=[0.117025405, 0.8043588, 0.53082883]\n",
      "epoch=66_train_batch=18, total_loss=12.349352836608887, pred_loss=[0.176217, 0.4350746, 0.1766876]\n",
      "epoch=66_train_batch=19, total_loss=13.215417861938477, pred_loss=[0.110789135, 0.77149, 0.7720923]\n",
      "epoch=66_train_batch=20, total_loss=12.297517776489258, pred_loss=[0.16615629, 0.3276808, 0.2429633]\n",
      "epoch=66_train_batch=21, total_loss=12.584100723266602, pred_loss=[0.13548374, 0.6848929, 0.20333904]\n",
      "epoch=66_train_batch=22, total_loss=17.061935424804688, pred_loss=[0.1016459, 1.8722093, 3.5280335]\n",
      "epoch=66_train_batch=23, total_loss=12.92257022857666, pred_loss=[0.17127097, 0.4972274, 0.6943672]\n",
      "epoch=66_train_batch=24, total_loss=13.818929672241211, pred_loss=[0.038546905, 0.71193004, 1.5090909]\n",
      "epoch=66_train_batch=25, total_loss=15.49288558959961, pred_loss=[0.118385054, 1.4025631, 2.41292]\n",
      "epoch=66_train_batch=26, total_loss=12.548218727111816, pred_loss=[0.1246122, 0.25264975, 0.6122878]\n",
      "epoch=66_train_batch=27, total_loss=14.243959426879883, pred_loss=[0.041321922, 0.64791536, 1.9964006]\n",
      "epoch=66_train_batch=28, total_loss=14.208252906799316, pred_loss=[0.21883431, 1.0865974, 1.3448503]\n",
      "epoch=66_train_batch=29, total_loss=13.634164810180664, pred_loss=[0.13923264, 1.2103993, 0.72691405]\n",
      "epoch=66_train_batch=30, total_loss=12.638684272766113, pred_loss=[0.07263995, 0.54687345, 0.461905]\n",
      "epoch=66_train_batch=31, total_loss=12.865863800048828, pred_loss=[0.32905072, 0.2632819, 0.7166201]\n",
      "epoch=66_train_batch=32, total_loss=13.227972030639648, pred_loss=[0.13112244, 0.7686503, 0.7716441]\n",
      "epoch=66_train_batch=33, total_loss=13.235032081604004, pred_loss=[0.15074354, 0.7324857, 0.79560494]\n",
      "epoch=66_train_batch=34, total_loss=12.524319648742676, pred_loss=[0.23986772, 0.40326884, 0.32533988]\n",
      "epoch=66_train_batch=35, total_loss=13.030712127685547, pred_loss=[0.23630317, 0.5863596, 0.6525617]\n",
      "epoch=66_train_batch=36, total_loss=16.09726333618164, pred_loss=[3.6885111, 0.42783585, 0.42578316]\n",
      "epoch=66_train_batch=37, total_loss=12.782454490661621, pred_loss=[0.16424203, 0.41193187, 0.65151876]\n",
      "epoch=66_train_batch=38, total_loss=12.521198272705078, pred_loss=[0.4366136, 0.2548459, 0.27529272]\n",
      "epoch=66_train_batch=39, total_loss=12.637585639953613, pred_loss=[0.107191205, 0.5867137, 0.3895098]\n",
      "epoch=66_train_batch=40, total_loss=12.992737770080566, pred_loss=[0.21444254, 0.33087265, 0.89350337]\n",
      "epoch=66_train_batch=41, total_loss=12.408331871032715, pred_loss=[0.1319109, 0.3002699, 0.42246723]\n",
      "epoch=66_train_batch=42, total_loss=12.532492637634277, pred_loss=[0.1160052, 0.4454332, 0.41759637]\n",
      "epoch=66_train_batch=43, total_loss=12.6268892288208, pred_loss=[0.43343148, 0.08238056, 0.5578414]\n",
      "epoch=66_train_batch=44, total_loss=12.843070983886719, pred_loss=[0.15491156, 0.64182043, 0.49332738]\n",
      "epoch=66_train_batch=45, total_loss=12.935897827148438, pred_loss=[0.28485125, 0.5911126, 0.50715]\n",
      "epoch=66_train_batch=46, total_loss=13.174423217773438, pred_loss=[0.047140636, 0.2832701, 1.2914622]\n",
      "epoch=66_train_batch=47, total_loss=13.591756820678711, pred_loss=[0.433367, 0.21739805, 1.3886786]\n",
      "epoch=66_train_batch=48, total_loss=12.2167387008667, pred_loss=[0.10789867, 0.25120208, 0.3055709]\n",
      "epoch=66_train_batch=49, total_loss=12.58877182006836, pred_loss=[0.32229012, 0.37146676, 0.343197]\n",
      "epoch=66_train_batch=50, total_loss=12.544437408447266, pred_loss=[0.28585625, 0.22655934, 0.48046324]\n",
      "epoch=66_train_batch=51, total_loss=16.26370620727539, pred_loss=[0.33463654, 1.8714452, 2.5063303]\n",
      "epoch=66_train_batch=52, total_loss=12.881353378295898, pred_loss=[0.08057617, 0.29971176, 0.9500421]\n",
      "epoch=66_train_batch=53, total_loss=13.175871849060059, pred_loss=[0.30124357, 0.34859243, 0.9752924]\n",
      "epoch=66_train_batch=54, total_loss=19.625247955322266, pred_loss=[0.309428, 2.0646346, 5.7007318]\n",
      "epoch=66_train_batch=55, total_loss=12.531137466430664, pred_loss=[0.2275039, 0.22383013, 0.5296454]\n",
      "epoch=66_train_batch=56, total_loss=13.076508522033691, pred_loss=[0.17395654, 0.37019047, 0.98250335]\n",
      "epoch=66_train_batch=57, total_loss=12.329277038574219, pred_loss=[0.16902144, 0.12493284, 0.48576874]\n",
      "epoch=66_train_batch=58, total_loss=12.974782943725586, pred_loss=[0.085313246, 0.9376731, 0.4025529]\n",
      "epoch=66_train_batch=59, total_loss=13.758739471435547, pred_loss=[0.21416765, 0.7461064, 1.2495337]\n",
      "epoch=66_train_batch=60, total_loss=12.846994400024414, pred_loss=[0.31774884, 0.14501171, 0.8356182]\n",
      "epoch=66_train_batch=61, total_loss=15.58050537109375, pred_loss=[0.8501336, 0.19725502, 2.984824]\n",
      "epoch=66_train_batch=62, total_loss=14.156904220581055, pred_loss=[0.4501488, 0.7052126, 1.4535642]\n",
      "epoch=66_train_batch=63, total_loss=14.02569580078125, pred_loss=[0.5876172, 0.74039805, 1.1500189]\n",
      "epoch=66_train_batch=64, total_loss=12.935518264770508, pred_loss=[0.21777475, 0.45027348, 0.72011834]\n",
      "epoch=66_train_batch=65, total_loss=15.549803733825684, pred_loss=[0.1851232, 0.9172475, 2.9003894]\n",
      "epoch=66_train_batch=66, total_loss=12.508393287658691, pred_loss=[0.32922113, 0.15773126, 0.47470936]\n",
      "epoch=66_train_batch=67, total_loss=12.630624771118164, pred_loss=[0.43752855, 0.40120196, 0.24547578]\n",
      "epoch=66_train_batch=68, total_loss=14.042726516723633, pred_loss=[0.24292503, 1.1135484, 1.1401513]\n",
      "epoch=66_train_batch=69, total_loss=12.751298904418945, pred_loss=[0.062446844, 0.5621044, 0.58096707]\n",
      "epoch=66_train_batch=70, total_loss=13.061371803283691, pred_loss=[0.83086866, 0.3877812, 0.29726315]\n",
      "epoch=66_train_batch=71, total_loss=12.666650772094727, pred_loss=[0.4438328, 0.11795446, 0.5597276]\n",
      "epoch=66_train_batch=72, total_loss=13.85357666015625, pred_loss=[0.1114084, 0.64907634, 1.548284]\n",
      "epoch=66_train_batch=73, total_loss=13.592636108398438, pred_loss=[0.24037416, 0.67312145, 1.1346617]\n",
      "epoch=66_train_batch=74, total_loss=13.60722541809082, pred_loss=[1.4526759, 0.31529677, 0.2951082]\n",
      "epoch=66_train_batch=75, total_loss=13.892847061157227, pred_loss=[0.24778035, 0.3536951, 1.7475461]\n",
      "epoch=66_train_batch=76, total_loss=15.219221115112305, pred_loss=[0.016732784, 0.92784595, 2.7311416]\n",
      "epoch=66_train_batch=77, total_loss=12.809602737426758, pred_loss=[0.16130114, 0.47465813, 0.63046825]\n",
      "epoch=66_train_batch=78, total_loss=13.145957946777344, pred_loss=[0.21760401, 0.1279368, 1.257569]\n",
      "epoch=66_train_batch=79, total_loss=12.524553298950195, pred_loss=[0.4924622, 0.24412674, 0.24544571]\n",
      "epoch=66_train_batch=80, total_loss=14.512645721435547, pred_loss=[0.12077198, 0.44265822, 2.4070272]\n",
      "epoch=66_train_batch=81, total_loss=13.148271560668945, pred_loss=[0.1302446, 0.6689999, 0.8071698]\n",
      "epoch=66_train_batch=82, total_loss=12.461029052734375, pred_loss=[0.11133367, 0.20894748, 0.5992229]\n",
      "epoch=66_train_batch=83, total_loss=12.309514045715332, pred_loss=[0.3123346, 0.18505597, 0.2709341]\n",
      "epoch=66_train_batch=84, total_loss=12.971000671386719, pred_loss=[0.5082843, 0.3732171, 0.548651]\n",
      "epoch=66_train_batch=85, total_loss=14.17347526550293, pred_loss=[1.5301089, 0.26393336, 0.83892596]\n",
      "epoch=66_train_batch=86, total_loss=13.28148078918457, pred_loss=[0.46785146, 0.80316377, 0.47027248]\n",
      "epoch=66_train_batch=87, total_loss=11.894789695739746, pred_loss=[0.07079099, 0.19780132, 0.08630527]\n",
      "epoch=66_val_batch=0, total_val_loss=775.7716064453125, pred_val_loss[0.47961664, 55.480946, 708.2714]\n",
      "epoch=66_val_batch=1, total_val_loss=215.16868591308594, pred_val_loss[0.1314007, 123.2823, 80.215385]\n",
      "epoch=66_val_batch=2, total_val_loss=79.34599304199219, pred_val_loss[12.146492, 12.810525, 42.84938]\n",
      "epoch=66_val_batch=3, total_val_loss=117.44840240478516, pred_val_loss[1.1688591, 25.64194, 79.09801]\n",
      "epoch=66_val_batch=4, total_val_loss=101.59260559082031, pred_val_loss[3.51968, 24.035892, 62.497433]\n",
      "epoch=66_val_batch=5, total_val_loss=62.36954116821289, pred_val_loss[15.465095, 7.0428543, 28.321991]\n",
      "epoch=66_val_batch=6, total_val_loss=225.24502563476562, pred_val_loss[22.774338, 7.8192997, 183.11179]\n",
      "epoch=66_val_batch=7, total_val_loss=167.4264373779297, pred_val_loss[0.94982886, 60.408203, 94.52881]\n",
      "epoch=66_val_batch=8, total_val_loss=54.09878921508789, pred_val_loss[0.32015803, 35.187027, 7.052003]\n",
      "epoch=66_val_batch=9, total_val_loss=125.3411865234375, pred_val_loss[5.41835, 55.05076, 53.33248]\n",
      "epoch=66_val_batch=10, total_val_loss=128.5045166015625, pred_val_loss[28.203598, 8.686295, 80.07503]\n",
      "epoch=66_val_batch=11, total_val_loss=158.3144073486328, pred_val_loss[11.77302, 64.43167, 70.570114]\n",
      "epoch=66_val_batch=12, total_val_loss=25.268856048583984, pred_val_loss[1.2648154, 5.324784, 7.139656]\n",
      "epoch=66_val_batch=13, total_val_loss=90.98294830322266, pred_val_loss[0.19295312, 36.939842, 42.310555]\n",
      "epoch=66_val_batch=14, total_val_loss=105.45635223388672, pred_val_loss[13.044441, 29.492355, 51.37996]\n",
      "epoch=66_val_batch=15, total_val_loss=78.93020629882812, pred_val_loss[21.484936, 1.8335651, 44.07211]\n",
      "epoch=66_val_batch=16, total_val_loss=205.33656311035156, pred_val_loss[9.502808, 64.88518, 119.40898]\n",
      "epoch=66_val_batch=17, total_val_loss=165.86585998535156, pred_val_loss[20.325186, 14.717341, 119.28374]\n",
      "epoch=66_val_batch=18, total_val_loss=158.62371826171875, pred_val_loss[4.8152285, 30.629425, 111.639465]\n",
      "epoch=66, train: avg_loss=13.412906646728516, val: avg_val_loss=160.0574493408203\n",
      "Saved checkpoint for step 77: ./tf_ckpts/ckpt-76\n",
      "epoch=67_train_batch=0, total_loss=12.635887145996094, pred_loss=[0.26590157, 0.10950753, 0.7208789]\n",
      "epoch=67_train_batch=1, total_loss=19.077634811401367, pred_loss=[0.33009472, 0.334642, 6.873591]\n",
      "epoch=67_train_batch=2, total_loss=13.386289596557617, pred_loss=[0.34293202, 0.33111995, 1.1732213]\n",
      "epoch=67_train_batch=3, total_loss=13.461304664611816, pred_loss=[0.45357642, 0.33088702, 1.138115]\n",
      "epoch=67_train_batch=4, total_loss=14.27882194519043, pred_loss=[0.24150556, 0.8916204, 1.6072649]\n",
      "epoch=67_train_batch=5, total_loss=14.047367095947266, pred_loss=[1.469419, 0.5473323, 0.4924796]\n",
      "epoch=67_train_batch=6, total_loss=14.509933471679688, pred_loss=[0.4474218, 0.14448932, 2.380201]\n",
      "epoch=67_train_batch=7, total_loss=13.373119354248047, pred_loss=[0.19000074, 1.1545055, 0.49110362]\n",
      "epoch=67_train_batch=8, total_loss=12.531303405761719, pred_loss=[0.18435642, 0.5650371, 0.24471328]\n",
      "epoch=67_train_batch=9, total_loss=17.855228424072266, pred_loss=[0.08773779, 0.43729168, 5.793317]\n",
      "epoch=67_train_batch=10, total_loss=14.805675506591797, pred_loss=[0.5993329, 0.5646822, 2.1050906]\n",
      "epoch=67_train_batch=11, total_loss=12.878003120422363, pred_loss=[0.37387243, 0.6503916, 0.31749588]\n",
      "epoch=67_train_batch=12, total_loss=13.551656723022461, pred_loss=[0.5256585, 0.5571731, 0.9329029]\n",
      "epoch=67_train_batch=13, total_loss=12.841179847717285, pred_loss=[0.26038545, 0.36402398, 0.6811663]\n",
      "epoch=67_train_batch=14, total_loss=14.837154388427734, pred_loss=[1.9883486, 0.36785984, 0.9456582]\n",
      "epoch=67_train_batch=15, total_loss=12.667527198791504, pred_loss=[0.5235074, 0.33956146, 0.2694621]\n",
      "epoch=67_train_batch=16, total_loss=12.947891235351562, pred_loss=[0.6206207, 0.418718, 0.3738497]\n",
      "epoch=67_train_batch=17, total_loss=12.881208419799805, pred_loss=[0.4792099, 0.46300867, 0.40458122]\n",
      "epoch=67_train_batch=18, total_loss=12.629717826843262, pred_loss=[0.4575209, 0.11414057, 0.5239427]\n",
      "epoch=67_train_batch=19, total_loss=14.99005126953125, pred_loss=[0.15114637, 0.49708188, 2.8080075]\n",
      "epoch=67_train_batch=20, total_loss=13.2930269241333, pred_loss=[0.32669556, 0.6250092, 0.8078074]\n",
      "epoch=67_train_batch=21, total_loss=23.380172729492188, pred_loss=[0.62119246, 1.303648, 9.922121]\n",
      "epoch=67_train_batch=22, total_loss=13.003981590270996, pred_loss=[0.27488607, 0.17476627, 1.021419]\n",
      "epoch=67_train_batch=23, total_loss=13.43109130859375, pred_loss=[0.51914626, 0.7998098, 0.57952785]\n",
      "epoch=67_train_batch=24, total_loss=13.239884376525879, pred_loss=[0.41195452, 0.28755772, 1.0080696]\n",
      "epoch=67_train_batch=25, total_loss=13.904136657714844, pred_loss=[0.24523465, 0.29166198, 1.8352467]\n",
      "epoch=67_train_batch=26, total_loss=14.446605682373047, pred_loss=[0.20046724, 0.50799435, 2.2064629]\n",
      "epoch=67_train_batch=27, total_loss=12.420899391174316, pred_loss=[0.25658348, 0.21776824, 0.4151826]\n",
      "epoch=67_train_batch=28, total_loss=16.47040557861328, pred_loss=[0.2633825, 1.3493147, 3.3266635]\n",
      "epoch=67_train_batch=29, total_loss=16.328685760498047, pred_loss=[1.7957801, 0.2683062, 2.7338774]\n",
      "epoch=67_train_batch=30, total_loss=15.981820106506348, pred_loss=[0.39897543, 1.2498035, 2.802655]\n",
      "epoch=67_train_batch=31, total_loss=13.678149223327637, pred_loss=[0.53033125, 0.5634412, 1.0543276]\n",
      "epoch=67_train_batch=32, total_loss=14.112974166870117, pred_loss=[0.3388397, 0.20480561, 2.0396142]\n",
      "epoch=67_train_batch=33, total_loss=13.423583984375, pred_loss=[0.8777865, 0.23228773, 0.7841289]\n",
      "epoch=67_train_batch=34, total_loss=14.997430801391602, pred_loss=[0.36062324, 0.34301117, 2.7647436]\n",
      "epoch=67_train_batch=35, total_loss=12.445944786071777, pred_loss=[0.2746596, 0.3628883, 0.27967015]\n",
      "epoch=67_train_batch=36, total_loss=12.574173927307129, pred_loss=[0.20312123, 0.4335747, 0.40907675]\n",
      "epoch=67_train_batch=37, total_loss=12.741095542907715, pred_loss=[0.34526873, 0.16956657, 0.6981847]\n",
      "epoch=67_train_batch=38, total_loss=12.59405517578125, pred_loss=[0.44076815, 0.32830924, 0.2972299]\n",
      "epoch=67_train_batch=39, total_loss=12.747537612915039, pred_loss=[0.7553227, 0.13788873, 0.32691208]\n",
      "epoch=67_train_batch=40, total_loss=12.755167007446289, pred_loss=[0.25241435, 0.53598464, 0.4396875]\n",
      "epoch=67_train_batch=41, total_loss=12.583921432495117, pred_loss=[0.38263094, 0.37032843, 0.3042196]\n",
      "epoch=67_train_batch=42, total_loss=12.473252296447754, pred_loss=[0.21773541, 0.24155362, 0.4875623]\n",
      "epoch=67_train_batch=43, total_loss=12.855205535888672, pred_loss=[0.35720873, 0.7008039, 0.27113783]\n",
      "epoch=67_train_batch=44, total_loss=12.69107723236084, pred_loss=[0.5384628, 0.2818696, 0.34503537]\n",
      "epoch=67_train_batch=45, total_loss=12.47093677520752, pred_loss=[0.112241365, 0.5262133, 0.3071261]\n",
      "epoch=67_train_batch=46, total_loss=12.770524978637695, pred_loss=[0.012763901, 0.76947725, 0.46328357]\n",
      "epoch=67_train_batch=47, total_loss=12.786478042602539, pred_loss=[0.062074568, 0.34012815, 0.85963273]\n",
      "epoch=67_train_batch=48, total_loss=12.882699966430664, pred_loss=[0.18920293, 0.11616753, 1.0530457]\n",
      "epoch=67_train_batch=49, total_loss=12.316547393798828, pred_loss=[0.3855657, 0.12773782, 0.2793226]\n",
      "epoch=67_train_batch=50, total_loss=13.629545211791992, pred_loss=[0.15537271, 0.6080238, 1.3425926]\n",
      "epoch=67_train_batch=51, total_loss=13.273483276367188, pred_loss=[0.09490379, 0.32871395, 1.3266776]\n",
      "epoch=67_train_batch=52, total_loss=12.762641906738281, pred_loss=[0.6860277, 0.3817706, 0.17202607]\n",
      "epoch=67_train_batch=53, total_loss=13.25071907043457, pred_loss=[0.2067735, 1.0123676, 0.5091287]\n",
      "epoch=67_train_batch=54, total_loss=12.452038764953613, pred_loss=[0.2178368, 0.3130793, 0.39904776]\n",
      "epoch=67_train_batch=55, total_loss=12.497574806213379, pred_loss=[0.056965444, 0.39389095, 0.5250164]\n",
      "epoch=67_train_batch=56, total_loss=12.75952434539795, pred_loss=[0.58040416, 0.45100477, 0.2067857]\n",
      "epoch=67_train_batch=57, total_loss=13.202531814575195, pred_loss=[0.45202947, 0.4510373, 0.7785161]\n",
      "epoch=67_train_batch=58, total_loss=12.588789939880371, pred_loss=[0.30672508, 0.30647907, 0.45501155]\n",
      "epoch=67_train_batch=59, total_loss=12.948259353637695, pred_loss=[0.05931826, 0.92779636, 0.4409455]\n",
      "epoch=67_train_batch=60, total_loss=12.856863975524902, pred_loss=[0.14041325, 0.23086172, 0.9657624]\n",
      "epoch=67_train_batch=61, total_loss=14.074509620666504, pred_loss=[0.25215095, 0.8140427, 1.4888608]\n",
      "epoch=67_train_batch=62, total_loss=12.333212852478027, pred_loss=[0.2196252, 0.36348334, 0.23101936]\n",
      "epoch=67_train_batch=63, total_loss=12.593827247619629, pred_loss=[0.42921823, 0.15631151, 0.48958445]\n",
      "epoch=67_train_batch=64, total_loss=12.582585334777832, pred_loss=[0.40066528, 0.31642982, 0.3471472]\n",
      "epoch=67_train_batch=65, total_loss=12.631874084472656, pred_loss=[0.16106863, 0.17594036, 0.77689445]\n",
      "epoch=67_train_batch=66, total_loss=12.866866111755371, pred_loss=[0.28028268, 0.16701412, 0.9019723]\n",
      "epoch=67_train_batch=67, total_loss=13.94485855102539, pred_loss=[0.11526227, 0.308012, 2.0043626]\n",
      "epoch=67_train_batch=68, total_loss=12.50858211517334, pred_loss=[0.23453103, 0.23983765, 0.5173706]\n",
      "epoch=67_train_batch=69, total_loss=12.361928939819336, pred_loss=[0.38222414, 0.2973838, 0.16585714]\n",
      "epoch=67_train_batch=70, total_loss=12.62581729888916, pred_loss=[0.23752087, 0.40602338, 0.46618992]\n",
      "epoch=67_train_batch=71, total_loss=13.326251029968262, pred_loss=[0.16354302, 0.8401977, 0.80681]\n",
      "epoch=67_train_batch=72, total_loss=15.522546768188477, pred_loss=[0.66255045, 1.4085773, 1.9361014]\n",
      "epoch=67_train_batch=73, total_loss=12.363207817077637, pred_loss=[0.32093906, 0.2884243, 0.23890805]\n",
      "epoch=67_train_batch=74, total_loss=14.141914367675781, pred_loss=[0.005883863, 1.2148631, 1.4066112]\n",
      "epoch=67_train_batch=75, total_loss=13.385415077209473, pred_loss=[0.3563913, 0.45716816, 1.0576773]\n",
      "epoch=67_train_batch=76, total_loss=12.345090866088867, pred_loss=[0.08324084, 0.19515339, 0.5528954]\n",
      "epoch=67_train_batch=77, total_loss=13.070233345031738, pred_loss=[0.110463485, 0.23050849, 1.2158353]\n",
      "epoch=67_train_batch=78, total_loss=13.046161651611328, pred_loss=[0.21473412, 0.73822784, 0.5801492]\n",
      "epoch=67_train_batch=79, total_loss=15.671815872192383, pred_loss=[0.52146053, 0.8795066, 2.7581694]\n",
      "epoch=67_train_batch=80, total_loss=13.75407600402832, pred_loss=[0.40920416, 0.104768306, 1.7277972]\n",
      "epoch=67_train_batch=81, total_loss=12.579373359680176, pred_loss=[0.18139245, 0.51631767, 0.3697269]\n",
      "epoch=67_train_batch=82, total_loss=12.89607048034668, pred_loss=[0.44948357, 0.51197165, 0.42305022]\n",
      "epoch=67_train_batch=83, total_loss=12.78907299041748, pred_loss=[0.08760596, 0.2530548, 0.93721867]\n",
      "epoch=67_train_batch=84, total_loss=12.631389617919922, pred_loss=[0.14233477, 0.29604775, 0.68218607]\n",
      "epoch=67_train_batch=85, total_loss=13.241850852966309, pred_loss=[0.29334572, 0.24684483, 1.1912131]\n",
      "epoch=67_train_batch=86, total_loss=12.50704574584961, pred_loss=[0.17074737, 0.30546877, 0.5207546]\n",
      "epoch=67_train_batch=87, total_loss=11.794649124145508, pred_loss=[0.15465012, 0.04753379, 0.08276264]\n",
      "epoch=67_val_batch=0, total_val_loss=731.8956909179688, pred_val_loss[0.20072779, 56.56826, 663.6174]\n",
      "epoch=67_val_batch=1, total_val_loss=217.51101684570312, pred_val_loss[0.20448782, 125.22748, 80.569725]\n",
      "epoch=67_val_batch=2, total_val_loss=76.69596862792969, pred_val_loss[10.418639, 11.695074, 43.072926]\n",
      "epoch=67_val_batch=3, total_val_loss=116.3479995727539, pred_val_loss[0.9586182, 25.721863, 78.15819]\n",
      "epoch=67_val_batch=4, total_val_loss=94.2912368774414, pred_val_loss[6.375959, 22.9612, 53.444748]\n",
      "epoch=67_val_batch=5, total_val_loss=59.80961227416992, pred_val_loss[16.72105, 7.7493534, 23.829884]\n",
      "epoch=67_val_batch=6, total_val_loss=221.6065673828125, pred_val_loss[20.820225, 7.233959, 182.04306]\n",
      "epoch=67_val_batch=7, total_val_loss=159.63380432128906, pred_val_loss[0.65251756, 57.39484, 90.07712]\n",
      "epoch=67_val_batch=8, total_val_loss=57.840187072753906, pred_val_loss[0.3578337, 38.597645, 7.3753824]\n",
      "epoch=67_val_batch=9, total_val_loss=118.30509185791016, pred_val_loss[5.5350704, 52.606464, 48.65423]\n",
      "epoch=67_val_batch=10, total_val_loss=130.87332153320312, pred_val_loss[30.579956, 10.078353, 78.70568]\n",
      "epoch=67_val_batch=11, total_val_loss=159.39768981933594, pred_val_loss[7.469606, 68.91001, 71.50875]\n",
      "epoch=67_val_batch=12, total_val_loss=26.758270263671875, pred_val_loss[0.7922246, 5.5202127, 8.936505]\n",
      "epoch=67_val_batch=13, total_val_loss=95.58885955810547, pred_val_loss[0.26741946, 40.8043, 43.007816]\n",
      "epoch=67_val_batch=14, total_val_loss=99.08309936523438, pred_val_loss[8.796986, 30.922878, 47.853905]\n",
      "epoch=67_val_batch=15, total_val_loss=75.12610626220703, pred_val_loss[18.433033, 2.3509169, 42.832825]\n",
      "epoch=67_val_batch=16, total_val_loss=201.3079376220703, pred_val_loss[9.749698, 62.49949, 117.54944]\n",
      "epoch=67_val_batch=17, total_val_loss=163.76890563964844, pred_val_loss[17.730194, 15.504173, 119.02521]\n",
      "epoch=67_val_batch=18, total_val_loss=143.77456665039062, pred_val_loss[3.3038452, 29.993553, 98.96784]\n",
      "epoch=67, train: avg_loss=13.497733116149902, val: avg_val_loss=155.24293518066406\n",
      "Saved checkpoint for step 78: ./tf_ckpts/ckpt-77\n",
      "epoch=68_train_batch=0, total_loss=12.27045726776123, pred_loss=[0.043333862, 0.34603697, 0.37175834]\n",
      "epoch=68_train_batch=1, total_loss=14.080582618713379, pred_loss=[1.2874643, 0.17674907, 1.1074169]\n",
      "epoch=68_train_batch=2, total_loss=12.877062797546387, pred_loss=[0.46276802, 0.16895159, 0.7367457]\n",
      "epoch=68_train_batch=3, total_loss=12.730886459350586, pred_loss=[0.2970276, 0.28045613, 0.64514744]\n",
      "epoch=68_train_batch=4, total_loss=12.669130325317383, pred_loss=[0.58505654, 0.22635132, 0.34980273]\n",
      "epoch=68_train_batch=5, total_loss=12.517255783081055, pred_loss=[0.20531265, 0.22500518, 0.57935196]\n",
      "epoch=68_train_batch=6, total_loss=12.726527214050293, pred_loss=[0.33115822, 0.30603325, 0.5820794]\n",
      "epoch=68_train_batch=7, total_loss=12.589810371398926, pred_loss=[0.4767534, 0.4402371, 0.16589344]\n",
      "epoch=68_train_batch=8, total_loss=12.25313949584961, pred_loss=[0.34831467, 0.061204277, 0.3370297]\n",
      "epoch=68_train_batch=9, total_loss=12.431693077087402, pred_loss=[0.2777017, 0.26652548, 0.38121554]\n",
      "epoch=68_train_batch=10, total_loss=12.549033164978027, pred_loss=[0.22324602, 0.510781, 0.3091002]\n",
      "epoch=68_train_batch=11, total_loss=15.979182243347168, pred_loss=[0.10408584, 1.1776544, 3.1918812]\n",
      "epoch=68_train_batch=12, total_loss=13.43384075164795, pred_loss=[0.13596214, 0.61903596, 1.1736333]\n",
      "epoch=68_train_batch=13, total_loss=12.642495155334473, pred_loss=[0.40738794, 0.27401203, 0.4562423]\n",
      "epoch=68_train_batch=14, total_loss=12.396225929260254, pred_loss=[0.21919507, 0.23683748, 0.43569803]\n",
      "epoch=68_train_batch=15, total_loss=12.622464179992676, pred_loss=[0.60325944, 0.11051059, 0.40455934]\n",
      "epoch=68_train_batch=16, total_loss=13.258604049682617, pred_loss=[0.8782969, 0.71574104, 0.16079134]\n",
      "epoch=68_train_batch=17, total_loss=13.094106674194336, pred_loss=[0.091919936, 0.6787857, 0.81999797]\n",
      "epoch=68_train_batch=18, total_loss=13.325891494750977, pred_loss=[0.35821727, 0.33685857, 1.1277841]\n",
      "epoch=68_train_batch=19, total_loss=14.276944160461426, pred_loss=[0.074450955, 0.16599323, 2.5338383]\n",
      "epoch=68_train_batch=20, total_loss=14.048877716064453, pred_loss=[0.55311596, 0.061567757, 1.9319029]\n",
      "epoch=68_train_batch=21, total_loss=13.381339073181152, pred_loss=[0.41030458, 0.10904895, 1.3600656]\n",
      "epoch=68_train_batch=22, total_loss=14.59559440612793, pred_loss=[0.16171159, 0.4712706, 2.461066]\n",
      "epoch=68_train_batch=23, total_loss=14.055171012878418, pred_loss=[1.6957841, 0.6416305, 0.21658337]\n",
      "epoch=68_train_batch=24, total_loss=17.451942443847656, pred_loss=[0.8162597, 2.3372793, 2.7976012]\n",
      "epoch=68_train_batch=25, total_loss=12.461614608764648, pred_loss=[0.33312377, 0.29039967, 0.33766538]\n",
      "epoch=68_train_batch=26, total_loss=13.314935684204102, pred_loss=[0.41626194, 0.994213, 0.4044034]\n",
      "epoch=68_train_batch=27, total_loss=13.34532642364502, pred_loss=[0.17891839, 1.5083463, 0.15836242]\n",
      "epoch=68_train_batch=28, total_loss=16.366853713989258, pred_loss=[0.73182243, 0.82085586, 3.314822]\n",
      "epoch=68_train_batch=29, total_loss=12.971521377563477, pred_loss=[0.16771571, 0.22223793, 1.082546]\n",
      "epoch=68_train_batch=30, total_loss=12.327322006225586, pred_loss=[0.25078252, 0.220265, 0.35758564]\n",
      "epoch=68_train_batch=31, total_loss=23.246261596679688, pred_loss=[0.012236546, 1.5582032, 10.177464]\n",
      "epoch=68_train_batch=32, total_loss=12.928777694702148, pred_loss=[0.04611359, 0.49867353, 0.8859624]\n",
      "epoch=68_train_batch=33, total_loss=12.918642044067383, pred_loss=[0.18634099, 0.65153813, 0.5830643]\n",
      "epoch=68_train_batch=34, total_loss=12.642241477966309, pred_loss=[0.13585906, 0.4528243, 0.5561904]\n",
      "epoch=68_train_batch=35, total_loss=12.698843002319336, pred_loss=[0.13269006, 0.91366893, 0.15544827]\n",
      "epoch=68_train_batch=36, total_loss=12.56325912475586, pred_loss=[0.49886942, 0.36121213, 0.20647706]\n",
      "epoch=68_train_batch=37, total_loss=13.220118522644043, pred_loss=[0.38058326, 0.31992555, 1.0232502]\n",
      "epoch=68_train_batch=38, total_loss=13.393308639526367, pred_loss=[0.38820207, 0.33156008, 1.1775298]\n",
      "epoch=68_train_batch=39, total_loss=12.686683654785156, pred_loss=[0.11841789, 0.6016247, 0.47097164]\n",
      "epoch=68_train_batch=40, total_loss=15.83908748626709, pred_loss=[0.21113844, 2.1600466, 1.9725839]\n",
      "epoch=68_train_batch=41, total_loss=14.975647926330566, pred_loss=[0.24695238, 0.25663733, 2.9770927]\n",
      "epoch=68_train_batch=42, total_loss=13.448965072631836, pred_loss=[0.11035114, 0.52233076, 1.3216742]\n",
      "epoch=68_train_batch=43, total_loss=12.551691055297852, pred_loss=[0.19302957, 0.337905, 0.52650994]\n",
      "epoch=68_train_batch=44, total_loss=12.357985496520996, pred_loss=[0.37506175, 0.28846067, 0.20058095]\n",
      "epoch=68_train_batch=45, total_loss=13.400538444519043, pred_loss=[0.18311965, 1.2846167, 0.43928504]\n",
      "epoch=68_train_batch=46, total_loss=14.363607406616211, pred_loss=[0.042602528, 0.8268291, 2.0010295]\n",
      "epoch=68_train_batch=47, total_loss=12.756881713867188, pred_loss=[0.17888668, 0.35989124, 0.72533053]\n",
      "epoch=68_train_batch=48, total_loss=12.342485427856445, pred_loss=[0.11402284, 0.31084442, 0.42521703]\n",
      "epoch=68_train_batch=49, total_loss=13.36465072631836, pred_loss=[0.06052883, 0.87195927, 0.9401342]\n",
      "epoch=68_train_batch=50, total_loss=12.989276885986328, pred_loss=[0.32233024, 0.42105764, 0.7542359]\n",
      "epoch=68_train_batch=51, total_loss=12.795572280883789, pred_loss=[0.61684465, 0.46618724, 0.22126463]\n",
      "epoch=68_train_batch=52, total_loss=12.5840425491333, pred_loss=[0.30001557, 0.5406988, 0.25243202]\n",
      "epoch=68_train_batch=53, total_loss=12.801228523254395, pred_loss=[0.35417438, 0.31739938, 0.6391364]\n",
      "epoch=68_train_batch=54, total_loss=13.693281173706055, pred_loss=[0.29610133, 0.51677954, 1.3902603]\n",
      "epoch=68_train_batch=55, total_loss=13.670421600341797, pred_loss=[0.112530634, 0.13811526, 1.9300135]\n",
      "epoch=68_train_batch=56, total_loss=12.283197402954102, pred_loss=[0.1508694, 0.29794845, 0.34499696]\n",
      "epoch=68_train_batch=57, total_loss=12.213298797607422, pred_loss=[0.12133267, 0.30530548, 0.29765904]\n",
      "epoch=68_train_batch=58, total_loss=12.582679748535156, pred_loss=[0.22419153, 0.59006876, 0.2798015]\n",
      "epoch=68_train_batch=59, total_loss=12.52327823638916, pred_loss=[0.21139866, 0.585165, 0.23847905]\n",
      "epoch=68_train_batch=60, total_loss=12.566590309143066, pred_loss=[0.21062544, 0.4402135, 0.4278983]\n",
      "epoch=68_train_batch=61, total_loss=12.116127014160156, pred_loss=[0.28564036, 0.17930691, 0.16370602]\n",
      "epoch=68_train_batch=62, total_loss=12.600461959838867, pred_loss=[0.1104507, 0.24189997, 0.7610198]\n",
      "epoch=68_train_batch=63, total_loss=12.726292610168457, pred_loss=[0.009597645, 0.67102885, 0.55895805]\n",
      "epoch=68_train_batch=64, total_loss=13.697930335998535, pred_loss=[0.05703903, 0.3928417, 1.7617252]\n",
      "epoch=68_train_batch=65, total_loss=13.302919387817383, pred_loss=[0.1349624, 0.2715337, 1.4104853]\n",
      "epoch=68_train_batch=66, total_loss=13.107534408569336, pred_loss=[0.29847383, 0.2727636, 1.0507454]\n",
      "epoch=68_train_batch=67, total_loss=12.77904987335205, pred_loss=[0.16403703, 0.36494422, 0.76490647]\n",
      "epoch=68_train_batch=68, total_loss=12.675715446472168, pred_loss=[0.08777048, 0.7148272, 0.38834327]\n",
      "epoch=68_train_batch=69, total_loss=13.116095542907715, pred_loss=[0.10027222, 0.70203567, 0.8294019]\n",
      "epoch=68_train_batch=70, total_loss=12.501249313354492, pred_loss=[0.024326678, 0.4402957, 0.55263156]\n",
      "epoch=68_train_batch=71, total_loss=12.934755325317383, pred_loss=[0.39072, 0.34782073, 0.712606]\n",
      "epoch=68_train_batch=72, total_loss=12.403631210327148, pred_loss=[0.061761796, 0.6809542, 0.17769668]\n",
      "epoch=68_train_batch=73, total_loss=13.153303146362305, pred_loss=[0.46885037, 0.17612821, 1.0254955]\n",
      "epoch=68_train_batch=74, total_loss=13.220900535583496, pred_loss=[0.021887384, 0.47473353, 1.2418377]\n",
      "epoch=68_train_batch=75, total_loss=12.327653884887695, pred_loss=[0.0487177, 0.34371388, 0.4531681]\n",
      "epoch=68_train_batch=76, total_loss=21.55829429626465, pred_loss=[0.06763042, 1.5502089, 8.458789]\n",
      "epoch=68_train_batch=77, total_loss=12.234501838684082, pred_loss=[0.40869933, 0.15654252, 0.18798548]\n",
      "epoch=68_train_batch=78, total_loss=12.543596267700195, pred_loss=[0.60825473, 0.1925027, 0.26195574]\n",
      "epoch=68_train_batch=79, total_loss=12.47421646118164, pred_loss=[0.23175329, 0.43400332, 0.32796454]\n",
      "epoch=68_train_batch=80, total_loss=12.65760612487793, pred_loss=[0.3971763, 0.22436798, 0.55595315]\n",
      "epoch=68_train_batch=81, total_loss=13.090580940246582, pred_loss=[0.049592443, 0.36012957, 1.2011335]\n",
      "epoch=68_train_batch=82, total_loss=12.217641830444336, pred_loss=[0.1623523, 0.385458, 0.1904867]\n",
      "epoch=68_train_batch=83, total_loss=12.652864456176758, pred_loss=[0.5517416, 0.14624988, 0.47590932]\n",
      "epoch=68_train_batch=84, total_loss=15.146875381469727, pred_loss=[0.16026686, 0.63447464, 2.873551]\n",
      "epoch=68_train_batch=85, total_loss=12.349141120910645, pred_loss=[0.2706383, 0.26920712, 0.33109093]\n",
      "epoch=68_train_batch=86, total_loss=12.011058807373047, pred_loss=[0.26129198, 0.115636624, 0.15630603]\n",
      "epoch=68_train_batch=87, total_loss=11.760563850402832, pred_loss=[0.10880609, 0.09316039, 0.081154905]\n",
      "epoch=68_val_batch=0, total_val_loss=663.0745239257812, pred_val_loss[0.2168363, 56.718395, 594.66223]\n",
      "epoch=68_val_batch=1, total_val_loss=213.32142639160156, pred_val_loss[0.06290239, 122.123276, 79.65817]\n",
      "epoch=68_val_batch=2, total_val_loss=80.40196228027344, pred_val_loss[12.496674, 12.098383, 44.32985]\n",
      "epoch=68_val_batch=3, total_val_loss=118.49089050292969, pred_val_loss[4.283618, 24.91374, 77.816475]\n",
      "epoch=68_val_batch=4, total_val_loss=86.19779205322266, pred_val_loss[5.130715, 24.807358, 44.782665]\n",
      "epoch=68_val_batch=5, total_val_loss=59.31995391845703, pred_val_loss[15.364746, 8.48425, 23.9939]\n",
      "epoch=68_val_batch=6, total_val_loss=208.1890869140625, pred_val_loss[24.1067, 7.5526047, 165.05272]\n",
      "epoch=68_val_batch=7, total_val_loss=160.11512756347656, pred_val_loss[0.6943982, 56.395153, 91.54851]\n",
      "epoch=68_val_batch=8, total_val_loss=61.933876037597656, pred_val_loss[0.27977633, 42.771015, 7.406026]\n",
      "epoch=68_val_batch=9, total_val_loss=115.47306060791016, pred_val_loss[2.8806105, 53.346985, 47.768406]\n",
      "epoch=68_val_batch=10, total_val_loss=130.8568572998047, pred_val_loss[30.407356, 10.094563, 78.87787]\n",
      "epoch=68_val_batch=11, total_val_loss=161.4089813232422, pred_val_loss[9.217619, 69.01993, 71.69436]\n",
      "epoch=68_val_batch=12, total_val_loss=28.814533233642578, pred_val_loss[0.539934, 7.0528316, 9.74471]\n",
      "epoch=68_val_batch=13, total_val_loss=99.0936508178711, pred_val_loss[0.1634499, 45.066315, 42.386826]\n",
      "epoch=68_val_batch=14, total_val_loss=96.70626068115234, pred_val_loss[10.313839, 29.974476, 44.94089]\n",
      "epoch=68_val_batch=15, total_val_loss=76.45305633544922, pred_val_loss[20.34424, 2.3813176, 42.250443]\n",
      "epoch=68_val_batch=16, total_val_loss=194.82005310058594, pred_val_loss[8.689866, 61.927254, 112.72586]\n",
      "epoch=68_val_batch=17, total_val_loss=161.13229370117188, pred_val_loss[17.627277, 16.4681, 115.55985]\n",
      "epoch=68_val_batch=18, total_val_loss=139.1231231689453, pred_val_loss[4.8225517, 33.08589, 89.73761]\n",
      "epoch=68, train: avg_loss=13.304647445678711, val: avg_val_loss=150.25929260253906\n",
      "Saved checkpoint for step 79: ./tf_ckpts/ckpt-78\n",
      "epoch=69_train_batch=0, total_loss=12.194456100463867, pred_loss=[0.17099985, 0.3450643, 0.20133239]\n",
      "epoch=69_train_batch=1, total_loss=12.03353500366211, pred_loss=[0.2663172, 0.11128297, 0.17926198]\n",
      "epoch=69_train_batch=2, total_loss=12.363748550415039, pred_loss=[0.32324928, 0.34734815, 0.21686539]\n",
      "epoch=69_train_batch=3, total_loss=14.116905212402344, pred_loss=[0.16140148, 0.3559651, 2.1236415]\n",
      "epoch=69_train_batch=4, total_loss=12.927835464477539, pred_loss=[0.25930005, 0.17823274, 1.014795]\n",
      "epoch=69_train_batch=5, total_loss=12.442227363586426, pred_loss=[0.24661067, 0.22842374, 0.49207446]\n",
      "epoch=69_train_batch=6, total_loss=12.242854118347168, pred_loss=[0.36051834, 0.16396031, 0.24364646]\n",
      "epoch=69_train_batch=7, total_loss=13.183253288269043, pred_loss=[0.5393173, 0.9395497, 0.23004839]\n",
      "epoch=69_train_batch=8, total_loss=12.488407135009766, pred_loss=[0.04873915, 0.28808933, 0.6776378]\n",
      "epoch=69_train_batch=9, total_loss=13.778162956237793, pred_loss=[0.04897619, 0.2056485, 2.049992]\n",
      "epoch=69_train_batch=10, total_loss=12.390924453735352, pred_loss=[0.007293299, 0.5042256, 0.4062553]\n",
      "epoch=69_train_batch=11, total_loss=12.96623706817627, pred_loss=[0.0054196846, 0.8264134, 0.6616531]\n",
      "epoch=69_train_batch=12, total_loss=12.260347366333008, pred_loss=[0.09415431, 0.30120298, 0.39263842]\n",
      "epoch=69_train_batch=13, total_loss=13.12972354888916, pred_loss=[0.01839183, 0.517649, 1.12173]\n",
      "epoch=69_train_batch=14, total_loss=12.477219581604004, pred_loss=[0.03398827, 0.6394887, 0.33218938]\n",
      "epoch=69_train_batch=15, total_loss=12.39556884765625, pred_loss=[0.2118513, 0.36303714, 0.34952748]\n",
      "epoch=69_train_batch=16, total_loss=15.982765197753906, pred_loss=[0.4387966, 0.13604634, 3.9371662]\n",
      "epoch=69_train_batch=17, total_loss=12.066268920898438, pred_loss=[0.20644608, 0.14670242, 0.24276164]\n",
      "epoch=69_train_batch=18, total_loss=15.50958251953125, pred_loss=[0.11282953, 0.3380264, 3.588762]\n",
      "epoch=69_train_batch=19, total_loss=12.085938453674316, pred_loss=[0.29444715, 0.14873669, 0.1731824]\n",
      "epoch=69_train_batch=20, total_loss=12.36336612701416, pred_loss=[0.10309736, 0.4812323, 0.30985504]\n",
      "epoch=69_train_batch=21, total_loss=13.038778305053711, pred_loss=[0.19019867, 0.65737534, 0.7224127]\n",
      "epoch=69_train_batch=22, total_loss=12.074085235595703, pred_loss=[0.24166447, 0.21380197, 0.15021378]\n",
      "epoch=69_train_batch=23, total_loss=12.326835632324219, pred_loss=[0.069976486, 0.29990944, 0.4889318]\n",
      "epoch=69_train_batch=24, total_loss=12.204753875732422, pred_loss=[0.06233106, 0.26381248, 0.41097945]\n",
      "epoch=69_train_batch=25, total_loss=12.442631721496582, pred_loss=[0.14056587, 0.32445934, 0.5103642]\n",
      "epoch=69_train_batch=26, total_loss=20.936716079711914, pred_loss=[0.0990171, 0.3121944, 9.058651]\n",
      "epoch=69_train_batch=27, total_loss=22.88002586364746, pred_loss=[0.24050954, 1.8324239, 9.3406315]\n",
      "epoch=69_train_batch=28, total_loss=13.73100471496582, pred_loss=[1.6950086, 0.2531268, 0.31679726]\n",
      "epoch=69_train_batch=29, total_loss=13.161328315734863, pred_loss=[0.13105655, 0.09618991, 1.4684018]\n",
      "epoch=69_train_batch=30, total_loss=12.148000717163086, pred_loss=[0.08490988, 0.20636676, 0.39141554]\n",
      "epoch=69_train_batch=31, total_loss=12.451406478881836, pred_loss=[0.45112017, 0.16000247, 0.37533516]\n",
      "epoch=69_train_batch=32, total_loss=12.929759979248047, pred_loss=[0.56529987, 0.10294368, 0.7969218]\n",
      "epoch=69_train_batch=33, total_loss=12.53056526184082, pred_loss=[0.04637064, 0.44737545, 0.5725684]\n",
      "epoch=69_train_batch=34, total_loss=12.669282913208008, pred_loss=[0.30347776, 0.24174368, 0.6601537]\n",
      "epoch=69_train_batch=35, total_loss=12.179603576660156, pred_loss=[0.39591208, 0.1658695, 0.15425727]\n",
      "epoch=69_train_batch=36, total_loss=12.390206336975098, pred_loss=[0.19786164, 0.31438896, 0.4147354]\n",
      "epoch=69_train_batch=37, total_loss=13.374317169189453, pred_loss=[0.2419729, 0.106403716, 1.5630629]\n",
      "epoch=69_train_batch=38, total_loss=12.538110733032227, pred_loss=[0.2814844, 0.18058246, 0.6135187]\n",
      "epoch=69_train_batch=39, total_loss=14.341227531433105, pred_loss=[0.0930071, 0.9033376, 1.8827103]\n",
      "epoch=69_train_batch=40, total_loss=12.143588066101074, pred_loss=[0.09130752, 0.3095503, 0.2809086]\n",
      "epoch=69_train_batch=41, total_loss=12.428933143615723, pred_loss=[0.41385785, 0.35190004, 0.20170665]\n",
      "epoch=69_train_batch=42, total_loss=12.211930274963379, pred_loss=[0.20793872, 0.3080325, 0.23484257]\n",
      "epoch=69_train_batch=43, total_loss=12.348794937133789, pred_loss=[0.22017813, 0.44369233, 0.22416162]\n",
      "epoch=69_train_batch=44, total_loss=13.630003929138184, pred_loss=[0.24594596, 0.2905811, 1.6330696]\n",
      "epoch=69_train_batch=45, total_loss=13.049492835998535, pred_loss=[0.25523162, 0.5637485, 0.77046436]\n",
      "epoch=69_train_batch=46, total_loss=12.06305980682373, pred_loss=[0.1505774, 0.25186726, 0.20092472]\n",
      "epoch=69_train_batch=47, total_loss=12.430588722229004, pred_loss=[0.18575545, 0.114303894, 0.67120206]\n",
      "epoch=69_train_batch=48, total_loss=15.833364486694336, pred_loss=[0.20408764, 0.20395824, 3.9663575]\n",
      "epoch=69_train_batch=49, total_loss=12.585742950439453, pred_loss=[0.22549708, 0.3852909, 0.5163634]\n",
      "epoch=69_train_batch=50, total_loss=12.747299194335938, pred_loss=[0.117545314, 0.14761305, 1.0239191]\n",
      "epoch=69_train_batch=51, total_loss=12.406816482543945, pred_loss=[0.16111284, 0.33449644, 0.45335948]\n",
      "epoch=69_train_batch=52, total_loss=13.9928560256958, pred_loss=[0.02283568, 0.4180464, 2.0945013]\n",
      "epoch=69_train_batch=53, total_loss=12.645866394042969, pred_loss=[0.007313756, 0.49494103, 0.68651545]\n",
      "epoch=69_train_batch=54, total_loss=12.609603881835938, pred_loss=[0.21856526, 0.3727955, 0.56152904]\n",
      "epoch=69_train_batch=55, total_loss=12.477792739868164, pred_loss=[0.26460737, 0.23437467, 0.5224808]\n",
      "epoch=69_train_batch=56, total_loss=12.521516799926758, pred_loss=[0.17540923, 0.16061062, 0.7295543]\n",
      "epoch=69_train_batch=57, total_loss=17.89205551147461, pred_loss=[0.008040985, 0.48228362, 5.9461765]\n",
      "epoch=69_train_batch=58, total_loss=13.133293151855469, pred_loss=[0.18741664, 0.21964228, 1.2710712]\n",
      "epoch=69_train_batch=59, total_loss=13.197420120239258, pred_loss=[0.22656997, 0.1264883, 1.3895911]\n",
      "epoch=69_train_batch=60, total_loss=12.715841293334961, pred_loss=[0.15443581, 0.21710202, 0.8899274]\n",
      "epoch=69_train_batch=61, total_loss=12.875537872314453, pred_loss=[0.047678884, 0.39269364, 0.98118347]\n",
      "epoch=69_train_batch=62, total_loss=12.631063461303711, pred_loss=[0.055343788, 0.2918275, 0.83030593]\n",
      "epoch=69_train_batch=63, total_loss=13.243345260620117, pred_loss=[0.2206896, 0.090262584, 1.4792018]\n",
      "epoch=69_train_batch=64, total_loss=12.814685821533203, pred_loss=[0.037402563, 0.25482035, 1.0696691]\n",
      "epoch=69_train_batch=65, total_loss=12.262312889099121, pred_loss=[0.31179658, 0.28171533, 0.21640518]\n",
      "epoch=69_train_batch=66, total_loss=12.90423583984375, pred_loss=[0.34740174, 0.26813853, 0.83670247]\n",
      "epoch=69_train_batch=67, total_loss=12.473248481750488, pred_loss=[0.17081065, 0.27841842, 0.5724299]\n",
      "epoch=69_train_batch=68, total_loss=13.040420532226562, pred_loss=[0.0880232, 0.10352397, 1.3976878]\n",
      "epoch=69_train_batch=69, total_loss=12.497832298278809, pred_loss=[0.14396358, 0.33370537, 0.5693824]\n",
      "epoch=69_train_batch=70, total_loss=12.83604621887207, pred_loss=[0.28285798, 0.34479758, 0.75801516]\n",
      "epoch=69_train_batch=71, total_loss=12.255276679992676, pred_loss=[0.04285655, 0.4019012, 0.36054805]\n",
      "epoch=69_train_batch=72, total_loss=15.5277099609375, pred_loss=[0.10637676, 1.01903, 2.9527378]\n",
      "epoch=69_train_batch=73, total_loss=12.262718200683594, pred_loss=[0.29542863, 0.26812136, 0.25000766]\n",
      "epoch=69_train_batch=74, total_loss=13.746709823608398, pred_loss=[0.014407217, 0.58257663, 1.7009735]\n",
      "epoch=69_train_batch=75, total_loss=12.373777389526367, pred_loss=[0.21964258, 0.2746029, 0.43118772]\n",
      "epoch=69_train_batch=76, total_loss=12.287059783935547, pred_loss=[0.016114991, 0.40249074, 0.42051828]\n",
      "epoch=69_train_batch=77, total_loss=12.058361053466797, pred_loss=[0.3311563, 0.044280592, 0.2353948]\n",
      "epoch=69_train_batch=78, total_loss=13.76623249053955, pred_loss=[0.30249748, 0.61631155, 1.4003046]\n",
      "epoch=69_train_batch=79, total_loss=13.403486251831055, pred_loss=[1.0017864, 0.14959621, 0.8053971]\n",
      "epoch=69_train_batch=80, total_loss=17.87111473083496, pred_loss=[0.172953, 2.5227604, 3.7291002]\n",
      "epoch=69_train_batch=81, total_loss=12.8566312789917, pred_loss=[0.26796168, 0.30240306, 0.84037006]\n",
      "epoch=69_train_batch=82, total_loss=12.223494529724121, pred_loss=[0.08806382, 0.37188637, 0.31804878]\n",
      "epoch=69_train_batch=83, total_loss=13.085660934448242, pred_loss=[0.05365711, 0.8408559, 0.74605095]\n",
      "epoch=69_train_batch=84, total_loss=12.579211235046387, pred_loss=[0.049799554, 0.47643986, 0.6082722]\n",
      "epoch=69_train_batch=85, total_loss=12.105718612670898, pred_loss=[0.21021193, 0.067487046, 0.38371584]\n",
      "epoch=69_train_batch=86, total_loss=12.345331192016602, pred_loss=[0.18858412, 0.101006106, 0.61183417]\n",
      "epoch=69_train_batch=87, total_loss=12.369036674499512, pred_loss=[0.028430566, 0.35688597, 0.54021]\n",
      "epoch=69_val_batch=0, total_val_loss=696.1751708984375, pred_val_loss[0.25097713, 53.878235, 630.60284]\n",
      "epoch=69_val_batch=1, total_val_loss=209.6048126220703, pred_val_loss[0.36235145, 117.4787, 80.32065]\n",
      "epoch=69_val_batch=2, total_val_loss=74.26893615722656, pred_val_loss[9.90118, 11.864486, 41.06016]\n",
      "epoch=69_val_batch=3, total_val_loss=121.92678833007812, pred_val_loss[6.2503753, 24.610434, 79.62286]\n",
      "epoch=69_val_batch=4, total_val_loss=94.8724365234375, pred_val_loss[4.6862144, 23.882278, 54.86083]\n",
      "epoch=69_val_batch=5, total_val_loss=60.8018684387207, pred_val_loss[17.408716, 5.8378725, 26.112167]\n",
      "epoch=69_val_batch=6, total_val_loss=213.57833862304688, pred_val_loss[15.250534, 6.5966935, 180.288]\n",
      "epoch=69_val_batch=7, total_val_loss=158.6757049560547, pred_val_loss[0.71739167, 55.42651, 91.08869]\n",
      "epoch=69_val_batch=8, total_val_loss=54.19428253173828, pred_val_loss[0.19659911, 34.498238, 8.0563345]\n",
      "epoch=69_val_batch=9, total_val_loss=124.53971862792969, pred_val_loss[5.615101, 54.316715, 53.164795]\n",
      "epoch=69_val_batch=10, total_val_loss=127.08108520507812, pred_val_loss[26.051443, 9.612865, 79.97367]\n",
      "epoch=69_val_batch=11, total_val_loss=149.93727111816406, pred_val_loss[8.287925, 60.812515, 69.393715]\n",
      "epoch=69_val_batch=12, total_val_loss=24.83275032043457, pred_val_loss[0.3586502, 5.61787, 7.4131184]\n",
      "epoch=69_val_batch=13, total_val_loss=92.8941650390625, pred_val_loss[0.21968734, 37.40363, 43.827736]\n",
      "epoch=69_val_batch=14, total_val_loss=93.90155029296875, pred_val_loss[8.801626, 28.356134, 45.300682]\n",
      "epoch=69_val_batch=15, total_val_loss=76.67208862304688, pred_val_loss[16.780186, 1.7346077, 46.71418]\n",
      "epoch=69_val_batch=16, total_val_loss=197.28347778320312, pred_val_loss[6.528722, 61.76684, 117.54479]\n",
      "epoch=69_val_batch=17, total_val_loss=162.22756958007812, pred_val_loss[16.780779, 14.5189295, 119.48475]\n",
      "epoch=69_val_batch=18, total_val_loss=144.6199951171875, pred_val_loss[2.296018, 32.411182, 98.46969]\n",
      "epoch=69, train: avg_loss=13.153525352478027, val: avg_val_loss=151.4783172607422\n",
      "Saved checkpoint for step 80: ./tf_ckpts/ckpt-79\n",
      "epoch=70_train_batch=0, total_loss=13.850260734558105, pred_loss=[0.033903353, 1.1824548, 1.1907911]\n",
      "epoch=70_train_batch=1, total_loss=12.431246757507324, pred_loss=[0.05941596, 0.22225541, 0.7068633]\n",
      "epoch=70_train_batch=2, total_loss=12.164630889892578, pred_loss=[0.2588287, 0.17490506, 0.28858602]\n",
      "epoch=70_train_batch=3, total_loss=12.127396583557129, pred_loss=[0.051939383, 0.13222036, 0.50132704]\n",
      "epoch=70_train_batch=4, total_loss=12.074396133422852, pred_loss=[0.09897175, 0.06218239, 0.4717339]\n",
      "epoch=70_train_batch=5, total_loss=12.43238353729248, pred_loss=[0.27235088, 0.39689073, 0.32203722]\n",
      "epoch=70_train_batch=6, total_loss=12.15916633605957, pred_loss=[0.22363277, 0.28127313, 0.21356007]\n",
      "epoch=70_train_batch=7, total_loss=15.992115020751953, pred_loss=[0.35440233, 0.3726338, 3.8247838]\n",
      "epoch=70_train_batch=8, total_loss=12.301302909851074, pred_loss=[0.24197584, 0.3178056, 0.30163446]\n",
      "epoch=70_train_batch=9, total_loss=12.843350410461426, pred_loss=[0.3087098, 0.4259936, 0.6691646]\n",
      "epoch=70_train_batch=10, total_loss=12.685900688171387, pred_loss=[0.12727605, 0.4156584, 0.703892]\n",
      "epoch=70_train_batch=11, total_loss=12.24644660949707, pred_loss=[0.19053057, 0.30346677, 0.3137834]\n",
      "epoch=70_train_batch=12, total_loss=12.206815719604492, pred_loss=[0.13295436, 0.23649219, 0.39911464]\n",
      "epoch=70_train_batch=13, total_loss=12.394133567810059, pred_loss=[0.17370331, 0.47237486, 0.31021214]\n",
      "epoch=70_train_batch=14, total_loss=12.24118423461914, pred_loss=[0.2095189, 0.15722267, 0.43700805]\n",
      "epoch=70_train_batch=15, total_loss=12.411574363708496, pred_loss=[0.09482321, 0.52056897, 0.35915634]\n",
      "epoch=70_train_batch=16, total_loss=12.575636863708496, pred_loss=[0.13947345, 0.4813448, 0.5182037]\n",
      "epoch=70_train_batch=17, total_loss=12.083900451660156, pred_loss=[0.1030551, 0.39856765, 0.1460745]\n",
      "epoch=70_train_batch=18, total_loss=12.516260147094727, pred_loss=[0.08766484, 0.29416996, 0.69863296]\n",
      "epoch=70_train_batch=19, total_loss=12.473160743713379, pred_loss=[0.177564, 0.17898387, 0.6812316]\n",
      "epoch=70_train_batch=20, total_loss=12.391077995300293, pred_loss=[0.26778936, 0.22816887, 0.46015]\n",
      "epoch=70_train_batch=21, total_loss=19.08075714111328, pred_loss=[0.07596642, 0.22543931, 7.344796]\n",
      "epoch=70_train_batch=22, total_loss=12.83772087097168, pred_loss=[0.11040437, 0.30110386, 0.9920701]\n",
      "epoch=70_train_batch=23, total_loss=13.752963066101074, pred_loss=[0.056259286, 0.89909136, 1.3638793]\n",
      "epoch=70_train_batch=24, total_loss=12.431244850158691, pred_loss=[0.29491207, 0.10210955, 0.60089815]\n",
      "epoch=70_train_batch=25, total_loss=12.20136833190918, pred_loss=[0.084053695, 0.22761229, 0.4567849]\n",
      "epoch=70_train_batch=26, total_loss=13.327144622802734, pred_loss=[0.20638788, 1.0778998, 0.61034787]\n",
      "epoch=70_train_batch=27, total_loss=12.789383888244629, pred_loss=[0.13066202, 0.5191293, 0.70749235]\n",
      "epoch=70_train_batch=28, total_loss=13.901726722717285, pred_loss=[0.09022631, 0.2109336, 2.1688766]\n",
      "epoch=70_train_batch=29, total_loss=12.9656343460083, pred_loss=[0.095510006, 0.19485492, 1.2439872]\n",
      "epoch=70_train_batch=30, total_loss=12.144472122192383, pred_loss=[0.135002, 0.37427756, 0.20431942]\n",
      "epoch=70_train_batch=31, total_loss=14.891132354736328, pred_loss=[0.08303875, 0.54117763, 2.8364534]\n",
      "epoch=70_train_batch=32, total_loss=12.204378128051758, pred_loss=[0.08606705, 0.080703795, 0.6075555]\n",
      "epoch=70_train_batch=33, total_loss=13.56727123260498, pred_loss=[0.15520848, 0.7807249, 1.2016971]\n",
      "epoch=70_train_batch=34, total_loss=13.420305252075195, pred_loss=[1.3070711, 0.5490696, 0.13493499]\n",
      "epoch=70_train_batch=35, total_loss=12.822089195251465, pred_loss=[0.021151468, 0.5205998, 0.8515177]\n",
      "epoch=70_train_batch=36, total_loss=12.2240629196167, pred_loss=[0.07758193, 0.47411656, 0.24395159]\n",
      "epoch=70_train_batch=37, total_loss=13.434821128845215, pred_loss=[0.7165281, 0.5622133, 0.7280737]\n",
      "epoch=70_train_batch=38, total_loss=12.751898765563965, pred_loss=[0.047632024, 0.11271727, 1.163945]\n",
      "epoch=70_train_batch=39, total_loss=12.053645133972168, pred_loss=[0.07735766, 0.13049999, 0.41858158]\n",
      "epoch=70_train_batch=40, total_loss=12.302129745483398, pred_loss=[0.12740284, 0.61907923, 0.1288412]\n",
      "epoch=70_train_batch=41, total_loss=12.468888282775879, pred_loss=[0.3563463, 0.32245237, 0.36368245]\n",
      "epoch=70_train_batch=42, total_loss=16.054899215698242, pred_loss=[0.08335547, 1.6094646, 2.9360723]\n",
      "epoch=70_train_batch=43, total_loss=12.428963661193848, pred_loss=[0.10236957, 0.36036843, 0.5406168]\n",
      "epoch=70_train_batch=44, total_loss=12.100348472595215, pred_loss=[0.15112934, 0.31816012, 0.20585036]\n",
      "epoch=70_train_batch=45, total_loss=12.160329818725586, pred_loss=[0.10340619, 0.1864262, 0.44568974]\n",
      "epoch=70_train_batch=46, total_loss=13.008636474609375, pred_loss=[0.0097512435, 0.42763528, 1.1468463]\n",
      "epoch=70_train_batch=47, total_loss=12.19509220123291, pred_loss=[0.07403944, 0.2035872, 0.49346477]\n",
      "epoch=70_train_batch=48, total_loss=12.568487167358398, pred_loss=[0.09945288, 0.16816826, 0.8772722]\n",
      "epoch=70_train_batch=49, total_loss=11.984731674194336, pred_loss=[0.044552088, 0.27311513, 0.24388096]\n",
      "epoch=70_train_batch=50, total_loss=12.278238296508789, pred_loss=[0.1597678, 0.20453978, 0.4911582]\n",
      "epoch=70_train_batch=51, total_loss=11.966194152832031, pred_loss=[0.13126886, 0.16169843, 0.2508654]\n",
      "epoch=70_train_batch=52, total_loss=12.585210800170898, pred_loss=[0.15319706, 0.33070338, 0.6793618]\n",
      "epoch=70_train_batch=53, total_loss=12.724542617797852, pred_loss=[0.1852516, 0.45670044, 0.66105807]\n",
      "epoch=70_train_batch=54, total_loss=12.132669448852539, pred_loss=[0.17048374, 0.19961995, 0.34144938]\n",
      "epoch=70_train_batch=55, total_loss=12.421870231628418, pred_loss=[0.13074537, 0.20147194, 0.6689532]\n",
      "epoch=70_train_batch=56, total_loss=12.26150894165039, pred_loss=[0.22237659, 0.18798895, 0.4308623]\n",
      "epoch=70_train_batch=57, total_loss=13.636417388916016, pred_loss=[0.15908271, 0.32014543, 1.7373269]\n",
      "epoch=70_train_batch=58, total_loss=12.492881774902344, pred_loss=[0.075529635, 0.17685743, 0.8210505]\n",
      "epoch=70_train_batch=59, total_loss=12.564282417297363, pred_loss=[0.7098737, 0.25099826, 0.1843873]\n",
      "epoch=70_train_batch=60, total_loss=12.908860206604004, pred_loss=[0.03499323, 0.36641508, 1.0888507]\n",
      "epoch=70_train_batch=61, total_loss=11.849546432495117, pred_loss=[0.092507824, 0.109006464, 0.2298534]\n",
      "epoch=70_train_batch=62, total_loss=12.398181915283203, pred_loss=[0.08366333, 0.39694834, 0.49981534]\n",
      "epoch=70_train_batch=63, total_loss=12.07410717010498, pred_loss=[0.12585641, 0.26976702, 0.2611522]\n",
      "epoch=70_train_batch=64, total_loss=12.95254898071289, pred_loss=[0.63394564, 0.26163918, 0.6400565]\n",
      "epoch=70_train_batch=65, total_loss=12.256207466125488, pred_loss=[0.05237888, 0.30619243, 0.48115695]\n",
      "epoch=70_train_batch=66, total_loss=12.369842529296875, pred_loss=[0.16861784, 0.09928951, 0.6858864]\n",
      "epoch=70_train_batch=67, total_loss=12.26977252960205, pred_loss=[0.08918784, 0.17332657, 0.5916369]\n",
      "epoch=70_train_batch=68, total_loss=11.900033950805664, pred_loss=[0.21193597, 0.137748, 0.13515593]\n",
      "epoch=70_train_batch=69, total_loss=12.907914161682129, pred_loss=[0.15493535, 0.36754015, 0.9706708]\n",
      "epoch=70_train_batch=70, total_loss=11.961616516113281, pred_loss=[0.0434802, 0.09899705, 0.40479875]\n",
      "epoch=70_train_batch=71, total_loss=20.343496322631836, pred_loss=[0.025988098, 0.618587, 8.285007]\n",
      "epoch=70_train_batch=72, total_loss=12.165962219238281, pred_loss=[0.09925506, 0.23166743, 0.42155212]\n",
      "epoch=70_train_batch=73, total_loss=12.302395820617676, pred_loss=[0.15059334, 0.18254063, 0.5561992]\n",
      "epoch=70_train_batch=74, total_loss=12.153213500976562, pred_loss=[0.16510083, 0.2876096, 0.28786367]\n",
      "epoch=70_train_batch=75, total_loss=13.677587509155273, pred_loss=[0.00852021, 0.2906096, 1.9662414]\n",
      "epoch=70_train_batch=76, total_loss=11.887674331665039, pred_loss=[0.06988008, 0.17595644, 0.23004426]\n",
      "epoch=70_train_batch=77, total_loss=12.800200462341309, pred_loss=[0.3260225, 0.081282, 0.98152703]\n",
      "epoch=70_train_batch=78, total_loss=16.342693328857422, pred_loss=[0.2489751, 0.21005322, 4.4727182]\n",
      "epoch=70_train_batch=79, total_loss=16.431190490722656, pred_loss=[0.06995, 2.861276, 2.089442]\n",
      "epoch=70_train_batch=80, total_loss=12.568653106689453, pred_loss=[0.03474395, 0.45220274, 0.67160517]\n",
      "epoch=70_train_batch=81, total_loss=18.013835906982422, pred_loss=[0.0038496242, 0.12015193, 6.480158]\n",
      "epoch=70_train_batch=82, total_loss=12.114213943481445, pred_loss=[0.117935084, 0.30140734, 0.2856198]\n",
      "epoch=70_train_batch=83, total_loss=12.1515474319458, pred_loss=[0.14210975, 0.37377176, 0.22683446]\n",
      "epoch=70_train_batch=84, total_loss=13.924023628234863, pred_loss=[0.15201873, 0.21466343, 2.1489275]\n",
      "epoch=70_train_batch=85, total_loss=12.125718116760254, pred_loss=[0.11997787, 0.15172374, 0.4460169]\n",
      "epoch=70_train_batch=86, total_loss=12.188602447509766, pred_loss=[0.15860134, 0.22723162, 0.39518458]\n",
      "epoch=70_train_batch=87, total_loss=12.332803726196289, pred_loss=[0.08981384, 0.09730393, 0.738516]\n",
      "epoch=70_val_batch=0, total_val_loss=706.3507080078125, pred_val_loss[0.17308806, 54.26726, 640.5036]\n",
      "epoch=70_val_batch=1, total_val_loss=218.03797912597656, pred_val_loss[0.040994477, 125.57465, 81.01559]\n",
      "epoch=70_val_batch=2, total_val_loss=74.84567260742188, pred_val_loss[8.684335, 12.207809, 42.546776]\n",
      "epoch=70_val_batch=3, total_val_loss=121.7633056640625, pred_val_loss[6.3238697, 25.549084, 78.4836]\n",
      "epoch=70_val_batch=4, total_val_loss=90.12334442138672, pred_val_loss[3.6240866, 25.036129, 50.056374]\n",
      "epoch=70_val_batch=5, total_val_loss=61.198883056640625, pred_val_loss[18.201809, 8.228472, 23.361847]\n",
      "epoch=70_val_batch=6, total_val_loss=218.55517578125, pred_val_loss[16.481417, 7.2493095, 183.4177]\n",
      "epoch=70_val_batch=7, total_val_loss=151.44500732421875, pred_val_loss[0.63328344, 55.176506, 84.22846]\n",
      "epoch=70_val_batch=8, total_val_loss=57.737369537353516, pred_val_loss[0.23287107, 39.181305, 6.9164395]\n",
      "epoch=70_val_batch=9, total_val_loss=119.40020751953125, pred_val_loss[4.069272, 55.97615, 47.94803]\n",
      "epoch=70_val_batch=10, total_val_loss=126.58924102783203, pred_val_loss[27.408836, 9.865213, 77.90844]\n",
      "epoch=70_val_batch=11, total_val_loss=159.4905548095703, pred_val_loss[8.614628, 67.73836, 71.73082]\n",
      "epoch=70_val_batch=12, total_val_loss=27.051692962646484, pred_val_loss[0.32476547, 6.6886673, 8.631506]\n",
      "epoch=70_val_batch=13, total_val_loss=94.60038757324219, pred_val_loss[0.19912136, 42.37933, 40.61518]\n",
      "epoch=70_val_batch=14, total_val_loss=94.85697937011719, pred_val_loss[9.606097, 30.923573, 42.920555]\n",
      "epoch=70_val_batch=15, total_val_loss=70.0197982788086, pred_val_loss[16.828012, 2.416244, 39.368786]\n",
      "epoch=70_val_batch=16, total_val_loss=195.3720245361328, pred_val_loss[7.6685443, 64.00028, 112.296455]\n",
      "epoch=70_val_batch=17, total_val_loss=158.1197967529297, pred_val_loss[16.409233, 15.553068, 114.75074]\n",
      "epoch=70_val_batch=18, total_val_loss=147.63267517089844, pred_val_loss[3.31193, 34.057953, 98.85603]\n",
      "epoch=70, train: avg_loss=12.944464683532715, val: avg_val_loss=152.27320861816406\n",
      "Saved checkpoint for step 81: ./tf_ckpts/ckpt-80\n",
      "epoch=71_train_batch=0, total_loss=17.15804672241211, pred_loss=[0.014649264, 0.104236, 5.632406]\n",
      "epoch=71_train_batch=1, total_loss=12.00390911102295, pred_loss=[0.1508432, 0.3110846, 0.13564482]\n",
      "epoch=71_train_batch=2, total_loss=13.182701110839844, pred_loss=[0.08568774, 0.28937802, 1.4017178]\n",
      "epoch=71_train_batch=3, total_loss=12.077020645141602, pred_loss=[0.03684648, 0.34333193, 0.29134518]\n",
      "epoch=71_train_batch=4, total_loss=12.457866668701172, pred_loss=[0.114998624, 0.29325086, 0.64453816]\n",
      "epoch=71_train_batch=5, total_loss=11.857244491577148, pred_loss=[0.0817651, 0.16378242, 0.20703948]\n",
      "epoch=71_train_batch=6, total_loss=12.189640045166016, pred_loss=[0.08340412, 0.26571864, 0.43628097]\n",
      "epoch=71_train_batch=7, total_loss=12.770108222961426, pred_loss=[0.13381507, 0.21026549, 1.0222117]\n",
      "epoch=71_train_batch=8, total_loss=11.980252265930176, pred_loss=[0.28942013, 0.134109, 0.1533258]\n",
      "epoch=71_train_batch=9, total_loss=11.942150115966797, pred_loss=[0.16957876, 0.08909662, 0.28049716]\n",
      "epoch=71_train_batch=10, total_loss=12.120450973510742, pred_loss=[0.08640921, 0.1428147, 0.4886702]\n",
      "epoch=71_train_batch=11, total_loss=12.087382316589355, pred_loss=[0.067861944, 0.43755457, 0.17983012]\n",
      "epoch=71_train_batch=12, total_loss=12.093818664550781, pred_loss=[0.18493621, 0.18656875, 0.3206004]\n",
      "epoch=71_train_batch=13, total_loss=12.522920608520508, pred_loss=[0.20417342, 0.09295782, 0.8245]\n",
      "epoch=71_train_batch=14, total_loss=15.395671844482422, pred_loss=[0.021973733, 0.15512052, 3.8177142]\n",
      "epoch=71_train_batch=15, total_loss=12.213080406188965, pred_loss=[0.5324302, 0.13752653, 0.14268917]\n",
      "epoch=71_train_batch=16, total_loss=12.650848388671875, pred_loss=[0.10001803, 0.38616246, 0.76466465]\n",
      "epoch=71_train_batch=17, total_loss=12.708518028259277, pred_loss=[0.12869552, 0.18663383, 0.9936122]\n",
      "epoch=71_train_batch=18, total_loss=11.83291244506836, pred_loss=[0.1638098, 0.14347503, 0.12647904]\n",
      "epoch=71_train_batch=19, total_loss=12.234572410583496, pred_loss=[0.28649622, 0.12823102, 0.42112154]\n",
      "epoch=71_train_batch=20, total_loss=12.442049980163574, pred_loss=[0.12396026, 0.107875496, 0.81191707]\n",
      "epoch=71_train_batch=21, total_loss=12.35931396484375, pred_loss=[0.2540295, 0.33132863, 0.37608272]\n",
      "epoch=71_train_batch=22, total_loss=12.84065055847168, pred_loss=[0.09436931, 0.6140318, 0.7347989]\n",
      "epoch=71_train_batch=23, total_loss=12.145766258239746, pred_loss=[0.14649355, 0.17998697, 0.42225498]\n",
      "epoch=71_train_batch=24, total_loss=15.599205017089844, pred_loss=[0.01739922, 0.5701531, 3.61504]\n",
      "epoch=71_train_batch=25, total_loss=12.846078872680664, pred_loss=[0.02202893, 0.3885888, 1.0392667]\n",
      "epoch=71_train_batch=26, total_loss=12.304821014404297, pred_loss=[0.07881351, 0.16767064, 0.6625566]\n",
      "epoch=71_train_batch=27, total_loss=12.613137245178223, pred_loss=[0.3046762, 0.19888419, 0.7142098]\n",
      "epoch=71_train_batch=28, total_loss=12.865713119506836, pred_loss=[0.026487745, 0.47422415, 0.97004807]\n",
      "epoch=71_train_batch=29, total_loss=12.668723106384277, pred_loss=[0.09726758, 0.8407419, 0.33617517]\n",
      "epoch=71_train_batch=30, total_loss=13.025094032287598, pred_loss=[0.05797525, 0.30701905, 1.2659769]\n",
      "epoch=71_train_batch=31, total_loss=12.58258056640625, pred_loss=[0.052553646, 0.31189615, 0.8244239]\n",
      "epoch=71_train_batch=32, total_loss=13.642817497253418, pred_loss=[0.07815581, 0.5658618, 1.6055104]\n",
      "epoch=71_train_batch=33, total_loss=12.50158405303955, pred_loss=[0.08351854, 0.5824541, 0.4427393]\n",
      "epoch=71_train_batch=34, total_loss=12.846952438354492, pred_loss=[0.2063174, 0.29143727, 0.95674455]\n",
      "epoch=71_train_batch=35, total_loss=11.97270393371582, pred_loss=[0.07236792, 0.347312, 0.16099252]\n",
      "epoch=71_train_batch=36, total_loss=13.530454635620117, pred_loss=[0.8927463, 0.6008656, 0.64523256]\n",
      "epoch=71_train_batch=37, total_loss=13.107779502868652, pred_loss=[0.09861399, 0.35250956, 1.2654662]\n",
      "epoch=71_train_batch=38, total_loss=12.72850513458252, pred_loss=[0.0038936387, 0.8555573, 0.47828346]\n",
      "epoch=71_train_batch=39, total_loss=12.286712646484375, pred_loss=[0.25128606, 0.46319342, 0.18188262]\n",
      "epoch=71_train_batch=40, total_loss=12.682106018066406, pred_loss=[0.08509339, 0.26410922, 0.9429712]\n",
      "epoch=71_train_batch=41, total_loss=12.050434112548828, pred_loss=[0.18826175, 0.33649307, 0.13616455]\n",
      "epoch=71_train_batch=42, total_loss=12.373984336853027, pred_loss=[0.12660106, 0.41870198, 0.43958408]\n",
      "epoch=71_train_batch=43, total_loss=22.152050018310547, pred_loss=[0.04132377, 0.7764256, 9.94562]\n",
      "epoch=71_train_batch=44, total_loss=12.063937187194824, pred_loss=[0.09359524, 0.35711092, 0.22496378]\n",
      "epoch=71_train_batch=45, total_loss=12.123727798461914, pred_loss=[0.03473722, 0.25301063, 0.4481281]\n",
      "epoch=71_train_batch=46, total_loss=12.444384574890137, pred_loss=[0.051182542, 0.3835289, 0.62223434]\n",
      "epoch=71_train_batch=47, total_loss=13.814502716064453, pred_loss=[0.26962316, 0.18143979, 1.9764178]\n",
      "epoch=71_train_batch=48, total_loss=12.811199188232422, pred_loss=[0.23657066, 0.2869586, 0.9010643]\n",
      "epoch=71_train_batch=49, total_loss=12.601234436035156, pred_loss=[0.023507591, 0.32277307, 0.86876714]\n",
      "epoch=71_train_batch=50, total_loss=12.280447006225586, pred_loss=[0.08759111, 0.16031009, 0.6467805]\n",
      "epoch=71_train_batch=51, total_loss=12.073604583740234, pred_loss=[0.15824069, 0.34824666, 0.181776]\n",
      "epoch=71_train_batch=52, total_loss=12.393001556396484, pred_loss=[0.08417335, 0.18929598, 0.73461586]\n",
      "epoch=71_train_batch=53, total_loss=15.127223014831543, pred_loss=[0.11688846, 0.1606553, 3.4651923]\n",
      "epoch=71_train_batch=54, total_loss=13.195301055908203, pred_loss=[0.27727354, 0.90448, 0.6294877]\n",
      "epoch=71_train_batch=55, total_loss=12.251867294311523, pred_loss=[0.09146833, 0.46411008, 0.31265533]\n",
      "epoch=71_train_batch=56, total_loss=15.071355819702148, pred_loss=[0.019571219, 0.27447104, 3.3941066]\n",
      "epoch=71_train_batch=57, total_loss=14.741458892822266, pred_loss=[0.05052229, 0.53940296, 2.7687588]\n",
      "epoch=71_train_batch=58, total_loss=12.163848876953125, pred_loss=[0.1268265, 0.17926392, 0.4754146]\n",
      "epoch=71_train_batch=59, total_loss=13.894721031188965, pred_loss=[0.11762974, 0.20891246, 2.186264]\n",
      "epoch=71_train_batch=60, total_loss=11.977219581604004, pred_loss=[0.14654878, 0.10175212, 0.34743392]\n",
      "epoch=71_train_batch=61, total_loss=12.268959999084473, pred_loss=[0.19176175, 0.19690436, 0.49924037]\n",
      "epoch=71_train_batch=62, total_loss=12.247147560119629, pred_loss=[0.02325502, 0.34891886, 0.49434888]\n",
      "epoch=71_train_batch=63, total_loss=24.047426223754883, pred_loss=[0.11641765, 1.6027305, 10.948083]\n",
      "epoch=71_train_batch=64, total_loss=11.910825729370117, pred_loss=[0.19235435, 0.108683884, 0.23002113]\n",
      "epoch=71_train_batch=65, total_loss=13.387009620666504, pred_loss=[0.49620938, 0.6688161, 0.8426471]\n",
      "epoch=71_train_batch=66, total_loss=12.362154006958008, pred_loss=[0.015653148, 0.6548424, 0.31274962]\n",
      "epoch=71_train_batch=67, total_loss=12.201745986938477, pred_loss=[0.189511, 0.14715011, 0.486601]\n",
      "epoch=71_train_batch=68, total_loss=12.219901084899902, pred_loss=[0.12978451, 0.17491673, 0.53713936]\n",
      "epoch=71_train_batch=69, total_loss=12.046685218811035, pred_loss=[0.09845412, 0.24345209, 0.32714385]\n",
      "epoch=71_train_batch=70, total_loss=13.808653831481934, pred_loss=[0.05919932, 0.5452913, 1.8269525]\n",
      "epoch=71_train_batch=71, total_loss=16.359394073486328, pred_loss=[0.004147103, 0.6002421, 4.3782177]\n",
      "epoch=71_train_batch=72, total_loss=12.163504600524902, pred_loss=[0.122753724, 0.46203026, 0.20235805]\n",
      "epoch=71_train_batch=73, total_loss=12.392791748046875, pred_loss=[0.22513516, 0.1637351, 0.62798285]\n",
      "epoch=71_train_batch=74, total_loss=12.62905216217041, pred_loss=[0.14711359, 0.25577617, 0.85064536]\n",
      "epoch=71_train_batch=75, total_loss=12.452083587646484, pred_loss=[0.18439111, 0.46715504, 0.42544335]\n",
      "epoch=71_train_batch=76, total_loss=11.983476638793945, pred_loss=[0.08487885, 0.3537408, 0.17018557]\n",
      "epoch=71_train_batch=77, total_loss=12.18643569946289, pred_loss=[0.057962984, 0.24308246, 0.5111425]\n",
      "epoch=71_train_batch=78, total_loss=13.357791900634766, pred_loss=[0.090939105, 0.17110753, 1.7219218]\n",
      "epoch=71_train_batch=79, total_loss=12.027853965759277, pred_loss=[0.13627033, 0.2915005, 0.22668466]\n",
      "epoch=71_train_batch=80, total_loss=12.529397964477539, pred_loss=[0.2455923, 0.20203027, 0.7088008]\n",
      "epoch=71_train_batch=81, total_loss=12.370265007019043, pred_loss=[0.121343836, 0.2895059, 0.5868665]\n",
      "epoch=71_train_batch=82, total_loss=12.26169204711914, pred_loss=[0.106060036, 0.22286956, 0.56063926]\n",
      "epoch=71_train_batch=83, total_loss=12.120610237121582, pred_loss=[0.16797173, 0.27357703, 0.3073665]\n",
      "epoch=71_train_batch=84, total_loss=12.154509544372559, pred_loss=[0.05568613, 0.45162588, 0.27593172]\n",
      "epoch=71_train_batch=85, total_loss=17.45656967163086, pred_loss=[0.09819407, 2.5618858, 3.4256546]\n",
      "epoch=71_train_batch=86, total_loss=12.504068374633789, pred_loss=[0.046258494, 0.122238345, 0.9651666]\n",
      "epoch=71_train_batch=87, total_loss=12.029046058654785, pred_loss=[0.04170318, 0.031729322, 0.58563787]\n",
      "epoch=71_val_batch=0, total_val_loss=658.7921142578125, pred_val_loss[0.14150739, 55.801235, 591.4798]\n",
      "epoch=71_val_batch=1, total_val_loss=214.324951171875, pred_val_loss[0.046219762, 121.126144, 81.78304]\n",
      "epoch=71_val_batch=2, total_val_loss=76.30235290527344, pred_val_loss[11.204197, 12.8006935, 40.927917]\n",
      "epoch=71_val_batch=3, total_val_loss=120.6708755493164, pred_val_loss[6.3082657, 25.041147, 77.95192]\n",
      "epoch=71_val_batch=4, total_val_loss=86.53804779052734, pred_val_loss[4.0060563, 25.52098, 45.641464]\n",
      "epoch=71_val_batch=5, total_val_loss=63.35064697265625, pred_val_loss[17.856161, 7.0406494, 27.08429]\n",
      "epoch=71_val_batch=6, total_val_loss=207.92684936523438, pred_val_loss[16.195963, 7.369686, 172.99167]\n",
      "epoch=71_val_batch=7, total_val_loss=160.47177124023438, pred_val_loss[0.8211259, 58.560177, 89.72093]\n",
      "epoch=71_val_batch=8, total_val_loss=59.96581268310547, pred_val_loss[0.2476405, 37.97343, 10.3752]\n",
      "epoch=71_val_batch=9, total_val_loss=118.38561248779297, pred_val_loss[3.0396295, 57.18978, 46.786655]\n",
      "epoch=71_val_batch=10, total_val_loss=121.75032806396484, pred_val_loss[25.343546, 9.345839, 75.6914]\n",
      "epoch=71_val_batch=11, total_val_loss=155.55230712890625, pred_val_loss[9.510477, 65.7703, 68.902]\n",
      "epoch=71_val_batch=12, total_val_loss=27.238670349121094, pred_val_loss[0.45515996, 5.962891, 9.451075]\n",
      "epoch=71_val_batch=13, total_val_loss=94.1324462890625, pred_val_loss[0.22661838, 41.182472, 41.35381]\n",
      "epoch=71_val_batch=14, total_val_loss=91.09046936035156, pred_val_loss[7.963564, 30.38493, 41.37243]\n",
      "epoch=71_val_batch=15, total_val_loss=72.7090072631836, pred_val_loss[16.137033, 2.2527776, 42.949654]\n",
      "epoch=71_val_batch=16, total_val_loss=198.37185668945312, pred_val_loss[7.041335, 66.13447, 113.82651]\n",
      "epoch=71_val_batch=17, total_val_loss=154.77801513671875, pred_val_loss[14.979783, 14.430046, 113.99866]\n",
      "epoch=71_val_batch=18, total_val_loss=134.05410766601562, pred_val_loss[4.3835454, 33.925, 84.376015]\n",
      "epoch=71, train: avg_loss=13.024506568908691, val: avg_val_loss=148.23191833496094\n",
      "Saved checkpoint for step 82: ./tf_ckpts/ckpt-81\n",
      "epoch=72_train_batch=0, total_loss=12.03538990020752, pred_loss=[0.04731077, 0.4305047, 0.18802926]\n",
      "epoch=72_train_batch=1, total_loss=12.086691856384277, pred_loss=[0.0032501626, 0.3192997, 0.3950285]\n",
      "epoch=72_train_batch=2, total_loss=12.785172462463379, pred_loss=[0.13473621, 0.12338042, 1.1583768]\n",
      "epoch=72_train_batch=3, total_loss=14.480969429016113, pred_loss=[0.12710942, 1.1897522, 1.7958654]\n",
      "epoch=72_train_batch=4, total_loss=11.909810066223145, pred_loss=[0.04564008, 0.04576425, 0.4505997]\n",
      "epoch=72_train_batch=5, total_loss=11.919136047363281, pred_loss=[0.0807277, 0.13696122, 0.3340761]\n",
      "epoch=72_train_batch=6, total_loss=11.906938552856445, pred_loss=[0.14452022, 0.27380204, 0.121681094]\n",
      "epoch=72_train_batch=7, total_loss=12.73227596282959, pred_loss=[0.08019431, 0.5349607, 0.75062126]\n",
      "epoch=72_train_batch=8, total_loss=13.871438980102539, pred_loss=[0.105313905, 0.08412686, 2.3159347]\n",
      "epoch=72_train_batch=9, total_loss=12.199872970581055, pred_loss=[0.0733091, 0.26807955, 0.49285883]\n",
      "epoch=72_train_batch=10, total_loss=12.594752311706543, pred_loss=[0.14572564, 0.22176912, 0.862066]\n",
      "epoch=72_train_batch=11, total_loss=12.296192169189453, pred_loss=[0.0044789426, 0.67923903, 0.24771887]\n",
      "epoch=72_train_batch=12, total_loss=12.289016723632812, pred_loss=[0.031526677, 0.29931068, 0.5938593]\n",
      "epoch=72_train_batch=13, total_loss=11.9319429397583, pred_loss=[0.055241086, 0.1375218, 0.3752997]\n",
      "epoch=72_train_batch=14, total_loss=12.140569686889648, pred_loss=[0.026737351, 0.13024208, 0.6201486]\n",
      "epoch=72_train_batch=15, total_loss=12.750154495239258, pred_loss=[0.11972642, 0.275675, 0.9917535]\n",
      "epoch=72_train_batch=16, total_loss=12.20853328704834, pred_loss=[0.1187276, 0.2869292, 0.44031623]\n",
      "epoch=72_train_batch=17, total_loss=12.365544319152832, pred_loss=[0.110151336, 0.41322726, 0.480047]\n",
      "epoch=72_train_batch=18, total_loss=13.129087448120117, pred_loss=[0.1349937, 0.13708267, 1.495336]\n",
      "epoch=72_train_batch=19, total_loss=11.908669471740723, pred_loss=[0.1539017, 0.18503293, 0.2085062]\n",
      "epoch=72_train_batch=20, total_loss=12.866793632507324, pred_loss=[0.2291146, 0.6399139, 0.63697994]\n",
      "epoch=72_train_batch=21, total_loss=11.954461097717285, pred_loss=[0.11193174, 0.0819917, 0.40019816]\n",
      "epoch=72_train_batch=22, total_loss=12.954535484313965, pred_loss=[0.0645886, 0.36294526, 1.1671056]\n",
      "epoch=72_train_batch=23, total_loss=11.814952850341797, pred_loss=[0.117315695, 0.1586401, 0.1795474]\n",
      "epoch=72_train_batch=24, total_loss=12.27964973449707, pred_loss=[0.024679977, 0.32661083, 0.56935346]\n",
      "epoch=72_train_batch=25, total_loss=12.024040222167969, pred_loss=[0.01856501, 0.24186562, 0.40504915]\n",
      "epoch=72_train_batch=26, total_loss=12.640833854675293, pred_loss=[0.06360765, 0.77925026, 0.4398616]\n",
      "epoch=72_train_batch=27, total_loss=18.311386108398438, pred_loss=[0.0031085, 2.6031137, 4.347497]\n",
      "epoch=72_train_batch=28, total_loss=12.05314826965332, pred_loss=[0.06803031, 0.11272225, 0.51517403]\n",
      "epoch=72_train_batch=29, total_loss=12.643341064453125, pred_loss=[0.080024645, 0.42000878, 0.7865319]\n",
      "epoch=72_train_batch=30, total_loss=12.02500057220459, pred_loss=[0.290628, 0.12722397, 0.25081757]\n",
      "epoch=72_train_batch=31, total_loss=12.4086275100708, pred_loss=[0.020569686, 0.60923254, 0.4229395]\n",
      "epoch=72_train_batch=32, total_loss=13.064676284790039, pred_loss=[0.20682606, 0.67763007, 0.82477987]\n",
      "epoch=72_train_batch=33, total_loss=13.385087966918945, pred_loss=[0.14479086, 0.44386977, 1.4414315]\n",
      "epoch=72_train_batch=34, total_loss=20.566390991210938, pred_loss=[0.04890026, 0.6812128, 8.481723]\n",
      "epoch=72_train_batch=35, total_loss=11.760051727294922, pred_loss=[0.027453452, 0.2248067, 0.15367387]\n",
      "epoch=72_train_batch=36, total_loss=12.293073654174805, pred_loss=[0.14630875, 0.25650355, 0.5365801]\n",
      "epoch=72_train_batch=37, total_loss=12.6174955368042, pred_loss=[0.024649058, 0.4549827, 0.7846167]\n",
      "epoch=72_train_batch=38, total_loss=12.142723083496094, pred_loss=[0.0799173, 0.18975449, 0.5202358]\n",
      "epoch=72_train_batch=39, total_loss=12.802860260009766, pred_loss=[0.075106874, 0.587655, 0.7877151]\n",
      "epoch=72_train_batch=40, total_loss=12.611846923828125, pred_loss=[0.025466017, 0.556424, 0.67800677]\n",
      "epoch=72_train_batch=41, total_loss=12.115592956542969, pred_loss=[0.08237007, 0.17681393, 0.50489223]\n",
      "epoch=72_train_batch=42, total_loss=12.022149085998535, pred_loss=[0.04462452, 0.1970465, 0.4293924]\n",
      "epoch=72_train_batch=43, total_loss=11.917645454406738, pred_loss=[0.1547215, 0.12557133, 0.28670132]\n",
      "epoch=72_train_batch=44, total_loss=12.161765098571777, pred_loss=[0.17290238, 0.45747936, 0.18116659]\n",
      "epoch=72_train_batch=45, total_loss=12.67385482788086, pred_loss=[0.015496652, 0.73397446, 0.5746024]\n",
      "epoch=72_train_batch=46, total_loss=12.242345809936523, pred_loss=[0.28015226, 0.4376101, 0.17524019]\n",
      "epoch=72_train_batch=47, total_loss=12.41881275177002, pred_loss=[0.093721874, 0.42769572, 0.54848874]\n",
      "epoch=72_train_batch=48, total_loss=11.961382865905762, pred_loss=[0.02659097, 0.18561909, 0.40070516]\n",
      "epoch=72_train_batch=49, total_loss=12.164961814880371, pred_loss=[0.1124047, 0.4059678, 0.29856095]\n",
      "epoch=72_train_batch=50, total_loss=12.754959106445312, pred_loss=[0.06122823, 0.44117135, 0.90497184]\n",
      "epoch=72_train_batch=51, total_loss=11.775067329406738, pred_loss=[0.081764296, 0.18304232, 0.16311279]\n",
      "epoch=72_train_batch=52, total_loss=12.434599876403809, pred_loss=[0.117760815, 0.3224951, 0.6476373]\n",
      "epoch=72_train_batch=53, total_loss=12.310796737670898, pred_loss=[0.10910036, 0.16094297, 0.6944885]\n",
      "epoch=72_train_batch=54, total_loss=12.852177619934082, pred_loss=[0.06404884, 0.51872826, 0.9235801]\n",
      "epoch=72_train_batch=55, total_loss=13.2698392868042, pred_loss=[0.0040757935, 0.6797968, 1.2405913]\n",
      "epoch=72_train_batch=56, total_loss=12.07822322845459, pred_loss=[0.16380122, 0.29327023, 0.27622083]\n",
      "epoch=72_train_batch=57, total_loss=12.275431632995605, pred_loss=[0.056009047, 0.33421698, 0.5407193]\n",
      "epoch=72_train_batch=58, total_loss=14.777215957641602, pred_loss=[0.07174919, 0.19059029, 3.1708345]\n",
      "epoch=72_train_batch=59, total_loss=11.770306587219238, pred_loss=[0.28697455, 0.026733717, 0.11299713]\n",
      "epoch=72_train_batch=60, total_loss=12.412229537963867, pred_loss=[0.1950159, 0.41004205, 0.46401048]\n",
      "epoch=72_train_batch=61, total_loss=13.014595985412598, pred_loss=[0.017101444, 0.45913583, 1.1956384]\n",
      "epoch=72_train_batch=62, total_loss=13.654078483581543, pred_loss=[0.029558409, 0.39246485, 1.8897778]\n",
      "epoch=72_train_batch=63, total_loss=11.913448333740234, pred_loss=[0.07554765, 0.13956678, 0.35649854]\n",
      "epoch=72_train_batch=64, total_loss=12.8121337890625, pred_loss=[0.102625236, 0.17654863, 1.1915677]\n",
      "epoch=72_train_batch=65, total_loss=12.540470123291016, pred_loss=[0.055850156, 0.21552289, 0.9281473]\n",
      "epoch=72_train_batch=66, total_loss=12.378140449523926, pred_loss=[0.064459085, 0.7559895, 0.21718302]\n",
      "epoch=72_train_batch=67, total_loss=11.859695434570312, pred_loss=[0.12515847, 0.27546224, 0.11900982]\n",
      "epoch=72_train_batch=68, total_loss=13.106363296508789, pred_loss=[0.07970221, 0.45835316, 1.2286867]\n",
      "epoch=72_train_batch=69, total_loss=12.001131057739258, pred_loss=[0.23318705, 0.1468968, 0.28186893]\n",
      "epoch=72_train_batch=70, total_loss=12.2032470703125, pred_loss=[0.16743277, 0.09906084, 0.59801805]\n",
      "epoch=72_train_batch=71, total_loss=11.99776554107666, pred_loss=[0.04577659, 0.43269658, 0.18099946]\n",
      "epoch=72_train_batch=72, total_loss=12.155050277709961, pred_loss=[0.07448606, 0.34096912, 0.4017437]\n",
      "epoch=72_train_batch=73, total_loss=12.586965560913086, pred_loss=[0.21925691, 0.24631806, 0.78398246]\n",
      "epoch=72_train_batch=74, total_loss=12.657663345336914, pred_loss=[0.16837776, 0.44692534, 0.70539576]\n",
      "epoch=72_train_batch=75, total_loss=12.501694679260254, pred_loss=[0.33879825, 0.5962081, 0.2301685]\n",
      "epoch=72_train_batch=76, total_loss=12.969934463500977, pred_loss=[0.0061606094, 0.7830478, 0.8446524]\n",
      "epoch=72_train_batch=77, total_loss=12.354691505432129, pred_loss=[0.028774178, 0.69723606, 0.29305273]\n",
      "epoch=72_train_batch=78, total_loss=23.16170883178711, pred_loss=[0.029071119, 1.459121, 10.338334]\n",
      "epoch=72_train_batch=79, total_loss=12.267879486083984, pred_loss=[0.0764886, 0.31093943, 0.5457105]\n",
      "epoch=72_train_batch=80, total_loss=12.579460144042969, pred_loss=[0.041413054, 0.7736371, 0.43010855]\n",
      "epoch=72_train_batch=81, total_loss=12.764124870300293, pred_loss=[0.116021395, 0.4304134, 0.8838277]\n",
      "epoch=72_train_batch=82, total_loss=12.423151016235352, pred_loss=[0.072850846, 0.3947596, 0.6221132]\n",
      "epoch=72_train_batch=83, total_loss=16.1839656829834, pred_loss=[0.05485025, 0.19560263, 4.6005197]\n",
      "epoch=72_train_batch=84, total_loss=11.908103942871094, pred_loss=[0.10932547, 0.29228365, 0.17393553]\n",
      "epoch=72_train_batch=85, total_loss=12.801929473876953, pred_loss=[0.080995396, 0.5090922, 0.87971497]\n",
      "epoch=72_train_batch=86, total_loss=16.334850311279297, pred_loss=[0.07647713, 0.38047466, 4.5462055]\n",
      "epoch=72_train_batch=87, total_loss=11.550267219543457, pred_loss=[0.07445759, 0.08644569, 0.058105882]\n",
      "epoch=72_val_batch=0, total_val_loss=729.6410522460938, pred_val_loss[0.10068018, 55.037308, 663.17224]\n",
      "epoch=72_val_batch=1, total_val_loss=215.94142150878906, pred_val_loss[0.04805892, 121.36548, 83.19705]\n",
      "epoch=72_val_batch=2, total_val_loss=77.62893676757812, pred_val_loss[10.957697, 12.383266, 42.95715]\n",
      "epoch=72_val_batch=3, total_val_loss=125.13749694824219, pred_val_loss[6.4439955, 25.528688, 81.833984]\n",
      "epoch=72_val_batch=4, total_val_loss=91.6871337890625, pred_val_loss[3.9973047, 24.829376, 51.529625]\n",
      "epoch=72_val_batch=5, total_val_loss=62.553367614746094, pred_val_loss[17.990156, 9.994532, 23.237852]\n",
      "epoch=72_val_batch=6, total_val_loss=225.28538513183594, pred_val_loss[16.563023, 7.8001356, 189.5914]\n",
      "epoch=72_val_batch=7, total_val_loss=155.44497680664062, pred_val_loss[0.69867134, 56.612564, 86.80292]\n",
      "epoch=72_val_batch=8, total_val_loss=60.762115478515625, pred_val_loss[0.25282112, 40.224174, 8.954295]\n",
      "epoch=72_val_batch=9, total_val_loss=115.52898406982422, pred_val_loss[3.4964855, 53.82742, 46.874252]\n",
      "epoch=72_val_batch=10, total_val_loss=124.0413589477539, pred_val_loss[26.604832, 9.898341, 76.20736]\n",
      "epoch=72_val_batch=11, total_val_loss=158.70278930664062, pred_val_loss[9.217348, 65.99778, 72.15684]\n",
      "epoch=72_val_batch=12, total_val_loss=27.98954963684082, pred_val_loss[0.20885241, 6.795489, 9.654386]\n",
      "epoch=72_val_batch=13, total_val_loss=97.3466796875, pred_val_loss[0.22686021, 42.40423, 43.38477]\n",
      "epoch=72_val_batch=14, total_val_loss=96.18052673339844, pred_val_loss[9.7566595, 30.834822, 44.258217]\n",
      "epoch=72_val_batch=15, total_val_loss=71.7506332397461, pred_val_loss[16.112257, 1.991163, 42.316387]\n",
      "epoch=72_val_batch=16, total_val_loss=196.6830291748047, pred_val_loss[7.200386, 64.76663, 113.38519]\n",
      "epoch=72_val_batch=17, total_val_loss=158.8896942138672, pred_val_loss[15.447221, 15.2481, 116.86354]\n",
      "epoch=72_val_batch=18, total_val_loss=142.55894470214844, pred_val_loss[3.8423495, 33.403076, 93.9827]\n",
      "epoch=72, train: avg_loss=12.816305160522461, val: avg_val_loss=154.40809631347656\n",
      "Saved checkpoint for step 83: ./tf_ckpts/ckpt-82\n",
      "epoch=73_train_batch=0, total_loss=11.671672821044922, pred_loss=[0.080127545, 0.12277752, 0.13794339]\n",
      "epoch=73_train_batch=1, total_loss=12.123509407043457, pred_loss=[0.050923668, 0.33751798, 0.40467623]\n",
      "epoch=73_train_batch=2, total_loss=12.902715682983398, pred_loss=[0.199862, 0.5360187, 0.83687586]\n",
      "epoch=73_train_batch=3, total_loss=12.280182838439941, pred_loss=[0.10008725, 0.28232518, 0.5682473]\n",
      "epoch=73_train_batch=4, total_loss=11.693171501159668, pred_loss=[0.06617571, 0.1534555, 0.14445221]\n",
      "epoch=73_train_batch=5, total_loss=12.000295639038086, pred_loss=[0.043334693, 0.22267058, 0.40563887]\n",
      "epoch=73_train_batch=6, total_loss=13.860107421875, pred_loss=[0.15260676, 0.87774044, 1.5015476]\n",
      "epoch=73_train_batch=7, total_loss=21.294940948486328, pred_loss=[0.17989714, 0.1073032, 9.679971]\n",
      "epoch=73_train_batch=8, total_loss=12.202302932739258, pred_loss=[0.082730144, 0.56084806, 0.23139536]\n",
      "epoch=73_train_batch=9, total_loss=11.920512199401855, pred_loss=[0.045039743, 0.370858, 0.17772134]\n",
      "epoch=73_train_batch=10, total_loss=12.132904052734375, pred_loss=[0.19572575, 0.19866732, 0.41205293]\n",
      "epoch=73_train_batch=11, total_loss=12.31830883026123, pred_loss=[0.16424786, 0.23896766, 0.58906996]\n",
      "epoch=73_train_batch=12, total_loss=12.100028991699219, pred_loss=[0.09801285, 0.463831, 0.2125963]\n",
      "epoch=73_train_batch=13, total_loss=12.241113662719727, pred_loss=[0.12599726, 0.027095076, 0.76286614]\n",
      "epoch=73_train_batch=14, total_loss=12.1820068359375, pred_loss=[0.039083935, 0.30915722, 0.5090458]\n",
      "epoch=73_train_batch=15, total_loss=12.315252304077148, pred_loss=[0.008377058, 0.2943226, 0.6882683]\n",
      "epoch=73_train_batch=16, total_loss=12.47885799407959, pred_loss=[0.14230847, 0.117680825, 0.89502037]\n",
      "epoch=73_train_batch=17, total_loss=14.301512718200684, pred_loss=[0.025634522, 0.32671183, 2.625754]\n",
      "epoch=73_train_batch=18, total_loss=13.05691909790039, pred_loss=[0.04600486, 0.49688935, 1.1910498]\n",
      "epoch=73_train_batch=19, total_loss=12.018465995788574, pred_loss=[0.07489997, 0.36465377, 0.2563758]\n",
      "epoch=73_train_batch=20, total_loss=14.722152709960938, pred_loss=[0.2609323, 0.38179025, 2.7573366]\n",
      "epoch=73_train_batch=21, total_loss=17.634334564208984, pred_loss=[0.0042031626, 0.27751666, 6.0309577]\n",
      "epoch=73_train_batch=22, total_loss=12.373449325561523, pred_loss=[0.11302302, 0.20666222, 0.73253906]\n",
      "epoch=73_train_batch=23, total_loss=20.707176208496094, pred_loss=[0.1115638, 1.5155048, 7.7593136]\n",
      "epoch=73_train_batch=24, total_loss=12.222521781921387, pred_loss=[0.1021352, 0.48664257, 0.3133731]\n",
      "epoch=73_train_batch=25, total_loss=19.831939697265625, pred_loss=[0.053309694, 1.0858303, 7.3728533]\n",
      "epoch=73_train_batch=26, total_loss=11.892334938049316, pred_loss=[0.09519814, 0.31525993, 0.16235393]\n",
      "epoch=73_train_batch=27, total_loss=11.680543899536133, pred_loss=[0.08070568, 0.13023001, 0.15050982]\n",
      "epoch=73_train_batch=28, total_loss=11.947624206542969, pred_loss=[0.07817504, 0.2939396, 0.2568369]\n",
      "epoch=73_train_batch=29, total_loss=12.693612098693848, pred_loss=[0.030867014, 0.20584899, 1.1386504]\n",
      "epoch=73_train_batch=30, total_loss=11.938119888305664, pred_loss=[0.04193221, 0.25597852, 0.32239413]\n",
      "epoch=73_train_batch=31, total_loss=12.551295280456543, pred_loss=[0.13352439, 0.32826883, 0.77212006]\n",
      "epoch=73_train_batch=32, total_loss=14.949546813964844, pred_loss=[0.07642113, 1.7865394, 1.7696388]\n",
      "epoch=73_train_batch=33, total_loss=20.544418334960938, pred_loss=[0.20010085, 1.5170724, 7.5107336]\n",
      "epoch=73_train_batch=34, total_loss=12.639083862304688, pred_loss=[0.09865321, 0.5359466, 0.6884104]\n",
      "epoch=73_train_batch=35, total_loss=11.781023025512695, pred_loss=[0.15069532, 0.15030028, 0.16439334]\n",
      "epoch=73_train_batch=36, total_loss=11.76400089263916, pred_loss=[0.05360663, 0.23853002, 0.15666875]\n",
      "epoch=73_train_batch=37, total_loss=12.156898498535156, pred_loss=[0.031499032, 0.24695705, 0.56368667]\n",
      "epoch=73_train_batch=38, total_loss=19.855792999267578, pred_loss=[0.043073487, 0.51540935, 7.9829984]\n",
      "epoch=73_train_batch=39, total_loss=12.049772262573242, pred_loss=[0.05830863, 0.2781821, 0.399419]\n",
      "epoch=73_train_batch=40, total_loss=12.92966079711914, pred_loss=[0.076012395, 0.4267715, 1.1134609]\n",
      "epoch=73_train_batch=41, total_loss=11.88525104522705, pred_loss=[0.12305464, 0.33467296, 0.114553586]\n",
      "epoch=73_train_batch=42, total_loss=12.127604484558105, pred_loss=[0.05328595, 0.19233015, 0.5694611]\n",
      "epoch=73_train_batch=43, total_loss=12.565520286560059, pred_loss=[0.1681074, 0.10305336, 0.9822741]\n",
      "epoch=73_train_batch=44, total_loss=12.658737182617188, pred_loss=[0.16400245, 0.33990976, 0.8431819]\n",
      "epoch=73_train_batch=45, total_loss=12.594924926757812, pred_loss=[0.04541654, 0.2912188, 0.94708776]\n",
      "epoch=73_train_batch=46, total_loss=11.74465560913086, pred_loss=[0.050763607, 0.19547388, 0.18765771]\n",
      "epoch=73_train_batch=47, total_loss=12.556532859802246, pred_loss=[0.14194882, 0.4705016, 0.63376474]\n",
      "epoch=73_train_batch=48, total_loss=12.026599884033203, pred_loss=[0.16526106, 0.1889654, 0.3624993]\n",
      "epoch=73_train_batch=49, total_loss=12.2371826171875, pred_loss=[0.031875543, 0.30095887, 0.5949187]\n",
      "epoch=73_train_batch=50, total_loss=12.474472999572754, pred_loss=[0.016959084, 0.6320535, 0.51647544]\n",
      "epoch=73_train_batch=51, total_loss=12.091376304626465, pred_loss=[0.37324914, 0.19650072, 0.21308738]\n",
      "epoch=73_train_batch=52, total_loss=12.358988761901855, pred_loss=[0.07816287, 0.20441562, 0.7683209]\n",
      "epoch=73_train_batch=53, total_loss=12.63988208770752, pred_loss=[0.087282754, 0.5704898, 0.67446864]\n",
      "epoch=73_train_batch=54, total_loss=11.842108726501465, pred_loss=[0.10473324, 0.18134862, 0.24883619]\n",
      "epoch=73_train_batch=55, total_loss=12.392073631286621, pred_loss=[0.03436414, 0.40133744, 0.6496323]\n",
      "epoch=73_train_batch=56, total_loss=12.155660629272461, pred_loss=[0.05794865, 0.27445182, 0.51696795]\n",
      "epoch=73_train_batch=57, total_loss=12.104609489440918, pred_loss=[0.10222784, 0.27230126, 0.42423674]\n",
      "epoch=73_train_batch=58, total_loss=12.129053115844727, pred_loss=[0.035305277, 0.27531767, 0.51303595]\n",
      "epoch=73_train_batch=59, total_loss=11.872665405273438, pred_loss=[0.102443144, 0.17555866, 0.28972006]\n",
      "epoch=73_train_batch=60, total_loss=11.784703254699707, pred_loss=[0.041541412, 0.19509047, 0.24357855]\n",
      "epoch=73_train_batch=61, total_loss=12.309931755065918, pred_loss=[0.119896, 0.2339763, 0.6520201]\n",
      "epoch=73_train_batch=62, total_loss=13.51320743560791, pred_loss=[0.09604773, 0.13603799, 1.9775386]\n",
      "epoch=73_train_batch=63, total_loss=12.308395385742188, pred_loss=[0.24933101, 0.3975519, 0.35838246]\n",
      "epoch=73_train_batch=64, total_loss=12.031155586242676, pred_loss=[0.028686017, 0.21074007, 0.4890536]\n",
      "epoch=73_train_batch=65, total_loss=12.188017845153809, pred_loss=[0.10034071, 0.101378754, 0.6840743]\n",
      "epoch=73_train_batch=66, total_loss=11.858277320861816, pred_loss=[0.20525399, 0.2309385, 0.12031239]\n",
      "epoch=73_train_batch=67, total_loss=12.15005874633789, pred_loss=[0.0039885966, 0.24640206, 0.5983489]\n",
      "epoch=73_train_batch=68, total_loss=12.447855949401855, pred_loss=[0.017981045, 0.37921727, 0.7497914]\n",
      "epoch=73_train_batch=69, total_loss=22.97244644165039, pred_loss=[0.07584552, 0.171376, 11.424811]\n",
      "epoch=73_train_batch=70, total_loss=12.435175895690918, pred_loss=[0.1533605, 0.40840733, 0.5734425]\n",
      "epoch=73_train_batch=71, total_loss=12.077674865722656, pred_loss=[0.08802002, 0.24908836, 0.44104743]\n",
      "epoch=73_train_batch=72, total_loss=12.173393249511719, pred_loss=[0.29357633, 0.20434111, 0.37640142]\n",
      "epoch=73_train_batch=73, total_loss=11.72348690032959, pred_loss=[0.13157564, 0.073216096, 0.22006959]\n",
      "epoch=73_train_batch=74, total_loss=12.432653427124023, pred_loss=[0.04109822, 0.17668755, 0.91669106]\n",
      "epoch=73_train_batch=75, total_loss=12.402099609375, pred_loss=[0.08052932, 0.43742728, 0.58641297]\n",
      "epoch=73_train_batch=76, total_loss=12.520516395568848, pred_loss=[0.13590816, 0.33778858, 0.7495416]\n",
      "epoch=73_train_batch=77, total_loss=12.482595443725586, pred_loss=[0.20626365, 0.062839635, 0.9166656]\n",
      "epoch=73_train_batch=78, total_loss=20.411449432373047, pred_loss=[0.0748111, 0.06414156, 8.976129]\n",
      "epoch=73_train_batch=79, total_loss=11.9906644821167, pred_loss=[0.06512877, 0.3619487, 0.2676707]\n",
      "epoch=73_train_batch=80, total_loss=12.283390045166016, pred_loss=[0.08116906, 0.4903188, 0.41643405]\n",
      "epoch=73_train_batch=81, total_loss=15.037088394165039, pred_loss=[0.005611793, 0.16481115, 3.571644]\n",
      "epoch=73_train_batch=82, total_loss=12.876388549804688, pred_loss=[0.038644057, 0.45317587, 1.0899895]\n",
      "epoch=73_train_batch=83, total_loss=32.803741455078125, pred_loss=[0.13841152, 0.15793332, 21.213263]\n",
      "epoch=73_train_batch=84, total_loss=14.774496078491211, pred_loss=[0.16121426, 0.16395785, 3.155627]\n",
      "epoch=73_train_batch=85, total_loss=12.703371047973633, pred_loss=[0.06394001, 0.19693837, 1.1492268]\n",
      "epoch=73_train_batch=86, total_loss=13.347711563110352, pred_loss=[0.2425116, 0.21326573, 1.5990965]\n",
      "epoch=73_train_batch=87, total_loss=14.717520713806152, pred_loss=[0.06528886, 0.12762567, 3.2321966]\n",
      "epoch=73_val_batch=0, total_val_loss=725.4783325195312, pred_val_loss[0.108425006, 53.49178, 660.5861]\n",
      "epoch=73_val_batch=1, total_val_loss=221.22622680664062, pred_val_loss[0.061914757, 118.43842, 91.433914]\n",
      "epoch=73_val_batch=2, total_val_loss=82.65755462646484, pred_val_loss[9.697243, 12.795667, 48.872665]\n",
      "epoch=73_val_batch=3, total_val_loss=130.63597106933594, pred_val_loss[6.658684, 24.754318, 87.930984]\n",
      "epoch=73_val_batch=4, total_val_loss=102.3564453125, pred_val_loss[3.560153, 24.91201, 62.592297]\n",
      "epoch=73_val_batch=5, total_val_loss=68.71617126464844, pred_val_loss[17.853233, 8.684578, 30.886375]\n",
      "epoch=73_val_batch=6, total_val_loss=219.48580932617188, pred_val_loss[17.827427, 7.3123007, 183.05411]\n",
      "epoch=73_val_batch=7, total_val_loss=174.61245727539062, pred_val_loss[0.7364849, 55.06623, 107.51776]\n",
      "epoch=73_val_batch=8, total_val_loss=60.117454528808594, pred_val_loss[0.20770939, 36.626385, 11.991373]\n",
      "epoch=73_val_batch=9, total_val_loss=131.46658325195312, pred_val_loss[3.4037626, 55.205494, 61.56535]\n",
      "epoch=73_val_batch=10, total_val_loss=142.78768920898438, pred_val_loss[30.517372, 9.371435, 91.60689]\n",
      "epoch=73_val_batch=11, total_val_loss=161.7415771484375, pred_val_loss[9.903959, 66.35608, 74.18956]\n",
      "epoch=73_val_batch=12, total_val_loss=26.408113479614258, pred_val_loss[0.32371643, 6.310406, 8.482006]\n",
      "epoch=73_val_batch=13, total_val_loss=100.07835388183594, pred_val_loss[0.22880441, 39.494118, 49.063446]\n",
      "epoch=73_val_batch=14, total_val_loss=108.3629150390625, pred_val_loss[10.7752495, 30.03614, 56.25954]\n",
      "epoch=73_val_batch=15, total_val_loss=81.96420288085938, pred_val_loss[16.91394, 1.6114551, 52.14682]\n",
      "epoch=73_val_batch=16, total_val_loss=209.5460205078125, pred_val_loss[6.9031644, 64.88054, 126.47032]\n",
      "epoch=73_val_batch=17, total_val_loss=165.40267944335938, pred_val_loss[14.784435, 13.457771, 125.8685]\n",
      "epoch=73_val_batch=18, total_val_loss=149.28594970703125, pred_val_loss[3.75245, 31.894367, 102.34716]\n",
      "epoch=73, train: avg_loss=13.42245101928711, val: avg_val_loss=161.17529296875\n",
      "Saved checkpoint for step 84: ./tf_ckpts/ckpt-83\n",
      "epoch=74_train_batch=0, total_loss=12.077293395996094, pred_loss=[0.0035434924, 0.27956128, 0.5022038]\n",
      "epoch=74_train_batch=1, total_loss=12.325443267822266, pred_loss=[0.12758088, 0.26304972, 0.64325154]\n",
      "epoch=74_train_batch=2, total_loss=12.179882049560547, pred_loss=[0.19645722, 0.3719408, 0.32034662]\n",
      "epoch=74_train_batch=3, total_loss=13.631610870361328, pred_loss=[0.12868355, 0.12046563, 2.091747]\n",
      "epoch=74_train_batch=4, total_loss=11.909856796264648, pred_loss=[0.15134141, 0.28063366, 0.1875957]\n",
      "epoch=74_train_batch=5, total_loss=12.492532730102539, pred_loss=[0.044883296, 0.11691722, 1.0408766]\n",
      "epoch=74_train_batch=6, total_loss=14.404295921325684, pred_loss=[0.1477156, 0.116905615, 2.8502479]\n",
      "epoch=74_train_batch=7, total_loss=11.754919052124023, pred_loss=[0.06781543, 0.26042503, 0.13768238]\n",
      "epoch=74_train_batch=8, total_loss=12.740646362304688, pred_loss=[0.10890529, 0.24767713, 1.0955015]\n",
      "epoch=74_train_batch=9, total_loss=11.635209083557129, pred_loss=[0.16418736, 0.07847949, 0.10441373]\n",
      "epoch=74_train_batch=10, total_loss=23.641036987304688, pred_loss=[0.11334734, 1.5576799, 10.682317]\n",
      "epoch=74_train_batch=11, total_loss=12.55986213684082, pred_loss=[0.08920921, 0.30493647, 0.87845886]\n",
      "epoch=74_train_batch=12, total_loss=13.594106674194336, pred_loss=[0.037303597, 0.13914132, 2.1308408]\n",
      "epoch=74_train_batch=13, total_loss=13.290090560913086, pred_loss=[0.07292661, 0.09557715, 1.8352005]\n",
      "epoch=74_train_batch=14, total_loss=12.304130554199219, pred_loss=[0.034669306, 0.36548242, 0.6180289]\n",
      "epoch=74_train_batch=15, total_loss=12.003364562988281, pred_loss=[0.081653714, 0.14997959, 0.48622134]\n",
      "epoch=74_train_batch=16, total_loss=14.223678588867188, pred_loss=[0.11134869, 0.43805143, 2.3892095]\n",
      "epoch=74_train_batch=17, total_loss=12.072893142700195, pred_loss=[0.076273985, 0.09081394, 0.62118065]\n",
      "epoch=74_train_batch=18, total_loss=12.053120613098145, pred_loss=[0.046070118, 0.10779333, 0.61507714]\n",
      "epoch=74_train_batch=19, total_loss=12.080081939697266, pred_loss=[0.15769541, 0.326715, 0.31193864]\n",
      "epoch=74_train_batch=20, total_loss=11.801582336425781, pred_loss=[0.037341457, 0.22273394, 0.2582269]\n",
      "epoch=74_train_batch=21, total_loss=13.507573127746582, pred_loss=[0.041549735, 0.44688025, 1.7363139]\n",
      "epoch=74_train_batch=22, total_loss=24.407917022705078, pred_loss=[0.17027989, 0.18455002, 12.770712]\n",
      "epoch=74_train_batch=23, total_loss=14.389841079711914, pred_loss=[0.09062654, 0.07807893, 2.9392133]\n",
      "epoch=74_train_batch=24, total_loss=30.008075714111328, pred_loss=[0.11914716, 1.316083, 17.291372]\n",
      "epoch=74_train_batch=25, total_loss=12.695252418518066, pred_loss=[0.020467687, 0.22008626, 1.1736717]\n",
      "epoch=74_train_batch=26, total_loss=12.313743591308594, pred_loss=[0.12768364, 0.12145151, 0.7840179]\n",
      "epoch=74_train_batch=27, total_loss=11.867016792297363, pred_loss=[0.09319209, 0.3454739, 0.1481916]\n",
      "epoch=74_train_batch=28, total_loss=11.706082344055176, pred_loss=[0.14963037, 0.11051018, 0.16620965]\n",
      "epoch=74_train_batch=29, total_loss=12.526457786560059, pred_loss=[0.0062239403, 0.32094997, 0.9199777]\n",
      "epoch=74_train_batch=30, total_loss=12.334888458251953, pred_loss=[0.0565643, 0.17864801, 0.8207933]\n",
      "epoch=74_train_batch=31, total_loss=12.935523986816406, pred_loss=[0.14444698, 0.046423413, 1.4661978]\n",
      "epoch=74_train_batch=32, total_loss=12.980320930480957, pred_loss=[0.07500025, 0.23414148, 1.3931532]\n",
      "epoch=74_train_batch=33, total_loss=12.096722602844238, pred_loss=[0.06540068, 0.4078342, 0.34589022]\n",
      "epoch=74_train_batch=34, total_loss=12.419820785522461, pred_loss=[0.016522352, 0.37264103, 0.75349104]\n",
      "epoch=74_train_batch=35, total_loss=14.63752555847168, pred_loss=[0.11093435, 0.42962864, 2.8202286]\n",
      "epoch=74_train_batch=36, total_loss=13.83341121673584, pred_loss=[0.06710258, 0.7192657, 1.7707413]\n",
      "epoch=74_train_batch=37, total_loss=11.719417572021484, pred_loss=[0.05682219, 0.14914374, 0.23757401]\n",
      "epoch=74_train_batch=38, total_loss=17.35034942626953, pred_loss=[0.0679405, 0.112302035, 5.8946548]\n",
      "epoch=74_train_batch=39, total_loss=12.332894325256348, pred_loss=[0.14891763, 0.379661, 0.5292866]\n",
      "epoch=74_train_batch=40, total_loss=12.19902515411377, pred_loss=[0.10109402, 0.56355906, 0.25976765]\n",
      "epoch=74_train_batch=41, total_loss=12.752983093261719, pred_loss=[0.051532265, 0.43643576, 0.99083364]\n",
      "epoch=74_train_batch=42, total_loss=13.41366958618164, pred_loss=[0.05713586, 0.17244673, 1.9103324]\n",
      "epoch=74_train_batch=43, total_loss=11.790562629699707, pred_loss=[0.048317067, 0.2292004, 0.2397177]\n",
      "epoch=74_train_batch=44, total_loss=13.003442764282227, pred_loss=[0.035919968, 0.4176647, 1.2769608]\n",
      "epoch=74_train_batch=45, total_loss=13.167583465576172, pred_loss=[0.043538775, 0.327065, 1.5245153]\n",
      "epoch=74_train_batch=46, total_loss=15.87857723236084, pred_loss=[0.070828676, 0.30936882, 4.226349]\n",
      "epoch=74_train_batch=47, total_loss=15.105279922485352, pred_loss=[0.020059075, 0.21432154, 3.599301]\n",
      "epoch=74_train_batch=48, total_loss=11.671884536743164, pred_loss=[0.15180646, 0.035698034, 0.21321948]\n",
      "epoch=74_train_batch=49, total_loss=11.660463333129883, pred_loss=[0.07834446, 0.2043716, 0.10702685]\n",
      "epoch=74_train_batch=50, total_loss=14.306913375854492, pred_loss=[0.05341312, 0.7660705, 2.2171526]\n",
      "epoch=74_train_batch=51, total_loss=12.195551872253418, pred_loss=[0.046361234, 0.13713124, 0.74222636]\n",
      "epoch=74_train_batch=52, total_loss=12.557104110717773, pred_loss=[0.028449511, 0.404191, 0.8550769]\n",
      "epoch=74_train_batch=53, total_loss=12.577324867248535, pred_loss=[0.054273665, 0.7170157, 0.53709686]\n",
      "epoch=74_train_batch=54, total_loss=12.038455963134766, pred_loss=[0.12628263, 0.3376835, 0.30600086]\n",
      "epoch=74_train_batch=55, total_loss=11.89077377319336, pred_loss=[0.083204016, 0.18748045, 0.35205257]\n",
      "epoch=74_train_batch=56, total_loss=13.265085220336914, pred_loss=[0.0942161, 0.90419364, 0.9990938]\n",
      "epoch=74_train_batch=57, total_loss=13.59884262084961, pred_loss=[0.048778366, 0.9654669, 1.317472]\n",
      "epoch=74_train_batch=58, total_loss=11.919427871704102, pred_loss=[0.044820994, 0.20119695, 0.40674222]\n",
      "epoch=74_train_batch=59, total_loss=11.671303749084473, pred_loss=[0.13186443, 0.15032895, 0.12290035]\n",
      "epoch=74_train_batch=60, total_loss=15.033019065856934, pred_loss=[0.073938124, 1.4783998, 2.2149265]\n",
      "epoch=74_train_batch=61, total_loss=14.468082427978516, pred_loss=[0.04181856, 0.37377882, 2.7871876]\n",
      "epoch=74_train_batch=62, total_loss=11.90895938873291, pred_loss=[0.059438713, 0.13560957, 0.44907522]\n",
      "epoch=74_train_batch=63, total_loss=12.950715065002441, pred_loss=[0.018268248, 0.5927702, 1.0753007]\n",
      "epoch=74_train_batch=64, total_loss=12.474349975585938, pred_loss=[0.03193232, 0.8486098, 0.32989508]\n",
      "epoch=74_train_batch=65, total_loss=12.093070030212402, pred_loss=[0.04649469, 0.3994619, 0.38366407]\n",
      "epoch=74_train_batch=66, total_loss=12.58003044128418, pred_loss=[0.035121396, 0.3026738, 0.9792498]\n",
      "epoch=74_train_batch=67, total_loss=12.940791130065918, pred_loss=[0.06951571, 0.15009455, 1.4586601]\n",
      "epoch=74_train_batch=68, total_loss=12.143736839294434, pred_loss=[0.06526055, 0.23020123, 0.58621985]\n",
      "epoch=74_train_batch=69, total_loss=22.326526641845703, pred_loss=[0.032592636, 0.2337556, 10.79859]\n",
      "epoch=74_train_batch=70, total_loss=12.98586368560791, pred_loss=[0.012538155, 0.44251266, 1.2696836]\n",
      "epoch=74_train_batch=71, total_loss=12.051298141479492, pred_loss=[0.27763534, 0.40080303, 0.11219324]\n",
      "epoch=74_train_batch=72, total_loss=12.514302253723145, pred_loss=[0.009342533, 0.18415168, 1.0606015]\n",
      "epoch=74_train_batch=73, total_loss=12.302680015563965, pred_loss=[0.12756035, 0.6961123, 0.21926333]\n",
      "epoch=74_train_batch=74, total_loss=12.79737663269043, pred_loss=[0.03012238, 0.2679954, 1.2399797]\n",
      "epoch=74_train_batch=75, total_loss=11.77636432647705, pred_loss=[0.048512515, 0.27999657, 0.18903774]\n",
      "epoch=74_train_batch=76, total_loss=12.556075096130371, pred_loss=[0.04730718, 0.1578865, 1.0925274]\n",
      "epoch=74_train_batch=77, total_loss=11.871155738830566, pred_loss=[0.08156351, 0.22246386, 0.30923682]\n",
      "epoch=74_train_batch=78, total_loss=12.053083419799805, pred_loss=[0.048884682, 0.44750866, 0.29926193]\n",
      "epoch=74_train_batch=79, total_loss=12.49781608581543, pred_loss=[0.07462901, 0.3446399, 0.821584]\n",
      "epoch=74_train_batch=80, total_loss=12.87939167022705, pred_loss=[0.09245015, 0.05910761, 1.4713342]\n",
      "epoch=74_train_batch=81, total_loss=12.331835746765137, pred_loss=[0.2132895, 0.09286873, 0.7696434]\n",
      "epoch=74_train_batch=82, total_loss=15.078216552734375, pred_loss=[0.060155384, 0.7871299, 2.9753623]\n",
      "epoch=74_train_batch=83, total_loss=12.591764450073242, pred_loss=[0.111740775, 0.37483913, 0.85008466]\n",
      "epoch=74_train_batch=84, total_loss=13.54830551147461, pred_loss=[0.013062593, 0.4865098, 1.7941039]\n",
      "epoch=74_train_batch=85, total_loss=12.072784423828125, pred_loss=[0.08300382, 0.55513066, 0.18049414]\n",
      "epoch=74_train_batch=86, total_loss=11.918434143066406, pred_loss=[0.14740676, 0.25773636, 0.25960797]\n",
      "epoch=74_train_batch=87, total_loss=15.159369468688965, pred_loss=[0.043757495, 0.3533826, 3.5090184]\n",
      "epoch=74_val_batch=0, total_val_loss=707.9926147460938, pred_val_loss[0.13580923, 54.952583, 641.6515]\n",
      "epoch=74_val_batch=1, total_val_loss=217.75283813476562, pred_val_loss[0.044662468, 124.79623, 81.6592]\n",
      "epoch=74_val_batch=2, total_val_loss=78.3821029663086, pred_val_loss[9.712156, 15.256721, 42.160492]\n",
      "epoch=74_val_batch=3, total_val_loss=122.92362976074219, pred_val_loss[7.1441474, 26.010105, 78.51664]\n",
      "epoch=74_val_batch=4, total_val_loss=87.64694213867188, pred_val_loss[4.014225, 21.927856, 50.45212]\n",
      "epoch=74_val_batch=5, total_val_loss=63.400718688964844, pred_val_loss[17.453531, 9.027584, 25.666866]\n",
      "epoch=74_val_batch=6, total_val_loss=225.4459991455078, pred_val_loss[18.480284, 7.93592, 187.77705]\n",
      "epoch=74_val_batch=7, total_val_loss=152.4172821044922, pred_val_loss[0.54073066, 57.16514, 83.45867]\n",
      "epoch=74_val_batch=8, total_val_loss=55.215126037597656, pred_val_loss[0.27855077, 36.09199, 7.591843]\n",
      "epoch=74_val_batch=9, total_val_loss=119.37142181396484, pred_val_loss[3.7193904, 55.025135, 49.374157]\n",
      "epoch=74_val_batch=10, total_val_loss=127.07494354248047, pred_val_loss[26.780897, 9.7862835, 79.25502]\n",
      "epoch=74_val_batch=11, total_val_loss=151.6737060546875, pred_val_loss[9.792328, 64.81874, 65.80988]\n",
      "epoch=74_val_batch=12, total_val_loss=28.600496292114258, pred_val_loss[0.33160597, 6.9962215, 10.019927]\n",
      "epoch=74_val_batch=13, total_val_loss=91.49828338623047, pred_val_loss[0.23717655, 40.95549, 39.052883]\n",
      "epoch=74_val_batch=14, total_val_loss=95.92451477050781, pred_val_loss[11.255022, 31.973778, 41.442978]\n",
      "epoch=74_val_batch=15, total_val_loss=68.53369903564453, pred_val_loss[17.03551, 2.0439625, 38.201485]\n",
      "epoch=74_val_batch=16, total_val_loss=198.77423095703125, pred_val_loss[6.882988, 65.52793, 115.110565]\n",
      "epoch=74_val_batch=17, total_val_loss=148.60850524902344, pred_val_loss[15.057307, 14.382373, 107.916084]\n",
      "epoch=74_val_batch=18, total_val_loss=141.0182647705078, pred_val_loss[3.5816524, 30.75763, 95.42624]\n",
      "epoch=74, train: avg_loss=13.356911659240723, val: avg_val_loss=151.69764709472656\n",
      "Saved checkpoint for step 85: ./tf_ckpts/ckpt-84\n",
      "epoch=75_train_batch=0, total_loss=12.2679443359375, pred_loss=[0.091580756, 0.29442084, 0.6292019]\n",
      "epoch=75_train_batch=1, total_loss=16.60928726196289, pred_loss=[0.020838423, 1.1738534, 4.1623263]\n",
      "epoch=75_train_batch=2, total_loss=12.774694442749023, pred_loss=[0.16228901, 1.0711356, 0.28946596]\n",
      "epoch=75_train_batch=3, total_loss=12.31177043914795, pred_loss=[0.032328047, 0.7254658, 0.3026358]\n",
      "epoch=75_train_batch=4, total_loss=11.677135467529297, pred_loss=[0.103165925, 0.20994802, 0.113142684]\n",
      "epoch=75_train_batch=5, total_loss=12.449682235717773, pred_loss=[0.31348467, 0.19961473, 0.6861654]\n",
      "epoch=75_train_batch=6, total_loss=13.145944595336914, pred_loss=[0.070755, 0.20626974, 1.6189613]\n",
      "epoch=75_train_batch=7, total_loss=12.953560829162598, pred_loss=[0.03933514, 0.5978725, 1.066852]\n",
      "epoch=75_train_batch=8, total_loss=12.883255004882812, pred_loss=[0.07302621, 0.52693963, 1.0342473]\n",
      "epoch=75_train_batch=9, total_loss=12.87712574005127, pred_loss=[0.07674219, 0.29518852, 1.2566131]\n",
      "epoch=75_train_batch=10, total_loss=13.431158065795898, pred_loss=[0.12269792, 1.1056094, 0.95472646]\n",
      "epoch=75_train_batch=11, total_loss=11.880752563476562, pred_loss=[0.11379474, 0.2738504, 0.24544108]\n",
      "epoch=75_train_batch=12, total_loss=12.716344833374023, pred_loss=[0.06459556, 0.053333133, 1.3512077]\n",
      "epoch=75_train_batch=13, total_loss=12.864072799682617, pred_loss=[0.018210683, 0.8066133, 0.7924981]\n",
      "epoch=75_train_batch=14, total_loss=15.720282554626465, pred_loss=[0.07586177, 0.5781691, 3.8199575]\n",
      "epoch=75_train_batch=15, total_loss=15.055510520935059, pred_loss=[0.07058172, 0.6054617, 3.1336262]\n",
      "epoch=75_train_batch=16, total_loss=13.332810401916504, pred_loss=[0.100217044, 0.6034674, 1.3837315]\n",
      "epoch=75_train_batch=17, total_loss=13.238452911376953, pred_loss=[0.08455722, 0.5976552, 1.3112887]\n",
      "epoch=75_train_batch=18, total_loss=14.764097213745117, pred_loss=[0.030031286, 1.5451326, 1.9444249]\n",
      "epoch=75_train_batch=19, total_loss=12.460177421569824, pred_loss=[0.08634199, 0.3315978, 0.79817057]\n",
      "epoch=75_train_batch=20, total_loss=14.25204849243164, pred_loss=[0.23620375, 2.135346, 0.6368709]\n",
      "epoch=75_train_batch=21, total_loss=13.321568489074707, pred_loss=[0.06689671, 1.9035416, 0.10793026]\n",
      "epoch=75_train_batch=22, total_loss=17.272541046142578, pred_loss=[0.19036728, 0.62759954, 5.2118015]\n",
      "epoch=75_train_batch=23, total_loss=14.628616333007812, pred_loss=[0.0548641, 0.8922898, 2.4391215]\n",
      "epoch=75_train_batch=24, total_loss=13.30510139465332, pred_loss=[0.08681622, 0.73533505, 1.241042]\n",
      "epoch=75_train_batch=25, total_loss=15.073328018188477, pred_loss=[0.06528414, 0.68156695, 3.0849993]\n",
      "epoch=75_train_batch=26, total_loss=13.857660293579102, pred_loss=[0.047963843, 1.4459794, 1.1226702]\n",
      "epoch=75_train_batch=27, total_loss=15.639467239379883, pred_loss=[0.046285518, 0.50069696, 3.8518662]\n",
      "epoch=75_train_batch=28, total_loss=12.203568458557129, pred_loss=[0.1387122, 0.38826135, 0.43640617]\n",
      "epoch=75_train_batch=29, total_loss=13.076287269592285, pred_loss=[0.022165086, 0.33285648, 1.4815041]\n",
      "epoch=75_train_batch=30, total_loss=12.483366012573242, pred_loss=[0.10759829, 0.39508718, 0.7413482]\n",
      "epoch=75_train_batch=31, total_loss=13.309391975402832, pred_loss=[0.005729194, 0.8355517, 1.2292093]\n",
      "epoch=75_train_batch=32, total_loss=14.427427291870117, pred_loss=[0.16829607, 2.1371562, 0.88350576]\n",
      "epoch=75_train_batch=33, total_loss=13.116357803344727, pred_loss=[0.2161637, 1.0498407, 0.61231947]\n",
      "epoch=75_train_batch=34, total_loss=12.948208808898926, pred_loss=[0.080000855, 0.2760975, 1.3545114]\n",
      "epoch=75_train_batch=35, total_loss=14.651189804077148, pred_loss=[0.034358885, 0.526992, 2.852675]\n",
      "epoch=75_train_batch=36, total_loss=12.632905960083008, pred_loss=[0.18841034, 0.2794796, 0.9282867]\n",
      "epoch=75_train_batch=37, total_loss=12.267668724060059, pred_loss=[0.1736462, 0.6089672, 0.24876231]\n",
      "epoch=75_train_batch=38, total_loss=13.57661247253418, pred_loss=[0.18298809, 0.68064106, 1.4771281]\n",
      "epoch=75_train_batch=39, total_loss=13.501625061035156, pred_loss=[0.20566314, 0.63456786, 1.4259809]\n",
      "epoch=75_train_batch=40, total_loss=12.846802711486816, pred_loss=[0.1077573, 0.2421611, 1.261915]\n",
      "epoch=75_train_batch=41, total_loss=12.035337448120117, pred_loss=[0.04511968, 0.40098232, 0.35471344]\n",
      "epoch=75_train_batch=42, total_loss=12.374204635620117, pred_loss=[0.14145881, 0.32363656, 0.6750337]\n",
      "epoch=75_train_batch=43, total_loss=12.84399127960205, pred_loss=[0.077542275, 1.0439574, 0.4888659]\n",
      "epoch=75_train_batch=44, total_loss=12.517745971679688, pred_loss=[0.2551478, 0.86587304, 0.1635488]\n",
      "epoch=75_train_batch=45, total_loss=12.190497398376465, pred_loss=[0.37755185, 0.27639055, 0.30382994]\n",
      "epoch=75_train_batch=46, total_loss=12.360857963562012, pred_loss=[0.19958511, 0.22317769, 0.70581895]\n",
      "epoch=75_train_batch=47, total_loss=16.59981346130371, pred_loss=[0.43927112, 0.20158578, 4.7271295]\n",
      "epoch=75_train_batch=48, total_loss=12.547657012939453, pred_loss=[0.091649644, 0.88344115, 0.3411786]\n",
      "epoch=75_train_batch=49, total_loss=12.956911087036133, pred_loss=[0.08423872, 0.828567, 0.8131554]\n",
      "epoch=75_train_batch=50, total_loss=11.75050163269043, pred_loss=[0.3278771, 0.052716237, 0.13939458]\n",
      "epoch=75_train_batch=51, total_loss=14.476051330566406, pred_loss=[0.05004262, 0.30092162, 2.8950098]\n",
      "epoch=75_train_batch=52, total_loss=17.47643280029297, pred_loss=[0.4590251, 1.5304353, 4.2573357]\n",
      "epoch=75_train_batch=53, total_loss=12.569162368774414, pred_loss=[0.05490673, 0.24661699, 1.0384476]\n",
      "epoch=75_train_batch=54, total_loss=19.922348022460938, pred_loss=[0.1394319, 0.30729994, 8.246869]\n",
      "epoch=75_train_batch=55, total_loss=14.115957260131836, pred_loss=[0.0281857, 1.4641955, 1.3952732]\n",
      "epoch=75_train_batch=56, total_loss=16.331331253051758, pred_loss=[0.12154272, 0.83154464, 4.150378]\n",
      "epoch=75_train_batch=57, total_loss=12.099733352661133, pred_loss=[0.09527151, 0.16303387, 0.6139946]\n",
      "epoch=75_train_batch=58, total_loss=12.496665954589844, pred_loss=[0.18067592, 0.6122003, 0.47678638]\n",
      "epoch=75_train_batch=59, total_loss=12.296721458435059, pred_loss=[0.08367875, 0.48493117, 0.50153476]\n",
      "epoch=75_train_batch=60, total_loss=12.307788848876953, pred_loss=[0.17343542, 0.60426825, 0.30393612]\n",
      "epoch=75_train_batch=61, total_loss=12.790931701660156, pred_loss=[0.39820743, 0.6935202, 0.47348493]\n",
      "epoch=75_train_batch=62, total_loss=13.836939811706543, pred_loss=[0.29135665, 1.0016081, 1.3186884]\n",
      "epoch=75_train_batch=63, total_loss=13.3058443069458, pred_loss=[0.08112717, 0.28041065, 1.719451]\n",
      "epoch=75_train_batch=64, total_loss=12.02888011932373, pred_loss=[0.41460675, 0.2535262, 0.13632467]\n",
      "epoch=75_train_batch=65, total_loss=13.552789688110352, pred_loss=[0.13403007, 0.66100514, 1.5337677]\n",
      "epoch=75_train_batch=66, total_loss=12.623115539550781, pred_loss=[0.03207326, 0.54847974, 0.819014]\n",
      "epoch=75_train_batch=67, total_loss=13.887721061706543, pred_loss=[0.041612178, 0.95512545, 1.6678712]\n",
      "epoch=75_train_batch=68, total_loss=11.956594467163086, pred_loss=[0.06811057, 0.47638136, 0.18942511]\n",
      "epoch=75_train_batch=69, total_loss=12.181343078613281, pred_loss=[0.14007244, 0.17125139, 0.64778197]\n",
      "epoch=75_train_batch=70, total_loss=12.958499908447266, pred_loss=[0.03646656, 0.5041743, 1.1960598]\n",
      "epoch=75_train_batch=71, total_loss=14.988631248474121, pred_loss=[0.07068931, 0.80630326, 2.8902824]\n",
      "epoch=75_train_batch=72, total_loss=12.476323127746582, pred_loss=[0.062355716, 0.20518528, 0.98787504]\n",
      "epoch=75_train_batch=73, total_loss=12.797003746032715, pred_loss=[0.02149586, 0.26606974, 1.2889824]\n",
      "epoch=75_train_batch=74, total_loss=12.228569984436035, pred_loss=[0.018560069, 0.48801377, 0.5019948]\n",
      "epoch=75_train_batch=75, total_loss=20.6021728515625, pred_loss=[0.0027842172, 2.0582438, 7.3216]\n",
      "epoch=75_train_batch=76, total_loss=12.815240859985352, pred_loss=[0.05888579, 0.23051164, 1.3067561]\n",
      "epoch=75_train_batch=77, total_loss=13.281190872192383, pred_loss=[0.24457178, 0.14449672, 1.6734902]\n",
      "epoch=75_train_batch=78, total_loss=12.293203353881836, pred_loss=[0.039375845, 0.25134838, 0.784302]\n",
      "epoch=75_train_batch=79, total_loss=13.537851333618164, pred_loss=[0.11355564, 0.5741295, 1.6324463]\n",
      "epoch=75_train_batch=80, total_loss=19.382705688476562, pred_loss=[0.17688414, 0.38093084, 7.6076303]\n",
      "epoch=75_train_batch=81, total_loss=12.10031509399414, pred_loss=[0.15057208, 0.2562458, 0.47668895]\n",
      "epoch=75_train_batch=82, total_loss=13.228715896606445, pred_loss=[0.19018826, 0.19121954, 1.6309524]\n",
      "epoch=75_train_batch=83, total_loss=14.29849910736084, pred_loss=[0.067591, 0.58039486, 2.4346051]\n",
      "epoch=75_train_batch=84, total_loss=11.777844429016113, pred_loss=[0.1330563, 0.25843853, 0.17088905]\n",
      "epoch=75_train_batch=85, total_loss=12.475132942199707, pred_loss=[0.09572037, 0.57321227, 0.591185]\n",
      "epoch=75_train_batch=86, total_loss=12.098204612731934, pred_loss=[0.28190362, 0.4492341, 0.15249681]\n",
      "epoch=75_train_batch=87, total_loss=11.507847785949707, pred_loss=[0.106862925, 0.10749575, 0.07936488]\n",
      "epoch=75_val_batch=0, total_val_loss=740.4361572265625, pred_val_loss[0.14965081, 54.29962, 674.7732]\n",
      "epoch=75_val_batch=1, total_val_loss=223.24822998046875, pred_val_loss[0.04476668, 117.623795, 94.36598]\n",
      "epoch=75_val_batch=2, total_val_loss=86.14450073242188, pred_val_loss[11.13261, 14.79262, 49.005596]\n",
      "epoch=75_val_batch=3, total_val_loss=130.6486053466797, pred_val_loss[6.802797, 26.565563, 86.06657]\n",
      "epoch=75_val_batch=4, total_val_loss=101.92365264892578, pred_val_loss[3.0908868, 22.53468, 65.08441]\n",
      "epoch=75_val_batch=5, total_val_loss=66.99541473388672, pred_val_loss[18.078953, 9.602608, 28.100176]\n",
      "epoch=75_val_batch=6, total_val_loss=224.51724243164062, pred_val_loss[20.063042, 6.879116, 186.3614]\n",
      "epoch=75_val_batch=7, total_val_loss=166.6095428466797, pred_val_loss[0.68522, 52.274563, 102.43608]\n",
      "epoch=75_val_batch=8, total_val_loss=58.3150634765625, pred_val_loss[0.2915918, 36.945557, 9.864241]\n",
      "epoch=75_val_batch=9, total_val_loss=134.083984375, pred_val_loss[4.125989, 58.49257, 60.251743]\n",
      "epoch=75_val_batch=10, total_val_loss=134.951171875, pred_val_loss[26.314232, 10.0234585, 87.399796]\n",
      "epoch=75_val_batch=11, total_val_loss=163.15982055664062, pred_val_loss[11.146831, 64.219315, 76.57999]\n",
      "epoch=75_val_batch=12, total_val_loss=26.716075897216797, pred_val_loss[0.2823428, 5.9204345, 9.29962]\n",
      "epoch=75_val_batch=13, total_val_loss=101.24364471435547, pred_val_loss[0.27519146, 40.727917, 49.026863]\n",
      "epoch=75_val_batch=14, total_val_loss=94.93646240234375, pred_val_loss[9.9181385, 26.716629, 47.08802]\n",
      "epoch=75_val_batch=15, total_val_loss=81.99754333496094, pred_val_loss[18.070004, 2.0177891, 50.696075]\n",
      "epoch=75_val_batch=16, total_val_loss=213.78262329101562, pred_val_loss[7.6275196, 64.850494, 130.09093]\n",
      "epoch=75_val_batch=17, total_val_loss=162.30511474609375, pred_val_loss[16.33562, 13.4363365, 121.31947]\n",
      "epoch=75_val_batch=18, total_val_loss=153.14065551757812, pred_val_loss[3.5575984, 30.607624, 107.76176]\n",
      "epoch=75, train: avg_loss=13.489629745483398, val: avg_val_loss=161.32398986816406\n",
      "Saved checkpoint for step 86: ./tf_ckpts/ckpt-85\n",
      "epoch=76_train_batch=0, total_loss=13.238896369934082, pred_loss=[0.074436754, 0.16843155, 1.7823495]\n",
      "epoch=76_train_batch=1, total_loss=12.625679969787598, pred_loss=[0.0755616, 1.0153028, 0.3215862]\n",
      "epoch=76_train_batch=2, total_loss=14.513193130493164, pred_loss=[0.015631055, 0.3719555, 2.9128294]\n",
      "epoch=76_train_batch=3, total_loss=12.953597068786621, pred_loss=[0.015825221, 0.61707115, 1.1083748]\n",
      "epoch=76_train_batch=4, total_loss=12.863018035888672, pred_loss=[0.11787795, 0.21885976, 1.3144082]\n",
      "epoch=76_train_batch=5, total_loss=13.17345905303955, pred_loss=[0.18824208, 0.073427334, 1.7003746]\n",
      "epoch=76_train_batch=6, total_loss=11.722517013549805, pred_loss=[0.11475949, 0.25767702, 0.13912272]\n",
      "epoch=76_train_batch=7, total_loss=12.352616310119629, pred_loss=[0.10046995, 0.68151635, 0.3601323]\n",
      "epoch=76_train_batch=8, total_loss=12.972624778747559, pred_loss=[0.05488737, 0.76489687, 0.94280344]\n",
      "epoch=76_train_batch=9, total_loss=12.16801929473877, pred_loss=[0.048352264, 0.4090693, 0.50102645]\n",
      "epoch=76_train_batch=10, total_loss=12.176616668701172, pred_loss=[0.071332864, 0.08267619, 0.8135054]\n",
      "epoch=76_train_batch=11, total_loss=12.377344131469727, pred_loss=[0.17763893, 0.36730874, 0.62376356]\n",
      "epoch=76_train_batch=12, total_loss=15.421515464782715, pred_loss=[0.14780346, 1.1202221, 2.9453278]\n",
      "epoch=76_train_batch=13, total_loss=13.61285400390625, pred_loss=[0.06073682, 0.28794935, 2.0564754]\n",
      "epoch=76_train_batch=14, total_loss=12.319540977478027, pred_loss=[0.10184297, 0.55096674, 0.4595093]\n",
      "epoch=76_train_batch=15, total_loss=12.64915657043457, pred_loss=[0.21342604, 0.40911138, 0.8198677]\n",
      "epoch=76_train_batch=16, total_loss=13.604214668273926, pred_loss=[0.10117707, 1.6251508, 0.6716071]\n",
      "epoch=76_train_batch=17, total_loss=12.885944366455078, pred_loss=[0.28430736, 0.5474017, 0.848428]\n",
      "epoch=76_train_batch=18, total_loss=20.681446075439453, pred_loss=[0.14578491, 0.22545671, 9.104868]\n",
      "epoch=76_train_batch=19, total_loss=14.2755765914917, pred_loss=[0.14266975, 0.034687426, 2.8933492]\n",
      "epoch=76_train_batch=20, total_loss=15.672161102294922, pred_loss=[0.14209463, 0.3998741, 3.9257896]\n",
      "epoch=76_train_batch=21, total_loss=12.56784439086914, pred_loss=[0.042270213, 0.4617351, 0.85989773]\n",
      "epoch=76_train_batch=22, total_loss=13.105714797973633, pred_loss=[0.19744173, 1.4920806, 0.21271507]\n",
      "epoch=76_train_batch=23, total_loss=12.991636276245117, pred_loss=[0.14300634, 0.9327779, 0.7128362]\n",
      "epoch=76_train_batch=24, total_loss=13.757119178771973, pred_loss=[0.063136555, 1.5415663, 0.94986355]\n",
      "epoch=76_train_batch=25, total_loss=17.876928329467773, pred_loss=[0.12909947, 2.3019748, 4.2437644]\n",
      "epoch=76_train_batch=26, total_loss=11.989885330200195, pred_loss=[0.11814156, 0.21001244, 0.46010315]\n",
      "epoch=76_train_batch=27, total_loss=13.833948135375977, pred_loss=[0.19509369, 0.3170764, 2.1206086]\n",
      "epoch=76_train_batch=28, total_loss=12.79552936553955, pred_loss=[0.07289939, 0.8410567, 0.6808604]\n",
      "epoch=76_train_batch=29, total_loss=11.79623794555664, pred_loss=[0.16460627, 0.31943163, 0.111943826]\n",
      "epoch=76_train_batch=30, total_loss=14.108675003051758, pred_loss=[0.05935847, 1.2570621, 1.5924553]\n",
      "epoch=76_train_batch=31, total_loss=12.40328598022461, pred_loss=[0.06585659, 0.48621842, 0.65186983]\n",
      "epoch=76_train_batch=32, total_loss=12.720948219299316, pred_loss=[0.28246063, 0.5066396, 0.73296666]\n",
      "epoch=76_train_batch=33, total_loss=12.253334045410156, pred_loss=[0.08922331, 0.3812125, 0.58448297]\n",
      "epoch=76_train_batch=34, total_loss=12.142939567565918, pred_loss=[0.0910043, 0.28846234, 0.56552416]\n",
      "epoch=76_train_batch=35, total_loss=12.502909660339355, pred_loss=[0.08110912, 0.6411058, 0.5832121]\n",
      "epoch=76_train_batch=36, total_loss=13.154022216796875, pred_loss=[0.37146047, 0.9634727, 0.6220747]\n",
      "epoch=76_train_batch=37, total_loss=11.67034912109375, pred_loss=[0.20503432, 0.10911676, 0.15965313]\n",
      "epoch=76_train_batch=38, total_loss=13.353326797485352, pred_loss=[0.071247645, 0.23526436, 1.8507428]\n",
      "epoch=76_train_batch=39, total_loss=12.140630722045898, pred_loss=[0.06266764, 0.5504198, 0.33194682]\n",
      "epoch=76_train_batch=40, total_loss=12.662728309631348, pred_loss=[0.061525054, 0.29386657, 1.112214]\n",
      "epoch=76_train_batch=41, total_loss=12.702744483947754, pred_loss=[0.071850024, 0.20602812, 1.230217]\n",
      "epoch=76_train_batch=42, total_loss=12.965194702148438, pred_loss=[0.15004808, 0.39223397, 1.2287372]\n",
      "epoch=76_train_batch=43, total_loss=16.657123565673828, pred_loss=[0.050161052, 0.20660318, 5.2066603]\n",
      "epoch=76_train_batch=44, total_loss=12.12037181854248, pred_loss=[0.47870547, 0.22236086, 0.22608215]\n",
      "epoch=76_train_batch=45, total_loss=12.180388450622559, pred_loss=[0.17598575, 0.22315854, 0.58849543]\n",
      "epoch=76_train_batch=46, total_loss=12.470613479614258, pred_loss=[0.16394286, 0.35069773, 0.7636982]\n",
      "epoch=76_train_batch=47, total_loss=12.030715942382812, pred_loss=[0.07834591, 0.64506876, 0.115498185]\n",
      "epoch=76_train_batch=48, total_loss=13.013982772827148, pred_loss=[0.008318056, 0.5541119, 1.2602255]\n",
      "epoch=76_train_batch=49, total_loss=11.766525268554688, pred_loss=[0.1598794, 0.09367877, 0.32211348]\n",
      "epoch=76_train_batch=50, total_loss=13.95579719543457, pred_loss=[0.016149819, 0.46323106, 2.286037]\n",
      "epoch=76_train_batch=51, total_loss=12.27038860321045, pred_loss=[0.0047661257, 0.4686091, 0.60710526]\n",
      "epoch=76_train_batch=52, total_loss=11.757484436035156, pred_loss=[0.117334776, 0.33106697, 0.1196487]\n",
      "epoch=76_train_batch=53, total_loss=21.83011245727539, pred_loss=[0.1650265, 0.20659098, 10.269537]\n",
      "epoch=76_train_batch=54, total_loss=11.979854583740234, pred_loss=[0.11009299, 0.12836662, 0.55291975]\n",
      "epoch=76_train_batch=55, total_loss=14.192167282104492, pred_loss=[0.19371277, 0.18449385, 2.6259634]\n",
      "epoch=76_train_batch=56, total_loss=12.1267728805542, pred_loss=[0.117946416, 0.096295394, 0.7250103]\n",
      "epoch=76_train_batch=57, total_loss=12.323832511901855, pred_loss=[0.04422699, 0.30190176, 0.790659]\n",
      "epoch=76_train_batch=58, total_loss=11.912280082702637, pred_loss=[0.121735625, 0.3936034, 0.2103677]\n",
      "epoch=76_train_batch=59, total_loss=12.285186767578125, pred_loss=[0.1375352, 0.119673684, 0.8418766]\n",
      "epoch=76_train_batch=60, total_loss=17.73918914794922, pred_loss=[0.024044817, 0.4158712, 6.1136394]\n",
      "epoch=76_train_batch=61, total_loss=13.509033203125, pred_loss=[0.022940101, 0.5226093, 1.7783223]\n",
      "epoch=76_train_batch=62, total_loss=11.731164932250977, pred_loss=[0.061030224, 0.2678063, 0.21763651]\n",
      "epoch=76_train_batch=63, total_loss=12.156517028808594, pred_loss=[0.03389875, 0.6224294, 0.31596684]\n",
      "epoch=76_train_batch=64, total_loss=12.526004791259766, pred_loss=[0.3585402, 0.30199715, 0.6817143]\n",
      "epoch=76_train_batch=65, total_loss=13.233800888061523, pred_loss=[0.027778175, 0.380378, 1.6423575]\n",
      "epoch=76_train_batch=66, total_loss=12.92234992980957, pred_loss=[0.11166536, 1.3465878, 0.28127304]\n",
      "epoch=76_train_batch=67, total_loss=15.200064659118652, pred_loss=[0.10967444, 1.200963, 2.707075]\n",
      "epoch=76_train_batch=68, total_loss=13.015990257263184, pred_loss=[0.030452589, 0.6704484, 1.1332017]\n",
      "epoch=76_train_batch=69, total_loss=11.94379711151123, pred_loss=[0.14828031, 0.38235435, 0.23173076]\n",
      "epoch=76_train_batch=70, total_loss=13.495233535766602, pred_loss=[0.1336055, 0.27898574, 1.9016593]\n",
      "epoch=76_train_batch=71, total_loss=12.657939910888672, pred_loss=[0.100778274, 0.3108839, 1.0657417]\n",
      "epoch=76_train_batch=72, total_loss=12.07064437866211, pred_loss=[0.10729865, 0.37543067, 0.40782082]\n",
      "epoch=76_train_batch=73, total_loss=15.080015182495117, pred_loss=[0.02382002, 0.3366121, 3.5399313]\n",
      "epoch=76_train_batch=74, total_loss=11.726929664611816, pred_loss=[0.04518313, 0.1541657, 0.34837055]\n",
      "epoch=76_train_batch=75, total_loss=11.975616455078125, pred_loss=[0.013969469, 0.40965763, 0.3732236]\n",
      "epoch=76_train_batch=76, total_loss=13.37389087677002, pred_loss=[0.9224856, 0.31385794, 0.9592267]\n",
      "epoch=76_train_batch=77, total_loss=15.935871124267578, pred_loss=[0.002615998, 0.33905494, 4.4163017]\n",
      "epoch=76_train_batch=78, total_loss=11.977770805358887, pred_loss=[0.040723715, 0.4967734, 0.26279122]\n",
      "epoch=76_train_batch=79, total_loss=12.144298553466797, pred_loss=[0.042685233, 0.4757143, 0.4488308]\n",
      "epoch=76_train_batch=80, total_loss=12.296603202819824, pred_loss=[0.2303665, 0.16502905, 0.7245513]\n",
      "epoch=76_train_batch=81, total_loss=11.724145889282227, pred_loss=[0.17053172, 0.19995165, 0.17742173]\n",
      "epoch=76_train_batch=82, total_loss=12.12661075592041, pred_loss=[0.19090551, 0.24842556, 0.5114584]\n",
      "epoch=76_train_batch=83, total_loss=11.889288902282715, pred_loss=[0.11885759, 0.4931838, 0.10184953]\n",
      "epoch=76_train_batch=84, total_loss=13.764179229736328, pred_loss=[0.07064583, 0.50511825, 2.013442]\n",
      "epoch=76_train_batch=85, total_loss=11.73232364654541, pred_loss=[0.087844655, 0.32266715, 0.14726818]\n",
      "epoch=76_train_batch=86, total_loss=12.726612091064453, pred_loss=[0.017887216, 0.30221945, 1.232395]\n",
      "epoch=76_train_batch=87, total_loss=12.5939302444458, pred_loss=[0.0316957, 0.06536077, 1.323202]\n",
      "epoch=76_val_batch=0, total_val_loss=723.2119140625, pred_val_loss[0.17453112, 50.01637, 661.8478]\n",
      "epoch=76_val_batch=1, total_val_loss=216.48765563964844, pred_val_loss[0.065888494, 113.70459, 91.54395]\n",
      "epoch=76_val_batch=2, total_val_loss=75.56886291503906, pred_val_loss[11.369169, 8.24673, 44.77973]\n",
      "epoch=76_val_batch=3, total_val_loss=129.40643310546875, pred_val_loss[10.575897, 25.298164, 82.359146]\n",
      "epoch=76_val_batch=4, total_val_loss=98.6405029296875, pred_val_loss[6.0895457, 24.603138, 56.774582]\n",
      "epoch=76_val_batch=5, total_val_loss=60.860103607177734, pred_val_loss[18.887236, 6.878943, 23.920696]\n",
      "epoch=76_val_batch=6, total_val_loss=226.2665252685547, pred_val_loss[24.609074, 5.615422, 184.8688]\n",
      "epoch=76_val_batch=7, total_val_loss=152.26101684570312, pred_val_loss[0.96823895, 50.409645, 89.7099]\n",
      "epoch=76_val_batch=8, total_val_loss=55.67192077636719, pred_val_loss[0.42647818, 36.34798, 7.724232]\n",
      "epoch=76_val_batch=9, total_val_loss=121.78834533691406, pred_val_loss[4.377271, 51.94201, 54.295834]\n",
      "epoch=76_val_batch=10, total_val_loss=137.1080780029297, pred_val_loss[29.680325, 20.009003, 76.245514]\n",
      "epoch=76_val_batch=11, total_val_loss=172.21263122558594, pred_val_loss[12.566791, 70.73888, 77.73373]\n",
      "epoch=76_val_batch=12, total_val_loss=27.561870574951172, pred_val_loss[0.60220176, 5.7079644, 10.078475]\n",
      "epoch=76_val_batch=13, total_val_loss=94.70782470703125, pred_val_loss[0.28235856, 37.507023, 45.745216]\n",
      "epoch=76_val_batch=14, total_val_loss=93.81686401367188, pred_val_loss[11.937866, 24.639153, 46.066616]\n",
      "epoch=76_val_batch=15, total_val_loss=76.55186462402344, pred_val_loss[18.688696, 3.0638096, 43.62613]\n",
      "epoch=76_val_batch=16, total_val_loss=190.60012817382812, pred_val_loss[8.942744, 53.705864, 116.77828]\n",
      "epoch=76_val_batch=17, total_val_loss=163.8284912109375, pred_val_loss[18.839495, 15.286483, 118.52928]\n",
      "epoch=76_val_batch=18, total_val_loss=154.18443298339844, pred_val_loss[3.997924, 29.83783, 109.17545]\n",
      "epoch=76, train: avg_loss=13.157944679260254, val: avg_val_loss=156.3544464111328\n",
      "Saved checkpoint for step 87: ./tf_ckpts/ckpt-86\n",
      "epoch=77_train_batch=0, total_loss=12.317741394042969, pred_loss=[0.21264479, 0.29515004, 0.63671756]\n",
      "epoch=77_train_batch=1, total_loss=13.246842384338379, pred_loss=[0.17231432, 0.1682709, 1.733479]\n",
      "epoch=77_train_batch=2, total_loss=12.92327880859375, pred_loss=[0.59025747, 0.9095365, 0.25116158]\n",
      "epoch=77_train_batch=3, total_loss=12.136799812316895, pred_loss=[0.17127942, 0.18596709, 0.60768515]\n",
      "epoch=77_train_batch=4, total_loss=12.013230323791504, pred_loss=[0.22566059, 0.51177096, 0.104389004]\n",
      "epoch=77_train_batch=5, total_loss=17.88326644897461, pred_loss=[0.06259565, 2.1001182, 4.5496016]\n",
      "epoch=77_train_batch=6, total_loss=11.798759460449219, pred_loss=[0.15219861, 0.1547257, 0.32134497]\n",
      "epoch=77_train_batch=7, total_loss=12.252959251403809, pred_loss=[0.096000046, 0.38958907, 0.59734267]\n",
      "epoch=77_train_batch=8, total_loss=11.97575855255127, pred_loss=[0.092974216, 0.24156152, 0.4716589]\n",
      "epoch=77_train_batch=9, total_loss=12.747556686401367, pred_loss=[0.28585964, 0.5749231, 0.71767753]\n",
      "epoch=77_train_batch=10, total_loss=12.017066955566406, pred_loss=[0.31869665, 0.433483, 0.096260235]\n",
      "epoch=77_train_batch=11, total_loss=12.42141342163086, pred_loss=[0.19651653, 0.83956647, 0.21717405]\n",
      "epoch=77_train_batch=12, total_loss=12.219515800476074, pred_loss=[0.17375873, 0.51215553, 0.36591712]\n",
      "epoch=77_train_batch=13, total_loss=11.806601524353027, pred_loss=[0.06667115, 0.10453931, 0.46817875]\n",
      "epoch=77_train_batch=14, total_loss=12.79725170135498, pred_loss=[0.16656125, 0.6117828, 0.8521683]\n",
      "epoch=77_train_batch=15, total_loss=16.236900329589844, pred_loss=[0.036061417, 0.27197954, 4.762596]\n",
      "epoch=77_train_batch=16, total_loss=13.318246841430664, pred_loss=[0.41017497, 0.6168067, 1.125481]\n",
      "epoch=77_train_batch=17, total_loss=11.780196189880371, pred_loss=[0.103825845, 0.31088746, 0.20018099]\n",
      "epoch=77_train_batch=18, total_loss=12.990200996398926, pred_loss=[0.06334838, 0.600242, 1.1617873]\n",
      "epoch=77_train_batch=19, total_loss=12.836390495300293, pred_loss=[0.07680672, 0.40230846, 1.1929324]\n",
      "epoch=77_train_batch=20, total_loss=13.050082206726074, pred_loss=[0.8845702, 0.4295382, 0.5721117]\n",
      "epoch=77_train_batch=21, total_loss=12.397966384887695, pred_loss=[0.018370286, 0.43551353, 0.7807022]\n",
      "epoch=77_train_batch=22, total_loss=11.768722534179688, pred_loss=[0.19516236, 0.2120181, 0.19863415]\n",
      "epoch=77_train_batch=23, total_loss=12.428647994995117, pred_loss=[0.049560774, 0.1811436, 1.0355072]\n",
      "epoch=77_train_batch=24, total_loss=11.85219669342041, pred_loss=[0.09137826, 0.26643267, 0.3324175]\n",
      "epoch=77_train_batch=25, total_loss=11.859996795654297, pred_loss=[0.096834704, 0.4068054, 0.19485393]\n",
      "epoch=77_train_batch=26, total_loss=12.321466445922852, pred_loss=[0.6691946, 0.3121127, 0.17912298]\n",
      "epoch=77_train_batch=27, total_loss=13.343863487243652, pred_loss=[0.12213525, 0.13437657, 1.9267805]\n",
      "epoch=77_train_batch=28, total_loss=14.367733001708984, pred_loss=[0.017298566, 2.9656677, 0.22466397]\n",
      "epoch=77_train_batch=29, total_loss=11.968733787536621, pred_loss=[0.11729416, 0.5193893, 0.17241648]\n",
      "epoch=77_train_batch=30, total_loss=12.050274848937988, pred_loss=[0.24884576, 0.17316158, 0.46910024]\n",
      "epoch=77_train_batch=31, total_loss=12.00280475616455, pred_loss=[0.11903008, 0.33373132, 0.39134055]\n",
      "epoch=77_train_batch=32, total_loss=12.280855178833008, pred_loss=[0.2461691, 0.33022168, 0.546222]\n",
      "epoch=77_train_batch=33, total_loss=14.128963470458984, pred_loss=[0.12502906, 0.88344985, 1.9627042]\n",
      "epoch=77_train_batch=34, total_loss=12.278806686401367, pred_loss=[0.22994107, 0.51431906, 0.37722635]\n",
      "epoch=77_train_batch=35, total_loss=12.305984497070312, pred_loss=[0.052546572, 0.5180727, 0.5785067]\n",
      "epoch=77_train_batch=36, total_loss=12.1021728515625, pred_loss=[0.14044614, 0.39183602, 0.4134943]\n",
      "epoch=77_train_batch=37, total_loss=12.069212913513184, pred_loss=[0.04160663, 0.21097548, 0.66069555]\n",
      "epoch=77_train_batch=38, total_loss=12.216114044189453, pred_loss=[0.14912944, 0.68414, 0.22737464]\n",
      "epoch=77_train_batch=39, total_loss=12.849575996398926, pred_loss=[0.6360176, 0.40281963, 0.6557362]\n",
      "epoch=77_train_batch=40, total_loss=12.62421989440918, pred_loss=[0.0915189, 0.31428373, 1.0638813]\n",
      "epoch=77_train_batch=41, total_loss=11.673446655273438, pred_loss=[0.06406727, 0.1737836, 0.28152612]\n",
      "epoch=77_train_batch=42, total_loss=12.285371780395508, pred_loss=[0.07525045, 0.23417895, 0.82234204]\n",
      "epoch=77_train_batch=43, total_loss=11.918285369873047, pred_loss=[0.1846785, 0.4265065, 0.15397044]\n",
      "epoch=77_train_batch=44, total_loss=12.724074363708496, pred_loss=[0.005363933, 0.5970347, 0.96902037]\n",
      "epoch=77_train_batch=45, total_loss=12.804381370544434, pred_loss=[0.050178014, 1.0614431, 0.5405815]\n",
      "epoch=77_train_batch=46, total_loss=12.806005477905273, pred_loss=[0.09933004, 0.2819324, 1.2730421]\n",
      "epoch=77_train_batch=47, total_loss=13.002176284790039, pred_loss=[0.0806836, 0.6165517, 1.1537207]\n",
      "epoch=77_train_batch=48, total_loss=12.460269927978516, pred_loss=[0.10390484, 0.28245077, 0.9231736]\n",
      "epoch=77_train_batch=49, total_loss=12.27928352355957, pred_loss=[0.031278647, 0.7884816, 0.30926275]\n",
      "epoch=77_train_batch=50, total_loss=12.765925407409668, pred_loss=[0.031049237, 0.4524834, 1.1326116]\n",
      "epoch=77_train_batch=51, total_loss=12.308785438537598, pred_loss=[0.27819747, 0.2141181, 0.66717]\n",
      "epoch=77_train_batch=52, total_loss=12.984407424926758, pred_loss=[0.050413795, 0.22644967, 1.5587273]\n",
      "epoch=77_train_batch=53, total_loss=11.895082473754883, pred_loss=[0.017059386, 0.3695079, 0.36017892]\n",
      "epoch=77_train_batch=54, total_loss=11.746262550354004, pred_loss=[0.23091908, 0.26970488, 0.09778468]\n",
      "epoch=77_train_batch=55, total_loss=12.551322937011719, pred_loss=[0.123745546, 0.8540664, 0.42614296]\n",
      "epoch=77_train_batch=56, total_loss=12.238174438476562, pred_loss=[0.3277331, 0.34872308, 0.4148385]\n",
      "epoch=77_train_batch=57, total_loss=12.657090187072754, pred_loss=[0.041140124, 0.7570331, 0.7125281]\n",
      "epoch=77_train_batch=58, total_loss=18.578269958496094, pred_loss=[0.041469056, 2.7194886, 4.6714115]\n",
      "epoch=77_train_batch=59, total_loss=12.283893585205078, pred_loss=[0.070406035, 0.3545265, 0.7135424]\n",
      "epoch=77_train_batch=60, total_loss=11.998943328857422, pred_loss=[0.075232945, 0.3693693, 0.40940115]\n",
      "epoch=77_train_batch=61, total_loss=13.940384864807129, pred_loss=[0.330783, 1.2797885, 1.1853497]\n",
      "epoch=77_train_batch=62, total_loss=13.355996131896973, pred_loss=[0.17110397, 0.14865239, 1.892251]\n",
      "epoch=77_train_batch=63, total_loss=12.529924392700195, pred_loss=[0.15182239, 0.19683255, 1.0377549]\n",
      "epoch=77_train_batch=64, total_loss=12.47050952911377, pred_loss=[0.07493663, 0.36213827, 0.8903932]\n",
      "epoch=77_train_batch=65, total_loss=11.695661544799805, pred_loss=[0.04928727, 0.37126243, 0.13254192]\n",
      "epoch=77_train_batch=66, total_loss=13.844562530517578, pred_loss=[0.05704318, 0.5000836, 2.14534]\n",
      "epoch=77_train_batch=67, total_loss=15.056499481201172, pred_loss=[0.18439934, 0.39575228, 3.3347273]\n",
      "epoch=77_train_batch=68, total_loss=12.039055824279785, pred_loss=[0.13389967, 0.21928644, 0.5447255]\n",
      "epoch=77_train_batch=69, total_loss=12.698517799377441, pred_loss=[0.0842061, 0.26886326, 1.2047812]\n",
      "epoch=77_train_batch=70, total_loss=13.987627029418945, pred_loss=[0.16192228, 0.47194192, 2.2135742]\n",
      "epoch=77_train_batch=71, total_loss=12.234552383422852, pred_loss=[0.30377582, 0.539517, 0.2515537]\n",
      "epoch=77_train_batch=72, total_loss=11.843992233276367, pred_loss=[0.21206996, 0.28966928, 0.20303369]\n",
      "epoch=77_train_batch=73, total_loss=13.106640815734863, pred_loss=[0.08638046, 0.44698507, 1.4345434]\n",
      "epoch=77_train_batch=74, total_loss=12.489490509033203, pred_loss=[0.5859382, 0.1462591, 0.6190494]\n",
      "epoch=77_train_batch=75, total_loss=12.033411026000977, pred_loss=[0.13008168, 0.3186683, 0.44688073]\n",
      "epoch=77_train_batch=76, total_loss=12.028091430664062, pred_loss=[0.20925522, 0.2980078, 0.38350615]\n",
      "epoch=77_train_batch=77, total_loss=12.215815544128418, pred_loss=[0.68123424, 0.20928375, 0.18842877]\n",
      "epoch=77_train_batch=78, total_loss=11.937705039978027, pred_loss=[0.1686122, 0.28051886, 0.3521538]\n",
      "epoch=77_train_batch=79, total_loss=12.773479461669922, pred_loss=[0.17350055, 0.7811218, 0.6828842]\n",
      "epoch=77_train_batch=80, total_loss=11.857831001281738, pred_loss=[0.07695567, 0.34448478, 0.3008666]\n",
      "epoch=77_train_batch=81, total_loss=11.876960754394531, pred_loss=[0.21393901, 0.2227937, 0.30515277]\n",
      "epoch=77_train_batch=82, total_loss=15.359585762023926, pred_loss=[0.0787044, 1.9756315, 2.1706233]\n",
      "epoch=77_train_batch=83, total_loss=12.111051559448242, pred_loss=[0.16110644, 0.42553648, 0.39023283]\n",
      "epoch=77_train_batch=84, total_loss=12.108697891235352, pred_loss=[0.71628034, 0.13888715, 0.11981016]\n",
      "epoch=77_train_batch=85, total_loss=12.506302833557129, pred_loss=[0.19023743, 0.6881113, 0.49470383]\n",
      "epoch=77_train_batch=86, total_loss=12.189743041992188, pred_loss=[0.09583226, 0.27980852, 0.68132454]\n",
      "epoch=77_train_batch=87, total_loss=11.452699661254883, pred_loss=[0.02690127, 0.0982107, 0.19527869]\n",
      "epoch=77_val_batch=0, total_val_loss=669.7547607421875, pred_val_loss[0.27438024, 52.659706, 605.68884]\n",
      "epoch=77_val_batch=1, total_val_loss=213.61468505859375, pred_val_loss[0.07552806, 117.17685, 85.23048]\n",
      "epoch=77_val_batch=2, total_val_loss=81.12133026123047, pred_val_loss[13.390454, 11.548853, 45.050182]\n",
      "epoch=77_val_batch=3, total_val_loss=121.16510772705078, pred_val_loss[6.984708, 25.357178, 77.691376]\n",
      "epoch=77_val_batch=4, total_val_loss=85.11593627929688, pred_val_loss[3.9342563, 25.4844, 44.565437]\n",
      "epoch=77_val_batch=5, total_val_loss=57.43084716796875, pred_val_loss[14.51813, 9.365919, 22.414955]\n",
      "epoch=77_val_batch=6, total_val_loss=212.8201904296875, pred_val_loss[17.81713, 6.5615287, 177.3097]\n",
      "epoch=77_val_batch=7, total_val_loss=154.82528686523438, pred_val_loss[0.8073245, 53.78703, 89.099106]\n",
      "epoch=77_val_batch=8, total_val_loss=56.27552795410156, pred_val_loss[0.23705718, 37.572487, 7.3341413]\n",
      "epoch=77_val_batch=9, total_val_loss=117.31034851074219, pred_val_loss[4.205509, 49.89795, 52.075047]\n",
      "epoch=77_val_batch=10, total_val_loss=120.57376861572266, pred_val_loss[24.203318, 9.329306, 75.9093]\n",
      "epoch=77_val_batch=11, total_val_loss=160.32923889160156, pred_val_loss[11.707847, 67.460335, 70.02922]\n",
      "epoch=77_val_batch=12, total_val_loss=26.305770874023438, pred_val_loss[0.446107, 5.2731442, 9.454678]\n",
      "epoch=77_val_batch=13, total_val_loss=94.59452056884766, pred_val_loss[0.24434948, 40.389584, 42.828743]\n",
      "epoch=77_val_batch=14, total_val_loss=93.57268524169922, pred_val_loss[12.323014, 28.533693, 41.584137]\n",
      "epoch=77_val_batch=15, total_val_loss=76.33170318603516, pred_val_loss[20.920542, 3.090173, 41.18914]\n",
      "epoch=77_val_batch=16, total_val_loss=200.8202667236328, pred_val_loss[9.119282, 63.74054, 116.82861]\n",
      "epoch=77_val_batch=17, total_val_loss=151.1719512939453, pred_val_loss[16.18624, 14.599783, 109.2541]\n",
      "epoch=77_val_batch=18, total_val_loss=141.05209350585938, pred_val_loss[9.73322, 33.029675, 87.157364]\n",
      "epoch=77, train: avg_loss=12.678350448608398, val: avg_val_loss=149.1676788330078\n",
      "Saved checkpoint for step 88: ./tf_ckpts/ckpt-87\n",
      "epoch=78_train_batch=0, total_loss=12.462818145751953, pred_loss=[0.46901, 0.22795153, 0.6340143]\n",
      "epoch=78_train_batch=1, total_loss=12.143253326416016, pred_loss=[0.24759075, 0.57648027, 0.1878087]\n",
      "epoch=78_train_batch=2, total_loss=12.322795867919922, pred_loss=[0.2523988, 0.27168185, 0.667814]\n",
      "epoch=78_train_batch=3, total_loss=12.5493803024292, pred_loss=[0.09412422, 0.97695696, 0.3478669]\n",
      "epoch=78_train_batch=4, total_loss=14.345388412475586, pred_loss=[0.083419204, 0.9961186, 2.1358876]\n",
      "epoch=78_train_batch=5, total_loss=12.276329040527344, pred_loss=[0.20077296, 0.29366267, 0.6523947]\n",
      "epoch=78_train_batch=6, total_loss=11.714591026306152, pred_loss=[0.21080726, 0.283633, 0.09111695]\n",
      "epoch=78_train_batch=7, total_loss=13.194757461547852, pred_loss=[0.7064061, 0.2642478, 1.0955344]\n",
      "epoch=78_train_batch=8, total_loss=12.231067657470703, pred_loss=[0.61709744, 0.29929826, 0.18656597]\n",
      "epoch=78_train_batch=9, total_loss=12.973852157592773, pred_loss=[0.7545463, 0.96086586, 0.1307942]\n",
      "epoch=78_train_batch=10, total_loss=15.085163116455078, pred_loss=[0.30991802, 0.73963034, 2.9084249]\n",
      "epoch=78_train_batch=11, total_loss=12.03950023651123, pred_loss=[0.12247525, 0.18510824, 0.6051799]\n",
      "epoch=78_train_batch=12, total_loss=12.69526481628418, pred_loss=[0.43040937, 0.22580706, 0.91276616]\n",
      "epoch=78_train_batch=13, total_loss=11.958752632141113, pred_loss=[0.11713498, 0.34846434, 0.36732364]\n",
      "epoch=78_train_batch=14, total_loss=12.394187927246094, pred_loss=[0.44389713, 0.63287085, 0.19204651]\n",
      "epoch=78_train_batch=15, total_loss=12.938127517700195, pred_loss=[0.095063195, 1.0955482, 0.62259686]\n",
      "epoch=78_train_batch=16, total_loss=15.874570846557617, pred_loss=[0.1916591, 1.7368824, 2.8215637]\n",
      "epoch=78_train_batch=17, total_loss=12.956404685974121, pred_loss=[0.1637203, 0.068764195, 1.5999086]\n",
      "epoch=78_train_batch=18, total_loss=11.937540054321289, pred_loss=[0.4871313, 0.10235857, 0.22449028]\n",
      "epoch=78_train_batch=19, total_loss=12.393999099731445, pred_loss=[0.52893627, 0.4416323, 0.30032158]\n",
      "epoch=78_train_batch=20, total_loss=13.265121459960938, pred_loss=[0.12608616, 0.7393508, 1.2770329]\n",
      "epoch=78_train_batch=21, total_loss=15.027536392211914, pred_loss=[0.029278316, 1.3910728, 2.4849935]\n",
      "epoch=78_train_batch=22, total_loss=11.718011856079102, pred_loss=[0.21082652, 0.16700818, 0.21844608]\n",
      "epoch=78_train_batch=23, total_loss=11.733595848083496, pred_loss=[0.22220106, 0.14988953, 0.24023402]\n",
      "epoch=78_train_batch=24, total_loss=11.676567077636719, pred_loss=[0.2501154, 0.0679135, 0.23772913]\n",
      "epoch=78_train_batch=25, total_loss=11.85118293762207, pred_loss=[0.08575286, 0.28356874, 0.3615167]\n",
      "epoch=78_train_batch=26, total_loss=12.67088508605957, pred_loss=[0.11393335, 0.26008582, 1.1769842]\n",
      "epoch=78_train_batch=27, total_loss=13.85067367553711, pred_loss=[0.060672443, 1.656836, 1.0137503]\n",
      "epoch=78_train_batch=28, total_loss=12.211870193481445, pred_loss=[0.34045905, 0.32389575, 0.42856723]\n",
      "epoch=78_train_batch=29, total_loss=15.36007308959961, pred_loss=[0.2719003, 1.686168, 2.283525]\n",
      "epoch=78_train_batch=30, total_loss=13.032705307006836, pred_loss=[0.17246845, 0.55290985, 1.1893246]\n",
      "epoch=78_train_batch=31, total_loss=12.322190284729004, pred_loss=[0.25129518, 0.21815875, 0.7352134]\n",
      "epoch=78_train_batch=32, total_loss=13.372164726257324, pred_loss=[0.1507968, 0.8743782, 1.2299451]\n",
      "epoch=78_train_batch=33, total_loss=12.166659355163574, pred_loss=[0.48384827, 0.3482132, 0.21803819]\n",
      "epoch=78_train_batch=34, total_loss=12.011988639831543, pred_loss=[0.057289444, 0.47186753, 0.36675572]\n",
      "epoch=78_train_batch=35, total_loss=12.688705444335938, pred_loss=[0.20000705, 0.25692868, 1.1161785]\n",
      "epoch=78_train_batch=36, total_loss=11.943947792053223, pred_loss=[0.26793218, 0.43125847, 0.12964875]\n",
      "epoch=78_train_batch=37, total_loss=11.768209457397461, pred_loss=[0.07527659, 0.42167422, 0.15662837]\n",
      "epoch=78_train_batch=38, total_loss=11.922228813171387, pred_loss=[0.24441731, 0.2429423, 0.32071564]\n",
      "epoch=78_train_batch=39, total_loss=11.944926261901855, pred_loss=[0.09013982, 0.2790987, 0.46201396]\n",
      "epoch=78_train_batch=40, total_loss=12.199712753295898, pred_loss=[0.03036413, 0.6019086, 0.45424777]\n",
      "epoch=78_train_batch=41, total_loss=12.082286834716797, pred_loss=[0.03137081, 0.24618992, 0.69201934]\n",
      "epoch=78_train_batch=42, total_loss=11.766109466552734, pred_loss=[0.051979147, 0.4001163, 0.20179406]\n",
      "epoch=78_train_batch=43, total_loss=12.379949569702148, pred_loss=[0.06194944, 0.32164207, 0.884629]\n",
      "epoch=78_train_batch=44, total_loss=11.873919486999512, pred_loss=[0.34011772, 0.18469976, 0.23786739]\n",
      "epoch=78_train_batch=45, total_loss=12.302547454833984, pred_loss=[0.33924532, 0.33407575, 0.51849186]\n",
      "epoch=78_train_batch=46, total_loss=11.779488563537598, pred_loss=[0.12920506, 0.29800642, 0.242044]\n",
      "epoch=78_train_batch=47, total_loss=11.7454252243042, pred_loss=[0.32389125, 0.116997615, 0.19480368]\n",
      "epoch=78_train_batch=48, total_loss=11.767910957336426, pred_loss=[0.032524627, 0.27660108, 0.3495527]\n",
      "epoch=78_train_batch=49, total_loss=11.538642883300781, pred_loss=[0.10309424, 0.18372023, 0.14309572]\n",
      "epoch=78_train_batch=50, total_loss=11.674444198608398, pred_loss=[0.15856504, 0.27326247, 0.13438591]\n",
      "epoch=78_train_batch=51, total_loss=12.750133514404297, pred_loss=[0.74434483, 0.60762775, 0.29043412]\n",
      "epoch=78_train_batch=52, total_loss=11.832879066467285, pred_loss=[0.17913404, 0.28781617, 0.25871193]\n",
      "epoch=78_train_batch=53, total_loss=12.537519454956055, pred_loss=[0.110187195, 0.5173732, 0.80324835]\n",
      "epoch=78_train_batch=54, total_loss=11.540699005126953, pred_loss=[0.14115407, 0.14229491, 0.15104687]\n",
      "epoch=78_train_batch=55, total_loss=11.916141510009766, pred_loss=[0.05421232, 0.3771042, 0.37912688]\n",
      "epoch=78_train_batch=56, total_loss=12.042470932006836, pred_loss=[0.13124883, 0.263938, 0.5420971]\n",
      "epoch=78_train_batch=57, total_loss=11.982693672180176, pred_loss=[0.24956909, 0.40633333, 0.22211291]\n",
      "epoch=78_train_batch=58, total_loss=12.795990943908691, pred_loss=[0.21679878, 0.37555, 1.0994779]\n",
      "epoch=78_train_batch=59, total_loss=12.097846984863281, pred_loss=[0.09144008, 0.43433443, 0.46842286]\n",
      "epoch=78_train_batch=60, total_loss=12.438488006591797, pred_loss=[0.05266897, 0.23480399, 1.0478808]\n",
      "epoch=78_train_batch=61, total_loss=11.740473747253418, pred_loss=[0.1797448, 0.17717734, 0.28093335]\n",
      "epoch=78_train_batch=62, total_loss=12.036524772644043, pred_loss=[0.27428478, 0.17930238, 0.4808326]\n",
      "epoch=78_train_batch=63, total_loss=17.083538055419922, pred_loss=[0.12702401, 0.2704578, 5.584464]\n",
      "epoch=78_train_batch=64, total_loss=12.018206596374512, pred_loss=[0.08360642, 0.42314157, 0.41037562]\n",
      "epoch=78_train_batch=65, total_loss=11.715261459350586, pred_loss=[0.09025933, 0.329454, 0.19497141]\n",
      "epoch=78_train_batch=66, total_loss=12.175453186035156, pred_loss=[0.085620716, 0.6527071, 0.33705258]\n",
      "epoch=78_train_batch=67, total_loss=12.042215347290039, pred_loss=[0.025614267, 0.4453231, 0.4717088]\n",
      "epoch=78_train_batch=68, total_loss=12.430334091186523, pred_loss=[0.049787514, 0.39107397, 0.8904049]\n",
      "epoch=78_train_batch=69, total_loss=13.314223289489746, pred_loss=[0.0032438808, 0.40293473, 1.8094827]\n",
      "epoch=78_train_batch=70, total_loss=12.301592826843262, pred_loss=[0.046550248, 0.46945047, 0.68753815]\n",
      "epoch=78_train_batch=71, total_loss=11.805914878845215, pred_loss=[0.14051968, 0.14806202, 0.41978535]\n",
      "epoch=78_train_batch=72, total_loss=11.641090393066406, pred_loss=[0.13688508, 0.18033151, 0.22683471]\n",
      "epoch=78_train_batch=73, total_loss=13.38722038269043, pred_loss=[0.0723912, 0.5587259, 1.6595738]\n",
      "epoch=78_train_batch=74, total_loss=14.771659851074219, pred_loss=[0.13023548, 0.06629528, 3.4791088]\n",
      "epoch=78_train_batch=75, total_loss=11.734989166259766, pred_loss=[0.16327533, 0.32441196, 0.15179107]\n",
      "epoch=78_train_batch=76, total_loss=11.794615745544434, pred_loss=[0.09336049, 0.4840126, 0.12224156]\n",
      "epoch=78_train_batch=77, total_loss=12.778220176696777, pred_loss=[0.109885976, 0.14169627, 1.4321421]\n",
      "epoch=78_train_batch=78, total_loss=12.40255355834961, pred_loss=[0.025381433, 0.7402773, 0.54290444]\n",
      "epoch=78_train_batch=79, total_loss=14.43635082244873, pred_loss=[0.07654454, 0.61951184, 2.6468112]\n",
      "epoch=78_train_batch=80, total_loss=13.62442398071289, pred_loss=[0.080549866, 0.39780885, 2.0530844]\n",
      "epoch=78_train_batch=81, total_loss=12.212127685546875, pred_loss=[0.5838557, 0.32812977, 0.20766044]\n",
      "epoch=78_train_batch=82, total_loss=12.125057220458984, pred_loss=[0.20499843, 0.5848868, 0.24318966]\n",
      "epoch=78_train_batch=83, total_loss=15.581937789916992, pred_loss=[0.0015893634, 0.86395574, 3.624912]\n",
      "epoch=78_train_batch=84, total_loss=12.729726791381836, pred_loss=[0.031755403, 0.24816209, 1.3588266]\n",
      "epoch=78_train_batch=85, total_loss=13.540671348571777, pred_loss=[0.040001623, 0.5424868, 1.8676963]\n",
      "epoch=78_train_batch=86, total_loss=12.593561172485352, pred_loss=[0.10015881, 0.5754201, 0.827989]\n",
      "epoch=78_train_batch=87, total_loss=11.409558296203613, pred_loss=[0.023280313, 0.25410366, 0.042673714]\n",
      "epoch=78_val_batch=0, total_val_loss=699.3072509765625, pred_val_loss[0.08214236, 52.503822, 635.6323]\n",
      "epoch=78_val_batch=1, total_val_loss=212.52357482910156, pred_val_loss[0.05035407, 115.29197, 86.09225]\n",
      "epoch=78_val_batch=2, total_val_loss=79.05874633789062, pred_val_loss[11.665568, 10.2144575, 46.089706]\n",
      "epoch=78_val_batch=3, total_val_loss=127.44017028808594, pred_val_loss[6.8221283, 24.270706, 85.25833]\n",
      "epoch=78_val_batch=4, total_val_loss=94.43714904785156, pred_val_loss[4.315831, 25.680834, 53.35148]\n",
      "epoch=78_val_batch=5, total_val_loss=61.48965835571289, pred_val_loss[15.272752, 8.538643, 26.589256]\n",
      "epoch=78_val_batch=6, total_val_loss=222.49111938476562, pred_val_loss[17.411242, 7.1989603, 186.79192]\n",
      "epoch=78_val_batch=7, total_val_loss=158.12811279296875, pred_val_loss[0.78612924, 53.638283, 92.6147]\n",
      "epoch=78_val_batch=8, total_val_loss=53.20548629760742, pred_val_loss[0.2703475, 33.554245, 8.291887]\n",
      "epoch=78_val_batch=9, total_val_loss=123.95173645019531, pred_val_loss[4.754702, 50.645004, 57.463017]\n",
      "epoch=78_val_batch=10, total_val_loss=132.7286376953125, pred_val_loss[29.861105, 10.100692, 81.67783]\n",
      "epoch=78_val_batch=11, total_val_loss=159.52784729003906, pred_val_loss[10.520809, 63.81979, 74.098236]\n",
      "epoch=78_val_batch=12, total_val_loss=25.45306968688965, pred_val_loss[0.3649052, 5.4716067, 8.52755]\n",
      "epoch=78_val_batch=13, total_val_loss=95.29612731933594, pred_val_loss[0.253203, 38.00878, 45.94513]\n",
      "epoch=78_val_batch=14, total_val_loss=99.78103637695312, pred_val_loss[12.929904, 28.725784, 47.036346]\n",
      "epoch=78_val_batch=15, total_val_loss=79.51420593261719, pred_val_loss[18.543766, 2.6519675, 47.22947]\n",
      "epoch=78_val_batch=16, total_val_loss=198.9359588623047, pred_val_loss[6.762861, 62.339325, 118.744774]\n",
      "epoch=78_val_batch=17, total_val_loss=153.22230529785156, pred_val_loss[14.531855, 13.094802, 114.506645]\n",
      "epoch=78_val_batch=18, total_val_loss=146.40097045898438, pred_val_loss[5.7393622, 32.460003, 97.1126]\n",
      "epoch=78, train: avg_loss=12.585223197937012, val: avg_val_loss=153.83648681640625\n",
      "Saved checkpoint for step 89: ./tf_ckpts/ckpt-88\n",
      "epoch=79_train_batch=0, total_loss=12.37085247039795, pred_loss=[0.14058322, 0.33168453, 0.80957633]\n",
      "epoch=79_train_batch=1, total_loss=12.400792121887207, pred_loss=[0.16335379, 0.63749254, 0.51143515]\n",
      "epoch=79_train_batch=2, total_loss=12.074467658996582, pred_loss=[0.1024351, 0.1484451, 0.7355712]\n",
      "epoch=79_train_batch=3, total_loss=13.028203964233398, pred_loss=[0.10284477, 0.37340057, 1.4644369]\n",
      "epoch=79_train_batch=4, total_loss=12.421388626098633, pred_loss=[0.019209433, 0.5816164, 0.73353803]\n",
      "epoch=79_train_batch=5, total_loss=12.840522766113281, pred_loss=[0.004148284, 1.1277852, 0.6220629]\n",
      "epoch=79_train_batch=6, total_loss=14.10755729675293, pred_loss=[0.060315963, 1.0429565, 1.9182621]\n",
      "epoch=79_train_batch=7, total_loss=12.581924438476562, pred_loss=[0.06892124, 0.4314832, 0.9960006]\n",
      "epoch=79_train_batch=8, total_loss=12.249597549438477, pred_loss=[0.04345978, 0.8003113, 0.32080662]\n",
      "epoch=79_train_batch=9, total_loss=13.10573959350586, pred_loss=[0.037007973, 0.5197575, 1.4644536]\n",
      "epoch=79_train_batch=10, total_loss=12.269266128540039, pred_loss=[0.04722526, 0.5401106, 0.5979069]\n",
      "epoch=79_train_batch=11, total_loss=12.298881530761719, pred_loss=[0.21514133, 0.32427087, 0.6759434]\n",
      "epoch=79_train_batch=12, total_loss=14.676008224487305, pred_loss=[0.052282717, 2.0467567, 1.493949]\n",
      "epoch=79_train_batch=13, total_loss=11.73785400390625, pred_loss=[0.06038942, 0.3935762, 0.20137385]\n",
      "epoch=79_train_batch=14, total_loss=12.512843132019043, pred_loss=[0.04789245, 0.4270296, 0.95590913]\n",
      "epoch=79_train_batch=15, total_loss=11.571016311645508, pred_loss=[0.062249873, 0.1673865, 0.2598709]\n",
      "epoch=79_train_batch=16, total_loss=11.729665756225586, pred_loss=[0.074912004, 0.40111083, 0.1726389]\n",
      "epoch=79_train_batch=17, total_loss=12.360881805419922, pred_loss=[0.07945964, 0.681193, 0.5197321]\n",
      "epoch=79_train_batch=18, total_loss=20.297809600830078, pred_loss=[0.024383927, 7.605193, 1.5882453]\n",
      "epoch=79_train_batch=19, total_loss=12.300785064697266, pred_loss=[0.0123180505, 0.35447526, 0.85451865]\n",
      "epoch=79_train_batch=20, total_loss=12.518682479858398, pred_loss=[0.09643544, 1.0170265, 0.32624257]\n",
      "epoch=79_train_batch=21, total_loss=12.650808334350586, pred_loss=[0.10062337, 1.0271609, 0.44453043]\n",
      "epoch=79_train_batch=22, total_loss=18.23571014404297, pred_loss=[0.1070289, 6.7842264, 0.26644078]\n",
      "epoch=79_train_batch=23, total_loss=15.53737735748291, pred_loss=[0.050424993, 3.797964, 0.6114505]\n",
      "epoch=79_train_batch=24, total_loss=14.623075485229492, pred_loss=[0.16489278, 0.86975724, 2.5113528]\n",
      "epoch=79_train_batch=25, total_loss=13.596518516540527, pred_loss=[0.038468678, 1.1861968, 1.2952374]\n",
      "epoch=79_train_batch=26, total_loss=15.098718643188477, pred_loss=[0.061633024, 3.1593223, 0.80159336]\n",
      "epoch=79_train_batch=27, total_loss=16.930225372314453, pred_loss=[0.38681304, 2.2022634, 3.265412]\n",
      "epoch=79_train_batch=28, total_loss=16.586885452270508, pred_loss=[0.004758794, 4.0451164, 1.4616972]\n",
      "epoch=79_train_batch=29, total_loss=12.486602783203125, pred_loss=[0.063541315, 0.80554926, 0.5426016]\n",
      "epoch=79_train_batch=30, total_loss=12.59156608581543, pred_loss=[0.17746523, 0.7557641, 0.5838208]\n",
      "epoch=79_train_batch=31, total_loss=16.259660720825195, pred_loss=[0.14523283, 1.7909987, 3.2493017]\n",
      "epoch=79_train_batch=32, total_loss=12.589203834533691, pred_loss=[0.16777408, 1.1540791, 0.19360998]\n",
      "epoch=79_train_batch=33, total_loss=12.438264846801758, pred_loss=[0.11372501, 1.0005646, 0.25062144]\n",
      "epoch=79_train_batch=34, total_loss=15.110677719116211, pred_loss=[0.02925969, 1.7559788, 2.2524767]\n",
      "epoch=79_train_batch=35, total_loss=14.075119972229004, pred_loss=[0.034307886, 1.7687008, 1.199545]\n",
      "epoch=79_train_batch=36, total_loss=11.823526382446289, pred_loss=[0.08689687, 0.5299786, 0.1344926]\n",
      "epoch=79_train_batch=37, total_loss=12.614286422729492, pred_loss=[0.32221326, 0.8544278, 0.3658985]\n",
      "epoch=79_train_batch=38, total_loss=12.862234115600586, pred_loss=[0.0020835034, 1.3416274, 0.44719058]\n",
      "epoch=79_train_batch=39, total_loss=13.119234085083008, pred_loss=[0.15164755, 0.7723604, 1.1243126]\n",
      "epoch=79_train_batch=40, total_loss=12.441543579101562, pred_loss=[0.09131373, 0.8115998, 0.46813995]\n",
      "epoch=79_train_batch=41, total_loss=12.515645980834961, pred_loss=[0.113035426, 1.2189829, 0.11356977]\n",
      "epoch=79_train_batch=42, total_loss=12.603048324584961, pred_loss=[0.084889404, 1.1552794, 0.29325575]\n",
      "epoch=79_train_batch=43, total_loss=12.489480018615723, pred_loss=[0.055691343, 0.34835985, 1.0162408]\n",
      "epoch=79_train_batch=44, total_loss=16.24422836303711, pred_loss=[0.002638195, 2.177659, 2.9951851]\n",
      "epoch=79_train_batch=45, total_loss=11.800308227539062, pred_loss=[0.13261288, 0.35427788, 0.24511865]\n",
      "epoch=79_train_batch=46, total_loss=14.12916374206543, pred_loss=[0.1302299, 1.54461, 1.3864802]\n",
      "epoch=79_train_batch=47, total_loss=12.587183952331543, pred_loss=[0.0032719355, 1.3425469, 0.17398342]\n",
      "epoch=79_train_batch=48, total_loss=12.418024063110352, pred_loss=[0.079861954, 0.8772507, 0.39399981]\n",
      "epoch=79_train_batch=49, total_loss=13.631229400634766, pred_loss=[0.10493554, 0.4009469, 2.0589082]\n",
      "epoch=79_train_batch=50, total_loss=12.112646102905273, pred_loss=[0.17380619, 0.40010163, 0.4727798]\n",
      "epoch=79_train_batch=51, total_loss=12.14384651184082, pred_loss=[0.1261721, 0.17953882, 0.77266085]\n",
      "epoch=79_train_batch=52, total_loss=11.831146240234375, pred_loss=[0.059689626, 0.6084336, 0.09803672]\n",
      "epoch=79_train_batch=53, total_loss=11.741629600524902, pred_loss=[0.19493215, 0.3709773, 0.11122513]\n",
      "epoch=79_train_batch=54, total_loss=12.155879974365234, pred_loss=[0.071490884, 0.7597781, 0.26061153]\n",
      "epoch=79_train_batch=55, total_loss=12.5490083694458, pred_loss=[0.08200082, 0.13524354, 1.2682594]\n",
      "epoch=79_train_batch=56, total_loss=12.101668357849121, pred_loss=[0.27059507, 0.3027435, 0.46532375]\n",
      "epoch=79_train_batch=57, total_loss=11.667835235595703, pred_loss=[0.17468166, 0.15299222, 0.27765694]\n",
      "epoch=79_train_batch=58, total_loss=12.351166725158691, pred_loss=[0.12353382, 0.60609126, 0.5595364]\n",
      "epoch=79_train_batch=59, total_loss=12.00671672821045, pred_loss=[0.17763942, 0.51611817, 0.25145662]\n",
      "epoch=79_train_batch=60, total_loss=11.588337898254395, pred_loss=[0.12686591, 0.17462784, 0.22584246]\n",
      "epoch=79_train_batch=61, total_loss=11.694021224975586, pred_loss=[0.10899301, 0.40925816, 0.115272835]\n",
      "epoch=79_train_batch=62, total_loss=11.632330894470215, pred_loss=[0.15313536, 0.2865819, 0.13262051]\n",
      "epoch=79_train_batch=63, total_loss=12.700572967529297, pred_loss=[0.116781354, 1.0874534, 0.43685353]\n",
      "epoch=79_train_batch=64, total_loss=13.224418640136719, pred_loss=[0.02664849, 0.18017966, 1.9586142]\n",
      "epoch=79_train_batch=65, total_loss=12.191015243530273, pred_loss=[0.13024345, 0.27188176, 0.73042244]\n",
      "epoch=79_train_batch=66, total_loss=11.831924438476562, pred_loss=[0.06835723, 0.41562653, 0.28997982]\n",
      "epoch=79_train_batch=67, total_loss=12.273174285888672, pred_loss=[0.18385784, 0.80586827, 0.22599567]\n",
      "epoch=79_train_batch=68, total_loss=12.268706321716309, pred_loss=[0.21623822, 0.26744694, 0.7280793]\n",
      "epoch=79_train_batch=69, total_loss=12.13946533203125, pred_loss=[0.15361813, 0.30298215, 0.62643474]\n",
      "epoch=79_train_batch=70, total_loss=12.631153106689453, pred_loss=[0.17560789, 0.25191748, 1.1477106]\n",
      "epoch=79_train_batch=71, total_loss=12.706086158752441, pred_loss=[0.074719556, 0.11578356, 1.4601781]\n",
      "epoch=79_train_batch=72, total_loss=12.282938003540039, pred_loss=[0.09118642, 0.4349063, 0.7019522]\n",
      "epoch=79_train_batch=73, total_loss=13.043400764465332, pred_loss=[0.4610057, 0.7036818, 0.82433593]\n",
      "epoch=79_train_batch=74, total_loss=11.908981323242188, pred_loss=[0.14912008, 0.44660956, 0.25938845]\n",
      "epoch=79_train_batch=75, total_loss=11.88164234161377, pred_loss=[0.057755113, 0.13455476, 0.63598144]\n",
      "epoch=79_train_batch=76, total_loss=12.158403396606445, pred_loss=[0.2184387, 0.45799777, 0.42912522]\n",
      "epoch=79_train_batch=77, total_loss=15.512489318847656, pred_loss=[0.07433253, 0.27537096, 4.1104546]\n",
      "epoch=79_train_batch=78, total_loss=12.701093673706055, pred_loss=[0.057698175, 0.12773845, 1.4638367]\n",
      "epoch=79_train_batch=79, total_loss=12.031598091125488, pred_loss=[0.6402192, 0.20761985, 0.13244717]\n",
      "epoch=79_train_batch=80, total_loss=11.794852256774902, pred_loss=[0.025199395, 0.44726726, 0.27158272]\n",
      "epoch=79_train_batch=81, total_loss=13.286709785461426, pred_loss=[0.30895358, 0.1681188, 1.7593414]\n",
      "epoch=79_train_batch=82, total_loss=13.042566299438477, pred_loss=[0.11743753, 0.732198, 1.1431429]\n",
      "epoch=79_train_batch=83, total_loss=12.392205238342285, pred_loss=[0.28672415, 0.32221296, 0.73398787]\n",
      "epoch=79_train_batch=84, total_loss=11.873814582824707, pred_loss=[0.18851069, 0.27720547, 0.35932493]\n",
      "epoch=79_train_batch=85, total_loss=12.931350708007812, pred_loss=[0.5582767, 0.38763303, 0.9371759]\n",
      "epoch=79_train_batch=86, total_loss=21.987342834472656, pred_loss=[0.014353081, 0.21856397, 10.706671]\n",
      "epoch=79_train_batch=87, total_loss=11.792757034301758, pred_loss=[0.0031576199, 0.68843794, 0.053906765]\n",
      "epoch=79_val_batch=0, total_val_loss=716.545654296875, pred_val_loss[0.10879041, 53.705948, 651.68414]\n",
      "epoch=79_val_batch=1, total_val_loss=210.1715087890625, pred_val_loss[0.16871709, 112.68514, 86.27089]\n",
      "epoch=79_val_batch=2, total_val_loss=78.58655548095703, pred_val_loss[11.75812, 10.295024, 45.486656]\n",
      "epoch=79_val_batch=3, total_val_loss=128.144287109375, pred_val_loss[7.41848, 26.318413, 83.36064]\n",
      "epoch=79_val_batch=4, total_val_loss=94.92447662353516, pred_val_loss[3.4046066, 24.581219, 55.891895]\n",
      "epoch=79_val_batch=5, total_val_loss=65.729736328125, pred_val_loss[18.029182, 9.380562, 27.273235]\n",
      "epoch=79_val_batch=6, total_val_loss=214.01275634765625, pred_val_loss[16.511063, 6.5107174, 179.94421]\n",
      "epoch=79_val_batch=7, total_val_loss=165.86520385742188, pred_val_loss[0.7168262, 58.98356, 95.11806]\n",
      "epoch=79_val_batch=8, total_val_loss=59.03997039794922, pred_val_loss[0.22831665, 39.198895, 8.565996]\n",
      "epoch=79_val_batch=9, total_val_loss=123.49137115478516, pred_val_loss[3.5076697, 52.410934, 56.52601]\n",
      "epoch=79_val_batch=10, total_val_loss=133.1943359375, pred_val_loss[25.153378, 9.449522, 87.54467]\n",
      "epoch=79_val_batch=11, total_val_loss=157.53305053710938, pred_val_loss[10.751621, 61.20622, 74.52846]\n",
      "epoch=79_val_batch=12, total_val_loss=27.36172103881836, pred_val_loss[0.31116337, 5.187924, 10.815872]\n",
      "epoch=79_val_batch=13, total_val_loss=98.9133071899414, pred_val_loss[0.1591917, 38.148247, 49.559105]\n",
      "epoch=79_val_batch=14, total_val_loss=96.37995147705078, pred_val_loss[11.215504, 28.931328, 45.186363]\n",
      "epoch=79_val_batch=15, total_val_loss=80.19473266601562, pred_val_loss[18.61559, 1.6223243, 48.910057]\n",
      "epoch=79_val_batch=16, total_val_loss=206.81387329101562, pred_val_loss[6.893425, 60.23603, 128.63765]\n",
      "epoch=79_val_batch=17, total_val_loss=153.53497314453125, pred_val_loss[13.9429455, 14.803281, 113.74199]\n",
      "epoch=79_val_batch=18, total_val_loss=143.79830932617188, pred_val_loss[5.432082, 29.682182, 97.637276]\n",
      "epoch=79, train: avg_loss=13.064879417419434, val: avg_val_loss=155.48609924316406\n",
      "Saved checkpoint for step 90: ./tf_ckpts/ckpt-89\n",
      "epoch=80_train_batch=0, total_loss=12.28367805480957, pred_loss=[0.13782744, 0.49026382, 0.60882604]\n",
      "epoch=80_train_batch=1, total_loss=12.547124862670898, pred_loss=[0.43093583, 0.45259312, 0.6173267]\n",
      "epoch=80_train_batch=2, total_loss=11.567863464355469, pred_loss=[0.1832476, 0.20271856, 0.13611437]\n",
      "epoch=80_train_batch=3, total_loss=11.491145133972168, pred_loss=[0.105162024, 0.051617093, 0.2890675]\n",
      "epoch=80_train_batch=4, total_loss=13.32210922241211, pred_loss=[0.08489376, 0.40325558, 1.7891473]\n",
      "epoch=80_train_batch=5, total_loss=15.403465270996094, pred_loss=[0.14049721, 3.9274592, 0.29118538]\n",
      "epoch=80_train_batch=6, total_loss=16.77533721923828, pred_loss=[0.066325925, 0.8155365, 4.8496118]\n",
      "epoch=80_train_batch=7, total_loss=11.804556846618652, pred_loss=[0.3493136, 0.07597026, 0.33584666]\n",
      "epoch=80_train_batch=8, total_loss=11.999837875366211, pred_loss=[0.41473398, 0.467961, 0.07413711]\n",
      "epoch=80_train_batch=9, total_loss=12.434697151184082, pred_loss=[0.2254718, 0.4454342, 0.7211922]\n",
      "epoch=80_train_batch=10, total_loss=15.138235092163086, pred_loss=[0.15356308, 0.12356506, 3.8189123]\n",
      "epoch=80_train_batch=11, total_loss=12.153327941894531, pred_loss=[0.20615327, 0.28275943, 0.62261915]\n",
      "epoch=80_train_batch=12, total_loss=15.897950172424316, pred_loss=[0.037684646, 0.5279765, 4.290896]\n",
      "epoch=80_train_batch=13, total_loss=15.559823989868164, pred_loss=[0.2299572, 0.34149823, 3.9473786]\n",
      "epoch=80_train_batch=14, total_loss=17.486351013183594, pred_loss=[0.21952981, 6.1125717, 0.11366534]\n",
      "epoch=80_train_batch=15, total_loss=12.275030136108398, pred_loss=[0.042995885, 0.6782069, 0.5136553]\n",
      "epoch=80_train_batch=16, total_loss=13.671314239501953, pred_loss=[0.102292694, 0.23738028, 2.2918398]\n",
      "epoch=80_train_batch=17, total_loss=11.922467231750488, pred_loss=[0.39371997, 0.27201965, 0.21726485]\n",
      "epoch=80_train_batch=18, total_loss=17.367441177368164, pred_loss=[0.08350276, 0.51928645, 5.7255087]\n",
      "epoch=80_train_batch=19, total_loss=17.500869750976562, pred_loss=[0.118872225, 0.88833123, 5.4548354]\n",
      "epoch=80_train_batch=20, total_loss=12.326964378356934, pred_loss=[0.11904601, 0.7173077, 0.45209002]\n",
      "epoch=80_train_batch=21, total_loss=12.789061546325684, pred_loss=[0.034101926, 0.7657107, 0.951035]\n",
      "epoch=80_train_batch=22, total_loss=14.76882553100586, pred_loss=[0.14282024, 0.6224369, 2.9656684]\n",
      "epoch=80_train_batch=23, total_loss=13.46986198425293, pred_loss=[0.07328256, 0.78628594, 1.5727097]\n",
      "epoch=80_train_batch=24, total_loss=17.64966583251953, pred_loss=[0.061709177, 4.986086, 1.5646093]\n",
      "epoch=80_train_batch=25, total_loss=13.530123710632324, pred_loss=[0.06506246, 0.7387271, 1.6893736]\n",
      "epoch=80_train_batch=26, total_loss=13.70523452758789, pred_loss=[0.15521419, 1.2385237, 1.2748207]\n",
      "epoch=80_train_batch=27, total_loss=23.36345672607422, pred_loss=[0.2853524, 3.7325485, 8.309156]\n",
      "epoch=80_train_batch=28, total_loss=13.004180908203125, pred_loss=[0.44661242, 1.3220775, 0.19931404]\n",
      "epoch=80_train_batch=29, total_loss=13.314701080322266, pred_loss=[0.08792554, 1.5958033, 0.59497064]\n",
      "epoch=80_train_batch=30, total_loss=14.063374519348145, pred_loss=[0.15474272, 1.3809068, 1.4918652]\n",
      "epoch=80_train_batch=31, total_loss=12.31472396850586, pred_loss=[0.10485234, 0.65550053, 0.5186371]\n",
      "epoch=80_train_batch=32, total_loss=16.023765563964844, pred_loss=[0.059093658, 3.65435, 1.2747087]\n",
      "epoch=80_train_batch=33, total_loss=14.534730911254883, pred_loss=[0.1891754, 1.8869494, 1.4231213]\n",
      "epoch=80_train_batch=34, total_loss=15.165504455566406, pred_loss=[0.17852458, 1.2709119, 2.6806636]\n",
      "epoch=80_train_batch=35, total_loss=13.683423042297363, pred_loss=[0.17980087, 0.24660224, 2.2216768]\n",
      "epoch=80_train_batch=36, total_loss=18.601911544799805, pred_loss=[0.078726, 0.8286214, 6.659271]\n",
      "epoch=80_train_batch=37, total_loss=12.57878589630127, pred_loss=[0.08345587, 0.82289195, 0.63719976]\n",
      "epoch=80_train_batch=38, total_loss=13.58203125, pred_loss=[0.06995081, 1.8474464, 0.6294538]\n",
      "epoch=80_train_batch=39, total_loss=13.17308235168457, pred_loss=[0.11374223, 0.66165626, 1.3625696]\n",
      "epoch=80_train_batch=40, total_loss=14.721885681152344, pred_loss=[0.18657012, 1.002794, 2.4974878]\n",
      "epoch=80_train_batch=41, total_loss=14.367369651794434, pred_loss=[0.22851354, 1.1317192, 1.9722035]\n",
      "epoch=80_train_batch=42, total_loss=16.979347229003906, pred_loss=[0.13894576, 1.4462361, 4.359351]\n",
      "epoch=80_train_batch=43, total_loss=12.836849212646484, pred_loss=[0.13627546, 0.7730639, 0.89283633]\n",
      "epoch=80_train_batch=44, total_loss=12.087043762207031, pred_loss=[0.07910697, 0.6295437, 0.3438868]\n",
      "epoch=80_train_batch=45, total_loss=14.361696243286133, pred_loss=[0.24690257, 2.8862739, 0.19420338]\n",
      "epoch=80_train_batch=46, total_loss=19.947982788085938, pred_loss=[0.03700713, 0.6081037, 8.2687645]\n",
      "epoch=80_train_batch=47, total_loss=13.128355026245117, pred_loss=[0.09433171, 1.1340468, 0.8661014]\n",
      "epoch=80_train_batch=48, total_loss=12.46849250793457, pred_loss=[0.18527249, 0.79348725, 0.45609617]\n",
      "epoch=80_train_batch=49, total_loss=12.0645112991333, pred_loss=[0.12631583, 0.7632587, 0.14155743]\n",
      "epoch=80_train_batch=50, total_loss=18.119892120361328, pred_loss=[0.114846155, 1.3462615, 5.6256776]\n",
      "epoch=80_train_batch=51, total_loss=24.594863891601562, pred_loss=[0.20392272, 1.2060317, 12.152094]\n",
      "epoch=80_train_batch=52, total_loss=15.742635726928711, pred_loss=[0.08791175, 0.670979, 3.9512246]\n",
      "epoch=80_train_batch=53, total_loss=16.135833740234375, pred_loss=[0.021010336, 3.2413585, 1.8412446]\n",
      "epoch=80_train_batch=54, total_loss=14.518714904785156, pred_loss=[0.03649079, 3.0853696, 0.3649518]\n",
      "epoch=80_train_batch=55, total_loss=11.992974281311035, pred_loss=[0.102678895, 0.68820584, 0.17049724]\n",
      "epoch=80_train_batch=56, total_loss=13.691482543945312, pred_loss=[0.12137679, 1.4083742, 1.1304231]\n",
      "epoch=80_train_batch=57, total_loss=12.82209587097168, pred_loss=[0.15501185, 1.1743491, 0.4616955]\n",
      "epoch=80_train_batch=58, total_loss=11.99824047088623, pred_loss=[0.14133027, 0.46670586, 0.35942635]\n",
      "epoch=80_train_batch=59, total_loss=11.948902130126953, pred_loss=[0.20671946, 0.3206628, 0.39100185]\n",
      "epoch=80_train_batch=60, total_loss=23.263708114624023, pred_loss=[0.028813824, 5.625995, 6.5786457]\n",
      "epoch=80_train_batch=61, total_loss=14.624754905700684, pred_loss=[0.1233337, 2.3333044, 1.1381276]\n",
      "epoch=80_train_batch=62, total_loss=21.16339111328125, pred_loss=[0.094084665, 2.9043198, 7.1352615]\n",
      "epoch=80_train_batch=63, total_loss=17.236099243164062, pred_loss=[0.08316697, 4.5752645, 1.5481911]\n",
      "epoch=80_train_batch=64, total_loss=14.428689956665039, pred_loss=[0.30566102, 2.2926917, 0.8010886]\n",
      "epoch=80_train_batch=65, total_loss=14.632245063781738, pred_loss=[0.43914163, 2.0603714, 1.1036876]\n",
      "epoch=80_train_batch=66, total_loss=17.425138473510742, pred_loss=[0.24109979, 1.3029268, 4.85227]\n",
      "epoch=80_train_batch=67, total_loss=16.475130081176758, pred_loss=[0.0021214583, 2.1738434, 3.2705288]\n",
      "epoch=80_train_batch=68, total_loss=15.216279983520508, pred_loss=[0.07198538, 3.1470706, 0.9687984]\n",
      "epoch=80_train_batch=69, total_loss=16.27016830444336, pred_loss=[0.142773, 2.1582801, 2.9409122]\n",
      "epoch=80_train_batch=70, total_loss=11.955400466918945, pred_loss=[0.17501837, 0.38454896, 0.36786574]\n",
      "epoch=80_train_batch=71, total_loss=13.87637996673584, pred_loss=[0.21047029, 1.1773033, 1.4608841]\n",
      "epoch=80_train_batch=72, total_loss=18.763641357421875, pred_loss=[0.18760195, 6.825237, 0.723338]\n",
      "epoch=80_train_batch=73, total_loss=13.432958602905273, pred_loss=[0.039793596, 1.2075083, 1.1584697]\n",
      "epoch=80_train_batch=74, total_loss=13.637998580932617, pred_loss=[0.13422991, 0.6387527, 1.8380792]\n",
      "epoch=80_train_batch=75, total_loss=20.140796661376953, pred_loss=[0.003168804, 4.695573, 4.4153433]\n",
      "epoch=80_train_batch=76, total_loss=14.964702606201172, pred_loss=[0.3197296, 1.9786701, 1.639801]\n",
      "epoch=80_train_batch=77, total_loss=13.806905746459961, pred_loss=[0.13903266, 1.8141785, 0.82737744]\n",
      "epoch=80_train_batch=78, total_loss=12.20479965209961, pred_loss=[0.20418799, 0.6684718, 0.30597004]\n",
      "epoch=80_train_batch=79, total_loss=13.456297874450684, pred_loss=[0.080778055, 1.5785081, 0.7709727]\n",
      "epoch=80_train_batch=80, total_loss=12.294384002685547, pred_loss=[0.14487611, 0.2707084, 0.852884]\n",
      "epoch=80_train_batch=81, total_loss=12.360026359558105, pred_loss=[0.23111442, 0.79531896, 0.30780557]\n",
      "epoch=80_train_batch=82, total_loss=13.637801170349121, pred_loss=[0.0015521237, 1.340132, 1.270464]\n",
      "epoch=80_train_batch=83, total_loss=12.990724563598633, pred_loss=[0.0052065803, 1.6948756, 0.26513934]\n",
      "epoch=80_train_batch=84, total_loss=12.388101577758789, pred_loss=[0.060060516, 0.7885543, 0.5141472]\n",
      "epoch=80_train_batch=85, total_loss=14.377782821655273, pred_loss=[0.2800517, 2.9074793, 0.16508806]\n",
      "epoch=80_train_batch=86, total_loss=15.142332077026367, pred_loss=[0.08539555, 3.2215545, 0.81039906]\n",
      "epoch=80_train_batch=87, total_loss=13.815467834472656, pred_loss=[0.0009771619, 2.6601162, 0.1295805]\n",
      "epoch=80_val_batch=0, total_val_loss=726.5726318359375, pred_val_loss[0.10671015, 71.59599, 643.84534]\n",
      "epoch=80_val_batch=1, total_val_loss=226.25732421875, pred_val_loss[0.096388586, 130.73528, 84.40106]\n",
      "epoch=80_val_batch=2, total_val_loss=82.0557861328125, pred_val_loss[11.347218, 15.985093, 43.698875]\n",
      "epoch=80_val_batch=3, total_val_loss=131.7744598388672, pred_val_loss[5.564265, 31.983412, 83.20218]\n",
      "epoch=80_val_batch=4, total_val_loss=104.99087524414062, pred_val_loss[0.8684851, 36.6455, 56.452293]\n",
      "epoch=80_val_batch=5, total_val_loss=68.3359146118164, pred_val_loss[16.520538, 11.409918, 29.380857]\n",
      "epoch=80_val_batch=6, total_val_loss=227.43563842773438, pred_val_loss[20.062662, 11.684798, 184.66359]\n",
      "epoch=80_val_batch=7, total_val_loss=175.30120849609375, pred_val_loss[0.6527051, 71.1523, 92.47162]\n",
      "epoch=80_val_batch=8, total_val_loss=65.34359741210938, pred_val_loss[0.20357269, 42.79789, 11.317535]\n",
      "epoch=80_val_batch=9, total_val_loss=145.78018188476562, pred_val_loss[6.001655, 72.20572, 56.548218]\n",
      "epoch=80_val_batch=10, total_val_loss=129.6492462158203, pred_val_loss[30.864407, 10.05278, 77.707466]\n",
      "epoch=80_val_batch=11, total_val_loss=155.86708068847656, pred_val_loss[10.128186, 60.48655, 74.227745]\n",
      "epoch=80_val_batch=12, total_val_loss=29.77750015258789, pred_val_loss[0.51962847, 6.798248, 11.435025]\n",
      "epoch=80_val_batch=13, total_val_loss=97.89131164550781, pred_val_loss[0.14227453, 43.897385, 42.827057]\n",
      "epoch=80_val_batch=14, total_val_loss=108.04644012451172, pred_val_loss[16.339846, 40.924072, 39.757927]\n",
      "epoch=80_val_batch=15, total_val_loss=77.80625915527344, pred_val_loss[16.141005, 2.479917, 48.16074]\n",
      "epoch=80_val_batch=16, total_val_loss=196.38780212402344, pred_val_loss[9.240704, 59.51693, 116.605576]\n",
      "epoch=80_val_batch=17, total_val_loss=157.251953125, pred_val_loss[11.063469, 22.911438, 112.25245]\n",
      "epoch=80_val_batch=18, total_val_loss=146.8784942626953, pred_val_loss[3.4616017, 39.282017, 93.110275]\n",
      "epoch=80, train: avg_loss=14.644969940185547, val: avg_val_loss=160.7054443359375\n",
      "Saved checkpoint for step 91: ./tf_ckpts/ckpt-90\n",
      "epoch=81_train_batch=0, total_loss=16.29867935180664, pred_loss=[0.15811583, 1.9323738, 3.1835914]\n",
      "epoch=81_train_batch=1, total_loss=12.262809753417969, pred_loss=[0.53852016, 0.61069036, 0.089194685]\n",
      "epoch=81_train_batch=2, total_loss=12.496357917785645, pred_loss=[0.26789317, 0.95898765, 0.24526227]\n",
      "epoch=81_train_batch=3, total_loss=12.747469902038574, pred_loss=[0.18774647, 0.3783183, 1.1573781]\n",
      "epoch=81_train_batch=4, total_loss=13.8389310836792, pred_loss=[0.19089723, 1.8961029, 0.7280955]\n",
      "epoch=81_train_batch=5, total_loss=12.113835334777832, pred_loss=[0.6372357, 0.3143217, 0.13864094]\n",
      "epoch=81_train_batch=6, total_loss=13.240571022033691, pred_loss=[0.0059029674, 1.4901613, 0.7210823]\n",
      "epoch=81_train_batch=7, total_loss=17.293685913085938, pred_loss=[0.060890213, 3.4858153, 2.7237785]\n",
      "epoch=81_train_batch=8, total_loss=12.233142852783203, pred_loss=[0.32286212, 0.592759, 0.2945503]\n",
      "epoch=81_train_batch=9, total_loss=17.305419921875, pred_loss=[0.3623848, 5.755331, 0.16497532]\n",
      "epoch=81_train_batch=10, total_loss=13.833351135253906, pred_loss=[0.29782128, 2.275361, 0.23770037]\n",
      "epoch=81_train_batch=11, total_loss=14.165410041809082, pred_loss=[0.19797358, 0.48251128, 2.462672]\n",
      "epoch=81_train_batch=12, total_loss=12.305009841918945, pred_loss=[0.56117105, 0.59289587, 0.1288835]\n",
      "epoch=81_train_batch=13, total_loss=12.382245063781738, pred_loss=[0.07153803, 0.82063067, 0.46819806]\n",
      "epoch=81_train_batch=14, total_loss=12.816410064697266, pred_loss=[0.15048109, 1.090347, 0.55388606]\n",
      "epoch=81_train_batch=15, total_loss=13.23422622680664, pred_loss=[0.22122006, 1.8099557, 0.18154019]\n",
      "epoch=81_train_batch=16, total_loss=13.39724063873291, pred_loss=[1.1481167, 0.57111084, 0.6566909]\n",
      "epoch=81_train_batch=17, total_loss=12.914255142211914, pred_loss=[0.3345316, 1.4360236, 0.12254014]\n",
      "epoch=81_train_batch=18, total_loss=15.728691101074219, pred_loss=[0.16828325, 0.42224592, 4.1171494]\n",
      "epoch=81_train_batch=19, total_loss=12.198209762573242, pred_loss=[0.22778308, 0.67399675, 0.27552706]\n",
      "epoch=81_train_batch=20, total_loss=12.725919723510742, pred_loss=[0.4033732, 0.4467505, 0.85497975]\n",
      "epoch=81_train_batch=21, total_loss=17.50508689880371, pred_loss=[5.584942, 0.77497303, 0.124433]\n",
      "epoch=81_train_batch=22, total_loss=12.721816062927246, pred_loss=[0.012247798, 0.6134995, 1.0753771]\n",
      "epoch=81_train_batch=23, total_loss=12.388101577758789, pred_loss=[0.51017994, 0.45532537, 0.4017502]\n",
      "epoch=81_train_batch=24, total_loss=15.16575813293457, pred_loss=[0.65824395, 1.0261247, 2.4602528]\n",
      "epoch=81_train_batch=25, total_loss=16.689308166503906, pred_loss=[0.92726785, 2.5213013, 2.2192209]\n",
      "epoch=81_train_batch=26, total_loss=17.773387908935547, pred_loss=[1.0891991, 2.6217067, 3.0405223]\n",
      "epoch=81_train_batch=27, total_loss=12.349632263183594, pred_loss=[0.39342368, 0.75023025, 0.18346474]\n",
      "epoch=81_train_batch=28, total_loss=16.214374542236328, pred_loss=[1.1142896, 3.2783067, 0.7986009]\n",
      "epoch=81_train_batch=29, total_loss=17.72930908203125, pred_loss=[0.45143378, 4.181445, 2.0724618]\n",
      "epoch=81_train_batch=30, total_loss=15.463712692260742, pred_loss=[1.3479009, 2.1023877, 0.9885364]\n",
      "epoch=81_train_batch=31, total_loss=15.88252067565918, pred_loss=[0.7703336, 1.4440899, 2.6422393]\n",
      "epoch=81_train_batch=32, total_loss=14.327305793762207, pred_loss=[0.09122649, 2.0711086, 1.1380692]\n",
      "epoch=81_train_batch=33, total_loss=13.657308578491211, pred_loss=[0.88473177, 0.5714799, 1.1731077]\n",
      "epoch=81_train_batch=34, total_loss=20.983238220214844, pred_loss=[3.3556383, 3.969535, 2.6289973]\n",
      "epoch=81_train_batch=35, total_loss=14.184663772583008, pred_loss=[0.47493312, 1.1265593, 1.5531112]\n",
      "epoch=81_train_batch=36, total_loss=14.924423217773438, pred_loss=[1.4313679, 1.2339875, 1.2279655]\n",
      "epoch=81_train_batch=37, total_loss=19.246580123901367, pred_loss=[3.9687176, 1.2273309, 3.0183892]\n",
      "epoch=81_train_batch=38, total_loss=14.767889022827148, pred_loss=[0.24868408, 1.5776341, 1.9083097]\n",
      "epoch=81_train_batch=39, total_loss=15.378589630126953, pred_loss=[1.4046946, 2.3422318, 0.597201]\n",
      "epoch=81_train_batch=40, total_loss=24.65207290649414, pred_loss=[5.305748, 8.141578, 0.16904762]\n",
      "epoch=81_train_batch=41, total_loss=16.440156936645508, pred_loss=[1.5478544, 0.6218331, 3.2333968]\n",
      "epoch=81_train_batch=42, total_loss=16.576457977294922, pred_loss=[0.79187363, 1.7835925, 2.9624014]\n",
      "epoch=81_train_batch=43, total_loss=18.575820922851562, pred_loss=[2.8161783, 4.2351313, 0.48430642]\n",
      "epoch=81_train_batch=44, total_loss=20.30202865600586, pred_loss=[5.4474325, 2.9370713, 0.8756284]\n",
      "epoch=81_train_batch=45, total_loss=22.08349609375, pred_loss=[2.2110305, 4.632045, 4.1967945]\n",
      "epoch=81_train_batch=46, total_loss=15.143978118896484, pred_loss=[0.5713386, 1.3976626, 2.1295204]\n",
      "epoch=81_train_batch=47, total_loss=25.213485717773438, pred_loss=[0.6571389, 12.012412, 1.4965777]\n",
      "epoch=81_train_batch=48, total_loss=13.86234188079834, pred_loss=[1.3794726, 1.3270628, 0.10652842]\n",
      "epoch=81_train_batch=49, total_loss=16.02764892578125, pred_loss=[1.0243351, 2.1800704, 1.7720178]\n",
      "epoch=81_train_batch=50, total_loss=17.512073516845703, pred_loss=[1.1473894, 4.6301947, 0.6813607]\n",
      "epoch=81_train_batch=51, total_loss=14.832098007202148, pred_loss=[0.85676754, 1.6984196, 1.2219262]\n",
      "epoch=81_train_batch=52, total_loss=29.81702423095703, pred_loss=[5.8702116, 12.136169, 0.75386465]\n",
      "epoch=81_train_batch=53, total_loss=20.640825271606445, pred_loss=[0.289034, 7.3892593, 1.9038577]\n",
      "epoch=81_train_batch=54, total_loss=26.162004470825195, pred_loss=[2.4824178, 9.673767, 2.9451153]\n",
      "epoch=81_train_batch=55, total_loss=18.134601593017578, pred_loss=[1.6080251, 3.8621447, 1.6016005]\n",
      "epoch=81_train_batch=56, total_loss=28.17978858947754, pred_loss=[3.5581064, 8.241002, 5.315673]\n",
      "epoch=81_train_batch=57, total_loss=28.442306518554688, pred_loss=[13.355378, 2.3934894, 1.6261759]\n",
      "epoch=81_train_batch=58, total_loss=14.905801773071289, pred_loss=[0.57791775, 2.5771456, 0.68111837]\n",
      "epoch=81_train_batch=59, total_loss=16.27562713623047, pred_loss=[1.7096317, 2.4020855, 1.0918329]\n",
      "epoch=81_train_batch=60, total_loss=45.840797424316406, pred_loss=[1.3834636, 30.259895, 3.1228976]\n",
      "epoch=81_train_batch=61, total_loss=24.679264068603516, pred_loss=[3.3171988, 9.249031, 1.0359886]\n",
      "epoch=81_train_batch=62, total_loss=28.39958953857422, pred_loss=[8.667666, 8.311672, 0.34024698]\n",
      "epoch=81_train_batch=63, total_loss=68.21549987792969, pred_loss=[0.26320633, 55.68901, 1.1798764]\n",
      "epoch=81_train_batch=64, total_loss=29.814321517944336, pred_loss=[0.22939548, 17.28947, 1.207813]\n",
      "epoch=81_train_batch=65, total_loss=45.11162567138672, pred_loss=[1.642587, 31.064095, 1.3123498]\n",
      "epoch=81_train_batch=66, total_loss=55.542110443115234, pred_loss=[1.0740806, 38.33084, 5.0392194]\n",
      "epoch=81_train_batch=67, total_loss=25.70305633544922, pred_loss=[2.7952182, 9.581811, 2.2223184]\n",
      "epoch=81_train_batch=68, total_loss=24.17860984802246, pred_loss=[4.079084, 4.874911, 4.1147423]\n",
      "epoch=81_train_batch=69, total_loss=17.350404739379883, pred_loss=[0.46690995, 4.599025, 1.1680603]\n",
      "epoch=81_train_batch=70, total_loss=35.97667694091797, pred_loss=[5.036041, 13.26365, 6.5538754]\n",
      "epoch=81_train_batch=71, total_loss=22.734661102294922, pred_loss=[0.4843835, 9.191653, 1.9287536]\n",
      "epoch=81_train_batch=72, total_loss=62.64223098754883, pred_loss=[0.10224578, 48.246117, 3.157175]\n",
      "epoch=81_train_batch=73, total_loss=28.488239288330078, pred_loss=[3.5792816, 11.28594, 2.479651]\n",
      "epoch=81_train_batch=74, total_loss=23.834014892578125, pred_loss=[2.5840094, 8.72667, 1.3733526]\n",
      "epoch=81_train_batch=75, total_loss=30.698516845703125, pred_loss=[2.927411, 10.145531, 6.469058]\n",
      "epoch=81_train_batch=76, total_loss=44.52888488769531, pred_loss=[0.5821266, 24.854187, 7.929587]\n",
      "epoch=81_train_batch=77, total_loss=37.67173767089844, pred_loss=[9.064358, 13.170967, 4.2671123]\n",
      "epoch=81_train_batch=78, total_loss=27.112491607666016, pred_loss=[0.910581, 12.745632, 2.2807918]\n",
      "epoch=81_train_batch=79, total_loss=41.380035400390625, pred_loss=[1.4325486, 16.506243, 12.25959]\n",
      "epoch=81_train_batch=80, total_loss=27.21524429321289, pred_loss=[0.49397898, 14.319929, 1.2136016]\n",
      "epoch=81_train_batch=81, total_loss=35.55713653564453, pred_loss=[7.3126383, 12.545645, 4.505088]\n",
      "epoch=81_train_batch=82, total_loss=32.91963577270508, pred_loss=[6.699316, 11.247231, 3.77325]\n",
      "epoch=81_train_batch=83, total_loss=33.452659606933594, pred_loss=[1.6543932, 13.160213, 7.4319897]\n",
      "epoch=81_train_batch=84, total_loss=38.43681716918945, pred_loss=[2.6455007, 21.616882, 2.9621038]\n",
      "epoch=81_train_batch=85, total_loss=38.2589225769043, pred_loss=[0.083238795, 19.908428, 7.0485806]\n",
      "epoch=81_train_batch=86, total_loss=37.9293327331543, pred_loss=[2.9877975, 11.100707, 12.615819]\n",
      "epoch=81_train_batch=87, total_loss=14.239265441894531, pred_loss=[0.5719352, 1.7907801, 0.6452468]\n",
      "epoch=81_val_batch=0, total_val_loss=636.257080078125, pred_val_loss[1.5937048, 70.02367, 553.40216]\n",
      "epoch=81_val_batch=1, total_val_loss=236.30996704101562, pred_val_loss[1.3976619, 136.3334, 87.341385]\n",
      "epoch=81_val_batch=2, total_val_loss=129.24105834960938, pred_val_loss[39.168148, 23.778599, 55.056774]\n",
      "epoch=81_val_batch=3, total_val_loss=162.4542236328125, pred_val_loss[7.6159925, 57.459255, 86.14146]\n",
      "epoch=81_val_batch=4, total_val_loss=99.42032623291016, pred_val_loss[8.490103, 39.863373, 39.829323]\n",
      "epoch=81_val_batch=5, total_val_loss=82.9874038696289, pred_val_loss[16.054785, 32.506386, 23.18871]\n",
      "epoch=81_val_batch=6, total_val_loss=231.56777954101562, pred_val_loss[50.280098, 7.176242, 162.8739]\n",
      "epoch=81_val_batch=7, total_val_loss=187.6103515625, pred_val_loss[8.345179, 93.820984, 74.20666]\n",
      "epoch=81_val_batch=8, total_val_loss=80.93049621582031, pred_val_loss[6.4916267, 48.254364, 14.94698]\n",
      "epoch=81_val_batch=9, total_val_loss=165.99392700195312, pred_val_loss[18.350554, 92.54904, 43.856815]\n",
      "epoch=81_val_batch=10, total_val_loss=164.14877319335938, pred_val_loss[42.225693, 25.422813, 85.26274]\n",
      "epoch=81_val_batch=11, total_val_loss=247.03912353515625, pred_val_loss[29.690054, 112.26021, 93.85135]\n",
      "epoch=81_val_batch=12, total_val_loss=64.4056167602539, pred_val_loss[22.6166, 9.631062, 20.92043]\n",
      "epoch=81_val_batch=13, total_val_loss=137.54461669921875, pred_val_loss[1.7817402, 77.08653, 47.43881]\n",
      "epoch=81_val_batch=14, total_val_loss=129.99517822265625, pred_val_loss[27.159306, 55.82599, 35.77236]\n",
      "epoch=81_val_batch=15, total_val_loss=120.95137786865234, pred_val_loss[40.76044, 22.940895, 46.01252]\n",
      "epoch=81_val_batch=16, total_val_loss=221.38772583007812, pred_val_loss[18.242779, 92.26091, 99.6465]\n",
      "epoch=81_val_batch=17, total_val_loss=176.8236083984375, pred_val_loss[51.709213, 25.319668, 88.557205]\n",
      "epoch=81_val_batch=18, total_val_loss=125.76256561279297, pred_val_loss[4.5550447, 28.693945, 81.276054]\n",
      "epoch=81, train: avg_loss=22.324729919433594, val: avg_val_loss=178.9910888671875\n",
      "Saved checkpoint for step 92: ./tf_ckpts/ckpt-91\n",
      "epoch=82_train_batch=0, total_loss=28.190889358520508, pred_loss=[6.1519203, 8.564762, 2.236681]\n",
      "epoch=82_train_batch=1, total_loss=34.4478759765625, pred_loss=[0.20673054, 13.815847, 9.181749]\n",
      "epoch=82_train_batch=2, total_loss=55.15021514892578, pred_loss=[0.71945935, 41.88509, 1.296176]\n",
      "epoch=82_train_batch=3, total_loss=15.42973518371582, pred_loss=[1.6401131, 1.8583769, 0.67603105]\n",
      "epoch=82_train_batch=4, total_loss=32.85188674926758, pred_loss=[4.655708, 16.063225, 0.872092]\n",
      "epoch=82_train_batch=5, total_loss=66.19011688232422, pred_loss=[1.4550666, 14.060687, 39.40796]\n",
      "epoch=82_train_batch=6, total_loss=56.02433776855469, pred_loss=[3.5947213, 10.718395, 30.439459]\n",
      "epoch=82_train_batch=7, total_loss=23.348257064819336, pred_loss=[1.0410017, 6.6692276, 4.3608723]\n",
      "epoch=82_train_batch=8, total_loss=48.15583038330078, pred_loss=[3.6050694, 5.306493, 27.961498]\n",
      "epoch=82_train_batch=9, total_loss=70.54984283447266, pred_loss=[2.4915025, 10.546902, 46.222694]\n",
      "epoch=82_train_batch=10, total_loss=33.00228500366211, pred_loss=[2.7569342, 6.9286013, 12.021578]\n",
      "epoch=82_train_batch=11, total_loss=62.358009338378906, pred_loss=[7.6559606, 23.264826, 20.13527]\n",
      "epoch=82_train_batch=12, total_loss=63.53057098388672, pred_loss=[7.0724297, 13.42695, 31.722353]\n",
      "epoch=82_train_batch=13, total_loss=116.82746124267578, pred_loss=[1.3025602, 9.491465, 94.71768]\n",
      "epoch=82_train_batch=14, total_loss=25.048477172851562, pred_loss=[0.46205395, 4.994567, 8.269088]\n",
      "epoch=82_train_batch=15, total_loss=44.18341064453125, pred_loss=[3.4856393, 23.70908, 5.658648]\n",
      "epoch=82_train_batch=16, total_loss=59.1827278137207, pred_loss=[4.5148697, 14.350786, 28.979633]\n",
      "epoch=82_train_batch=17, total_loss=37.95602035522461, pred_loss=[5.4484286, 10.888437, 10.274216]\n",
      "epoch=82_train_batch=18, total_loss=102.08092498779297, pred_loss=[2.1634264, 5.392501, 83.17262]\n",
      "epoch=82_train_batch=19, total_loss=48.78575897216797, pred_loss=[1.3100637, 21.503443, 14.612583]\n",
      "epoch=82_train_batch=20, total_loss=69.03527069091797, pred_loss=[6.733586, 8.233141, 42.70144]\n",
      "epoch=82_train_batch=21, total_loss=48.04443359375, pred_loss=[3.972994, 12.329355, 20.367474]\n",
      "epoch=82_train_batch=22, total_loss=22.478492736816406, pred_loss=[5.308114, 1.3018665, 4.4862766]\n",
      "epoch=82_train_batch=23, total_loss=40.48853302001953, pred_loss=[12.9624195, 5.921921, 10.214258]\n",
      "epoch=82_train_batch=24, total_loss=143.65737915039062, pred_loss=[0.53677297, 15.623696, 116.099174]\n",
      "epoch=82_train_batch=25, total_loss=60.338096618652344, pred_loss=[5.104621, 5.0627213, 38.7654]\n",
      "epoch=82_train_batch=26, total_loss=67.17240905761719, pred_loss=[7.117452, 12.783718, 35.85827]\n",
      "epoch=82_train_batch=27, total_loss=60.43565368652344, pred_loss=[7.9174356, 0.89980096, 40.197845]\n",
      "epoch=82_train_batch=28, total_loss=67.51854705810547, pred_loss=[5.913916, 17.052523, 33.123894]\n",
      "epoch=82_train_batch=29, total_loss=43.84996795654297, pred_loss=[2.6462512, 17.6391, 12.128783]\n",
      "epoch=82_train_batch=30, total_loss=73.27299499511719, pred_loss=[1.4652054, 24.224392, 36.1398]\n",
      "epoch=82_train_batch=31, total_loss=36.75457000732422, pred_loss=[7.512705, 14.803993, 2.986566]\n",
      "epoch=82_train_batch=32, total_loss=24.60399627685547, pred_loss=[7.9830213, 3.559041, 1.6029443]\n",
      "epoch=82_train_batch=33, total_loss=43.82002639770508, pred_loss=[5.1209183, 10.711169, 16.521433]\n",
      "epoch=82_train_batch=34, total_loss=79.39955139160156, pred_loss=[1.2502818, 15.9306755, 50.744705]\n",
      "epoch=82_train_batch=35, total_loss=69.31962585449219, pred_loss=[3.5278046, 7.545569, 46.76499]\n",
      "epoch=82_train_batch=36, total_loss=47.786476135253906, pred_loss=[0.5693161, 10.664674, 25.063866]\n",
      "epoch=82_train_batch=37, total_loss=54.16211700439453, pred_loss=[2.2461572, 21.546833, 18.873228]\n",
      "epoch=82_train_batch=38, total_loss=63.11415100097656, pred_loss=[4.137889, 19.060436, 28.412737]\n",
      "epoch=82_train_batch=39, total_loss=22.794984817504883, pred_loss=[5.641713, 2.2252455, 3.4176621]\n",
      "epoch=82_train_batch=40, total_loss=50.09933090209961, pred_loss=[0.63506687, 17.664757, 20.281902]\n",
      "epoch=82_train_batch=41, total_loss=38.34485626220703, pred_loss=[3.9506505, 8.3181095, 14.551466]\n",
      "epoch=82_train_batch=42, total_loss=33.71506881713867, pred_loss=[0.31220037, 10.682266, 11.189196]\n",
      "epoch=82_train_batch=43, total_loss=29.02754783630371, pred_loss=[0.14134416, 6.4323683, 10.915724]\n",
      "epoch=82_train_batch=44, total_loss=41.80753707885742, pred_loss=[0.7649249, 6.256612, 23.24131]\n",
      "epoch=82_train_batch=45, total_loss=28.019786834716797, pred_loss=[2.0552514, 3.1938045, 11.219666]\n",
      "epoch=82_train_batch=46, total_loss=35.792503356933594, pred_loss=[5.078425, 7.912924, 11.243869]\n",
      "epoch=82_train_batch=47, total_loss=197.53501892089844, pred_loss=[17.41293, 23.259804, 145.29907]\n",
      "epoch=82_train_batch=48, total_loss=41.32943344116211, pred_loss=[2.8149092, 10.116981, 16.82831]\n",
      "epoch=82_train_batch=49, total_loss=109.75273895263672, pred_loss=[0.27544045, 20.47036, 77.43141]\n",
      "epoch=82_train_batch=50, total_loss=84.02267456054688, pred_loss=[4.554182, 6.577018, 61.30961]\n",
      "epoch=82_train_batch=51, total_loss=55.17927169799805, pred_loss=[1.1816074, 9.596071, 32.81324]\n",
      "epoch=82_train_batch=52, total_loss=44.847862243652344, pred_loss=[1.3199373, 8.589444, 23.343452]\n",
      "epoch=82_train_batch=53, total_loss=55.52233123779297, pred_loss=[2.6634116, 13.236372, 28.020784]\n",
      "epoch=82_train_batch=54, total_loss=35.7153205871582, pred_loss=[4.0218916, 11.648256, 8.43679]\n",
      "epoch=82_train_batch=55, total_loss=39.86150360107422, pred_loss=[1.0692812, 4.5458045, 22.631645]\n",
      "epoch=82_train_batch=56, total_loss=60.84765625, pred_loss=[6.3922276, 11.380245, 31.454178]\n",
      "epoch=82_train_batch=57, total_loss=31.672819137573242, pred_loss=[1.3313246, 5.680194, 13.034181]\n",
      "epoch=82_train_batch=58, total_loss=59.783756256103516, pred_loss=[2.8998027, 8.091029, 37.159813]\n",
      "epoch=82_train_batch=59, total_loss=37.488243103027344, pred_loss=[0.5543636, 15.427957, 9.866936]\n",
      "epoch=82_train_batch=60, total_loss=42.74959945678711, pred_loss=[5.1984935, 8.876321, 17.03006]\n",
      "epoch=82_train_batch=61, total_loss=62.16576385498047, pred_loss=[4.120696, 6.3644986, 40.03027]\n",
      "epoch=82_train_batch=62, total_loss=87.40557861328125, pred_loss=[4.6755314, 5.19318, 65.88112]\n",
      "epoch=82_train_batch=63, total_loss=74.11491394042969, pred_loss=[0.2746037, 17.727364, 44.451584]\n",
      "epoch=82_train_batch=64, total_loss=45.06065368652344, pred_loss=[2.436479, 8.40279, 22.554348]\n",
      "epoch=82_train_batch=65, total_loss=82.10192108154297, pred_loss=[3.959243, 14.660288, 51.809723]\n",
      "epoch=82_train_batch=66, total_loss=39.27335739135742, pred_loss=[4.7846155, 9.91414, 12.896344]\n",
      "epoch=82_train_batch=67, total_loss=68.03866577148438, pred_loss=[0.8790177, 28.56136, 26.914413]\n",
      "epoch=82_train_batch=68, total_loss=49.265419006347656, pred_loss=[1.5084838, 26.353966, 9.713629]\n",
      "epoch=82_train_batch=69, total_loss=58.94294738769531, pred_loss=[3.1098156, 1.1128422, 43.025658]\n",
      "epoch=82_train_batch=70, total_loss=151.18316650390625, pred_loss=[1.5295112, 11.907999, 126.045815]\n",
      "epoch=82_train_batch=71, total_loss=89.85406494140625, pred_loss=[1.776943, 8.3536625, 68.01769]\n",
      "epoch=82_train_batch=72, total_loss=61.91447067260742, pred_loss=[1.0959074, 14.949047, 34.156425]\n",
      "epoch=82_train_batch=73, total_loss=187.65704345703125, pred_loss=[2.6474485, 22.826206, 150.46182]\n",
      "epoch=82_train_batch=74, total_loss=30.95800018310547, pred_loss=[1.2205702, 8.827044, 9.179441]\n",
      "epoch=82_train_batch=75, total_loss=82.79905700683594, pred_loss=[3.6116061, 43.662125, 23.784462]\n",
      "epoch=82_train_batch=76, total_loss=39.46009063720703, pred_loss=[0.10296822, 13.429937, 14.176262]\n",
      "epoch=82_train_batch=77, total_loss=38.04515838623047, pred_loss=[4.3338447, 11.451756, 10.498406]\n",
      "epoch=82_train_batch=78, total_loss=35.666439056396484, pred_loss=[2.1314514, 15.174133, 6.589566]\n",
      "epoch=82_train_batch=79, total_loss=148.5979766845703, pred_loss=[12.850421, 7.90938, 116.056946]\n",
      "epoch=82_train_batch=80, total_loss=71.1723861694336, pred_loss=[0.89595366, 7.201782, 51.283802]\n",
      "epoch=82_train_batch=81, total_loss=48.034278869628906, pred_loss=[0.8899417, 11.316477, 24.027534]\n",
      "epoch=82_train_batch=82, total_loss=48.20149230957031, pred_loss=[11.007282, 3.6386552, 21.745941]\n",
      "epoch=82_train_batch=83, total_loss=85.40127563476562, pred_loss=[9.132145, 17.346798, 47.103554]\n",
      "epoch=82_train_batch=84, total_loss=68.51921081542969, pred_loss=[2.3769944, 21.640257, 32.674274]\n",
      "epoch=82_train_batch=85, total_loss=79.35223388671875, pred_loss=[5.1568394, 4.8700914, 57.48903]\n",
      "epoch=82_train_batch=86, total_loss=106.95679473876953, pred_loss=[3.541169, 12.764322, 78.80661]\n",
      "epoch=82_train_batch=87, total_loss=15.72015380859375, pred_loss=[2.1786478, 0.4224427, 1.2661356]\n",
      "epoch=82_val_batch=0, total_val_loss=10490.5087890625, pred_val_loss[17.791063, 547.84534, 9913.011]\n",
      "epoch=82_val_batch=1, total_val_loss=592.56787109375, pred_val_loss[16.257801, 242.1453, 322.30386]\n",
      "epoch=82_val_batch=2, total_val_loss=549.8298950195312, pred_val_loss[48.283127, 253.61066, 236.07518]\n",
      "epoch=82_val_batch=3, total_val_loss=450.61004638671875, pred_val_loss[7.7380004, 39.48283, 391.52835]\n",
      "epoch=82_val_batch=4, total_val_loss=300.818603515625, pred_val_loss[50.989094, 56.507027, 181.46161]\n",
      "epoch=82_val_batch=5, total_val_loss=133.10440063476562, pred_val_loss[30.586784, 30.820547, 59.83618]\n",
      "epoch=82_val_batch=6, total_val_loss=667.6448364257812, pred_val_loss[28.908855, 35.795307, 591.0798]\n",
      "epoch=82_val_batch=7, total_val_loss=642.2000732421875, pred_val_loss[17.20049, 259.84473, 353.29395]\n",
      "epoch=82_val_batch=8, total_val_loss=305.8166809082031, pred_val_loss[25.22546, 193.28636, 75.44399]\n",
      "epoch=82_val_batch=9, total_val_loss=406.7404479980469, pred_val_loss[25.496681, 270.44772, 98.93518]\n",
      "epoch=82_val_batch=10, total_val_loss=317.1109924316406, pred_val_loss[44.922764, 60.848427, 199.47894]\n",
      "epoch=82_val_batch=11, total_val_loss=398.3979187011719, pred_val_loss[16.165731, 156.14139, 214.22995]\n",
      "epoch=82_val_batch=12, total_val_loss=131.6305389404297, pred_val_loss[8.644379, 51.584835, 59.540443]\n",
      "epoch=82_val_batch=13, total_val_loss=367.7760925292969, pred_val_loss[9.170435, 139.08278, 207.66202]\n",
      "epoch=82_val_batch=14, total_val_loss=464.730712890625, pred_val_loss[62.76069, 53.699577, 336.40958]\n",
      "epoch=82_val_batch=15, total_val_loss=241.82363891601562, pred_val_loss[71.48924, 21.622036, 136.85147]\n",
      "epoch=82_val_batch=16, total_val_loss=683.1054077148438, pred_val_loss[21.62692, 283.69574, 365.92188]\n",
      "epoch=82_val_batch=17, total_val_loss=451.4013366699219, pred_val_loss[37.271244, 26.346867, 375.92236]\n",
      "epoch=82_val_batch=18, total_val_loss=1354.1708984375, pred_val_loss[21.174534, 177.40088, 1143.7346]\n",
      "epoch=82, train: avg_loss=59.88998794555664, val: avg_val_loss=997.3677978515625\n",
      "Saved checkpoint for step 93: ./tf_ckpts/ckpt-92\n",
      "epoch=83_train_batch=0, total_loss=30.538728713989258, pred_loss=[4.1366777, 4.98118, 9.559991]\n",
      "epoch=83_train_batch=1, total_loss=51.57122039794922, pred_loss=[3.907983, 19.245129, 16.54957]\n",
      "epoch=83_train_batch=2, total_loss=45.390586853027344, pred_loss=[0.9526688, 4.020796, 28.541359]\n",
      "epoch=83_train_batch=3, total_loss=52.33538055419922, pred_loss=[5.092928, 6.6930943, 28.666733]\n",
      "epoch=83_train_batch=4, total_loss=38.635711669921875, pred_loss=[2.7509716, 6.2375507, 17.758074]\n",
      "epoch=83_train_batch=5, total_loss=50.03935241699219, pred_loss=[1.2898595, 18.807907, 18.046394]\n",
      "epoch=83_train_batch=6, total_loss=27.064735412597656, pred_loss=[2.7701976, 9.5768585, 2.8168774]\n",
      "epoch=83_train_batch=7, total_loss=207.51161193847656, pred_loss=[0.7947295, 8.308041, 186.50279]\n",
      "epoch=83_train_batch=8, total_loss=48.3712158203125, pred_loss=[0.972638, 3.2125738, 32.275093]\n",
      "epoch=83_train_batch=9, total_loss=74.42475891113281, pred_loss=[2.1410422, 3.8038793, 56.56391]\n",
      "epoch=83_train_batch=10, total_loss=154.41888427734375, pred_loss=[4.8412385, 90.791595, 46.864933]\n",
      "epoch=83_train_batch=11, total_loss=30.979978561401367, pred_loss=[1.6878793, 2.5642197, 14.79986]\n",
      "epoch=83_train_batch=12, total_loss=42.33172607421875, pred_loss=[1.5780282, 7.0576305, 21.758436]\n",
      "epoch=83_train_batch=13, total_loss=40.668846130371094, pred_loss=[2.5327306, 16.627695, 9.559382]\n",
      "epoch=83_train_batch=14, total_loss=127.36388397216797, pred_loss=[4.337491, 15.476168, 95.58859]\n",
      "epoch=83_train_batch=15, total_loss=18.801265716552734, pred_loss=[1.9777259, 4.2015433, 0.6469114]\n",
      "epoch=83_train_batch=16, total_loss=23.1755428314209, pred_loss=[3.7605672, 1.56813, 5.857565]\n",
      "epoch=83_train_batch=17, total_loss=35.35898208618164, pred_loss=[1.8301022, 12.488146, 9.036973]\n",
      "epoch=83_train_batch=18, total_loss=95.17899322509766, pred_loss=[5.7812138, 33.378536, 44.001053]\n",
      "epoch=83_train_batch=19, total_loss=94.9563980102539, pred_loss=[0.57367164, 27.39723, 54.952877]\n",
      "epoch=83_train_batch=20, total_loss=75.54837799072266, pred_loss=[0.90727913, 12.1514015, 50.44225]\n",
      "epoch=83_train_batch=21, total_loss=123.57772827148438, pred_loss=[6.348169, 8.8363285, 96.3307]\n",
      "epoch=83_train_batch=22, total_loss=45.93583679199219, pred_loss=[0.39604518, 16.455809, 17.006273]\n",
      "epoch=83_train_batch=23, total_loss=24.789817810058594, pred_loss=[0.5068873, 3.3338873, 8.856127]\n",
      "epoch=83_train_batch=24, total_loss=38.45882797241211, pred_loss=[0.77104557, 4.590665, 20.989256]\n",
      "epoch=83_train_batch=25, total_loss=62.21699523925781, pred_loss=[0.67224634, 6.3056993, 43.11674]\n",
      "epoch=83_train_batch=26, total_loss=102.48275756835938, pred_loss=[1.2620736, 9.158938, 79.92558]\n",
      "epoch=83_train_batch=27, total_loss=30.660091400146484, pred_loss=[2.9909825, 5.8984065, 9.621403]\n",
      "epoch=83_train_batch=28, total_loss=49.090702056884766, pred_loss=[0.31818324, 14.544775, 22.066061]\n",
      "epoch=83_train_batch=29, total_loss=110.3213119506836, pred_loss=[1.4847564, 10.142148, 86.521034]\n",
      "epoch=83_train_batch=30, total_loss=31.663169860839844, pred_loss=[7.749706, 9.741499, 1.987587]\n",
      "epoch=83_train_batch=31, total_loss=42.68843078613281, pred_loss=[2.693644, 7.254539, 20.545378]\n",
      "epoch=83_train_batch=32, total_loss=44.07867431640625, pred_loss=[0.52642643, 12.458165, 18.889368]\n",
      "epoch=83_train_batch=33, total_loss=59.762969970703125, pred_loss=[2.1939354, 30.10059, 15.254583]\n",
      "epoch=83_train_batch=34, total_loss=73.08526611328125, pred_loss=[0.13191031, 19.933971, 40.797066]\n",
      "epoch=83_train_batch=35, total_loss=52.47899627685547, pred_loss=[7.2796082, 14.279964, 18.689127]\n",
      "epoch=83_train_batch=36, total_loss=47.799076080322266, pred_loss=[0.611445, 27.922619, 7.0272093]\n",
      "epoch=83_train_batch=37, total_loss=42.9677734375, pred_loss=[0.72475314, 16.021309, 13.976712]\n",
      "epoch=83_train_batch=38, total_loss=72.32288360595703, pred_loss=[3.9669342, 18.46471, 37.639412]\n",
      "epoch=83_train_batch=39, total_loss=67.74513244628906, pred_loss=[1.0887806, 17.96437, 36.433666]\n",
      "epoch=83_train_batch=40, total_loss=26.756744384765625, pred_loss=[5.2414455, 6.4215317, 2.8294075]\n",
      "epoch=83_train_batch=41, total_loss=59.62807083129883, pred_loss=[0.35864413, 9.708414, 37.290825]\n",
      "epoch=83_train_batch=42, total_loss=51.25282287597656, pred_loss=[0.9224799, 13.318989, 24.735632]\n",
      "epoch=83_train_batch=43, total_loss=30.45358657836914, pred_loss=[5.709818, 5.883168, 6.5797086]\n",
      "epoch=83_train_batch=44, total_loss=23.09911346435547, pred_loss=[3.365363, 3.4194932, 4.0285735]\n",
      "epoch=83_train_batch=45, total_loss=39.0994873046875, pred_loss=[1.9509959, 17.254198, 7.6041245]\n",
      "epoch=83_train_batch=46, total_loss=28.32707977294922, pred_loss=[2.2404358, 7.6203604, 6.1719723]\n",
      "epoch=83_train_batch=47, total_loss=51.09702682495117, pred_loss=[0.48073876, 9.810826, 28.50729]\n",
      "epoch=83_train_batch=48, total_loss=24.37438201904297, pred_loss=[2.1392229, 2.9688747, 6.9644966]\n",
      "epoch=83_train_batch=49, total_loss=28.466644287109375, pred_loss=[1.9868047, 7.1780167, 6.9965873]\n",
      "epoch=83_train_batch=50, total_loss=27.845703125, pred_loss=[2.378015, 3.4777, 9.681569]\n",
      "epoch=83_train_batch=51, total_loss=79.998046875, pred_loss=[1.2021039, 9.049947, 57.434563]\n",
      "epoch=83_train_batch=52, total_loss=29.42719268798828, pred_loss=[3.487845, 5.258707, 8.366381]\n",
      "epoch=83_train_batch=53, total_loss=35.794761657714844, pred_loss=[9.9883175, 8.578335, 4.911139]\n",
      "epoch=83_train_batch=54, total_loss=48.86842727661133, pred_loss=[2.2504485, 23.865452, 10.433065]\n",
      "epoch=83_train_batch=55, total_loss=45.02199935913086, pred_loss=[5.0714912, 4.536444, 23.092274]\n",
      "epoch=83_train_batch=56, total_loss=60.866329193115234, pred_loss=[0.40625224, 11.837624, 36.298393]\n",
      "epoch=83_train_batch=57, total_loss=34.97472381591797, pred_loss=[5.009985, 10.826625, 6.811775]\n",
      "epoch=83_train_batch=58, total_loss=38.58818435668945, pred_loss=[4.239817, 4.3368106, 17.682781]\n",
      "epoch=83_train_batch=59, total_loss=39.62154769897461, pred_loss=[0.8954569, 10.434937, 15.959915]\n",
      "epoch=83_train_batch=60, total_loss=60.524375915527344, pred_loss=[1.4329275, 21.395233, 25.362526]\n",
      "epoch=83_train_batch=61, total_loss=27.76228141784668, pred_loss=[0.5586269, 5.70354, 9.164014]\n",
      "epoch=83_train_batch=62, total_loss=39.26820755004883, pred_loss=[4.001479, 9.717516, 13.210737]\n",
      "epoch=83_train_batch=63, total_loss=49.06147384643555, pred_loss=[6.250342, 7.2065825, 23.263714]\n",
      "epoch=83_train_batch=64, total_loss=42.55924606323242, pred_loss=[2.6271784, 12.293777, 15.29518]\n",
      "epoch=83_train_batch=65, total_loss=36.08820343017578, pred_loss=[4.4095707, 8.147565, 11.185683]\n",
      "epoch=83_train_batch=66, total_loss=53.22175979614258, pred_loss=[4.1347923, 3.0378969, 33.70156]\n",
      "epoch=83_train_batch=67, total_loss=28.312149047851562, pred_loss=[3.4617867, 5.4708014, 7.0298996]\n",
      "epoch=83_train_batch=68, total_loss=30.274044036865234, pred_loss=[5.3725004, 3.5214088, 9.028369]\n",
      "epoch=83_train_batch=69, total_loss=31.442134857177734, pred_loss=[0.5648692, 3.916655, 14.606747]\n",
      "epoch=83_train_batch=70, total_loss=33.96728515625, pred_loss=[0.79458743, 14.4101925, 6.4065485]\n",
      "epoch=83_train_batch=71, total_loss=29.80852508544922, pred_loss=[3.1500363, 5.2227526, 9.077839]\n",
      "epoch=83_train_batch=72, total_loss=35.23064041137695, pred_loss=[14.688973, 4.930893, 3.2509818]\n",
      "epoch=83_train_batch=73, total_loss=61.30403137207031, pred_loss=[1.4056576, 5.0964537, 42.44028]\n",
      "epoch=83_train_batch=74, total_loss=43.67875671386719, pred_loss=[0.45413905, 15.087638, 15.773532]\n",
      "epoch=83_train_batch=75, total_loss=27.20096206665039, pred_loss=[4.529282, 8.613836, 1.6925839]\n",
      "epoch=83_train_batch=76, total_loss=26.888713836669922, pred_loss=[7.695442, 3.620698, 3.2054796]\n",
      "epoch=83_train_batch=77, total_loss=30.647052764892578, pred_loss=[2.0555525, 5.299058, 10.923452]\n",
      "epoch=83_train_batch=78, total_loss=24.063331604003906, pred_loss=[1.1155714, 9.724276, 0.85265565]\n",
      "epoch=83_train_batch=79, total_loss=48.12603759765625, pred_loss=[1.0662118, 5.509261, 29.177984]\n",
      "epoch=83_train_batch=80, total_loss=33.23651885986328, pred_loss=[2.660509, 12.217228, 5.984513]\n",
      "epoch=83_train_batch=81, total_loss=27.044986724853516, pred_loss=[0.83274174, 8.363525, 5.4728494]\n",
      "epoch=83_train_batch=82, total_loss=22.50365447998047, pred_loss=[5.029154, 3.546842, 1.5502572]\n",
      "epoch=83_train_batch=83, total_loss=26.531143188476562, pred_loss=[3.874215, 4.9386187, 5.3394756]\n",
      "epoch=83_train_batch=84, total_loss=26.849853515625, pred_loss=[8.198586, 1.8243321, 4.4467173]\n",
      "epoch=83_train_batch=85, total_loss=44.170318603515625, pred_loss=[1.4760067, 10.532884, 19.779694]\n",
      "epoch=83_train_batch=86, total_loss=30.31487464904785, pred_loss=[4.1528583, 4.3171425, 9.461608]\n",
      "epoch=83_train_batch=87, total_loss=36.508880615234375, pred_loss=[7.378713, 8.928729, 7.8166757]\n",
      "epoch=83_val_batch=0, total_val_loss=773.33740234375, pred_val_loss[0.44692993, 65.36254, 695.1417]\n",
      "epoch=83_val_batch=1, total_val_loss=239.9906005859375, pred_val_loss[27.294102, 104.02228, 96.28797]\n",
      "epoch=83_val_batch=2, total_val_loss=163.988037109375, pred_val_loss[70.489586, 21.91296, 59.19924]\n",
      "epoch=83_val_batch=3, total_val_loss=157.08717346191406, pred_val_loss[6.57228, 34.677597, 103.451035]\n",
      "epoch=83_val_batch=4, total_val_loss=96.12451934814453, pred_val_loss[2.6919408, 35.872856, 45.17347]\n",
      "epoch=83_val_batch=5, total_val_loss=62.41970443725586, pred_val_loss[22.544695, 5.827936, 21.660818]\n",
      "epoch=83_val_batch=6, total_val_loss=198.74139404296875, pred_val_loss[19.73819, 4.9157643, 161.70117]\n",
      "epoch=83_val_batch=7, total_val_loss=179.8597412109375, pred_val_loss[1.9693186, 65.693756, 99.810394]\n",
      "epoch=83_val_batch=8, total_val_loss=59.05210494995117, pred_val_loss[1.2145294, 35.940876, 9.510443]\n",
      "epoch=83_val_batch=9, total_val_loss=185.67510986328125, pred_val_loss[57.34748, 54.625687, 61.315678]\n",
      "epoch=83_val_batch=10, total_val_loss=147.0098876953125, pred_val_loss[34.56185, 23.807362, 76.25441]\n",
      "epoch=83_val_batch=11, total_val_loss=197.57838439941406, pred_val_loss[57.503998, 47.121147, 80.56698]\n",
      "epoch=83_val_batch=12, total_val_loss=46.364498138427734, pred_val_loss[11.076098, 6.580165, 16.321978]\n",
      "epoch=83_val_batch=13, total_val_loss=90.65311431884766, pred_val_loss[0.6974251, 32.095303, 45.47413]\n",
      "epoch=83_val_batch=14, total_val_loss=180.4925079345703, pred_val_loss[85.17132, 44.933968, 38.00096]\n",
      "epoch=83_val_batch=15, total_val_loss=118.55040740966797, pred_val_loss[43.59987, 6.939902, 55.624386]\n",
      "epoch=83_val_batch=16, total_val_loss=236.19338989257812, pred_val_loss[13.819414, 69.05293, 140.93478]\n",
      "epoch=83_val_batch=17, total_val_loss=253.57861328125, pred_val_loss[90.51933, 18.228373, 132.44464]\n",
      "epoch=83_val_batch=18, total_val_loss=138.8117218017578, pred_val_loss[18.30057, 23.474367, 84.65053]\n",
      "epoch=83, train: avg_loss=48.82890319824219, val: avg_val_loss=185.5530548095703\n",
      "Saved checkpoint for step 94: ./tf_ckpts/ckpt-93\n",
      "epoch=84_train_batch=0, total_loss=28.721778869628906, pred_loss=[0.6056514, 7.2573533, 8.472519]\n",
      "epoch=84_train_batch=1, total_loss=54.51976013183594, pred_loss=[1.4425962, 6.358489, 34.330906]\n",
      "epoch=84_train_batch=2, total_loss=29.102502822875977, pred_loss=[8.16511, 0.9122412, 7.635886]\n",
      "epoch=84_train_batch=3, total_loss=22.159488677978516, pred_loss=[5.541035, 1.1572332, 3.0703542]\n",
      "epoch=84_train_batch=4, total_loss=32.59759521484375, pred_loss=[6.6283655, 2.1244464, 11.452227]\n",
      "epoch=84_train_batch=5, total_loss=28.07500457763672, pred_loss=[2.413834, 2.0205, 11.246408]\n",
      "epoch=84_train_batch=6, total_loss=22.969215393066406, pred_loss=[2.0881085, 1.2361287, 7.249057]\n",
      "epoch=84_train_batch=7, total_loss=18.943330764770508, pred_loss=[1.3867166, 1.7483172, 3.4107468]\n",
      "epoch=84_train_batch=8, total_loss=36.18359375, pred_loss=[0.82313776, 10.611323, 12.350079]\n",
      "epoch=84_train_batch=9, total_loss=36.1201057434082, pred_loss=[0.6376143, 2.5459456, 20.536152]\n",
      "epoch=84_train_batch=10, total_loss=26.189138412475586, pred_loss=[0.96421504, 8.250632, 4.572673]\n",
      "epoch=84_train_batch=11, total_loss=24.534469604492188, pred_loss=[1.1459763, 4.7523003, 6.2334576]\n",
      "epoch=84_train_batch=12, total_loss=21.373807907104492, pred_loss=[1.0669277, 3.082719, 4.820398]\n",
      "epoch=84_train_batch=13, total_loss=24.66057586669922, pred_loss=[2.753288, 8.369401, 1.1331866]\n",
      "epoch=84_train_batch=14, total_loss=22.62092399597168, pred_loss=[1.4354743, 4.440241, 4.339681]\n",
      "epoch=84_train_batch=15, total_loss=29.127986907958984, pred_loss=[0.70833105, 6.5544643, 9.4589]\n",
      "epoch=84_train_batch=16, total_loss=28.648456573486328, pred_loss=[1.7258766, 6.0657597, 8.449839]\n",
      "epoch=84_train_batch=17, total_loss=33.654945373535156, pred_loss=[8.744955, 5.4945245, 7.0078444]\n",
      "epoch=84_train_batch=18, total_loss=25.833641052246094, pred_loss=[1.2185929, 3.0257254, 9.181101]\n",
      "epoch=84_train_batch=19, total_loss=24.080814361572266, pred_loss=[0.84033823, 3.0622606, 7.7694297]\n",
      "epoch=84_train_batch=20, total_loss=20.143756866455078, pred_loss=[2.1813352, 1.2255379, 4.3275976]\n",
      "epoch=84_train_batch=21, total_loss=26.484085083007812, pred_loss=[1.7961812, 9.298128, 2.980073]\n",
      "epoch=84_train_batch=22, total_loss=27.104328155517578, pred_loss=[2.537087, 8.892158, 3.2649481]\n",
      "epoch=84_train_batch=23, total_loss=20.238861083984375, pred_loss=[1.5513167, 1.345187, 4.931805]\n",
      "epoch=84_train_batch=24, total_loss=22.149673461914062, pred_loss=[4.058916, 4.1118574, 1.5679674]\n",
      "epoch=84_train_batch=25, total_loss=16.57501220703125, pred_loss=[1.6199614, 2.2721643, 0.27164346]\n",
      "epoch=84_train_batch=26, total_loss=25.88234519958496, pred_loss=[1.2998195, 9.722696, 2.4483364]\n",
      "epoch=84_train_batch=27, total_loss=33.13325500488281, pred_loss=[3.49008, 8.51164, 8.719865]\n",
      "epoch=84_train_batch=28, total_loss=20.686237335205078, pred_loss=[1.4040377, 2.9223738, 3.9480577]\n",
      "epoch=84_train_batch=29, total_loss=17.972755432128906, pred_loss=[0.20791754, 3.5780537, 1.7749159]\n",
      "epoch=84_train_batch=30, total_loss=22.65096664428711, pred_loss=[0.19138902, 3.7415984, 6.306036]\n",
      "epoch=84_train_batch=31, total_loss=18.693336486816406, pred_loss=[0.7730807, 3.7300906, 1.7781823]\n",
      "epoch=84_train_batch=32, total_loss=17.900035858154297, pred_loss=[0.6226031, 2.9495182, 1.9159224]\n",
      "epoch=84_train_batch=33, total_loss=31.48136329650879, pred_loss=[6.5616207, 6.8409014, 5.6668634]\n",
      "epoch=84_train_batch=34, total_loss=19.586746215820312, pred_loss=[3.8339162, 3.0305662, 0.31021363]\n",
      "epoch=84_train_batch=35, total_loss=22.95217514038086, pred_loss=[5.343354, 3.2235935, 1.9730662]\n",
      "epoch=84_train_batch=36, total_loss=17.54241180419922, pred_loss=[1.3827997, 1.5875199, 2.1598911]\n",
      "epoch=84_train_batch=37, total_loss=23.304645538330078, pred_loss=[1.617929, 3.9057655, 5.3686624]\n",
      "epoch=84_train_batch=38, total_loss=29.704235076904297, pred_loss=[0.5656734, 1.1463895, 15.579834]\n",
      "epoch=84_train_batch=39, total_loss=18.024293899536133, pred_loss=[0.41495833, 4.566, 0.6309399]\n",
      "epoch=84_train_batch=40, total_loss=16.731849670410156, pred_loss=[0.9621332, 2.2346578, 1.1226056]\n",
      "epoch=84_train_batch=41, total_loss=25.85573959350586, pred_loss=[8.212257, 3.4429874, 1.7880158]\n",
      "epoch=84_train_batch=42, total_loss=18.39720916748047, pred_loss=[1.7274582, 3.3734488, 0.88381636]\n",
      "epoch=84_train_batch=43, total_loss=17.32140350341797, pred_loss=[1.3556814, 2.087543, 1.4657483]\n",
      "epoch=84_train_batch=44, total_loss=18.671066284179688, pred_loss=[1.4136463, 1.188985, 3.656098]\n",
      "epoch=84_train_batch=45, total_loss=21.51995086669922, pred_loss=[0.043943252, 4.931699, 4.132091]\n",
      "epoch=84_train_batch=46, total_loss=35.72089385986328, pred_loss=[0.47596362, 9.548229, 13.284632]\n",
      "epoch=84_train_batch=47, total_loss=27.441633224487305, pred_loss=[0.23564239, 1.3646302, 13.429523]\n",
      "epoch=84_train_batch=48, total_loss=18.36157989501953, pred_loss=[0.28390652, 4.1700544, 1.4960421]\n",
      "epoch=84_train_batch=49, total_loss=18.818096160888672, pred_loss=[3.4598825, 2.628932, 0.31792465]\n",
      "epoch=84_train_batch=50, total_loss=19.59590721130371, pred_loss=[1.7013296, 1.1516039, 4.3317986]\n",
      "epoch=84_train_batch=51, total_loss=19.855426788330078, pred_loss=[1.0915166, 3.5296066, 2.8232765]\n",
      "epoch=84_train_batch=52, total_loss=22.05493927001953, pred_loss=[0.14107801, 5.474922, 4.0280447]\n",
      "epoch=84_train_batch=53, total_loss=25.531902313232422, pred_loss=[0.21170719, 2.5900438, 10.319403]\n",
      "epoch=84_train_batch=54, total_loss=32.38235092163086, pred_loss=[0.22445022, 12.546211, 7.2010794]\n",
      "epoch=84_train_batch=55, total_loss=20.535099029541016, pred_loss=[1.7903452, 4.081656, 2.2525768]\n",
      "epoch=84_train_batch=56, total_loss=28.564754486083984, pred_loss=[0.36932227, 4.595455, 11.189441]\n",
      "epoch=84_train_batch=57, total_loss=21.913942337036133, pred_loss=[0.26112074, 5.4475484, 3.7946923]\n",
      "epoch=84_train_batch=58, total_loss=20.507339477539062, pred_loss=[0.97750527, 1.9139252, 5.2052546]\n",
      "epoch=84_train_batch=59, total_loss=25.077898025512695, pred_loss=[0.1529328, 9.825054, 2.689212]\n",
      "epoch=84_train_batch=60, total_loss=22.68263053894043, pred_loss=[2.642685, 1.7441901, 5.8850756]\n",
      "epoch=84_train_batch=61, total_loss=16.291807174682617, pred_loss=[0.637736, 0.93531275, 2.30799]\n",
      "epoch=84_train_batch=62, total_loss=21.553882598876953, pred_loss=[0.5536823, 1.7939163, 6.795436]\n",
      "epoch=84_train_batch=63, total_loss=33.763702392578125, pred_loss=[1.630972, 7.6096067, 12.112263]\n",
      "epoch=84_train_batch=64, total_loss=16.01035499572754, pred_loss=[1.2695874, 1.8175615, 0.51240927]\n",
      "epoch=84_train_batch=65, total_loss=24.75779914855957, pred_loss=[4.240361, 5.463065, 2.6436794]\n",
      "epoch=84_train_batch=66, total_loss=30.605817794799805, pred_loss=[0.051317617, 10.299713, 7.844265]\n",
      "epoch=84_train_batch=67, total_loss=16.473196029663086, pred_loss=[0.91048217, 2.0596738, 1.092715]\n",
      "epoch=84_train_batch=68, total_loss=22.096649169921875, pred_loss=[0.36719978, 3.513172, 5.8061113]\n",
      "epoch=84_train_batch=69, total_loss=18.031618118286133, pred_loss=[1.3604474, 1.2378111, 3.0233085]\n",
      "epoch=84_train_batch=70, total_loss=22.7044734954834, pred_loss=[1.3638107, 5.048139, 3.8826072]\n",
      "epoch=84_train_batch=71, total_loss=23.576644897460938, pred_loss=[5.046624, 1.624519, 4.4956894]\n",
      "epoch=84_train_batch=72, total_loss=17.24222183227539, pred_loss=[0.8180867, 2.4323735, 1.582038]\n",
      "epoch=84_train_batch=73, total_loss=17.0538330078125, pred_loss=[1.1919427, 1.7412968, 1.710932]\n",
      "epoch=84_train_batch=74, total_loss=21.44165802001953, pred_loss=[1.8162594, 2.9720492, 4.2437353]\n",
      "epoch=84_train_batch=75, total_loss=21.391578674316406, pred_loss=[0.57839715, 1.3926692, 7.0109606]\n",
      "epoch=84_train_batch=76, total_loss=35.655487060546875, pred_loss=[3.6919672, 12.073298, 7.480738]\n",
      "epoch=84_train_batch=77, total_loss=16.667139053344727, pred_loss=[1.5348809, 1.5051265, 1.2176905]\n",
      "epoch=84_train_batch=78, total_loss=28.078895568847656, pred_loss=[1.7756612, 5.501563, 8.392288]\n",
      "epoch=84_train_batch=79, total_loss=21.43317413330078, pred_loss=[0.19125232, 2.737852, 6.094783]\n",
      "epoch=84_train_batch=80, total_loss=21.23102569580078, pred_loss=[3.9815238, 0.691677, 4.148655]\n",
      "epoch=84_train_batch=81, total_loss=18.589563369750977, pred_loss=[0.45343062, 4.301153, 1.4259409]\n",
      "epoch=84_train_batch=82, total_loss=29.676834106445312, pred_loss=[0.49231976, 1.1103435, 15.665256]\n",
      "epoch=84_train_batch=83, total_loss=19.435758590698242, pred_loss=[3.0631866, 2.581604, 1.3821987]\n",
      "epoch=84_train_batch=84, total_loss=29.693777084350586, pred_loss=[4.7282553, 2.9213414, 9.635531]\n",
      "epoch=84_train_batch=85, total_loss=16.023834228515625, pred_loss=[0.770324, 0.94788563, 1.8971323]\n",
      "epoch=84_train_batch=86, total_loss=18.89661407470703, pred_loss=[2.7729957, 1.7311406, 1.9841207]\n",
      "epoch=84_train_batch=87, total_loss=14.362309455871582, pred_loss=[0.37641338, 0.7745909, 0.8030257]\n",
      "epoch=84_val_batch=0, total_val_loss=667.4625244140625, pred_val_loss[1.9287243, 70.855675, 582.2699]\n",
      "epoch=84_val_batch=1, total_val_loss=194.54974365234375, pred_val_loss[0.64336264, 110.54109, 70.95709]\n",
      "epoch=84_val_batch=2, total_val_loss=88.58016967773438, pred_val_loss[17.182568, 14.017415, 44.971992]\n",
      "epoch=84_val_batch=3, total_val_loss=126.42132568359375, pred_val_loss[1.0920726, 31.1806, 81.74045]\n",
      "epoch=84_val_batch=4, total_val_loss=86.71212768554688, pred_val_loss[4.723168, 32.59741, 36.983345]\n",
      "epoch=84_val_batch=5, total_val_loss=55.16355514526367, pred_val_loss[14.049938, 7.211322, 21.494093]\n",
      "epoch=84_val_batch=6, total_val_loss=201.40829467773438, pred_val_loss[20.846165, 6.667536, 161.48639]\n",
      "epoch=84_val_batch=7, total_val_loss=147.57716369628906, pred_val_loss[1.0299971, 67.63922, 66.49974]\n",
      "epoch=84_val_batch=8, total_val_loss=70.73602294921875, pred_val_loss[0.5572276, 39.376335, 18.394262]\n",
      "epoch=84_val_batch=9, total_val_loss=102.27049255371094, pred_val_loss[0.8075099, 58.810074, 30.244709]\n",
      "epoch=84_val_batch=10, total_val_loss=126.17974853515625, pred_val_loss[28.751461, 11.377849, 73.642235]\n",
      "epoch=84_val_batch=11, total_val_loss=158.95111083984375, pred_val_loss[15.322546, 54.249702, 76.97065]\n",
      "epoch=84_val_batch=12, total_val_loss=30.042285919189453, pred_val_loss[0.49485362, 7.620946, 9.518287]\n",
      "epoch=84_val_batch=13, total_val_loss=92.69807434082031, pred_val_loss[0.5796157, 38.080547, 41.629715]\n",
      "epoch=84_val_batch=14, total_val_loss=113.07603454589844, pred_val_loss[19.790298, 43.617844, 37.25969]\n",
      "epoch=84_val_batch=15, total_val_loss=75.25640869140625, pred_val_loss[24.31684, 2.380577, 36.150795]\n",
      "epoch=84_val_batch=16, total_val_loss=176.79234313964844, pred_val_loss[11.957134, 59.740112, 92.68689]\n",
      "epoch=84_val_batch=17, total_val_loss=145.97837829589844, pred_val_loss[18.397755, 12.58686, 102.58556]\n",
      "epoch=84_val_batch=18, total_val_loss=109.30401611328125, pred_val_loss[3.6497512, 23.249508, 69.99655]\n",
      "epoch=84, train: avg_loss=23.779645919799805, val: avg_val_loss=145.74522399902344\n",
      "Saved checkpoint for step 95: ./tf_ckpts/ckpt-94\n",
      "epoch=85_train_batch=0, total_loss=21.371837615966797, pred_loss=[0.9483294, 5.026798, 2.988512]\n",
      "epoch=85_train_batch=1, total_loss=42.91977310180664, pred_loss=[0.45953488, 6.7542005, 23.29786]\n",
      "epoch=85_train_batch=2, total_loss=17.057666778564453, pred_loss=[0.47920907, 2.6029024, 1.5674099]\n",
      "epoch=85_train_batch=3, total_loss=15.612162590026855, pred_loss=[1.1449548, 0.60406417, 1.4550529]\n",
      "epoch=85_train_batch=4, total_loss=19.116653442382812, pred_loss=[0.81333756, 1.9426302, 3.952651]\n",
      "epoch=85_train_batch=5, total_loss=17.086862564086914, pred_loss=[1.8320234, 2.6102057, 0.23667204]\n",
      "epoch=85_train_batch=6, total_loss=21.356233596801758, pred_loss=[0.7245325, 2.1118042, 6.1120048]\n",
      "epoch=85_train_batch=7, total_loss=18.945507049560547, pred_loss=[1.3517079, 3.050755, 2.135226]\n",
      "epoch=85_train_batch=8, total_loss=19.25689697265625, pred_loss=[0.9215095, 3.8877077, 2.0399513]\n",
      "epoch=85_train_batch=9, total_loss=30.230205535888672, pred_loss=[4.146711, 8.207492, 5.468402]\n",
      "epoch=85_train_batch=10, total_loss=19.360916137695312, pred_loss=[0.30342847, 3.3782504, 3.271861]\n",
      "epoch=85_train_batch=11, total_loss=17.001028060913086, pred_loss=[1.1041856, 1.8391039, 1.6504668]\n",
      "epoch=85_train_batch=12, total_loss=24.367717742919922, pred_loss=[0.582474, 6.8110266, 4.5669794]\n",
      "epoch=85_train_batch=13, total_loss=21.805585861206055, pred_loss=[0.49272043, 6.5191736, 2.386449]\n",
      "epoch=85_train_batch=14, total_loss=17.071094512939453, pred_loss=[1.3409559, 2.731158, 0.5916872]\n",
      "epoch=85_train_batch=15, total_loss=16.26128387451172, pred_loss=[0.29442188, 3.3733182, 0.18620035]\n",
      "epoch=85_train_batch=16, total_loss=17.2076473236084, pred_loss=[0.5823609, 1.4461265, 2.7717736]\n",
      "epoch=85_train_batch=17, total_loss=17.275012969970703, pred_loss=[2.472971, 0.81764096, 1.5769851]\n",
      "epoch=85_train_batch=18, total_loss=20.954116821289062, pred_loss=[4.812951, 1.2007875, 2.5329728]\n",
      "epoch=85_train_batch=19, total_loss=20.309003829956055, pred_loss=[0.7668427, 4.1510906, 2.9835806]\n",
      "epoch=85_train_batch=20, total_loss=17.10988998413086, pred_loss=[1.1340089, 2.0867717, 1.4815099]\n",
      "epoch=85_train_batch=21, total_loss=24.551633834838867, pred_loss=[1.2969084, 0.9527549, 9.894267]\n",
      "epoch=85_train_batch=22, total_loss=15.27605152130127, pred_loss=[1.4794295, 0.9657593, 0.42308122]\n",
      "epoch=85_train_batch=23, total_loss=18.52325439453125, pred_loss=[1.1826987, 2.3171456, 2.6155987]\n",
      "epoch=85_train_batch=24, total_loss=23.00100326538086, pred_loss=[0.7914387, 1.1267755, 8.67497]\n",
      "epoch=85_train_batch=25, total_loss=16.132051467895508, pred_loss=[0.20451048, 2.6961887, 0.8235838]\n",
      "epoch=85_train_batch=26, total_loss=19.178173065185547, pred_loss=[3.5644987, 2.4695358, 0.73646027]\n",
      "epoch=85_train_batch=27, total_loss=17.820009231567383, pred_loss=[2.327792, 2.0634754, 1.021155]\n",
      "epoch=85_train_batch=28, total_loss=21.213520050048828, pred_loss=[0.04677064, 3.0443325, 5.714979]\n",
      "epoch=85_train_batch=29, total_loss=20.201013565063477, pred_loss=[0.21084419, 2.2187037, 5.3641686]\n",
      "epoch=85_train_batch=30, total_loss=15.500629425048828, pred_loss=[1.38053, 1.2374547, 0.4755129]\n",
      "epoch=85_train_batch=31, total_loss=24.578893661499023, pred_loss=[4.7650433, 2.5072908, 4.899663]\n",
      "epoch=85_train_batch=32, total_loss=24.667482376098633, pred_loss=[0.42167887, 6.5945063, 5.244629]\n",
      "epoch=85_train_batch=33, total_loss=15.612588882446289, pred_loss=[0.67084956, 0.42540228, 2.1098888]\n",
      "epoch=85_train_batch=34, total_loss=24.378047943115234, pred_loss=[0.25120577, 4.864497, 6.85611]\n",
      "epoch=85_train_batch=35, total_loss=24.042369842529297, pred_loss=[0.45654592, 1.9613361, 9.218445]\n",
      "epoch=85_train_batch=36, total_loss=19.455684661865234, pred_loss=[1.2676885, 3.2679005, 2.5142431]\n",
      "epoch=85_train_batch=37, total_loss=16.49338150024414, pred_loss=[0.40787104, 1.2645032, 2.4153574]\n",
      "epoch=85_train_batch=38, total_loss=25.35411834716797, pred_loss=[3.8822434, 3.197875, 5.8685675]\n",
      "epoch=85_train_batch=39, total_loss=20.302030563354492, pred_loss=[0.80825704, 2.4784913, 4.609999]\n",
      "epoch=85_train_batch=40, total_loss=22.940719604492188, pred_loss=[1.3312263, 0.7989085, 8.405441]\n",
      "epoch=85_train_batch=41, total_loss=15.640317916870117, pred_loss=[0.58606935, 1.562613, 1.0866339]\n",
      "epoch=85_train_batch=42, total_loss=17.264989852905273, pred_loss=[1.094965, 2.3149433, 1.4502368]\n",
      "epoch=85_train_batch=43, total_loss=19.111499786376953, pred_loss=[0.68307483, 0.60208225, 5.421651]\n",
      "epoch=85_train_batch=44, total_loss=18.268463134765625, pred_loss=[2.9980028, 0.09369495, 2.772251]\n",
      "epoch=85_train_batch=45, total_loss=19.060089111328125, pred_loss=[0.97806764, 1.538168, 4.1395435]\n",
      "epoch=85_train_batch=46, total_loss=17.438125610351562, pred_loss=[1.1886833, 1.8025806, 2.0427673]\n",
      "epoch=85_train_batch=47, total_loss=16.59202766418457, pred_loss=[0.025706504, 2.480996, 1.6814579]\n",
      "epoch=85_train_batch=48, total_loss=17.830684661865234, pred_loss=[1.0126226, 3.4070961, 1.0073502]\n",
      "epoch=85_train_batch=49, total_loss=18.41726303100586, pred_loss=[2.941291, 0.8751746, 2.1974556]\n",
      "epoch=85_train_batch=50, total_loss=30.305160522460938, pred_loss=[0.2549763, 3.2773986, 14.369653]\n",
      "epoch=85_train_batch=51, total_loss=17.560508728027344, pred_loss=[1.5292397, 1.217625, 2.4107199]\n",
      "epoch=85_train_batch=52, total_loss=26.30552101135254, pred_loss=[0.7036892, 5.524892, 7.6742573]\n",
      "epoch=85_train_batch=53, total_loss=22.498334884643555, pred_loss=[2.2069106, 4.793036, 3.0959613]\n",
      "epoch=85_train_batch=54, total_loss=18.618350982666016, pred_loss=[1.0674222, 0.8403722, 4.308383]\n",
      "epoch=85_train_batch=55, total_loss=17.6168212890625, pred_loss=[2.3500323, 1.0078506, 1.8570209]\n",
      "epoch=85_train_batch=56, total_loss=21.48738670349121, pred_loss=[1.2063372, 5.178842, 2.7005794]\n",
      "epoch=85_train_batch=57, total_loss=19.420360565185547, pred_loss=[2.242357, 0.39600214, 4.3807364]\n",
      "epoch=85_train_batch=58, total_loss=16.752872467041016, pred_loss=[0.62388, 2.847186, 0.88097507]\n",
      "epoch=85_train_batch=59, total_loss=17.97821044921875, pred_loss=[2.0558453, 2.7966073, 0.72537345]\n",
      "epoch=85_train_batch=60, total_loss=20.20694351196289, pred_loss=[1.0796502, 1.1090899, 5.618277]\n",
      "epoch=85_train_batch=61, total_loss=14.581171035766602, pred_loss=[0.7320118, 0.6531122, 0.7965888]\n",
      "epoch=85_train_batch=62, total_loss=20.782184600830078, pred_loss=[0.6199883, 4.2110615, 3.5521364]\n",
      "epoch=85_train_batch=63, total_loss=17.458126068115234, pred_loss=[0.36556223, 2.0323431, 2.6616771]\n",
      "epoch=85_train_batch=64, total_loss=16.98715591430664, pred_loss=[0.44024503, 1.0159364, 3.1328778]\n",
      "epoch=85_train_batch=65, total_loss=17.327821731567383, pred_loss=[0.997088, 2.4793968, 1.4536947]\n",
      "epoch=85_train_batch=66, total_loss=15.50112533569336, pred_loss=[0.9258935, 0.83748233, 1.3405728]\n",
      "epoch=85_train_batch=67, total_loss=18.343162536621094, pred_loss=[1.2433846, 3.5892909, 1.1137861]\n",
      "epoch=85_train_batch=68, total_loss=15.717962265014648, pred_loss=[0.49521795, 2.0310562, 0.7954607]\n",
      "epoch=85_train_batch=69, total_loss=16.023935317993164, pred_loss=[1.903469, 0.5130683, 1.2116524]\n",
      "epoch=85_train_batch=70, total_loss=16.812179565429688, pred_loss=[0.7943214, 2.2383943, 1.3842018]\n",
      "epoch=85_train_batch=71, total_loss=15.879261016845703, pred_loss=[0.119916745, 2.6575904, 0.70697254]\n",
      "epoch=85_train_batch=72, total_loss=15.198379516601562, pred_loss=[0.729429, 1.1204693, 0.9541887]\n",
      "epoch=85_train_batch=73, total_loss=19.39735221862793, pred_loss=[0.84107906, 3.906902, 2.2555666]\n",
      "epoch=85_train_batch=74, total_loss=15.841285705566406, pred_loss=[0.37221932, 2.079378, 0.9963746]\n",
      "epoch=85_train_batch=75, total_loss=16.560405731201172, pred_loss=[0.34174174, 2.424606, 1.4012306]\n",
      "epoch=85_train_batch=76, total_loss=18.866785049438477, pred_loss=[0.30065063, 2.897177, 3.276624]\n",
      "epoch=85_train_batch=77, total_loss=17.26357650756836, pred_loss=[0.3237396, 2.6766357, 1.8713698]\n",
      "epoch=85_train_batch=78, total_loss=21.35141372680664, pred_loss=[1.7253399, 4.2388372, 2.9958985]\n",
      "epoch=85_train_batch=79, total_loss=20.113327026367188, pred_loss=[0.17241034, 2.01343, 5.5366826]\n",
      "epoch=85_train_batch=80, total_loss=15.243509292602539, pred_loss=[1.1904285, 0.78765273, 0.8751515]\n",
      "epoch=85_train_batch=81, total_loss=16.920185089111328, pred_loss=[0.5718822, 1.8723619, 2.0862045]\n",
      "epoch=85_train_batch=82, total_loss=16.30398941040039, pred_loss=[0.42171004, 0.61927426, 2.8738213]\n",
      "epoch=85_train_batch=83, total_loss=29.063020706176758, pred_loss=[0.014609615, 2.4075441, 14.252243]\n",
      "epoch=85_train_batch=84, total_loss=15.015300750732422, pred_loss=[0.26282835, 2.0140774, 0.35036296]\n",
      "epoch=85_train_batch=85, total_loss=14.413436889648438, pred_loss=[0.2826019, 1.3676488, 0.37575683]\n",
      "epoch=85_train_batch=86, total_loss=16.888565063476562, pred_loss=[0.4225291, 1.7174033, 2.3618116]\n",
      "epoch=85_train_batch=87, total_loss=13.804739952087402, pred_loss=[0.101753265, 0.9585767, 0.3582095]\n",
      "epoch=85_val_batch=0, total_val_loss=657.7984619140625, pred_val_loss[0.33088398, 66.274536, 578.8075]\n",
      "epoch=85_val_batch=1, total_val_loss=194.4291229248047, pred_val_loss[0.13715246, 105.37634, 76.53005]\n",
      "epoch=85_val_batch=2, total_val_loss=92.52681732177734, pred_val_loss[13.891051, 14.509078, 51.74111]\n",
      "epoch=85_val_batch=3, total_val_loss=126.15936279296875, pred_val_loss[2.294293, 27.039558, 84.43994]\n",
      "epoch=85_val_batch=4, total_val_loss=83.97630310058594, pred_val_loss[5.565124, 36.358494, 29.667114]\n",
      "epoch=85_val_batch=5, total_val_loss=58.1063232421875, pred_val_loss[11.22695, 8.084633, 26.409168]\n",
      "epoch=85_val_batch=6, total_val_loss=215.14364624023438, pred_val_loss[18.369944, 5.1073604, 179.28076]\n",
      "epoch=85_val_batch=7, total_val_loss=145.54661560058594, pred_val_loss[0.5713721, 55.99607, 76.5936]\n",
      "epoch=85_val_batch=8, total_val_loss=53.21430969238281, pred_val_loss[0.3685039, 29.136683, 11.323551]\n",
      "epoch=85_val_batch=9, total_val_loss=112.65068817138672, pred_val_loss[2.772511, 53.08967, 44.402935]\n",
      "epoch=85_val_batch=10, total_val_loss=141.26023864746094, pred_val_loss[41.16725, 7.4753838, 80.23203]\n",
      "epoch=85_val_batch=11, total_val_loss=165.40013122558594, pred_val_loss[17.373812, 51.12418, 84.516556]\n",
      "epoch=85_val_batch=12, total_val_loss=27.680599212646484, pred_val_loss[0.5978232, 6.651992, 8.04521]\n",
      "epoch=85_val_batch=13, total_val_loss=87.11161041259766, pred_val_loss[0.38768998, 30.107525, 44.23082]\n",
      "epoch=85_val_batch=14, total_val_loss=95.84889221191406, pred_val_loss[6.9545064, 38.69066, 37.818153]\n",
      "epoch=85_val_batch=15, total_val_loss=81.75900268554688, pred_val_loss[28.500994, 0.5814379, 40.290993]\n",
      "epoch=85_val_batch=16, total_val_loss=201.0421905517578, pred_val_loss[11.98377, 65.35198, 111.32086]\n",
      "epoch=85_val_batch=17, total_val_loss=156.8360595703125, pred_val_loss[10.442593, 12.264368, 121.74353]\n",
      "epoch=85_val_batch=18, total_val_loss=116.94493103027344, pred_val_loss[7.23241, 27.163757, 70.163185]\n",
      "epoch=85, train: avg_loss=19.2833309173584, val: avg_val_loss=148.0755615234375\n",
      "Saved checkpoint for step 96: ./tf_ckpts/ckpt-95\n",
      "epoch=86_train_batch=0, total_loss=16.614797592163086, pred_loss=[0.12661351, 0.5247235, 3.5778878]\n",
      "epoch=86_train_batch=1, total_loss=14.413236618041992, pred_loss=[0.35455754, 0.90729237, 0.7664493]\n",
      "epoch=86_train_batch=2, total_loss=15.043883323669434, pred_loss=[1.2206628, 1.1588786, 0.28005117]\n",
      "epoch=86_train_batch=3, total_loss=14.180146217346191, pred_loss=[0.8537458, 0.8310871, 0.11167269]\n",
      "epoch=86_train_batch=4, total_loss=18.093605041503906, pred_loss=[0.2607344, 1.2691938, 4.180685]\n",
      "epoch=86_train_batch=5, total_loss=14.62935733795166, pred_loss=[0.30509642, 1.7609019, 0.18101889]\n",
      "epoch=86_train_batch=6, total_loss=15.530890464782715, pred_loss=[0.15528958, 1.0595815, 1.9343436]\n",
      "epoch=86_train_batch=7, total_loss=13.709212303161621, pred_loss=[0.3629474, 0.6452225, 0.32003903]\n",
      "epoch=86_train_batch=8, total_loss=15.625595092773438, pred_loss=[1.669733, 0.7726051, 0.80293083]\n",
      "epoch=86_train_batch=9, total_loss=19.90542221069336, pred_loss=[0.7414178, 2.2364702, 4.5478296]\n",
      "epoch=86_train_batch=10, total_loss=14.652559280395508, pred_loss=[0.24873188, 1.3764708, 0.64828646]\n",
      "epoch=86_train_batch=11, total_loss=18.149391174316406, pred_loss=[0.011934662, 5.0089054, 0.75012374]\n",
      "epoch=86_train_batch=12, total_loss=14.288113594055176, pred_loss=[0.99878484, 0.5029094, 0.4086611]\n",
      "epoch=86_train_batch=13, total_loss=14.26723861694336, pred_loss=[0.16252586, 1.2605388, 0.46702078]\n",
      "epoch=86_train_batch=14, total_loss=16.482656478881836, pred_loss=[0.15288575, 0.98995054, 2.9632225]\n",
      "epoch=86_train_batch=15, total_loss=21.057857513427734, pred_loss=[0.30466813, 1.5728769, 6.804243]\n",
      "epoch=86_train_batch=16, total_loss=18.425888061523438, pred_loss=[0.12618774, 2.0248075, 3.8993323]\n",
      "epoch=86_train_batch=17, total_loss=15.3458833694458, pred_loss=[1.0652593, 0.33789945, 1.5676652]\n",
      "epoch=86_train_batch=18, total_loss=17.394699096679688, pred_loss=[0.3253394, 2.6806042, 2.014203]\n",
      "epoch=86_train_batch=19, total_loss=15.151396751403809, pred_loss=[0.27880457, 1.5846685, 0.91387635]\n",
      "epoch=86_train_batch=20, total_loss=20.765762329101562, pred_loss=[0.54659283, 1.3728096, 6.4728246]\n",
      "epoch=86_train_batch=21, total_loss=16.312454223632812, pred_loss=[1.0092646, 0.40952194, 2.5206552]\n",
      "epoch=86_train_batch=22, total_loss=14.306292533874512, pred_loss=[0.33278662, 0.7047949, 0.89624727]\n",
      "epoch=86_train_batch=23, total_loss=15.074796676635742, pred_loss=[1.2831018, 0.62686396, 0.7929117]\n",
      "epoch=86_train_batch=24, total_loss=13.958534240722656, pred_loss=[0.34580114, 0.67901933, 0.5623506]\n",
      "epoch=86_train_batch=25, total_loss=19.323562622070312, pred_loss=[0.23442039, 1.2351326, 5.483202]\n",
      "epoch=86_train_batch=26, total_loss=16.575183868408203, pred_loss=[0.31509504, 1.215838, 2.6739953]\n",
      "epoch=86_train_batch=27, total_loss=13.869706153869629, pred_loss=[0.46334955, 0.3560004, 0.6806704]\n",
      "epoch=86_train_batch=28, total_loss=14.706087112426758, pred_loss=[0.66270065, 0.77597296, 0.8983152]\n",
      "epoch=86_train_batch=29, total_loss=15.93040657043457, pred_loss=[0.23090512, 1.4894601, 1.8415425]\n",
      "epoch=86_train_batch=30, total_loss=19.40938377380371, pred_loss=[0.34639594, 2.9284012, 3.7666893]\n",
      "epoch=86_train_batch=31, total_loss=14.175310134887695, pred_loss=[0.074402146, 1.1957676, 0.53784674]\n",
      "epoch=86_train_batch=32, total_loss=18.683120727539062, pred_loss=[0.22717106, 1.3445443, 4.74472]\n",
      "epoch=86_train_batch=33, total_loss=15.727422714233398, pred_loss=[0.023933345, 1.7529361, 1.5844877]\n",
      "epoch=86_train_batch=34, total_loss=16.34296989440918, pred_loss=[1.5265832, 0.86561793, 1.5853297]\n",
      "epoch=86_train_batch=35, total_loss=17.65744400024414, pred_loss=[0.89399415, 0.9688116, 3.429852]\n",
      "epoch=86_train_batch=36, total_loss=15.384727478027344, pred_loss=[0.66531837, 1.0226302, 1.3326585]\n",
      "epoch=86_train_batch=37, total_loss=15.41843318939209, pred_loss=[0.5537038, 0.93287385, 1.5684055]\n",
      "epoch=86_train_batch=38, total_loss=16.84282112121582, pred_loss=[0.2797265, 0.42846888, 3.7718534]\n",
      "epoch=86_train_batch=39, total_loss=15.643257141113281, pred_loss=[0.7681788, 0.3193238, 2.1936612]\n",
      "epoch=86_train_batch=40, total_loss=14.821959495544434, pred_loss=[0.5081951, 1.2452835, 0.7070965]\n",
      "epoch=86_train_batch=41, total_loss=15.260112762451172, pred_loss=[1.1967988, 1.189753, 0.51287794]\n",
      "epoch=86_train_batch=42, total_loss=14.046611785888672, pred_loss=[0.6297578, 0.82218933, 0.23467848]\n",
      "epoch=86_train_batch=43, total_loss=14.425435066223145, pred_loss=[0.3347199, 0.93684196, 0.7945833]\n",
      "epoch=86_train_batch=44, total_loss=18.423723220825195, pred_loss=[0.3326518, 1.9649895, 3.7675018]\n",
      "epoch=86_train_batch=45, total_loss=14.788657188415527, pred_loss=[0.11868145, 0.28606987, 2.026037]\n",
      "epoch=86_train_batch=46, total_loss=17.28229331970215, pred_loss=[0.06055168, 3.065268, 1.7993202]\n",
      "epoch=86_train_batch=47, total_loss=17.957857131958008, pred_loss=[0.7181866, 0.87253356, 4.0106936]\n",
      "epoch=86_train_batch=48, total_loss=15.77917766571045, pred_loss=[1.5563196, 0.7833713, 1.0837569]\n",
      "epoch=86_train_batch=49, total_loss=15.753538131713867, pred_loss=[0.20410039, 1.0432836, 2.1511452]\n",
      "epoch=86_train_batch=50, total_loss=15.010736465454102, pred_loss=[0.36333603, 1.7292888, 0.5638114]\n",
      "epoch=86_train_batch=51, total_loss=16.629446029663086, pred_loss=[0.4934918, 2.196929, 1.5854338]\n",
      "epoch=86_train_batch=52, total_loss=16.929515838623047, pred_loss=[3.0256472, 0.35491794, 1.1960647]\n",
      "epoch=86_train_batch=53, total_loss=16.87833595275879, pred_loss=[1.016879, 1.7565198, 1.7527921]\n",
      "epoch=86_train_batch=54, total_loss=14.784564971923828, pred_loss=[0.4816221, 0.5031525, 1.44834]\n",
      "epoch=86_train_batch=55, total_loss=13.969727516174316, pred_loss=[0.13025084, 0.11815589, 1.3705457]\n",
      "epoch=86_train_batch=56, total_loss=14.477286338806152, pred_loss=[0.6745783, 1.1134126, 0.33918142]\n",
      "epoch=86_train_batch=57, total_loss=15.171928405761719, pred_loss=[0.16311382, 0.9100354, 1.7493165]\n",
      "epoch=86_train_batch=58, total_loss=15.409446716308594, pred_loss=[0.16873515, 1.2589295, 1.6329675]\n",
      "epoch=86_train_batch=59, total_loss=14.36931037902832, pred_loss=[0.80937344, 0.5894059, 0.62236595]\n",
      "epoch=86_train_batch=60, total_loss=22.22929573059082, pred_loss=[0.2084709, 3.124262, 6.5490513]\n",
      "epoch=86_train_batch=61, total_loss=18.279403686523438, pred_loss=[0.29811466, 0.24511859, 5.3893175]\n",
      "epoch=86_train_batch=62, total_loss=15.830534934997559, pred_loss=[0.32211274, 0.86390764, 2.298324]\n",
      "epoch=86_train_batch=63, total_loss=14.99921989440918, pred_loss=[0.07964572, 1.2796925, 1.294347]\n",
      "epoch=86_train_batch=64, total_loss=14.182522773742676, pred_loss=[0.3025547, 0.42367616, 1.1114146]\n",
      "epoch=86_train_batch=65, total_loss=14.69454574584961, pred_loss=[0.0740583, 1.3404438, 0.9358276]\n",
      "epoch=86_train_batch=66, total_loss=15.516560554504395, pred_loss=[1.2883441, 0.6139868, 1.270685]\n",
      "epoch=86_train_batch=67, total_loss=14.794733047485352, pred_loss=[0.27832338, 1.4154637, 0.75805956]\n",
      "epoch=86_train_batch=68, total_loss=17.229469299316406, pred_loss=[0.15613815, 1.981663, 2.7494538]\n",
      "epoch=86_train_batch=69, total_loss=15.06008529663086, pred_loss=[0.0931975, 1.3571, 1.2682486]\n",
      "epoch=86_train_batch=70, total_loss=14.800044059753418, pred_loss=[0.5417297, 0.856752, 1.0607069]\n",
      "epoch=86_train_batch=71, total_loss=15.516401290893555, pred_loss=[0.3412971, 1.2509276, 1.5840024]\n",
      "epoch=86_train_batch=72, total_loss=13.824054718017578, pred_loss=[0.33558536, 0.67302924, 0.47595477]\n",
      "epoch=86_train_batch=73, total_loss=20.832183837890625, pred_loss=[0.1334852, 1.9914979, 6.3684044]\n",
      "epoch=86_train_batch=74, total_loss=15.648826599121094, pred_loss=[0.26336622, 0.9884442, 2.0588982]\n",
      "epoch=86_train_batch=75, total_loss=14.304826736450195, pred_loss=[0.3936665, 0.7052073, 0.86852044]\n",
      "epoch=86_train_batch=76, total_loss=15.206439018249512, pred_loss=[0.53956234, 2.0160809, 0.31405574]\n",
      "epoch=86_train_batch=77, total_loss=16.52395248413086, pred_loss=[0.78549665, 1.2415047, 2.160912]\n",
      "epoch=86_train_batch=78, total_loss=20.899105072021484, pred_loss=[0.15098184, 0.89885986, 7.5139284]\n",
      "epoch=86_train_batch=79, total_loss=16.545631408691406, pred_loss=[0.3028277, 1.3231642, 2.5850139]\n",
      "epoch=86_train_batch=80, total_loss=19.183029174804688, pred_loss=[0.16061841, 3.0914717, 3.597025]\n",
      "epoch=86_train_batch=81, total_loss=19.94629669189453, pred_loss=[0.24521244, 2.181116, 5.1867633]\n",
      "epoch=86_train_batch=82, total_loss=15.749919891357422, pred_loss=[0.73541605, 1.5846704, 1.097337]\n",
      "epoch=86_train_batch=83, total_loss=19.12816619873047, pred_loss=[0.19679487, 3.5419216, 3.0576491]\n",
      "epoch=86_train_batch=84, total_loss=13.693852424621582, pred_loss=[0.18513688, 0.7123545, 0.46526566]\n",
      "epoch=86_train_batch=85, total_loss=13.321090698242188, pred_loss=[0.3492762, 0.42183822, 0.21958101]\n",
      "epoch=86_train_batch=86, total_loss=14.838525772094727, pred_loss=[0.40458292, 1.7583255, 0.3459303]\n",
      "epoch=86_train_batch=87, total_loss=13.560820579528809, pred_loss=[0.33855492, 0.026185744, 0.86710596]\n",
      "epoch=86_val_batch=0, total_val_loss=764.5322875976562, pred_val_loss[0.39641395, 62.475323, 689.3323]\n",
      "epoch=86_val_batch=1, total_val_loss=199.86489868164062, pred_val_loss[0.061453406, 105.15102, 82.32419]\n",
      "epoch=86_val_batch=2, total_val_loss=86.97504425048828, pred_val_loss[13.473135, 14.599813, 46.573837]\n",
      "epoch=86_val_batch=3, total_val_loss=130.0596923828125, pred_val_loss[3.4137115, 26.58585, 87.73189]\n",
      "epoch=86_val_batch=4, total_val_loss=93.87303924560547, pred_val_loss[5.315558, 35.444916, 40.784306]\n",
      "epoch=86_val_batch=5, total_val_loss=60.37659454345703, pred_val_loss[12.234716, 10.859783, 24.953842]\n",
      "epoch=86_val_batch=6, total_val_loss=232.94781494140625, pred_val_loss[17.752262, 5.3366976, 197.53061]\n",
      "epoch=86_val_batch=7, total_val_loss=143.63211059570312, pred_val_loss[0.654549, 59.142807, 71.506516]\n",
      "epoch=86_val_batch=8, total_val_loss=54.28717803955078, pred_val_loss[0.21591248, 29.974731, 11.768282]\n",
      "epoch=86_val_batch=9, total_val_loss=110.13269805908203, pred_val_loss[3.9413943, 53.945305, 39.917744]\n",
      "epoch=86_val_batch=10, total_val_loss=144.72412109375, pred_val_loss[39.77976, 6.499408, 86.116714]\n",
      "epoch=86_val_batch=11, total_val_loss=163.04525756835938, pred_val_loss[19.946468, 52.375885, 78.39466]\n",
      "epoch=86_val_batch=12, total_val_loss=28.673828125, pred_val_loss[0.9842305, 7.4528522, 7.9084916]\n",
      "epoch=86_val_batch=13, total_val_loss=87.4657974243164, pred_val_loss[0.24402133, 34.797703, 40.095818]\n",
      "epoch=86_val_batch=14, total_val_loss=107.12873077392578, pred_val_loss[11.453835, 40.569893, 42.77675]\n",
      "epoch=86_val_batch=15, total_val_loss=88.07843780517578, pred_val_loss[30.747145, 1.2528282, 43.750206]\n",
      "epoch=86_val_batch=16, total_val_loss=203.01358032226562, pred_val_loss[12.207705, 66.859634, 111.618]\n",
      "epoch=86_val_batch=17, total_val_loss=172.20758056640625, pred_val_loss[12.023897, 14.071112, 133.78432]\n",
      "epoch=86_val_batch=18, total_val_loss=137.85427856445312, pred_val_loss[9.153807, 27.688593, 88.683624]\n",
      "epoch=86, train: avg_loss=16.10884666442871, val: avg_val_loss=158.36172485351562\n",
      "Saved checkpoint for step 97: ./tf_ckpts/ckpt-96\n",
      "epoch=87_train_batch=0, total_loss=19.642433166503906, pred_loss=[0.2748785, 1.7321234, 5.3071775]\n",
      "epoch=87_train_batch=1, total_loss=14.081961631774902, pred_loss=[0.22908117, 0.78956413, 0.73578584]\n",
      "epoch=87_train_batch=2, total_loss=14.14192008972168, pred_loss=[0.7915616, 0.81113243, 0.21242273]\n",
      "epoch=87_train_batch=3, total_loss=13.289690971374512, pred_loss=[0.5460452, 0.26650643, 0.15107042]\n",
      "epoch=87_train_batch=4, total_loss=13.876076698303223, pred_loss=[0.1515937, 0.6901398, 0.7090117]\n",
      "epoch=87_train_batch=5, total_loss=14.524325370788574, pred_loss=[0.22370344, 0.9281309, 1.0478944]\n",
      "epoch=87_train_batch=6, total_loss=18.384693145751953, pred_loss=[0.30183986, 2.3599615, 3.3990307]\n",
      "epoch=87_train_batch=7, total_loss=18.733409881591797, pred_loss=[0.70064247, 1.917469, 3.792172]\n",
      "epoch=87_train_batch=8, total_loss=14.441566467285156, pred_loss=[0.07654908, 0.80244553, 1.2401961]\n",
      "epoch=87_train_batch=9, total_loss=14.31229305267334, pred_loss=[0.25452244, 0.5082288, 1.2279096]\n",
      "epoch=87_train_batch=10, total_loss=14.075592041015625, pred_loss=[0.21304232, 1.4340085, 0.107652776]\n",
      "epoch=87_train_batch=11, total_loss=14.584768295288086, pred_loss=[0.42530432, 0.51799333, 1.3213223]\n",
      "epoch=87_train_batch=12, total_loss=13.963105201721191, pred_loss=[0.22301672, 0.39097613, 1.0297105]\n",
      "epoch=87_train_batch=13, total_loss=13.769112586975098, pred_loss=[0.26061547, 0.53656507, 0.6532759]\n",
      "epoch=87_train_batch=14, total_loss=13.953022956848145, pred_loss=[0.30741817, 0.7117613, 0.61593914]\n",
      "epoch=87_train_batch=15, total_loss=14.03559684753418, pred_loss=[0.54150563, 0.60324156, 0.5736976]\n",
      "epoch=87_train_batch=16, total_loss=13.777998924255371, pred_loss=[0.48466557, 0.57980627, 0.39713115]\n",
      "epoch=87_train_batch=17, total_loss=16.984050750732422, pred_loss=[0.32911292, 1.8255455, 2.5137734]\n",
      "epoch=87_train_batch=18, total_loss=14.480962753295898, pred_loss=[0.79963696, 0.8018568, 0.5646373]\n",
      "epoch=87_train_batch=19, total_loss=13.6701021194458, pred_loss=[0.5649012, 0.3625425, 0.4286213]\n",
      "epoch=87_train_batch=20, total_loss=16.083595275878906, pred_loss=[0.27327806, 1.1482693, 2.3488016]\n",
      "epoch=87_train_batch=21, total_loss=14.008366584777832, pred_loss=[0.2738078, 0.60552686, 0.8165703]\n",
      "epoch=87_train_batch=22, total_loss=14.109790802001953, pred_loss=[0.5110502, 0.7566605, 0.5303968]\n",
      "epoch=87_train_batch=23, total_loss=15.218250274658203, pred_loss=[0.18323109, 0.97011214, 1.7539967]\n",
      "epoch=87_train_batch=24, total_loss=14.696122169494629, pred_loss=[0.473659, 0.44913936, 1.4631906]\n",
      "epoch=87_train_batch=25, total_loss=14.655406951904297, pred_loss=[0.1480551, 0.9181487, 1.2798449]\n",
      "epoch=87_train_batch=26, total_loss=13.757150650024414, pred_loss=[0.09494025, 1.0416732, 0.31195366]\n",
      "epoch=87_train_batch=27, total_loss=14.272042274475098, pred_loss=[0.5716691, 0.3048111, 1.087755]\n",
      "epoch=87_train_batch=28, total_loss=19.110885620117188, pred_loss=[5.2067556, 0.77962404, 0.8174704]\n",
      "epoch=87_train_batch=29, total_loss=14.299449920654297, pred_loss=[0.15794446, 1.291368, 0.5438068]\n",
      "epoch=87_train_batch=30, total_loss=14.342578887939453, pred_loss=[0.13873546, 0.46716645, 1.4310343]\n",
      "epoch=87_train_batch=31, total_loss=15.2055025100708, pred_loss=[0.76003563, 0.711714, 1.4287841]\n",
      "epoch=87_train_batch=32, total_loss=14.319254875183105, pred_loss=[0.19441652, 1.3920263, 0.4285145]\n",
      "epoch=87_train_batch=33, total_loss=15.900185585021973, pred_loss=[0.23330393, 0.34178042, 3.0214674]\n",
      "epoch=87_train_batch=34, total_loss=14.213554382324219, pred_loss=[0.12773795, 1.1970534, 0.58578813]\n",
      "epoch=87_train_batch=35, total_loss=13.703075408935547, pred_loss=[0.51254165, 0.33883053, 0.549387]\n",
      "epoch=87_train_batch=36, total_loss=16.86813735961914, pred_loss=[0.45459557, 3.5475385, 0.564353]\n",
      "epoch=87_train_batch=37, total_loss=14.093090057373047, pred_loss=[0.07153256, 0.83540523, 0.88516784]\n",
      "epoch=87_train_batch=38, total_loss=16.18560028076172, pred_loss=[0.28112987, 1.2438431, 2.360309]\n",
      "epoch=87_train_batch=39, total_loss=15.87680721282959, pred_loss=[0.1155653, 2.150079, 1.3115146]\n",
      "epoch=87_train_batch=40, total_loss=15.231071472167969, pred_loss=[0.9728594, 1.2396533, 0.71959174]\n",
      "epoch=87_train_batch=41, total_loss=13.745447158813477, pred_loss=[0.33799672, 0.5657765, 0.54334587]\n",
      "epoch=87_train_batch=42, total_loss=14.121285438537598, pred_loss=[0.13713676, 0.3368845, 1.3495852]\n",
      "epoch=87_train_batch=43, total_loss=15.63237476348877, pred_loss=[0.2183516, 2.0697072, 1.0472932]\n",
      "epoch=87_train_batch=44, total_loss=14.276094436645508, pred_loss=[0.15565047, 0.8123204, 1.0117617]\n",
      "epoch=87_train_batch=45, total_loss=15.609579086303711, pred_loss=[0.049090154, 2.0586753, 1.206117]\n",
      "epoch=87_train_batch=46, total_loss=13.832494735717773, pred_loss=[0.23285252, 1.120221, 0.1844076]\n",
      "epoch=87_train_batch=47, total_loss=13.980560302734375, pred_loss=[0.39945713, 1.1049845, 0.18180479]\n",
      "epoch=87_train_batch=48, total_loss=14.372241020202637, pred_loss=[0.1968138, 0.5113678, 1.3704623]\n",
      "epoch=87_train_batch=49, total_loss=14.502034187316895, pred_loss=[0.13296819, 1.158604, 0.9175884]\n",
      "epoch=87_train_batch=50, total_loss=20.146581649780273, pred_loss=[0.055880494, 2.0679607, 5.730599]\n",
      "epoch=87_train_batch=51, total_loss=13.787903785705566, pred_loss=[0.25990704, 0.97810096, 0.25849083]\n",
      "epoch=87_train_batch=52, total_loss=13.461094856262207, pred_loss=[0.3000977, 0.37788343, 0.49245363]\n",
      "epoch=87_train_batch=53, total_loss=13.720513343811035, pred_loss=[0.20457143, 0.8743799, 0.35165188]\n",
      "epoch=87_train_batch=54, total_loss=14.099946022033691, pred_loss=[0.53609204, 0.7951944, 0.47951025]\n",
      "epoch=87_train_batch=55, total_loss=15.42361068725586, pred_loss=[0.20156936, 0.9215938, 2.0120697]\n",
      "epoch=87_train_batch=56, total_loss=13.386229515075684, pred_loss=[0.4868725, 0.52763665, 0.08412011]\n",
      "epoch=87_train_batch=57, total_loss=14.508687973022461, pred_loss=[0.35958505, 0.9517534, 0.9105296]\n",
      "epoch=87_train_batch=58, total_loss=14.297656059265137, pred_loss=[0.20318389, 1.2219056, 0.586529]\n",
      "epoch=87_train_batch=59, total_loss=14.903722763061523, pred_loss=[0.42291135, 0.93816364, 1.2573911]\n",
      "epoch=87_train_batch=60, total_loss=15.037726402282715, pred_loss=[0.37142625, 0.82949924, 1.5523264]\n",
      "epoch=87_train_batch=61, total_loss=14.064702033996582, pred_loss=[0.09464483, 1.1890118, 0.49736288]\n",
      "epoch=87_train_batch=62, total_loss=15.056999206542969, pred_loss=[1.7193336, 0.3349759, 0.71980107]\n",
      "epoch=87_train_batch=63, total_loss=17.125822067260742, pred_loss=[3.9094896, 0.5383794, 0.39587048]\n",
      "epoch=87_train_batch=64, total_loss=13.527586936950684, pred_loss=[0.020669945, 0.7648041, 0.4608209]\n",
      "epoch=87_train_batch=65, total_loss=15.946680068969727, pred_loss=[0.10348038, 1.3541874, 2.2084718]\n",
      "epoch=87_train_batch=66, total_loss=13.883779525756836, pred_loss=[0.2854691, 0.9230079, 0.39548317]\n",
      "epoch=87_train_batch=67, total_loss=16.48273277282715, pred_loss=[0.0060518216, 1.6436588, 2.5539083]\n",
      "epoch=87_train_batch=68, total_loss=15.878823280334473, pred_loss=[1.4174827, 0.82562363, 1.3572994]\n",
      "epoch=87_train_batch=69, total_loss=19.49073600769043, pred_loss=[0.02359933, 0.6848814, 6.5045185]\n",
      "epoch=87_train_batch=70, total_loss=14.213037490844727, pred_loss=[0.14916523, 0.4849047, 1.3019023]\n",
      "epoch=87_train_batch=71, total_loss=15.1141357421875, pred_loss=[0.40210307, 0.65869385, 1.7769387]\n",
      "epoch=87_train_batch=72, total_loss=14.551961898803711, pred_loss=[0.28055894, 0.7539841, 1.2416897]\n",
      "epoch=87_train_batch=73, total_loss=13.843785285949707, pred_loss=[0.6530723, 0.71573126, 0.19992469]\n",
      "epoch=87_train_batch=74, total_loss=13.9556884765625, pred_loss=[0.62430495, 0.5553507, 0.5016602]\n",
      "epoch=87_train_batch=75, total_loss=19.596012115478516, pred_loss=[0.14449129, 4.3192854, 2.8585484]\n",
      "epoch=87_train_batch=76, total_loss=16.82203483581543, pred_loss=[2.752849, 0.10930231, 1.6868798]\n",
      "epoch=87_train_batch=77, total_loss=13.76976203918457, pred_loss=[0.5426531, 0.22383371, 0.73093796]\n",
      "epoch=87_train_batch=78, total_loss=14.372113227844238, pred_loss=[0.3998842, 0.3698501, 1.3306934]\n",
      "epoch=87_train_batch=79, total_loss=14.025254249572754, pred_loss=[0.7803173, 0.1977721, 0.77611184]\n",
      "epoch=87_train_batch=80, total_loss=18.404144287109375, pred_loss=[0.6235354, 0.9001201, 4.6100526]\n",
      "epoch=87_train_batch=81, total_loss=13.89557933807373, pred_loss=[0.8066756, 0.6901613, 0.12890436]\n",
      "epoch=87_train_batch=82, total_loss=25.805625915527344, pred_loss=[0.20852506, 2.8573375, 10.470515]\n",
      "epoch=87_train_batch=83, total_loss=18.238637924194336, pred_loss=[0.1161314, 0.73366475, 5.1201816]\n",
      "epoch=87_train_batch=84, total_loss=14.473906517028809, pred_loss=[0.5588351, 0.7413813, 0.90561324]\n",
      "epoch=87_train_batch=85, total_loss=14.623363494873047, pred_loss=[0.1627114, 0.7264981, 1.4666649]\n",
      "epoch=87_train_batch=86, total_loss=13.888347625732422, pred_loss=[0.64250237, 0.7971009, 0.18185373]\n",
      "epoch=87_train_batch=87, total_loss=13.356218338012695, pred_loss=[0.003192585, 0.6284968, 0.4582396]\n",
      "epoch=87_val_batch=0, total_val_loss=750.4650268554688, pred_val_loss[0.2230839, 63.633926, 674.34235]\n",
      "epoch=87_val_batch=1, total_val_loss=203.8038330078125, pred_val_loss[0.09669125, 112.80437, 78.637085]\n",
      "epoch=87_val_batch=2, total_val_loss=83.63092041015625, pred_val_loss[11.534612, 14.085886, 45.744743]\n",
      "epoch=87_val_batch=3, total_val_loss=124.52061462402344, pred_val_loss[3.8905437, 25.085743, 83.27865]\n",
      "epoch=87_val_batch=4, total_val_loss=88.82942962646484, pred_val_loss[3.5408335, 36.757545, 36.265373]\n",
      "epoch=87_val_batch=5, total_val_loss=55.29735565185547, pred_val_loss[12.165823, 5.115181, 25.750675]\n",
      "epoch=87_val_batch=6, total_val_loss=231.89166259765625, pred_val_loss[20.313606, 5.7426987, 193.56969]\n",
      "epoch=87_val_batch=7, total_val_loss=149.07015991210938, pred_val_loss[0.5480287, 62.455765, 73.8007]\n",
      "epoch=87_val_batch=8, total_val_loss=56.54087448120117, pred_val_loss[0.27517843, 33.644394, 10.355626]\n",
      "epoch=87_val_batch=9, total_val_loss=109.01947784423828, pred_val_loss[3.6982527, 55.24694, 37.8086]\n",
      "epoch=87_val_batch=10, total_val_loss=148.34173583984375, pred_val_loss[43.172173, 6.9665003, 85.937386]\n",
      "epoch=87_val_batch=11, total_val_loss=179.58346557617188, pred_val_loss[20.171524, 60.395638, 86.75062]\n",
      "epoch=87_val_batch=12, total_val_loss=26.886781692504883, pred_val_loss[0.9116794, 5.8918333, 7.8175907]\n",
      "epoch=87_val_batch=13, total_val_loss=90.79046630859375, pred_val_loss[0.2800541, 38.209892, 40.034843]\n",
      "epoch=87_val_batch=14, total_val_loss=107.65044403076172, pred_val_loss[11.415389, 42.712162, 41.257217]\n",
      "epoch=87_val_batch=15, total_val_loss=83.12427520751953, pred_val_loss[29.793396, 1.3893805, 39.67582]\n",
      "epoch=87_val_batch=16, total_val_loss=204.49111938476562, pred_val_loss[11.762417, 66.6599, 113.80312]\n",
      "epoch=87_val_batch=17, total_val_loss=169.923583984375, pred_val_loss[14.004831, 18.086487, 125.56659]\n",
      "epoch=87_val_batch=18, total_val_loss=129.65652465820312, pred_val_loss[3.2060466, 27.993643, 86.19116]\n",
      "epoch=87, train: avg_loss=15.137795448303223, val: avg_val_loss=157.5535888671875\n",
      "Saved checkpoint for step 98: ./tf_ckpts/ckpt-97\n",
      "epoch=88_train_batch=0, total_loss=13.453104972839355, pred_loss=[0.2486044, 0.68336475, 0.25545716]\n",
      "epoch=88_train_batch=1, total_loss=13.407540321350098, pred_loss=[0.44163004, 0.38451785, 0.31633484]\n",
      "epoch=88_train_batch=2, total_loss=14.711994171142578, pred_loss=[0.07282524, 0.62317127, 1.7515647]\n",
      "epoch=88_train_batch=3, total_loss=14.39212417602539, pred_loss=[0.5888325, 0.3741701, 1.1653289]\n",
      "epoch=88_train_batch=4, total_loss=17.469768524169922, pred_loss=[0.0092982175, 1.6798906, 3.517451]\n",
      "epoch=88_train_batch=5, total_loss=13.491684913635254, pred_loss=[0.54597574, 0.05774796, 0.625507]\n",
      "epoch=88_train_batch=6, total_loss=15.92463493347168, pred_loss=[0.22976057, 0.8850601, 2.548045]\n",
      "epoch=88_train_batch=7, total_loss=13.97626781463623, pred_loss=[0.1811566, 0.6824261, 0.8516184]\n",
      "epoch=88_train_batch=8, total_loss=13.883635520935059, pred_loss=[0.043243177, 0.5499103, 1.0301244]\n",
      "epoch=88_train_batch=9, total_loss=14.237062454223633, pred_loss=[0.1814509, 0.37057844, 1.4253923]\n",
      "epoch=88_train_batch=10, total_loss=13.888350486755371, pred_loss=[0.62770575, 0.08749944, 0.9142335]\n",
      "epoch=88_train_batch=11, total_loss=21.70352554321289, pred_loss=[0.29651272, 1.1437309, 8.005114]\n",
      "epoch=88_train_batch=12, total_loss=13.066781044006348, pred_loss=[0.40222993, 0.23182365, 0.17531344]\n",
      "epoch=88_train_batch=13, total_loss=13.757206916809082, pred_loss=[0.35627595, 0.43747243, 0.7068001]\n",
      "epoch=88_train_batch=14, total_loss=13.945643424987793, pred_loss=[0.37520838, 0.46103185, 0.8535012]\n",
      "epoch=88_train_batch=15, total_loss=14.140094757080078, pred_loss=[0.15441144, 0.41545424, 1.3150864]\n",
      "epoch=88_train_batch=16, total_loss=21.267135620117188, pred_loss=[0.6264348, 3.1455173, 5.2408]\n",
      "epoch=88_train_batch=17, total_loss=14.045543670654297, pred_loss=[0.15644741, 0.2362743, 1.3992037]\n",
      "epoch=88_train_batch=18, total_loss=14.004398345947266, pred_loss=[0.68816245, 0.22552845, 0.8378501]\n",
      "epoch=88_train_batch=19, total_loss=13.56603717803955, pred_loss=[0.18340062, 0.19698527, 0.93355584]\n",
      "epoch=88_train_batch=20, total_loss=13.729009628295898, pred_loss=[0.21412495, 0.47055507, 0.79299515]\n",
      "epoch=88_train_batch=21, total_loss=13.833296775817871, pred_loss=[0.26201472, 0.7349309, 0.5857789]\n",
      "epoch=88_train_batch=22, total_loss=14.369546890258789, pred_loss=[0.4942779, 0.30290177, 1.3225543]\n",
      "epoch=88_train_batch=23, total_loss=13.471711158752441, pred_loss=[0.4169308, 0.602349, 0.2033805]\n",
      "epoch=88_train_batch=24, total_loss=15.991706848144531, pred_loss=[0.09315743, 1.1581957, 2.4920664]\n",
      "epoch=88_train_batch=25, total_loss=18.634248733520508, pred_loss=[0.0652682, 0.40599328, 5.915463]\n",
      "epoch=88_train_batch=26, total_loss=14.232251167297363, pred_loss=[0.45154226, 0.45506048, 1.0788887]\n",
      "epoch=88_train_batch=27, total_loss=14.099966049194336, pred_loss=[0.18845847, 1.1024532, 0.56306213]\n",
      "epoch=88_train_batch=28, total_loss=13.779703140258789, pred_loss=[0.12846997, 0.29174197, 1.1142614]\n",
      "epoch=88_train_batch=29, total_loss=13.11987018585205, pred_loss=[0.34153172, 0.45751354, 0.0763583]\n",
      "epoch=88_train_batch=30, total_loss=14.566757202148438, pred_loss=[0.17862336, 0.24954627, 1.8948889]\n",
      "epoch=88_train_batch=31, total_loss=16.071640014648438, pred_loss=[0.116289504, 0.9273354, 2.7850885]\n",
      "epoch=88_train_batch=32, total_loss=16.301170349121094, pred_loss=[0.23131552, 1.3171369, 2.510569]\n",
      "epoch=88_train_batch=33, total_loss=24.150394439697266, pred_loss=[0.12992424, 0.817103, 10.961997]\n",
      "epoch=88_train_batch=34, total_loss=16.65597915649414, pred_loss=[0.5832446, 0.13540873, 3.696742]\n",
      "epoch=88_train_batch=35, total_loss=14.596067428588867, pred_loss=[0.21709155, 0.8474487, 1.2917199]\n",
      "epoch=88_train_batch=36, total_loss=13.240360260009766, pred_loss=[0.19203296, 0.3275083, 0.48178178]\n",
      "epoch=88_train_batch=37, total_loss=13.14061164855957, pred_loss=[0.20040442, 0.4724646, 0.22947277]\n",
      "epoch=88_train_batch=38, total_loss=16.263641357421875, pred_loss=[0.3874921, 0.81368923, 2.824958]\n",
      "epoch=88_train_batch=39, total_loss=15.776837348937988, pred_loss=[0.26060462, 1.2755945, 2.003894]\n",
      "epoch=88_train_batch=40, total_loss=15.564608573913574, pred_loss=[0.66839725, 0.37146586, 2.2887661]\n",
      "epoch=88_train_batch=41, total_loss=22.280136108398438, pred_loss=[0.030951586, 0.78258914, 9.231377]\n",
      "epoch=88_train_batch=42, total_loss=17.490001678466797, pred_loss=[0.07333234, 0.5860517, 4.5961657]\n",
      "epoch=88_train_batch=43, total_loss=15.011754989624023, pred_loss=[0.30329776, 1.1391116, 1.3356551]\n",
      "epoch=88_train_batch=44, total_loss=13.817000389099121, pred_loss=[0.34773165, 0.73930293, 0.49704117]\n",
      "epoch=88_train_batch=45, total_loss=13.780564308166504, pred_loss=[0.4474103, 0.31764287, 0.78336]\n",
      "epoch=88_train_batch=46, total_loss=13.983715057373047, pred_loss=[0.2913927, 1.3007251, 0.16021825]\n",
      "epoch=88_train_batch=47, total_loss=15.781051635742188, pred_loss=[0.4857107, 0.60985196, 2.454891]\n",
      "epoch=88_train_batch=48, total_loss=14.70899772644043, pred_loss=[0.06936105, 0.47650778, 1.9333178]\n",
      "epoch=88_train_batch=49, total_loss=14.811901092529297, pred_loss=[0.22732675, 0.44310212, 1.9124489]\n",
      "epoch=88_train_batch=50, total_loss=13.623472213745117, pred_loss=[0.15016474, 0.62675923, 0.61831284]\n",
      "epoch=88_train_batch=51, total_loss=13.057820320129395, pred_loss=[0.10301572, 0.5691421, 0.15821567]\n",
      "epoch=88_train_batch=52, total_loss=17.451873779296875, pred_loss=[0.10095893, 0.7273674, 4.396891]\n",
      "epoch=88_train_batch=53, total_loss=14.052218437194824, pred_loss=[0.94783264, 0.1577476, 0.72077554]\n",
      "epoch=88_train_batch=54, total_loss=14.278696060180664, pred_loss=[0.6147245, 0.8736687, 0.56522375]\n",
      "epoch=88_train_batch=55, total_loss=19.230621337890625, pred_loss=[0.14446336, 2.232033, 4.629817]\n",
      "epoch=88_train_batch=56, total_loss=13.970726013183594, pred_loss=[0.062066425, 0.9217625, 0.7633581]\n",
      "epoch=88_train_batch=57, total_loss=14.980957984924316, pred_loss=[0.0038572196, 1.3537288, 1.400607]\n",
      "epoch=88_train_batch=58, total_loss=13.087787628173828, pred_loss=[0.13168685, 0.5508589, 0.18325086]\n",
      "epoch=88_train_batch=59, total_loss=13.248661994934082, pred_loss=[0.34798375, 0.276159, 0.40330392]\n",
      "epoch=88_train_batch=60, total_loss=14.904577255249023, pred_loss=[0.14565061, 1.7353933, 0.80309975]\n",
      "epoch=88_train_batch=61, total_loss=15.036272048950195, pred_loss=[0.09534979, 0.71440136, 2.0068703]\n",
      "epoch=88_train_batch=62, total_loss=15.785299301147461, pred_loss=[0.07773694, 2.1501753, 1.3385261]\n",
      "epoch=88_train_batch=63, total_loss=14.25866985321045, pred_loss=[0.36774543, 0.40317753, 1.2696743]\n",
      "epoch=88_train_batch=64, total_loss=14.15671157836914, pred_loss=[0.10136882, 0.2750979, 1.5629652]\n",
      "epoch=88_train_batch=65, total_loss=13.41064167022705, pred_loss=[0.5161841, 0.4837363, 0.1942325]\n",
      "epoch=88_train_batch=66, total_loss=16.04865264892578, pred_loss=[0.05667728, 0.66952044, 3.1067624]\n",
      "epoch=88_train_batch=67, total_loss=15.349011421203613, pred_loss=[0.5549748, 0.70785046, 1.8712978]\n",
      "epoch=88_train_batch=68, total_loss=14.525395393371582, pred_loss=[0.14780875, 1.0381519, 1.1253539]\n",
      "epoch=88_train_batch=69, total_loss=33.4146842956543, pred_loss=[0.14096738, 0.3953827, 20.665066]\n",
      "epoch=88_train_batch=70, total_loss=15.381553649902344, pred_loss=[0.17446193, 2.3962443, 0.5983913]\n",
      "epoch=88_train_batch=71, total_loss=14.051370620727539, pred_loss=[0.08173968, 0.63712037, 1.1208506]\n",
      "epoch=88_train_batch=72, total_loss=14.418197631835938, pred_loss=[0.10693128, 0.9733174, 1.1270759]\n",
      "epoch=88_train_batch=73, total_loss=14.581680297851562, pred_loss=[0.16808358, 0.74270827, 1.460805]\n",
      "epoch=88_train_batch=74, total_loss=14.48959732055664, pred_loss=[0.44543922, 0.32167283, 1.5131887]\n",
      "epoch=88_train_batch=75, total_loss=16.66701889038086, pred_loss=[0.24131712, 0.86607397, 3.3511167]\n",
      "epoch=88_train_batch=76, total_loss=16.68508529663086, pred_loss=[0.06430118, 0.298167, 4.1148877]\n",
      "epoch=88_train_batch=77, total_loss=18.242168426513672, pred_loss=[0.049351506, 0.700999, 5.284874]\n",
      "epoch=88_train_batch=78, total_loss=15.313777923583984, pred_loss=[0.25770962, 1.4546167, 1.3952934]\n",
      "epoch=88_train_batch=79, total_loss=13.252766609191895, pred_loss=[0.25255513, 0.52957046, 0.265268]\n",
      "epoch=88_train_batch=80, total_loss=13.314440727233887, pred_loss=[0.16980314, 0.57136893, 0.36868268]\n",
      "epoch=88_train_batch=81, total_loss=18.474868774414062, pred_loss=[0.6923672, 0.50632715, 5.072373]\n",
      "epoch=88_train_batch=82, total_loss=17.592037200927734, pred_loss=[0.72135514, 0.5764357, 4.091243]\n",
      "epoch=88_train_batch=83, total_loss=14.63436222076416, pred_loss=[0.13494492, 0.8132491, 1.4839445]\n",
      "epoch=88_train_batch=84, total_loss=14.970202445983887, pred_loss=[0.16182086, 1.4558456, 1.1510875]\n",
      "epoch=88_train_batch=85, total_loss=13.565572738647461, pred_loss=[0.4417646, 0.35804385, 0.5650897]\n",
      "epoch=88_train_batch=86, total_loss=15.082143783569336, pred_loss=[0.35156822, 0.6780541, 1.8526375]\n",
      "epoch=88_train_batch=87, total_loss=13.096217155456543, pred_loss=[0.22263673, 0.07791386, 0.5965667]\n",
      "epoch=88_val_batch=0, total_val_loss=735.99169921875, pred_val_loss[0.1468091, 64.5068, 659.1398]\n",
      "epoch=88_val_batch=1, total_val_loss=217.02320861816406, pred_val_loss[0.050658677, 114.317856, 90.45637]\n",
      "epoch=88_val_batch=2, total_val_loss=91.69772338867188, pred_val_loss[11.403214, 14.175034, 53.92116]\n",
      "epoch=88_val_batch=3, total_val_loss=131.67861938476562, pred_val_loss[5.0939283, 28.040524, 86.345856]\n",
      "epoch=88_val_batch=4, total_val_loss=96.76708984375, pred_val_loss[5.544116, 37.634834, 41.389816]\n",
      "epoch=88_val_batch=5, total_val_loss=54.787010192871094, pred_val_loss[13.275803, 5.332714, 23.980173]\n",
      "epoch=88_val_batch=6, total_val_loss=218.45059204101562, pred_val_loss[17.727655, 5.6105976, 182.91402]\n",
      "epoch=88_val_batch=7, total_val_loss=157.3533477783203, pred_val_loss[0.5533985, 62.482246, 82.11939]\n",
      "epoch=88_val_batch=8, total_val_loss=54.56080627441406, pred_val_loss[0.16940445, 31.51063, 10.682457]\n",
      "epoch=88_val_batch=9, total_val_loss=113.89877319335938, pred_val_loss[1.1535044, 55.38199, 45.16496]\n",
      "epoch=88_val_batch=10, total_val_loss=135.08152770996094, pred_val_loss[29.896267, 6.1855674, 86.80138]\n",
      "epoch=88_val_batch=11, total_val_loss=171.4430389404297, pred_val_loss[16.383566, 59.13327, 83.72788]\n",
      "epoch=88_val_batch=12, total_val_loss=29.3127384185791, pred_val_loss[1.0690734, 6.0748115, 9.970537]\n",
      "epoch=88_val_batch=13, total_val_loss=101.23678588867188, pred_val_loss[0.2827946, 39.885994, 48.869675]\n",
      "epoch=88_val_batch=14, total_val_loss=113.58743286132812, pred_val_loss[14.775859, 43.049213, 43.564037]\n",
      "epoch=88_val_batch=15, total_val_loss=91.32856750488281, pred_val_loss[29.169636, 1.77829, 48.18232]\n",
      "epoch=88_val_batch=16, total_val_loss=204.8811492919922, pred_val_loss[9.53858, 65.93335, 117.21089]\n",
      "epoch=88_val_batch=17, total_val_loss=175.15414428710938, pred_val_loss[11.440352, 16.22992, 135.28555]\n",
      "epoch=88_val_batch=18, total_val_loss=135.45675659179688, pred_val_loss[4.3161535, 26.621496, 92.320786]\n",
      "epoch=88, train: avg_loss=15.332645416259766, val: avg_val_loss=159.45741271972656\n",
      "Saved checkpoint for step 99: ./tf_ckpts/ckpt-98\n",
      "epoch=89_train_batch=0, total_loss=14.056472778320312, pred_loss=[0.24383557, 0.5299768, 1.0843439]\n",
      "epoch=89_train_batch=1, total_loss=14.062636375427246, pred_loss=[0.23995455, 0.48704895, 1.1380996]\n",
      "epoch=89_train_batch=2, total_loss=19.000375747680664, pred_loss=[0.20864812, 2.3256774, 4.2692947]\n",
      "epoch=89_train_batch=3, total_loss=19.056373596191406, pred_loss=[0.07703233, 1.1934276, 5.589942]\n",
      "epoch=89_train_batch=4, total_loss=16.09083366394043, pred_loss=[0.050485887, 0.40336633, 3.4417944]\n",
      "epoch=89_train_batch=5, total_loss=13.250000953674316, pred_loss=[0.13581167, 0.31483492, 0.6049575]\n",
      "epoch=89_train_batch=6, total_loss=14.252137184143066, pred_loss=[0.2372712, 0.88386726, 0.93738496]\n",
      "epoch=89_train_batch=7, total_loss=13.437394142150879, pred_loss=[0.17703462, 0.5226312, 0.5448919]\n",
      "epoch=89_train_batch=8, total_loss=14.375502586364746, pred_loss=[0.1266929, 1.6913369, 0.36541343]\n",
      "epoch=89_train_batch=9, total_loss=14.376773834228516, pred_loss=[0.1729127, 1.0355027, 0.97707665]\n",
      "epoch=89_train_batch=10, total_loss=15.358436584472656, pred_loss=[0.5895271, 0.114492446, 2.4639144]\n",
      "epoch=89_train_batch=11, total_loss=14.753928184509277, pred_loss=[0.058982357, 0.73887783, 1.7663535]\n",
      "epoch=89_train_batch=12, total_loss=14.643804550170898, pred_loss=[0.806226, 0.45084706, 1.1978016]\n",
      "epoch=89_train_batch=13, total_loss=14.635345458984375, pred_loss=[0.37129462, 1.019872, 1.0560243]\n",
      "epoch=89_train_batch=14, total_loss=14.39305305480957, pred_loss=[0.5582335, 0.39162508, 1.2558085]\n",
      "epoch=89_train_batch=15, total_loss=14.027681350708008, pred_loss=[0.2639534, 0.6979902, 0.8791007]\n",
      "epoch=89_train_batch=16, total_loss=16.898956298828125, pred_loss=[0.23504198, 1.1914046, 3.2866158]\n",
      "epoch=89_train_batch=17, total_loss=12.919694900512695, pred_loss=[0.11934996, 0.25117642, 0.36402202]\n",
      "epoch=89_train_batch=18, total_loss=13.282937049865723, pred_loss=[0.4620868, 0.5111931, 0.12525432]\n",
      "epoch=89_train_batch=19, total_loss=13.522855758666992, pred_loss=[0.16990052, 0.17051572, 0.99878335]\n",
      "epoch=89_train_batch=20, total_loss=13.307671546936035, pred_loss=[0.10846947, 0.43725875, 0.57903427]\n",
      "epoch=89_train_batch=21, total_loss=28.45269775390625, pred_loss=[0.030018892, 1.3082811, 14.932242]\n",
      "epoch=89_train_batch=22, total_loss=13.184077262878418, pred_loss=[0.19250935, 0.3290534, 0.48109883]\n",
      "epoch=89_train_batch=23, total_loss=17.44411849975586, pred_loss=[0.37648207, 2.4432125, 2.4437494]\n",
      "epoch=89_train_batch=24, total_loss=14.375612258911133, pred_loss=[0.5085786, 0.41266605, 1.2744315]\n",
      "epoch=89_train_batch=25, total_loss=17.130157470703125, pred_loss=[0.22499153, 0.820675, 3.905292]\n",
      "epoch=89_train_batch=26, total_loss=13.919910430908203, pred_loss=[0.18885745, 0.9797092, 0.5728915]\n",
      "epoch=89_train_batch=27, total_loss=14.044275283813477, pred_loss=[0.31163716, 0.42969954, 1.1252364]\n",
      "epoch=89_train_batch=28, total_loss=17.212308883666992, pred_loss=[0.18644613, 0.63616395, 4.2127595]\n",
      "epoch=89_train_batch=29, total_loss=13.497848510742188, pred_loss=[0.12845537, 0.65954286, 0.5336834]\n",
      "epoch=89_train_batch=30, total_loss=15.137493133544922, pred_loss=[0.30641, 0.33902442, 2.3166652]\n",
      "epoch=89_train_batch=31, total_loss=13.245232582092285, pred_loss=[0.28245482, 0.614478, 0.17368078]\n",
      "epoch=89_train_batch=32, total_loss=14.329774856567383, pred_loss=[0.011411132, 0.65429664, 1.4902202]\n",
      "epoch=89_train_batch=33, total_loss=16.920791625976562, pred_loss=[0.19698718, 0.8370397, 3.71369]\n",
      "epoch=89_train_batch=34, total_loss=14.237669944763184, pred_loss=[1.3600485, 0.32064056, 0.38468915]\n",
      "epoch=89_train_batch=35, total_loss=14.571271896362305, pred_loss=[0.2571206, 0.7726501, 1.3700055]\n",
      "epoch=89_train_batch=36, total_loss=14.744146347045898, pred_loss=[0.3034681, 0.24556893, 2.0244036]\n",
      "epoch=89_train_batch=37, total_loss=13.515212059020996, pred_loss=[0.18262476, 0.49503064, 0.66763556]\n",
      "epoch=89_train_batch=38, total_loss=13.59793758392334, pred_loss=[0.27354652, 0.4279335, 0.72732055]\n",
      "epoch=89_train_batch=39, total_loss=13.415958404541016, pred_loss=[0.43595177, 0.35605606, 0.45559424]\n",
      "epoch=89_train_batch=40, total_loss=14.159412384033203, pred_loss=[0.6510771, 1.0724216, 0.26833844]\n",
      "epoch=89_train_batch=41, total_loss=13.60292911529541, pred_loss=[0.1025701, 0.25594828, 1.077615]\n",
      "epoch=89_train_batch=42, total_loss=14.629681587219238, pred_loss=[0.3579465, 0.39900583, 1.7067063]\n",
      "epoch=89_train_batch=43, total_loss=14.629314422607422, pred_loss=[0.03439738, 0.5038065, 1.9258593]\n",
      "epoch=89_train_batch=44, total_loss=14.768404006958008, pred_loss=[0.0565613, 0.27832896, 2.269037]\n",
      "epoch=89_train_batch=45, total_loss=13.609724044799805, pred_loss=[0.31311816, 0.20925552, 0.9236454]\n",
      "epoch=89_train_batch=46, total_loss=14.313612937927246, pred_loss=[0.0380118, 0.8803638, 1.2323012]\n",
      "epoch=89_train_batch=47, total_loss=20.79220962524414, pred_loss=[0.1937909, 1.3422478, 7.094008]\n",
      "epoch=89_train_batch=48, total_loss=13.655372619628906, pred_loss=[0.0045371377, 0.52439016, 0.9650761]\n",
      "epoch=89_train_batch=49, total_loss=14.051935195922852, pred_loss=[0.22227676, 0.29860103, 1.3703742]\n",
      "epoch=89_train_batch=50, total_loss=14.720463752746582, pred_loss=[0.062006753, 0.57250786, 1.9258683]\n",
      "epoch=89_train_batch=51, total_loss=13.664008140563965, pred_loss=[0.28504783, 0.1790379, 1.0403903]\n",
      "epoch=89_train_batch=52, total_loss=15.420333862304688, pred_loss=[0.41122139, 1.1003013, 1.7497929]\n",
      "epoch=89_train_batch=53, total_loss=17.012649536132812, pred_loss=[1.1967665, 0.20531037, 3.4520483]\n",
      "epoch=89_train_batch=54, total_loss=14.763006210327148, pred_loss=[0.34950927, 0.48766345, 1.7677778]\n",
      "epoch=89_train_batch=55, total_loss=12.835598945617676, pred_loss=[0.24914382, 0.2389227, 0.18994853]\n",
      "epoch=89_train_batch=56, total_loss=14.15928840637207, pred_loss=[0.23433147, 0.62444484, 1.1434025]\n",
      "epoch=89_train_batch=57, total_loss=13.974650382995605, pred_loss=[0.29344758, 0.79282916, 0.73175037]\n",
      "epoch=89_train_batch=58, total_loss=13.527963638305664, pred_loss=[0.15423816, 0.5554555, 0.6621536]\n",
      "epoch=89_train_batch=59, total_loss=15.882806777954102, pred_loss=[0.19825742, 1.5795848, 1.9493693]\n",
      "epoch=89_train_batch=60, total_loss=14.379175186157227, pred_loss=[0.06798914, 0.5302316, 1.6259062]\n",
      "epoch=89_train_batch=61, total_loss=14.101452827453613, pred_loss=[0.24954769, 0.27594295, 1.4214745]\n",
      "epoch=89_train_batch=62, total_loss=13.466911315917969, pred_loss=[0.34065408, 0.5344565, 0.4378951]\n",
      "epoch=89_train_batch=63, total_loss=13.14940357208252, pred_loss=[0.09904279, 0.62743217, 0.26962095]\n",
      "epoch=89_train_batch=64, total_loss=13.445536613464355, pred_loss=[0.36194146, 0.53742063, 0.3934806]\n",
      "epoch=89_train_batch=65, total_loss=14.516112327575684, pred_loss=[0.11971653, 0.71677125, 1.5275553]\n",
      "epoch=89_train_batch=66, total_loss=14.635546684265137, pred_loss=[0.16441238, 0.1757449, 2.1439524]\n",
      "epoch=89_train_batch=67, total_loss=28.51504135131836, pred_loss=[0.08528464, 2.1220102, 14.15695]\n",
      "epoch=89_train_batch=68, total_loss=13.927560806274414, pred_loss=[0.19908047, 0.5984044, 0.9799325]\n",
      "epoch=89_train_batch=69, total_loss=15.168266296386719, pred_loss=[0.1629041, 0.5040648, 2.35181]\n",
      "epoch=89_train_batch=70, total_loss=15.928823471069336, pred_loss=[0.44031042, 0.92565525, 2.4140341]\n",
      "epoch=89_train_batch=71, total_loss=14.239555358886719, pred_loss=[0.25189674, 0.64547455, 1.1940227]\n",
      "epoch=89_train_batch=72, total_loss=13.650063514709473, pred_loss=[0.1055323, 0.55840886, 0.8386347]\n",
      "epoch=89_train_batch=73, total_loss=14.167587280273438, pred_loss=[0.10624786, 0.37147695, 1.5430559]\n",
      "epoch=89_train_batch=74, total_loss=13.659435272216797, pred_loss=[0.29582694, 0.457563, 0.75993407]\n",
      "epoch=89_train_batch=75, total_loss=13.586102485656738, pred_loss=[0.1920753, 0.42423198, 0.82438946]\n",
      "epoch=89_train_batch=76, total_loss=15.368488311767578, pred_loss=[1.3030845, 0.56119245, 1.3595178]\n",
      "epoch=89_train_batch=77, total_loss=13.5823974609375, pred_loss=[0.16361926, 0.92660546, 0.3482353]\n",
      "epoch=89_train_batch=78, total_loss=20.206920623779297, pred_loss=[0.073149174, 0.29613012, 7.694441]\n",
      "epoch=89_train_batch=79, total_loss=13.704689025878906, pred_loss=[0.16958983, 0.74363, 0.64899254]\n",
      "epoch=89_train_batch=80, total_loss=13.945304870605469, pred_loss=[0.09416201, 0.58057344, 1.1287888]\n",
      "epoch=89_train_batch=81, total_loss=13.677614212036133, pred_loss=[0.2129771, 0.41664356, 0.90689695]\n",
      "epoch=89_train_batch=82, total_loss=17.987751007080078, pred_loss=[0.09830735, 2.797401, 2.9516234]\n",
      "epoch=89_train_batch=83, total_loss=13.335777282714844, pred_loss=[0.24700247, 0.27469712, 0.6743319]\n",
      "epoch=89_train_batch=84, total_loss=13.686901092529297, pred_loss=[0.007470917, 0.6028684, 0.9374861]\n",
      "epoch=89_train_batch=85, total_loss=22.144866943359375, pred_loss=[0.1319525, 1.4403719, 8.434138]\n",
      "epoch=89_train_batch=86, total_loss=14.2780122756958, pred_loss=[0.9912429, 0.48660704, 0.6624278]\n",
      "epoch=89_train_batch=87, total_loss=12.628849983215332, pred_loss=[0.21351019, 0.1250844, 0.15319353]\n",
      "epoch=89_val_batch=0, total_val_loss=743.6334228515625, pred_val_loss[0.25646654, 67.8212, 663.4194]\n",
      "epoch=89_val_batch=1, total_val_loss=208.87310791015625, pred_val_loss[0.07622132, 105.0269, 91.6336]\n",
      "epoch=89_val_batch=2, total_val_loss=95.64431762695312, pred_val_loss[12.891612, 18.729235, 51.887085]\n",
      "epoch=89_val_batch=3, total_val_loss=128.01243591308594, pred_val_loss[3.7348142, 28.70713, 83.43411]\n",
      "epoch=89_val_batch=4, total_val_loss=97.04151916503906, pred_val_loss[3.9589303, 36.394966, 44.551243]\n",
      "epoch=89_val_batch=5, total_val_loss=67.65478515625, pred_val_loss[11.727227, 15.3356, 28.455582]\n",
      "epoch=89_val_batch=6, total_val_loss=223.08737182617188, pred_val_loss[18.25498, 4.8781176, 187.81789]\n",
      "epoch=89_val_batch=7, total_val_loss=156.1448211669922, pred_val_loss[0.5712724, 60.902428, 82.53474]\n",
      "epoch=89_val_batch=8, total_val_loss=48.01829147338867, pred_val_loss[0.19416344, 26.017643, 9.670106]\n",
      "epoch=89_val_batch=9, total_val_loss=109.86552429199219, pred_val_loss[2.005207, 54.44835, 41.275593]\n",
      "epoch=89_val_batch=10, total_val_loss=142.6343536376953, pred_val_loss[34.280354, 6.9166245, 89.300995]\n",
      "epoch=89_val_batch=11, total_val_loss=158.34561157226562, pred_val_loss[15.584686, 47.311256, 83.31328]\n",
      "epoch=89_val_batch=12, total_val_loss=32.97484588623047, pred_val_loss[0.71455324, 10.288685, 9.835229]\n",
      "epoch=89_val_batch=13, total_val_loss=104.77291870117188, pred_val_loss[0.31598493, 36.334274, 55.986275]\n",
      "epoch=89_val_batch=14, total_val_loss=105.48733520507812, pred_val_loss[15.583481, 38.269173, 39.498306]\n",
      "epoch=89_val_batch=15, total_val_loss=85.71916198730469, pred_val_loss[27.029682, 0.5235845, 46.02952]\n",
      "epoch=89_val_batch=16, total_val_loss=206.52999877929688, pred_val_loss[11.991182, 70.98513, 111.4173]\n",
      "epoch=89_val_batch=17, total_val_loss=163.11912536621094, pred_val_loss[12.725222, 10.891916, 127.3656]\n",
      "epoch=89_val_batch=18, total_val_loss=133.5299530029297, pred_val_loss[3.9425588, 25.10608, 92.34493]\n",
      "epoch=89, train: avg_loss=15.022011756896973, val: avg_val_loss=158.47837829589844\n",
      "Saved checkpoint for step 100: ./tf_ckpts/ckpt-99\n",
      "epoch=90_train_batch=0, total_loss=17.434446334838867, pred_loss=[0.19839065, 2.4065301, 2.6931458]\n",
      "epoch=90_train_batch=1, total_loss=13.0159330368042, pred_loss=[0.45987317, 0.11760795, 0.30276585]\n",
      "epoch=90_train_batch=2, total_loss=13.831513404846191, pred_loss=[0.8331999, 0.3719033, 0.491415]\n",
      "epoch=90_train_batch=3, total_loss=14.004936218261719, pred_loss=[0.24797109, 1.0377144, 0.5849412]\n",
      "epoch=90_train_batch=4, total_loss=13.982342720031738, pred_loss=[0.02652282, 1.0689564, 0.75325024]\n",
      "epoch=90_train_batch=5, total_loss=14.138311386108398, pred_loss=[0.41887188, 0.5781672, 1.0083604]\n",
      "epoch=90_train_batch=6, total_loss=13.473637580871582, pred_loss=[0.6899767, 0.43060583, 0.22085744]\n",
      "epoch=90_train_batch=7, total_loss=15.72007942199707, pred_loss=[0.0087593505, 0.77691406, 2.802928]\n",
      "epoch=90_train_batch=8, total_loss=13.05170726776123, pred_loss=[0.45305306, 0.13341004, 0.334486]\n",
      "epoch=90_train_batch=9, total_loss=14.018001556396484, pred_loss=[0.12341619, 0.9918219, 0.77273846]\n",
      "epoch=90_train_batch=10, total_loss=14.28116226196289, pred_loss=[0.046261378, 1.1603913, 0.9452222]\n",
      "epoch=90_train_batch=11, total_loss=13.462268829345703, pred_loss=[0.17247516, 0.38407543, 0.77717566]\n",
      "epoch=90_train_batch=12, total_loss=14.363815307617188, pred_loss=[0.19896017, 0.5911699, 1.445889]\n",
      "epoch=90_train_batch=13, total_loss=13.291894912719727, pred_loss=[0.22037627, 0.4802059, 0.46426785]\n",
      "epoch=90_train_batch=14, total_loss=14.005717277526855, pred_loss=[0.05507966, 1.4979839, 0.3263706]\n",
      "epoch=90_train_batch=15, total_loss=13.651318550109863, pred_loss=[0.48453644, 0.184091, 0.8571764]\n",
      "epoch=90_train_batch=16, total_loss=14.112505912780762, pred_loss=[0.036561552, 0.4320181, 1.5191792]\n",
      "epoch=90_train_batch=17, total_loss=13.452491760253906, pred_loss=[0.3147145, 0.6781741, 0.3356293]\n",
      "epoch=90_train_batch=18, total_loss=13.220073699951172, pred_loss=[0.11257908, 0.7990917, 0.18520418]\n",
      "epoch=90_train_batch=19, total_loss=13.467116355895996, pred_loss=[0.08011761, 0.57515264, 0.6894288]\n",
      "epoch=90_train_batch=20, total_loss=13.546089172363281, pred_loss=[0.14938304, 0.50946367, 0.76561004]\n",
      "epoch=90_train_batch=21, total_loss=21.762630462646484, pred_loss=[0.09136542, 0.40559807, 9.144826]\n",
      "epoch=90_train_batch=22, total_loss=13.074034690856934, pred_loss=[0.46575403, 0.3425141, 0.1457244]\n",
      "epoch=90_train_batch=23, total_loss=12.941756248474121, pred_loss=[0.21770012, 0.49945635, 0.10535957]\n",
      "epoch=90_train_batch=24, total_loss=16.18214988708496, pred_loss=[0.42220852, 0.21803749, 3.4234638]\n",
      "epoch=90_train_batch=25, total_loss=13.552145004272461, pred_loss=[1.0592242, 0.31255382, 0.06273283]\n",
      "epoch=90_train_batch=26, total_loss=13.180900573730469, pred_loss=[0.12174035, 0.7305193, 0.2118196]\n",
      "epoch=90_train_batch=27, total_loss=13.696414947509766, pred_loss=[0.03327674, 0.7156082, 0.83151674]\n",
      "epoch=90_train_batch=28, total_loss=14.274396896362305, pred_loss=[0.3236494, 0.4192397, 1.4162996]\n",
      "epoch=90_train_batch=29, total_loss=14.466772079467773, pred_loss=[0.38353494, 0.33610284, 1.6327245]\n",
      "epoch=90_train_batch=30, total_loss=13.572696685791016, pred_loss=[0.25325677, 0.59478164, 0.6110318]\n",
      "epoch=90_train_batch=31, total_loss=14.789249420166016, pred_loss=[0.22829628, 0.21546572, 2.2326436]\n",
      "epoch=90_train_batch=32, total_loss=14.002840042114258, pred_loss=[0.15876392, 0.14528035, 1.5867333]\n",
      "epoch=90_train_batch=33, total_loss=13.686436653137207, pred_loss=[0.08581997, 0.7448167, 0.7445179]\n",
      "epoch=90_train_batch=34, total_loss=17.8041934967041, pred_loss=[0.03350404, 0.5707921, 5.0893917]\n",
      "epoch=90_train_batch=35, total_loss=14.165340423583984, pred_loss=[0.09914319, 0.41363195, 1.5428367]\n",
      "epoch=90_train_batch=36, total_loss=13.837926864624023, pred_loss=[0.40485668, 0.6761124, 0.64800656]\n",
      "epoch=90_train_batch=37, total_loss=13.502362251281738, pred_loss=[0.24843238, 0.33265275, 0.81310177]\n",
      "epoch=90_train_batch=38, total_loss=14.25172233581543, pred_loss=[0.0039154566, 0.8108293, 1.3295803]\n",
      "epoch=90_train_batch=39, total_loss=13.107891082763672, pred_loss=[0.29615206, 0.20568451, 0.4994425]\n",
      "epoch=90_train_batch=40, total_loss=13.138337135314941, pred_loss=[0.42365927, 0.3223819, 0.2864741]\n",
      "epoch=90_train_batch=41, total_loss=15.96286392211914, pred_loss=[0.15812097, 0.6350584, 3.0646462]\n",
      "epoch=90_train_batch=42, total_loss=16.280439376831055, pred_loss=[0.43206596, 0.42736804, 3.3167572]\n",
      "epoch=90_train_batch=43, total_loss=12.63072395324707, pred_loss=[0.14372846, 0.15103295, 0.23250687]\n",
      "epoch=90_train_batch=44, total_loss=20.879730224609375, pred_loss=[0.047895174, 0.4096353, 8.31954]\n",
      "epoch=90_train_batch=45, total_loss=13.046762466430664, pred_loss=[0.29327202, 0.19274786, 0.45887744]\n",
      "epoch=90_train_batch=46, total_loss=13.388980865478516, pred_loss=[0.30163983, 0.60787463, 0.37839985]\n",
      "epoch=90_train_batch=47, total_loss=13.782249450683594, pred_loss=[0.4543213, 0.4176119, 0.8100474]\n",
      "epoch=90_train_batch=48, total_loss=14.783568382263184, pred_loss=[0.021076437, 0.42660022, 2.2363985]\n",
      "epoch=90_train_batch=49, total_loss=13.027220726013184, pred_loss=[0.33244056, 0.3384149, 0.25765336]\n",
      "epoch=90_train_batch=50, total_loss=14.050450325012207, pred_loss=[0.46354833, 0.48599935, 1.0029662]\n",
      "epoch=90_train_batch=51, total_loss=17.557056427001953, pred_loss=[0.12574503, 0.23620978, 5.0979285]\n",
      "epoch=90_train_batch=52, total_loss=13.582160949707031, pred_loss=[0.46934253, 0.19502553, 0.8213837]\n",
      "epoch=90_train_batch=53, total_loss=23.573596954345703, pred_loss=[1.236047, 0.19336852, 10.048536]\n",
      "epoch=90_train_batch=54, total_loss=14.119604110717773, pred_loss=[0.22039896, 1.0276893, 0.776577]\n",
      "epoch=90_train_batch=55, total_loss=18.677289962768555, pred_loss=[0.0036818439, 0.692257, 5.8870955]\n",
      "epoch=90_train_batch=56, total_loss=13.788491249084473, pred_loss=[0.51558506, 0.5753881, 0.60394037]\n",
      "epoch=90_train_batch=57, total_loss=13.871988296508789, pred_loss=[1.2861146, 0.2760701, 0.21688849]\n",
      "epoch=90_train_batch=58, total_loss=14.680399894714355, pred_loss=[0.22626726, 0.4169581, 1.944925]\n",
      "epoch=90_train_batch=59, total_loss=14.694694519042969, pred_loss=[0.5696364, 0.9110335, 1.1224319]\n",
      "epoch=90_train_batch=60, total_loss=18.111005783081055, pred_loss=[5.521415, 0.342506, 0.1561507]\n",
      "epoch=90_train_batch=61, total_loss=13.331570625305176, pred_loss=[0.7872329, 0.31956077, 0.13449258]\n",
      "epoch=90_train_batch=62, total_loss=14.209331512451172, pred_loss=[0.28200454, 0.37819302, 1.4594177]\n",
      "epoch=90_train_batch=63, total_loss=14.303253173828125, pred_loss=[0.5506721, 0.43076253, 1.2326041]\n",
      "epoch=90_train_batch=64, total_loss=12.787385940551758, pred_loss=[0.27794147, 0.34740272, 0.07328155]\n",
      "epoch=90_train_batch=65, total_loss=14.83102035522461, pred_loss=[1.366823, 0.3148015, 1.0610698]\n",
      "epoch=90_train_batch=66, total_loss=13.66295051574707, pred_loss=[0.44811663, 0.26680714, 0.8602313]\n",
      "epoch=90_train_batch=67, total_loss=28.28813362121582, pred_loss=[0.15113401, 0.57767326, 15.472039]\n",
      "epoch=90_train_batch=68, total_loss=12.77585506439209, pred_loss=[0.22637725, 0.3264724, 0.13621661]\n",
      "epoch=90_train_batch=69, total_loss=14.360311508178711, pred_loss=[0.6118868, 0.15492325, 1.5072073]\n",
      "epoch=90_train_batch=70, total_loss=13.795866012573242, pred_loss=[0.22113085, 0.6135271, 0.87542653]\n",
      "epoch=90_train_batch=71, total_loss=18.57835578918457, pred_loss=[0.3369018, 2.8553138, 3.3008761]\n",
      "epoch=90_train_batch=72, total_loss=12.975128173828125, pred_loss=[0.17751645, 0.33129668, 0.38157487]\n",
      "epoch=90_train_batch=73, total_loss=15.836393356323242, pred_loss=[0.22101425, 0.80024403, 2.730925]\n",
      "epoch=90_train_batch=74, total_loss=13.975234031677246, pred_loss=[0.5544708, 0.636907, 0.7001797]\n",
      "epoch=90_train_batch=75, total_loss=16.749862670898438, pred_loss=[0.10930237, 0.5657533, 3.991675]\n",
      "epoch=90_train_batch=76, total_loss=15.512582778930664, pred_loss=[0.38281164, 0.88795346, 2.1592462]\n",
      "epoch=90_train_batch=77, total_loss=13.989582061767578, pred_loss=[0.269173, 0.45502156, 1.1833905]\n",
      "epoch=90_train_batch=78, total_loss=15.389961242675781, pred_loss=[0.2647604, 0.6634596, 2.3803291]\n",
      "epoch=90_train_batch=79, total_loss=13.376640319824219, pred_loss=[0.13407755, 0.6038711, 0.55788124]\n",
      "epoch=90_train_batch=80, total_loss=27.850967407226562, pred_loss=[0.73767185, 2.4887347, 12.5443735]\n",
      "epoch=90_train_batch=81, total_loss=13.361297607421875, pred_loss=[0.28959787, 0.6024815, 0.38968053]\n",
      "epoch=90_train_batch=82, total_loss=13.095250129699707, pred_loss=[0.20367323, 0.46383637, 0.34885865]\n",
      "epoch=90_train_batch=83, total_loss=13.715466499328613, pred_loss=[0.1629878, 0.7829885, 0.691271]\n",
      "epoch=90_train_batch=84, total_loss=13.011541366577148, pred_loss=[0.16727541, 0.23416334, 0.53255486]\n",
      "epoch=90_train_batch=85, total_loss=13.845626831054688, pred_loss=[1.0229018, 0.20822392, 0.5376286]\n",
      "epoch=90_train_batch=86, total_loss=17.905303955078125, pred_loss=[0.028320761, 2.8561115, 2.944676]\n",
      "epoch=90_train_batch=87, total_loss=12.709810256958008, pred_loss=[0.2485545, 0.12757543, 0.25817215]\n",
      "epoch=90_val_batch=0, total_val_loss=721.3756103515625, pred_val_loss[0.25658038, 66.99494, 642.04926]\n",
      "epoch=90_val_batch=1, total_val_loss=219.716064453125, pred_val_loss[0.09966335, 119.06634, 88.475235]\n",
      "epoch=90_val_batch=2, total_val_loss=90.40583038330078, pred_val_loss[14.946985, 14.968573, 48.415455]\n",
      "epoch=90_val_batch=3, total_val_loss=120.56814575195312, pred_val_loss[6.5687637, 26.233307, 75.69125]\n",
      "epoch=90_val_batch=4, total_val_loss=100.31397247314453, pred_val_loss[5.671327, 40.016403, 42.551422]\n",
      "epoch=90_val_batch=5, total_val_loss=59.385719299316406, pred_val_loss[13.9796, 7.133851, 26.197445]\n",
      "epoch=90_val_batch=6, total_val_loss=223.710205078125, pred_val_loss[27.832275, 6.7929425, 177.01016]\n",
      "epoch=90_val_batch=7, total_val_loss=157.2041015625, pred_val_loss[0.70328707, 66.74744, 77.67854]\n",
      "epoch=90_val_batch=8, total_val_loss=59.65176773071289, pred_val_loss[0.46453753, 37.42304, 9.689369]\n",
      "epoch=90_val_batch=9, total_val_loss=104.91065979003906, pred_val_loss[1.2515502, 54.26216, 37.32213]\n",
      "epoch=90_val_batch=10, total_val_loss=143.86187744140625, pred_val_loss[38.052265, 7.9806347, 85.75414]\n",
      "epoch=90_val_batch=11, total_val_loss=192.47494506835938, pred_val_loss[21.129114, 70.2504, 89.02061]\n",
      "epoch=90_val_batch=12, total_val_loss=27.753311157226562, pred_val_loss[0.5136662, 5.3727617, 9.792061]\n",
      "epoch=90_val_batch=13, total_val_loss=110.99420928955078, pred_val_loss[0.33199802, 46.23804, 52.349346]\n",
      "epoch=90_val_batch=14, total_val_loss=110.56342315673828, pred_val_loss[11.602569, 46.07148, 40.814552]\n",
      "epoch=90_val_batch=15, total_val_loss=85.34581756591797, pred_val_loss[30.636625, 1.5226374, 41.111736]\n",
      "epoch=90_val_batch=16, total_val_loss=197.48587036132812, pred_val_loss[9.038789, 69.59329, 106.77896]\n",
      "epoch=90_val_batch=17, total_val_loss=152.4735107421875, pred_val_loss[11.504692, 21.166708, 107.72728]\n",
      "epoch=90_val_batch=18, total_val_loss=140.97860717773438, pred_val_loss[8.317175, 30.06227, 90.524345]\n",
      "epoch=90, train: avg_loss=14.85488510131836, val: avg_val_loss=158.9038543701172\n",
      "Saved checkpoint for step 101: ./tf_ckpts/ckpt-100\n",
      "epoch=91_train_batch=0, total_loss=13.55208683013916, pred_loss=[1.0117931, 0.2886482, 0.17682403]\n",
      "epoch=91_train_batch=1, total_loss=12.954996109008789, pred_loss=[0.1680353, 0.36713955, 0.34567523]\n",
      "epoch=91_train_batch=2, total_loss=16.719085693359375, pred_loss=[0.12288513, 1.8827176, 2.6400185]\n",
      "epoch=91_train_batch=3, total_loss=14.628283500671387, pred_loss=[0.061701775, 0.4544856, 2.0393348]\n",
      "epoch=91_train_batch=4, total_loss=12.861035346984863, pred_loss=[0.24228096, 0.19159214, 0.35510808]\n",
      "epoch=91_train_batch=5, total_loss=24.987295150756836, pred_loss=[0.26669753, 3.5415196, 9.107741]\n",
      "epoch=91_train_batch=6, total_loss=14.430047035217285, pred_loss=[0.76818717, 0.2800609, 1.3111947]\n",
      "epoch=91_train_batch=7, total_loss=14.456925392150879, pred_loss=[0.16263294, 0.8822875, 1.3420995]\n",
      "epoch=91_train_batch=8, total_loss=13.711945533752441, pred_loss=[0.90662855, 0.19852419, 0.5375949]\n",
      "epoch=91_train_batch=9, total_loss=13.713340759277344, pred_loss=[0.37169304, 1.0750958, 0.19806956]\n",
      "epoch=91_train_batch=10, total_loss=13.984885215759277, pred_loss=[0.17892507, 0.39113113, 1.3470755]\n",
      "epoch=91_train_batch=11, total_loss=13.819573402404785, pred_loss=[0.33961225, 0.4115817, 1.0013562]\n",
      "epoch=91_train_batch=12, total_loss=13.425054550170898, pred_loss=[0.4499917, 0.2864836, 0.6222927]\n",
      "epoch=91_train_batch=13, total_loss=12.886919021606445, pred_loss=[0.16220833, 0.32313013, 0.33601195]\n",
      "epoch=91_train_batch=14, total_loss=13.988415718078613, pred_loss=[0.7209958, 0.8910009, 0.3115772]\n",
      "epoch=91_train_batch=15, total_loss=13.476713180541992, pred_loss=[0.6283549, 0.0869555, 0.69729185]\n",
      "epoch=91_train_batch=16, total_loss=13.131596565246582, pred_loss=[0.45811945, 0.2693467, 0.3407609]\n",
      "epoch=91_train_batch=17, total_loss=13.621002197265625, pred_loss=[0.24452445, 0.36985403, 0.94399947]\n",
      "epoch=91_train_batch=18, total_loss=13.829399108886719, pred_loss=[0.037441228, 0.9904382, 0.7396492]\n",
      "epoch=91_train_batch=19, total_loss=12.971444129943848, pred_loss=[0.19668666, 0.31239957, 0.40124995]\n",
      "epoch=91_train_batch=20, total_loss=14.4170560836792, pred_loss=[0.24193463, 0.33070236, 1.7840803]\n",
      "epoch=91_train_batch=21, total_loss=13.543193817138672, pred_loss=[0.24579233, 0.66242176, 0.57542634]\n",
      "epoch=91_train_batch=22, total_loss=20.366363525390625, pred_loss=[0.11889841, 0.10868002, 8.080026]\n",
      "epoch=91_train_batch=23, total_loss=13.409076690673828, pred_loss=[0.076478295, 0.7910852, 0.48355967]\n",
      "epoch=91_train_batch=24, total_loss=13.350874900817871, pred_loss=[0.5565612, 0.22480382, 0.5123616]\n",
      "epoch=91_train_batch=25, total_loss=13.468612670898438, pred_loss=[0.24137866, 0.34690207, 0.8239857]\n",
      "epoch=91_train_batch=26, total_loss=12.926689147949219, pred_loss=[0.4685877, 0.22671439, 0.17584449]\n",
      "epoch=91_train_batch=27, total_loss=13.102797508239746, pred_loss=[0.18750171, 0.5254128, 0.3351668]\n",
      "epoch=91_train_batch=28, total_loss=12.967986106872559, pred_loss=[0.26397222, 0.14341006, 0.5067153]\n",
      "epoch=91_train_batch=29, total_loss=13.515825271606445, pred_loss=[0.37061432, 0.13862081, 0.9535302]\n",
      "epoch=91_train_batch=30, total_loss=13.548693656921387, pred_loss=[0.085180424, 0.4335925, 0.9776882]\n",
      "epoch=91_train_batch=31, total_loss=13.149781227111816, pred_loss=[0.14870915, 0.34219924, 0.6074707]\n",
      "epoch=91_train_batch=32, total_loss=22.047138214111328, pred_loss=[1.3317739, 1.9074159, 6.757378]\n",
      "epoch=91_train_batch=33, total_loss=13.06244945526123, pred_loss=[0.06922312, 0.3727076, 0.57071316]\n",
      "epoch=91_train_batch=34, total_loss=13.042637825012207, pred_loss=[0.0900474, 0.5312077, 0.37233886]\n",
      "epoch=91_train_batch=35, total_loss=12.935510635375977, pred_loss=[0.2180252, 0.25588968, 0.4133098]\n",
      "epoch=91_train_batch=36, total_loss=13.68381118774414, pred_loss=[0.0046447474, 0.7042674, 0.9273665]\n",
      "epoch=91_train_batch=37, total_loss=12.884981155395508, pred_loss=[0.22175986, 0.1732359, 0.44321296]\n",
      "epoch=91_train_batch=38, total_loss=13.598894119262695, pred_loss=[0.43341967, 0.3113739, 0.808087]\n",
      "epoch=91_train_batch=39, total_loss=13.052620887756348, pred_loss=[0.5113782, 0.2546348, 0.24136673]\n",
      "epoch=91_train_batch=40, total_loss=13.002912521362305, pred_loss=[0.36874014, 0.25042078, 0.33929253]\n",
      "epoch=91_train_batch=41, total_loss=13.932098388671875, pred_loss=[0.26331478, 0.17620511, 1.4489086]\n",
      "epoch=91_train_batch=42, total_loss=13.026488304138184, pred_loss=[0.29028207, 0.34580368, 0.3475272]\n",
      "epoch=91_train_batch=43, total_loss=13.451438903808594, pred_loss=[0.4144528, 0.82821333, 0.16669805]\n",
      "epoch=91_train_batch=44, total_loss=13.511415481567383, pred_loss=[0.23677896, 0.2257137, 1.0076786]\n",
      "epoch=91_train_batch=45, total_loss=18.873714447021484, pred_loss=[0.16222739, 0.3903807, 6.28069]\n",
      "epoch=91_train_batch=46, total_loss=12.962120056152344, pred_loss=[0.16209719, 0.280815, 0.47961366]\n",
      "epoch=91_train_batch=47, total_loss=14.00128173828125, pred_loss=[0.49261293, 0.45830357, 1.0115931]\n",
      "epoch=91_train_batch=48, total_loss=15.292427062988281, pred_loss=[0.25871497, 0.625486, 2.3702693]\n",
      "epoch=91_train_batch=49, total_loss=12.833868980407715, pred_loss=[0.09143631, 0.4713082, 0.23398562]\n",
      "epoch=91_train_batch=50, total_loss=13.949014663696289, pred_loss=[0.16761285, 0.48389706, 1.2611821]\n",
      "epoch=91_train_batch=51, total_loss=13.951763153076172, pred_loss=[0.17109133, 0.5552886, 1.1898738]\n",
      "epoch=91_train_batch=52, total_loss=13.053230285644531, pred_loss=[0.23112097, 0.29567748, 0.4917387]\n",
      "epoch=91_train_batch=53, total_loss=12.62741756439209, pred_loss=[0.115811296, 0.2143824, 0.26334915]\n",
      "epoch=91_train_batch=54, total_loss=12.737364768981934, pred_loss=[0.27001145, 0.2593857, 0.17491521]\n",
      "epoch=91_train_batch=55, total_loss=12.826705932617188, pred_loss=[0.08904442, 0.3834566, 0.3219859]\n",
      "epoch=91_train_batch=56, total_loss=13.024445533752441, pred_loss=[0.070354976, 0.6796882, 0.24301997]\n",
      "epoch=91_train_batch=57, total_loss=14.17000675201416, pred_loss=[0.095747575, 0.5989608, 1.4447572]\n",
      "epoch=91_train_batch=58, total_loss=13.693557739257812, pred_loss=[0.05855547, 0.23374142, 1.3715647]\n",
      "epoch=91_train_batch=59, total_loss=13.151611328125, pred_loss=[0.16974302, 0.45888257, 0.49413222]\n",
      "epoch=91_train_batch=60, total_loss=12.826375007629395, pred_loss=[0.45639932, 0.10097101, 0.24099775]\n",
      "epoch=91_train_batch=61, total_loss=12.867764472961426, pred_loss=[0.15914762, 0.5490855, 0.13237068]\n",
      "epoch=91_train_batch=62, total_loss=14.0450439453125, pred_loss=[0.23189689, 0.7383845, 1.0484507]\n",
      "epoch=91_train_batch=63, total_loss=13.618315696716309, pred_loss=[0.18435988, 0.701052, 0.70744133]\n",
      "epoch=91_train_batch=64, total_loss=14.53099250793457, pred_loss=[0.0581218, 0.3965916, 2.0516686]\n",
      "epoch=91_train_batch=65, total_loss=12.911431312561035, pred_loss=[0.19605984, 0.44265538, 0.24896143]\n",
      "epoch=91_train_batch=66, total_loss=13.1162748336792, pred_loss=[0.3853125, 0.12875527, 0.5793077]\n",
      "epoch=91_train_batch=67, total_loss=26.631507873535156, pred_loss=[0.05382148, 2.2990842, 12.256553]\n",
      "epoch=91_train_batch=68, total_loss=13.802111625671387, pred_loss=[0.012413055, 1.3332413, 0.4352516]\n",
      "epoch=91_train_batch=69, total_loss=14.145376205444336, pred_loss=[2.0457034, 0.020328533, 0.058981754]\n",
      "epoch=91_train_batch=70, total_loss=12.836071014404297, pred_loss=[0.20736793, 0.4482302, 0.1610224]\n",
      "epoch=91_train_batch=71, total_loss=13.190479278564453, pred_loss=[0.05855836, 0.5887302, 0.5246188]\n",
      "epoch=91_train_batch=72, total_loss=13.555864334106445, pred_loss=[0.294394, 0.21057951, 1.0331743]\n",
      "epoch=91_train_batch=73, total_loss=15.229408264160156, pred_loss=[0.23800439, 0.43368006, 2.5408444]\n",
      "epoch=91_train_batch=74, total_loss=13.372172355651855, pred_loss=[0.62269646, 0.5151979, 0.21822849]\n",
      "epoch=91_train_batch=75, total_loss=22.15489959716797, pred_loss=[0.12903634, 2.1275344, 7.883109]\n",
      "epoch=91_train_batch=76, total_loss=14.021476745605469, pred_loss=[0.30104244, 0.31228858, 1.3937511]\n",
      "epoch=91_train_batch=77, total_loss=13.20296573638916, pred_loss=[0.32396254, 0.18748787, 0.6779468]\n",
      "epoch=91_train_batch=78, total_loss=12.674074172973633, pred_loss=[0.42164093, 0.097131394, 0.1425511]\n",
      "epoch=91_train_batch=79, total_loss=13.289478302001953, pred_loss=[0.36129856, 0.31866384, 0.5975658]\n",
      "epoch=91_train_batch=80, total_loss=14.095617294311523, pred_loss=[0.34691006, 0.72905195, 1.0085022]\n",
      "epoch=91_train_batch=81, total_loss=13.961324691772461, pred_loss=[0.4405995, 1.1623431, 0.3480199]\n",
      "epoch=91_train_batch=82, total_loss=12.96140193939209, pred_loss=[0.42110196, 0.20159529, 0.32913008]\n",
      "epoch=91_train_batch=83, total_loss=13.848419189453125, pred_loss=[0.069369845, 0.32813317, 1.4421083]\n",
      "epoch=91_train_batch=84, total_loss=12.936588287353516, pred_loss=[0.33022147, 0.46458834, 0.13373864]\n",
      "epoch=91_train_batch=85, total_loss=15.013604164123535, pred_loss=[0.13170794, 0.40258908, 2.4720373]\n",
      "epoch=91_train_batch=86, total_loss=13.3748779296875, pred_loss=[0.29437488, 0.47764868, 0.59635717]\n",
      "epoch=91_train_batch=87, total_loss=12.437077522277832, pred_loss=[0.3566473, 0.04989438, 0.024815153]\n",
      "epoch=91_val_batch=0, total_val_loss=729.9009399414062, pred_val_loss[0.20638166, 65.946785, 651.7428]\n",
      "epoch=91_val_batch=1, total_val_loss=216.70962524414062, pred_val_loss[0.039625473, 116.65529, 88.00977]\n",
      "epoch=91_val_batch=2, total_val_loss=94.38140106201172, pred_val_loss[13.287093, 16.353231, 52.73614]\n",
      "epoch=91_val_batch=3, total_val_loss=125.8371810913086, pred_val_loss[5.106208, 26.657875, 82.06816]\n",
      "epoch=91_val_batch=4, total_val_loss=94.69281768798828, pred_val_loss[4.2284245, 40.417206, 38.04225]\n",
      "epoch=91_val_batch=5, total_val_loss=58.574893951416016, pred_val_loss[17.006046, 6.012915, 23.550995]\n",
      "epoch=91_val_batch=6, total_val_loss=223.0107421875, pred_val_loss[25.644812, 5.2276793, 180.13332]\n",
      "epoch=91_val_batch=7, total_val_loss=155.26634216308594, pred_val_loss[0.6581871, 66.23036, 76.37285]\n",
      "epoch=91_val_batch=8, total_val_loss=56.42197036743164, pred_val_loss[0.42931968, 30.591759, 13.395952]\n",
      "epoch=91_val_batch=9, total_val_loss=107.31670379638672, pred_val_loss[1.1252364, 56.895298, 37.291237]\n",
      "epoch=91_val_batch=10, total_val_loss=135.4979248046875, pred_val_loss[31.690407, 5.100487, 86.70209]\n",
      "epoch=91_val_batch=11, total_val_loss=172.4463348388672, pred_val_loss[16.668137, 60.552746, 83.220505]\n",
      "epoch=91_val_batch=12, total_val_loss=26.736236572265625, pred_val_loss[0.9535702, 5.2408757, 8.536851]\n",
      "epoch=91_val_batch=13, total_val_loss=102.06302642822266, pred_val_loss[0.3134787, 41.625843, 48.118767]\n",
      "epoch=91_val_batch=14, total_val_loss=107.69921112060547, pred_val_loss[11.340801, 43.446335, 40.907135]\n",
      "epoch=91_val_batch=15, total_val_loss=78.88628387451172, pred_val_loss[22.197187, 1.2549171, 43.429245]\n",
      "epoch=91_val_batch=16, total_val_loss=210.13058471679688, pred_val_loss[11.678953, 73.01698, 113.4297]\n",
      "epoch=91_val_batch=17, total_val_loss=165.59165954589844, pred_val_loss[13.918634, 15.478957, 124.189125]\n",
      "epoch=91_val_batch=18, total_val_loss=137.2491455078125, pred_val_loss[4.271089, 29.49329, 91.47983]\n",
      "epoch=91, train: avg_loss=14.135782241821289, val: avg_val_loss=157.81121826171875\n",
      "Saved checkpoint for step 102: ./tf_ckpts/ckpt-101\n",
      "epoch=92_train_batch=0, total_loss=14.850772857666016, pred_loss=[0.27489543, 0.3552104, 2.2157283]\n",
      "epoch=92_train_batch=1, total_loss=12.762179374694824, pred_loss=[0.25663796, 0.314138, 0.1872469]\n",
      "epoch=92_train_batch=2, total_loss=13.807144165039062, pred_loss=[0.25685424, 0.63471466, 0.9122071]\n",
      "epoch=92_train_batch=3, total_loss=13.300098419189453, pred_loss=[0.059470676, 0.26954466, 0.9685067]\n",
      "epoch=92_train_batch=4, total_loss=13.37639331817627, pred_loss=[0.2771143, 0.3418765, 0.7556204]\n",
      "epoch=92_train_batch=5, total_loss=15.274351119995117, pred_loss=[2.5542157, 0.3574474, 0.36170605]\n",
      "epoch=92_train_batch=6, total_loss=13.04848861694336, pred_loss=[0.33937353, 0.17240836, 0.5363821]\n",
      "epoch=92_train_batch=7, total_loss=13.0540771484375, pred_loss=[0.07614993, 0.3214111, 0.6568093]\n",
      "epoch=92_train_batch=8, total_loss=13.25565242767334, pred_loss=[0.24676034, 0.16597958, 0.8438051]\n",
      "epoch=92_train_batch=9, total_loss=13.996949195861816, pred_loss=[0.13529336, 0.43268085, 1.4304547]\n",
      "epoch=92_train_batch=10, total_loss=12.962471008300781, pred_loss=[0.07856329, 0.42685676, 0.45912194]\n",
      "epoch=92_train_batch=11, total_loss=13.010154724121094, pred_loss=[0.33730385, 0.3966576, 0.27886653]\n",
      "epoch=92_train_batch=12, total_loss=12.568641662597656, pred_loss=[0.33903205, 0.068210475, 0.16468342]\n",
      "epoch=92_train_batch=13, total_loss=12.892203330993652, pred_loss=[0.22674936, 0.1998235, 0.4695502]\n",
      "epoch=92_train_batch=14, total_loss=12.774606704711914, pred_loss=[0.1596637, 0.24097288, 0.37854385]\n",
      "epoch=92_train_batch=15, total_loss=22.60995101928711, pred_loss=[0.19890404, 0.24574964, 10.170541]\n",
      "epoch=92_train_batch=16, total_loss=16.327661514282227, pred_loss=[0.19465044, 0.774833, 3.3641047]\n",
      "epoch=92_train_batch=17, total_loss=12.673501968383789, pred_loss=[0.3988101, 0.18889341, 0.09242429]\n",
      "epoch=92_train_batch=18, total_loss=19.912086486816406, pred_loss=[2.1078913, 0.076208, 5.7353387]\n",
      "epoch=92_train_batch=19, total_loss=13.441987991333008, pred_loss=[0.4110824, 0.07084681, 0.9682015]\n",
      "epoch=92_train_batch=20, total_loss=12.785110473632812, pred_loss=[0.19745037, 0.09820414, 0.49831787]\n",
      "epoch=92_train_batch=21, total_loss=16.892284393310547, pred_loss=[0.28484136, 2.1038237, 2.5131488]\n",
      "epoch=92_train_batch=22, total_loss=13.955816268920898, pred_loss=[1.5112928, 0.17584136, 0.27882868]\n",
      "epoch=92_train_batch=23, total_loss=12.842432022094727, pred_loss=[0.24006337, 0.39575183, 0.21742252]\n",
      "epoch=92_train_batch=24, total_loss=13.418527603149414, pred_loss=[0.117028736, 0.75316864, 0.559767]\n",
      "epoch=92_train_batch=25, total_loss=13.154561996459961, pred_loss=[0.07663072, 0.21634758, 0.87363577]\n",
      "epoch=92_train_batch=26, total_loss=12.607481002807617, pred_loss=[0.28267232, 0.27681208, 0.060653757]\n",
      "epoch=92_train_batch=27, total_loss=13.339212417602539, pred_loss=[0.54890996, 0.25449684, 0.5490724]\n",
      "epoch=92_train_batch=28, total_loss=13.314823150634766, pred_loss=[0.64293003, 0.39802995, 0.28774315]\n",
      "epoch=92_train_batch=29, total_loss=12.986347198486328, pred_loss=[0.3897819, 0.24843207, 0.36259967]\n",
      "epoch=92_train_batch=30, total_loss=14.201910018920898, pred_loss=[0.38693872, 0.26523983, 1.5647908]\n",
      "epoch=92_train_batch=31, total_loss=16.32077980041504, pred_loss=[0.29037613, 2.0266685, 2.019393]\n",
      "epoch=92_train_batch=32, total_loss=12.721231460571289, pred_loss=[0.0940648, 0.5152103, 0.12823132]\n",
      "epoch=92_train_batch=33, total_loss=13.151642799377441, pred_loss=[0.16447878, 0.37629452, 0.6277759]\n",
      "epoch=92_train_batch=34, total_loss=12.695136070251465, pred_loss=[0.3032041, 0.23005265, 0.17943197]\n",
      "epoch=92_train_batch=35, total_loss=14.46744155883789, pred_loss=[1.9328132, 0.22714502, 0.32569435]\n",
      "epoch=92_train_batch=36, total_loss=13.359922409057617, pred_loss=[0.24220103, 0.49225658, 0.64429474]\n",
      "epoch=92_train_batch=37, total_loss=20.364425659179688, pred_loss=[0.6121175, 1.3067296, 6.4650335]\n",
      "epoch=92_train_batch=38, total_loss=13.577103614807129, pred_loss=[0.86666965, 0.11268379, 0.6178491]\n",
      "epoch=92_train_batch=39, total_loss=13.06533432006836, pred_loss=[0.4197389, 0.024959764, 0.6413774]\n",
      "epoch=92_train_batch=40, total_loss=12.824828147888184, pred_loss=[0.22377476, 0.42396432, 0.19847645]\n",
      "epoch=92_train_batch=41, total_loss=12.90947151184082, pred_loss=[0.41541588, 0.3200028, 0.19609554]\n",
      "epoch=92_train_batch=42, total_loss=15.895654678344727, pred_loss=[0.4487242, 0.1529051, 3.3167305]\n",
      "epoch=92_train_batch=43, total_loss=12.774316787719727, pred_loss=[0.27227354, 0.3148121, 0.21060394]\n",
      "epoch=92_train_batch=44, total_loss=13.965497970581055, pred_loss=[0.09119066, 0.49230242, 1.4060497]\n",
      "epoch=92_train_batch=45, total_loss=14.06106185913086, pred_loss=[0.23324604, 0.32106653, 1.5314763]\n",
      "epoch=92_train_batch=46, total_loss=12.576549530029297, pred_loss=[0.13594034, 0.33108854, 0.13494511]\n",
      "epoch=92_train_batch=47, total_loss=14.068704605102539, pred_loss=[0.15496029, 0.68409175, 1.2557868]\n",
      "epoch=92_train_batch=48, total_loss=13.042278289794922, pred_loss=[0.14027098, 0.58764017, 0.34122616]\n",
      "epoch=92_train_batch=49, total_loss=12.465872764587402, pred_loss=[0.2767933, 0.16180843, 0.05486828]\n",
      "epoch=92_train_batch=50, total_loss=19.278366088867188, pred_loss=[0.22456811, 0.16045971, 6.9216824]\n",
      "epoch=92_train_batch=51, total_loss=13.130212783813477, pred_loss=[0.50655174, 0.13934863, 0.51341283]\n",
      "epoch=92_train_batch=52, total_loss=13.216148376464844, pred_loss=[0.113166206, 0.6073077, 0.5255392]\n",
      "epoch=92_train_batch=53, total_loss=13.609838485717773, pred_loss=[0.049329244, 0.3400452, 1.2511013]\n",
      "epoch=92_train_batch=54, total_loss=12.635894775390625, pred_loss=[0.15781188, 0.10980479, 0.39969417]\n",
      "epoch=92_train_batch=55, total_loss=12.802083969116211, pred_loss=[0.14757077, 0.47997108, 0.20674366]\n",
      "epoch=92_train_batch=56, total_loss=13.33786678314209, pred_loss=[0.6567899, 0.513115, 0.20094727]\n",
      "epoch=92_train_batch=57, total_loss=13.221700668334961, pred_loss=[0.25280824, 0.21166268, 0.7910043]\n",
      "epoch=92_train_batch=58, total_loss=13.208477020263672, pred_loss=[0.5858129, 0.2936305, 0.36360282]\n",
      "epoch=92_train_batch=59, total_loss=15.32905387878418, pred_loss=[0.2297297, 0.18711203, 2.9475625]\n",
      "epoch=92_train_batch=60, total_loss=12.97492504119873, pred_loss=[0.059563797, 0.4007029, 0.55079675]\n",
      "epoch=92_train_batch=61, total_loss=13.245336532592773, pred_loss=[0.4937982, 0.19985574, 0.58861667]\n",
      "epoch=92_train_batch=62, total_loss=15.322869300842285, pred_loss=[0.22826146, 0.68203694, 2.4503193]\n",
      "epoch=92_train_batch=63, total_loss=13.042070388793945, pred_loss=[0.22362812, 0.29026836, 0.56674004]\n",
      "epoch=92_train_batch=64, total_loss=12.91213321685791, pred_loss=[0.16222057, 0.22445726, 0.5648446]\n",
      "epoch=92_train_batch=65, total_loss=13.269054412841797, pred_loss=[0.50353503, 0.49423152, 0.311503]\n",
      "epoch=92_train_batch=66, total_loss=13.385992050170898, pred_loss=[0.05506121, 0.18278399, 1.1891948]\n",
      "epoch=92_train_batch=67, total_loss=14.147699356079102, pred_loss=[0.21618398, 0.35680753, 1.616589]\n",
      "epoch=92_train_batch=68, total_loss=14.157210350036621, pred_loss=[0.48255178, 0.47368404, 1.2436888]\n",
      "epoch=92_train_batch=69, total_loss=13.182828903198242, pred_loss=[0.08054891, 0.8250652, 0.32076034]\n",
      "epoch=92_train_batch=70, total_loss=13.676593780517578, pred_loss=[0.17687654, 0.18943548, 1.3546561]\n",
      "epoch=92_train_batch=71, total_loss=12.758127212524414, pred_loss=[0.1657588, 0.4091787, 0.22839102]\n",
      "epoch=92_train_batch=72, total_loss=13.057446479797363, pred_loss=[0.37091282, 0.24989837, 0.48266637]\n",
      "epoch=92_train_batch=73, total_loss=13.213640213012695, pred_loss=[0.27738196, 0.15408139, 0.8290297]\n",
      "epoch=92_train_batch=74, total_loss=12.61794376373291, pred_loss=[0.1994992, 0.2874795, 0.17864121]\n",
      "epoch=92_train_batch=75, total_loss=12.855666160583496, pred_loss=[0.13035622, 0.38633662, 0.38747972]\n",
      "epoch=92_train_batch=76, total_loss=12.608236312866211, pred_loss=[0.16337928, 0.24409355, 0.25010988]\n",
      "epoch=92_train_batch=77, total_loss=13.643291473388672, pred_loss=[0.37018102, 0.7462198, 0.57708794]\n",
      "epoch=92_train_batch=78, total_loss=13.5672025680542, pred_loss=[0.32577693, 0.27950394, 1.012977]\n",
      "epoch=92_train_batch=79, total_loss=12.828516006469727, pred_loss=[0.2077229, 0.11482303, 0.5578946]\n",
      "epoch=92_train_batch=80, total_loss=12.836624145507812, pred_loss=[0.28233713, 0.27979338, 0.327291]\n",
      "epoch=92_train_batch=81, total_loss=17.49896240234375, pred_loss=[0.02600812, 2.2506895, 3.2759223]\n",
      "epoch=92_train_batch=82, total_loss=12.641316413879395, pred_loss=[0.151406, 0.3105077, 0.23391834]\n",
      "epoch=92_train_batch=83, total_loss=13.499034881591797, pred_loss=[0.09395421, 0.45551664, 1.0049397]\n",
      "epoch=92_train_batch=84, total_loss=13.285252571105957, pred_loss=[0.15790395, 0.44653624, 0.7370471]\n",
      "epoch=92_train_batch=85, total_loss=12.534587860107422, pred_loss=[0.27375367, 0.1938693, 0.12406212]\n",
      "epoch=92_train_batch=86, total_loss=13.076788902282715, pred_loss=[0.42911002, 0.45837766, 0.24726565]\n",
      "epoch=92_train_batch=87, total_loss=12.401599884033203, pred_loss=[0.09598386, 0.052299008, 0.31215057]\n",
      "epoch=92_val_batch=0, total_val_loss=771.1371459960938, pred_val_loss[0.055794537, 66.739426, 692.4016]\n",
      "epoch=92_val_batch=1, total_val_loss=218.54815673828125, pred_val_loss[0.107302494, 111.598305, 94.90226]\n",
      "epoch=92_val_batch=2, total_val_loss=99.27825927734375, pred_val_loss[15.376736, 17.308609, 54.652615]\n",
      "epoch=92_val_batch=3, total_val_loss=127.02140808105469, pred_val_loss[2.2382677, 27.392288, 85.450554]\n",
      "epoch=92_val_batch=4, total_val_loss=102.09027099609375, pred_val_loss[6.82663, 38.619545, 44.703796]\n",
      "epoch=92_val_batch=5, total_val_loss=61.57465362548828, pred_val_loss[15.403104, 7.2621408, 26.969112]\n",
      "epoch=92_val_batch=6, total_val_loss=228.14578247070312, pred_val_loss[22.966734, 4.861507, 188.37724]\n",
      "epoch=92_val_batch=7, total_val_loss=161.51980590820312, pred_val_loss[0.43863133, 64.54965, 84.59123]\n",
      "epoch=92_val_batch=8, total_val_loss=55.29137420654297, pred_val_loss[0.24282433, 28.271406, 14.836847]\n",
      "epoch=92_val_batch=9, total_val_loss=116.99342346191406, pred_val_loss[5.4029255, 58.005547, 41.644657]\n",
      "epoch=92_val_batch=10, total_val_loss=146.8973846435547, pred_val_loss[39.644974, 5.702986, 89.60912]\n",
      "epoch=92_val_batch=11, total_val_loss=164.9541015625, pred_val_loss[12.710617, 54.193336, 86.109856]\n",
      "epoch=92_val_batch=12, total_val_loss=27.47797393798828, pred_val_loss[1.44508, 6.839348, 7.2532496]\n",
      "epoch=92_val_batch=13, total_val_loss=102.26835632324219, pred_val_loss[0.23850021, 38.279938, 51.80963]\n",
      "epoch=92_val_batch=14, total_val_loss=108.01399230957031, pred_val_loss[11.49437, 40.81608, 43.763252]\n",
      "epoch=92_val_batch=15, total_val_loss=88.96528625488281, pred_val_loss[28.295403, 0.6959803, 48.03361]\n",
      "epoch=92_val_batch=16, total_val_loss=213.92225646972656, pred_val_loss[12.911335, 72.51138, 116.55925]\n",
      "epoch=92_val_batch=17, total_val_loss=164.80128479003906, pred_val_loss[11.1862545, 12.182337, 129.4924]\n",
      "epoch=92_val_batch=18, total_val_loss=147.7871856689453, pred_val_loss[7.75054, 27.622467, 100.47389]\n",
      "epoch=92, train: avg_loss=13.792223930358887, val: avg_val_loss=163.5098876953125\n",
      "Saved checkpoint for step 103: ./tf_ckpts/ckpt-102\n",
      "epoch=93_train_batch=0, total_loss=12.727951049804688, pred_loss=[0.06447867, 0.21194495, 0.5112312]\n",
      "epoch=93_train_batch=1, total_loss=12.599282264709473, pred_loss=[0.26081204, 0.18823084, 0.21081477]\n",
      "epoch=93_train_batch=2, total_loss=13.114747047424316, pred_loss=[0.32945994, 0.23992202, 0.6068169]\n",
      "epoch=93_train_batch=3, total_loss=13.776484489440918, pred_loss=[0.046949055, 1.4162784, 0.3755958]\n",
      "epoch=93_train_batch=4, total_loss=16.96453857421875, pred_loss=[0.23795989, 0.21547037, 4.5743394]\n",
      "epoch=93_train_batch=5, total_loss=13.429061889648438, pred_loss=[0.62441427, 0.26432866, 0.6044256]\n",
      "epoch=93_train_batch=6, total_loss=13.456741333007812, pred_loss=[0.26789036, 0.5082601, 0.7455685]\n",
      "epoch=93_train_batch=7, total_loss=13.49970817565918, pred_loss=[0.16642234, 0.4614973, 0.9376307]\n",
      "epoch=93_train_batch=8, total_loss=15.320720672607422, pred_loss=[0.71419734, 0.4601879, 2.2130392]\n",
      "epoch=93_train_batch=9, total_loss=12.961429595947266, pred_loss=[0.2701344, 0.3175363, 0.44132918]\n",
      "epoch=93_train_batch=10, total_loss=17.613677978515625, pred_loss=[0.22438608, 1.5751965, 3.882527]\n",
      "epoch=93_train_batch=11, total_loss=12.973803520202637, pred_loss=[0.1781354, 0.29078206, 0.5741825]\n",
      "epoch=93_train_batch=12, total_loss=13.002063751220703, pred_loss=[0.19728968, 0.3260958, 0.5488344]\n",
      "epoch=93_train_batch=13, total_loss=15.035453796386719, pred_loss=[0.13200346, 0.85839725, 2.1160674]\n",
      "epoch=93_train_batch=14, total_loss=13.164196968078613, pred_loss=[0.13349724, 0.45771992, 0.6448532]\n",
      "epoch=93_train_batch=15, total_loss=12.95810604095459, pred_loss=[0.011008446, 0.51535, 0.50448626]\n",
      "epoch=93_train_batch=16, total_loss=13.179499626159668, pred_loss=[0.21699882, 0.503629, 0.5324791]\n",
      "epoch=93_train_batch=17, total_loss=14.922036170959473, pred_loss=[1.9071909, 0.5400478, 0.5492727]\n",
      "epoch=93_train_batch=18, total_loss=13.23210620880127, pred_loss=[0.5993862, 0.08575636, 0.6223879]\n",
      "epoch=93_train_batch=19, total_loss=13.582658767700195, pred_loss=[0.16342159, 1.0424569, 0.45311257]\n",
      "epoch=93_train_batch=20, total_loss=12.528754234313965, pred_loss=[0.19078693, 0.18546893, 0.22970144]\n",
      "epoch=93_train_batch=21, total_loss=13.400633811950684, pred_loss=[0.07724695, 0.21078761, 1.1906385]\n",
      "epoch=93_train_batch=22, total_loss=14.013343811035156, pred_loss=[0.12239823, 0.13226715, 1.837536]\n",
      "epoch=93_train_batch=23, total_loss=13.245063781738281, pred_loss=[0.9225552, 0.2396726, 0.1624952]\n",
      "epoch=93_train_batch=24, total_loss=13.264698028564453, pred_loss=[0.08856748, 0.5905736, 0.6659958]\n",
      "epoch=93_train_batch=25, total_loss=12.860950469970703, pred_loss=[0.20050994, 0.61270916, 0.12894595]\n",
      "epoch=93_train_batch=26, total_loss=12.992456436157227, pred_loss=[0.16733764, 0.415812, 0.4912915]\n",
      "epoch=93_train_batch=27, total_loss=13.223076820373535, pred_loss=[0.7260909, 0.36104035, 0.21869774]\n",
      "epoch=93_train_batch=28, total_loss=15.855385780334473, pred_loss=[0.36201137, 0.23024018, 3.346654]\n",
      "epoch=93_train_batch=29, total_loss=13.299342155456543, pred_loss=[0.14891352, 0.77889067, 0.4558255]\n",
      "epoch=93_train_batch=30, total_loss=13.069461822509766, pred_loss=[0.098764196, 0.41051805, 0.64523727]\n",
      "epoch=93_train_batch=31, total_loss=12.703878402709961, pred_loss=[0.39311486, 0.08452603, 0.3120715]\n",
      "epoch=93_train_batch=32, total_loss=12.934664726257324, pred_loss=[0.43407947, 0.21848454, 0.36870426]\n",
      "epoch=93_train_batch=33, total_loss=12.57894515991211, pred_loss=[0.35786533, 0.1908641, 0.11759563]\n",
      "epoch=93_train_batch=34, total_loss=12.941815376281738, pred_loss=[0.10470558, 0.3648792, 0.5603939]\n",
      "epoch=93_train_batch=35, total_loss=14.038337707519531, pred_loss=[1.4145724, 0.17028956, 0.5424273]\n",
      "epoch=93_train_batch=36, total_loss=12.823657989501953, pred_loss=[0.12087313, 0.68835926, 0.104070015]\n",
      "epoch=93_train_batch=37, total_loss=13.02172565460205, pred_loss=[0.03739688, 0.32607317, 0.74857926]\n",
      "epoch=93_train_batch=38, total_loss=13.058892250061035, pred_loss=[0.07736015, 0.103304535, 0.96922225]\n",
      "epoch=93_train_batch=39, total_loss=13.5635347366333, pred_loss=[0.062516324, 0.33256257, 1.2601246]\n",
      "epoch=93_train_batch=40, total_loss=12.596365928649902, pred_loss=[0.335998, 0.24513552, 0.107580245]\n",
      "epoch=93_train_batch=41, total_loss=12.84814739227295, pred_loss=[0.024512187, 0.51002717, 0.40664208]\n",
      "epoch=93_train_batch=42, total_loss=13.934189796447754, pred_loss=[0.036260657, 0.7344549, 1.257205]\n",
      "epoch=93_train_batch=43, total_loss=13.404574394226074, pred_loss=[0.112522624, 0.5407925, 0.84570146]\n",
      "epoch=93_train_batch=44, total_loss=15.570378303527832, pred_loss=[0.26430324, 0.3359921, 3.065248]\n",
      "epoch=93_train_batch=45, total_loss=13.010201454162598, pred_loss=[0.3689546, 0.21067908, 0.5264652]\n",
      "epoch=93_train_batch=46, total_loss=13.09682559967041, pred_loss=[0.5594916, 0.44936216, 0.1846163]\n",
      "epoch=93_train_batch=47, total_loss=13.15626049041748, pred_loss=[0.48985332, 0.189234, 0.5745951]\n",
      "epoch=93_train_batch=48, total_loss=14.883997917175293, pred_loss=[0.00504205, 0.68845326, 2.2887092]\n",
      "epoch=93_train_batch=49, total_loss=12.729141235351562, pred_loss=[0.55236924, 0.16718224, 0.10858917]\n",
      "epoch=93_train_batch=50, total_loss=16.151199340820312, pred_loss=[0.015364177, 0.72815424, 3.5074887]\n",
      "epoch=93_train_batch=51, total_loss=12.544537544250488, pred_loss=[0.17628628, 0.39436805, 0.07450178]\n",
      "epoch=93_train_batch=52, total_loss=12.623321533203125, pred_loss=[0.34459203, 0.11975387, 0.26040494]\n",
      "epoch=93_train_batch=53, total_loss=14.995817184448242, pred_loss=[0.37921026, 0.19191262, 2.5269406]\n",
      "epoch=93_train_batch=54, total_loss=13.143758773803711, pred_loss=[0.15479693, 0.51528025, 0.5767485]\n",
      "epoch=93_train_batch=55, total_loss=14.291357040405273, pred_loss=[0.8261696, 0.5205902, 1.0484862]\n",
      "epoch=93_train_batch=56, total_loss=12.688631057739258, pred_loss=[0.048169173, 0.59976417, 0.14540587]\n",
      "epoch=93_train_batch=57, total_loss=12.778816223144531, pred_loss=[0.1663934, 0.26551288, 0.45243716]\n",
      "epoch=93_train_batch=58, total_loss=12.441140174865723, pred_loss=[0.08859274, 0.19095644, 0.26793998]\n",
      "epoch=93_train_batch=59, total_loss=13.037145614624023, pred_loss=[0.24384658, 0.41868967, 0.48178554]\n",
      "epoch=93_train_batch=60, total_loss=13.521502494812012, pred_loss=[0.7319585, 0.2250883, 0.67247105]\n",
      "epoch=93_train_batch=61, total_loss=12.714147567749023, pred_loss=[0.25463846, 0.23902187, 0.32934523]\n",
      "epoch=93_train_batch=62, total_loss=12.819091796875, pred_loss=[0.32002145, 0.51501215, 0.09376763]\n",
      "epoch=93_train_batch=63, total_loss=13.485025405883789, pred_loss=[0.15217434, 0.4094987, 1.0339189]\n",
      "epoch=93_train_batch=64, total_loss=12.665072441101074, pred_loss=[0.07458468, 0.39301366, 0.3089014]\n",
      "epoch=93_train_batch=65, total_loss=13.088982582092285, pred_loss=[0.66755146, 0.37025213, 0.16347009]\n",
      "epoch=93_train_batch=66, total_loss=13.181695938110352, pred_loss=[0.080437884, 0.51416814, 0.7002579]\n",
      "epoch=93_train_batch=67, total_loss=12.456864356994629, pred_loss=[0.22562337, 0.29508057, 0.05020839]\n",
      "epoch=93_train_batch=68, total_loss=19.924091339111328, pred_loss=[0.12580651, 2.9297156, 4.983494]\n",
      "epoch=93_train_batch=69, total_loss=13.212687492370605, pred_loss=[0.36612087, 0.33502302, 0.6273372]\n",
      "epoch=93_train_batch=70, total_loss=13.691852569580078, pred_loss=[0.8614683, 0.16276816, 0.7842665]\n",
      "epoch=93_train_batch=71, total_loss=13.296106338500977, pred_loss=[0.22078484, 0.25603372, 0.9367974]\n",
      "epoch=93_train_batch=72, total_loss=14.803045272827148, pred_loss=[0.6313356, 1.8389803, 0.4510989]\n",
      "epoch=93_train_batch=73, total_loss=12.431960105895996, pred_loss=[0.16647458, 0.04005512, 0.34464133]\n",
      "epoch=93_train_batch=74, total_loss=12.982048034667969, pred_loss=[0.3532948, 0.31888312, 0.42991558]\n",
      "epoch=93_train_batch=75, total_loss=12.794509887695312, pred_loss=[0.5324359, 0.07678167, 0.306175]\n",
      "epoch=93_train_batch=76, total_loss=12.7264404296875, pred_loss=[0.37305275, 0.2617914, 0.21331726]\n",
      "epoch=93_train_batch=77, total_loss=12.841257095336914, pred_loss=[0.2574178, 0.5482198, 0.15817249]\n",
      "epoch=93_train_batch=78, total_loss=12.706459999084473, pred_loss=[0.20931372, 0.23766558, 0.38287002]\n",
      "epoch=93_train_batch=79, total_loss=13.111738204956055, pred_loss=[0.24598981, 0.35737544, 0.6326]\n",
      "epoch=93_train_batch=80, total_loss=12.647809982299805, pred_loss=[0.106915005, 0.38812336, 0.2778436]\n",
      "epoch=93_train_batch=81, total_loss=13.136693954467773, pred_loss=[0.5636569, 0.20626272, 0.49269378]\n",
      "epoch=93_train_batch=82, total_loss=15.601316452026367, pred_loss=[0.12601829, 1.1952332, 2.4068408]\n",
      "epoch=93_train_batch=83, total_loss=12.430583953857422, pred_loss=[0.03143447, 0.41286027, 0.11392798]\n",
      "epoch=93_train_batch=84, total_loss=12.623836517333984, pred_loss=[0.12698106, 0.17176113, 0.45359945]\n",
      "epoch=93_train_batch=85, total_loss=13.753596305847168, pred_loss=[0.08705984, 0.7132554, 1.0826514]\n",
      "epoch=93_train_batch=86, total_loss=12.437145233154297, pred_loss=[0.03389905, 0.3686269, 0.1648407]\n",
      "epoch=93_train_batch=87, total_loss=12.432641983032227, pred_loss=[0.50622004, 0.015630085, 0.041865773]\n",
      "epoch=93_val_batch=0, total_val_loss=764.5728759765625, pred_val_loss[0.07989621, 66.90178, 685.72314]\n",
      "epoch=93_val_batch=1, total_val_loss=219.59793090820312, pred_val_loss[0.030706625, 122.512695, 85.18647]\n",
      "epoch=93_val_batch=2, total_val_loss=95.59354400634766, pred_val_loss[16.440035, 17.907366, 49.37808]\n",
      "epoch=93_val_batch=3, total_val_loss=123.07610321044922, pred_val_loss[3.4614508, 26.882133, 80.864456]\n",
      "epoch=93_val_batch=4, total_val_loss=100.8375473022461, pred_val_loss[3.6023316, 42.144127, 43.223026]\n",
      "epoch=93_val_batch=5, total_val_loss=58.16188049316406, pred_val_loss[17.66524, 7.4536104, 21.174965]\n",
      "epoch=93_val_batch=6, total_val_loss=224.37635803222656, pred_val_loss[22.77068, 7.1542954, 182.58333]\n",
      "epoch=93_val_batch=7, total_val_loss=161.93601989746094, pred_val_loss[0.595049, 71.549, 77.923904]\n",
      "epoch=93_val_batch=8, total_val_loss=56.682334899902344, pred_val_loss[0.28087443, 33.957443, 10.575954]\n",
      "epoch=93_val_batch=9, total_val_loss=113.95002746582031, pred_val_loss[3.4983187, 59.30323, 39.280415]\n",
      "epoch=93_val_batch=10, total_val_loss=148.98426818847656, pred_val_loss[43.630863, 6.3153043, 87.17004]\n",
      "epoch=93_val_batch=11, total_val_loss=181.7719268798828, pred_val_loss[14.137401, 68.98337, 86.78311]\n",
      "epoch=93_val_batch=12, total_val_loss=27.761760711669922, pred_val_loss[1.0411013, 5.014594, 9.838001]\n",
      "epoch=93_val_batch=13, total_val_loss=107.60626983642578, pred_val_loss[0.182232, 45.831177, 49.724792]\n",
      "epoch=93_val_batch=14, total_val_loss=116.0428695678711, pred_val_loss[12.8786, 46.15521, 45.14099]\n",
      "epoch=93_val_batch=15, total_val_loss=84.38903045654297, pred_val_loss[27.542835, 1.5734019, 43.40473]\n",
      "epoch=93_val_batch=16, total_val_loss=207.5907440185547, pred_val_loss[13.702987, 74.3699, 107.64979]\n",
      "epoch=93_val_batch=17, total_val_loss=160.73435974121094, pred_val_loss[13.871496, 20.112608, 114.8822]\n",
      "epoch=93_val_batch=18, total_val_loss=145.1650390625, pred_val_loss[5.0838194, 32.13562, 96.077545]\n",
      "epoch=93, train: avg_loss=13.481554985046387, val: avg_val_loss=163.0963592529297\n",
      "Saved checkpoint for step 104: ./tf_ckpts/ckpt-103\n",
      "epoch=94_train_batch=0, total_loss=13.659790992736816, pred_loss=[0.07579517, 0.24337536, 1.4725577]\n",
      "epoch=94_train_batch=1, total_loss=16.089818954467773, pred_loss=[0.021245522, 0.43267387, 3.7686954]\n",
      "epoch=94_train_batch=2, total_loss=12.578889846801758, pred_loss=[0.15880282, 0.3874003, 0.16634525]\n",
      "epoch=94_train_batch=3, total_loss=12.950337409973145, pred_loss=[0.4972537, 0.3075382, 0.2800664]\n",
      "epoch=94_train_batch=4, total_loss=22.693580627441406, pred_loss=[0.0801062, 0.2775281, 10.471321]\n",
      "epoch=94_train_batch=5, total_loss=12.567070007324219, pred_loss=[0.14877231, 0.39069244, 0.1638332]\n",
      "epoch=94_train_batch=6, total_loss=13.306259155273438, pred_loss=[0.34422892, 0.23617698, 0.862931]\n",
      "epoch=94_train_batch=7, total_loss=12.985213279724121, pred_loss=[0.08276436, 0.32008174, 0.72029936]\n",
      "epoch=94_train_batch=8, total_loss=20.66867446899414, pred_loss=[0.18354271, 2.0522835, 6.5716357]\n",
      "epoch=94_train_batch=9, total_loss=12.801602363586426, pred_loss=[0.34317267, 0.3680541, 0.2300158]\n",
      "epoch=94_train_batch=10, total_loss=12.682129859924316, pred_loss=[0.061852142, 0.5068382, 0.2539111]\n",
      "epoch=94_train_batch=11, total_loss=13.863727569580078, pred_loss=[0.2406257, 1.2234943, 0.5409126]\n",
      "epoch=94_train_batch=12, total_loss=12.588390350341797, pred_loss=[0.44374207, 0.22308895, 0.06369428]\n",
      "epoch=94_train_batch=13, total_loss=12.636035919189453, pred_loss=[0.20039219, 0.06588362, 0.5127312]\n",
      "epoch=94_train_batch=14, total_loss=12.833807945251465, pred_loss=[0.35992014, 0.4588945, 0.15879849]\n",
      "epoch=94_train_batch=15, total_loss=12.40449047088623, pred_loss=[0.17718187, 0.28866765, 0.08328281]\n",
      "epoch=94_train_batch=16, total_loss=13.24289608001709, pred_loss=[0.14928514, 0.51139843, 0.7276879]\n",
      "epoch=94_train_batch=17, total_loss=13.480193138122559, pred_loss=[0.05446435, 0.6635181, 0.9085195]\n",
      "epoch=94_train_batch=18, total_loss=13.642955780029297, pred_loss=[0.6963706, 0.7493472, 0.34438187]\n",
      "epoch=94_train_batch=19, total_loss=12.863983154296875, pred_loss=[0.08602032, 0.22806264, 0.69787204]\n",
      "epoch=94_train_batch=20, total_loss=13.42920970916748, pred_loss=[0.11438488, 0.19320466, 1.270422]\n",
      "epoch=94_train_batch=21, total_loss=12.575385093688965, pred_loss=[0.09716594, 0.13089514, 0.49695364]\n",
      "epoch=94_train_batch=22, total_loss=13.408982276916504, pred_loss=[0.10651621, 1.235219, 0.21770905]\n",
      "epoch=94_train_batch=23, total_loss=13.666882514953613, pred_loss=[0.23761685, 0.21694854, 1.3636174]\n",
      "epoch=94_train_batch=24, total_loss=14.74346923828125, pred_loss=[0.29201853, 0.5570433, 2.0465505]\n",
      "epoch=94_train_batch=25, total_loss=12.596153259277344, pred_loss=[0.11372708, 0.15274414, 0.48267114]\n",
      "epoch=94_train_batch=26, total_loss=12.769269943237305, pred_loss=[0.16742478, 0.25874388, 0.49694303]\n",
      "epoch=94_train_batch=27, total_loss=12.643424987792969, pred_loss=[0.27971634, 0.2222949, 0.296113]\n",
      "epoch=94_train_batch=28, total_loss=12.385241508483887, pred_loss=[0.1461267, 0.3061113, 0.088562995]\n",
      "epoch=94_train_batch=29, total_loss=15.39097785949707, pred_loss=[0.7423143, 1.506741, 1.298348]\n",
      "epoch=94_train_batch=30, total_loss=13.041529655456543, pred_loss=[0.27686998, 0.30154806, 0.6203943]\n",
      "epoch=94_train_batch=31, total_loss=12.860841751098633, pred_loss=[0.45091432, 0.22114712, 0.34692395]\n",
      "epoch=94_train_batch=32, total_loss=14.559574127197266, pred_loss=[0.21678352, 2.1325674, 0.36922577]\n",
      "epoch=94_train_batch=33, total_loss=12.678790092468262, pred_loss=[0.14782017, 0.120137535, 0.57068765]\n",
      "epoch=94_train_batch=34, total_loss=13.35448932647705, pred_loss=[0.3418634, 0.4286343, 0.74467224]\n",
      "epoch=94_train_batch=35, total_loss=12.50399398803711, pred_loss=[0.18929893, 0.34027714, 0.13591073]\n",
      "epoch=94_train_batch=36, total_loss=12.94250774383545, pred_loss=[0.60789084, 0.33256412, 0.16434494]\n",
      "epoch=94_train_batch=37, total_loss=12.617685317993164, pred_loss=[0.25964192, 0.36773065, 0.15339324]\n",
      "epoch=94_train_batch=38, total_loss=12.378870964050293, pred_loss=[0.04488721, 0.24858317, 0.24926221]\n",
      "epoch=94_train_batch=39, total_loss=12.417689323425293, pred_loss=[0.107480064, 0.2568816, 0.21796882]\n",
      "epoch=94_train_batch=40, total_loss=14.580753326416016, pred_loss=[0.05149167, 0.8887584, 1.8059282]\n",
      "epoch=94_train_batch=41, total_loss=12.552567481994629, pred_loss=[0.13742828, 0.20738912, 0.3739683]\n",
      "epoch=94_train_batch=42, total_loss=13.250482559204102, pred_loss=[0.64538133, 0.2988889, 0.47322962]\n",
      "epoch=94_train_batch=43, total_loss=12.510164260864258, pred_loss=[0.3234008, 0.24909064, 0.10550042]\n",
      "epoch=94_train_batch=44, total_loss=12.662113189697266, pred_loss=[0.2362563, 0.21398309, 0.3805117]\n",
      "epoch=94_train_batch=45, total_loss=12.445219039916992, pred_loss=[0.047624577, 0.25982726, 0.3072213]\n",
      "epoch=94_train_batch=46, total_loss=12.809751510620117, pred_loss=[0.07577106, 0.38302523, 0.52123]\n",
      "epoch=94_train_batch=47, total_loss=12.627397537231445, pred_loss=[0.1314655, 0.25535917, 0.4116725]\n",
      "epoch=94_train_batch=48, total_loss=12.431398391723633, pred_loss=[0.301208, 0.13437887, 0.16773716]\n",
      "epoch=94_train_batch=49, total_loss=13.516216278076172, pred_loss=[0.8267221, 0.18361524, 0.67863244]\n",
      "epoch=94_train_batch=50, total_loss=12.641900062561035, pred_loss=[0.28254068, 0.18399167, 0.3488972]\n",
      "epoch=94_train_batch=51, total_loss=13.40398120880127, pred_loss=[0.21267557, 0.66069865, 0.70491946]\n",
      "epoch=94_train_batch=52, total_loss=12.709467887878418, pred_loss=[0.0048276787, 0.35426742, 0.5254677]\n",
      "epoch=94_train_batch=53, total_loss=13.25878620147705, pred_loss=[0.90138745, 0.40796226, 0.12532069]\n",
      "epoch=94_train_batch=54, total_loss=13.168802261352539, pred_loss=[0.18707763, 0.99053216, 0.16785708]\n",
      "epoch=94_train_batch=55, total_loss=12.365579605102539, pred_loss=[0.39775252, 0.057837345, 0.08744561]\n",
      "epoch=94_train_batch=56, total_loss=13.06235408782959, pred_loss=[0.17543918, 0.22838488, 0.8367847]\n",
      "epoch=94_train_batch=57, total_loss=13.046191215515137, pred_loss=[0.7089697, 0.2988009, 0.21748158]\n",
      "epoch=94_train_batch=58, total_loss=12.957879066467285, pred_loss=[0.3330422, 0.20193101, 0.6027802]\n",
      "epoch=94_train_batch=59, total_loss=12.446582794189453, pred_loss=[0.36312518, 0.09977985, 0.16436803]\n",
      "epoch=94_train_batch=60, total_loss=13.22750186920166, pred_loss=[0.1469625, 0.8980059, 0.36404255]\n",
      "epoch=94_train_batch=61, total_loss=13.65610408782959, pred_loss=[0.0037863222, 1.1420219, 0.6926292]\n",
      "epoch=94_train_batch=62, total_loss=12.560919761657715, pred_loss=[0.08501647, 0.20824529, 0.45081508]\n",
      "epoch=94_train_batch=63, total_loss=13.250638008117676, pred_loss=[0.32232153, 0.34975764, 0.76254374]\n",
      "epoch=94_train_batch=64, total_loss=12.498764991760254, pred_loss=[0.09611719, 0.46340218, 0.12406137]\n",
      "epoch=94_train_batch=65, total_loss=12.383345603942871, pred_loss=[0.16757739, 0.18945144, 0.21196526]\n",
      "epoch=94_train_batch=66, total_loss=12.860270500183105, pred_loss=[0.18856563, 0.25028855, 0.6079029]\n",
      "epoch=94_train_batch=67, total_loss=14.716517448425293, pred_loss=[0.04193491, 0.6087241, 2.2531846]\n",
      "epoch=94_train_batch=68, total_loss=17.207717895507812, pred_loss=[0.113102295, 2.2504964, 3.0323002]\n",
      "epoch=94_train_batch=69, total_loss=13.170110702514648, pred_loss=[0.18389516, 0.39022115, 0.7850339]\n",
      "epoch=94_train_batch=70, total_loss=13.351175308227539, pred_loss=[0.23684436, 0.33228403, 0.9719466]\n",
      "epoch=94_train_batch=71, total_loss=13.58084487915039, pred_loss=[0.41049623, 0.21492553, 1.1461852]\n",
      "epoch=94_train_batch=72, total_loss=12.791794776916504, pred_loss=[0.15970916, 0.75365984, 0.070062235]\n",
      "epoch=94_train_batch=73, total_loss=15.057672500610352, pred_loss=[0.1100201, 0.33028275, 2.8098845]\n",
      "epoch=94_train_batch=74, total_loss=14.495743751525879, pred_loss=[0.37329918, 0.4525203, 1.8633139]\n",
      "epoch=94_train_batch=75, total_loss=12.738984107971191, pred_loss=[0.27173245, 0.47553894, 0.18596974]\n",
      "epoch=94_train_batch=76, total_loss=15.107677459716797, pred_loss=[0.063749075, 0.548158, 2.6908946]\n",
      "epoch=94_train_batch=77, total_loss=12.769695281982422, pred_loss=[0.11215789, 0.2612125, 0.5923146]\n",
      "epoch=94_train_batch=78, total_loss=12.759862899780273, pred_loss=[0.33453047, 0.25702822, 0.36515865]\n",
      "epoch=94_train_batch=79, total_loss=12.482465744018555, pred_loss=[0.4955312, 0.14182368, 0.042837724]\n",
      "epoch=94_train_batch=80, total_loss=13.561517715454102, pred_loss=[0.20149758, 1.3767385, 0.18189146]\n",
      "epoch=94_train_batch=81, total_loss=14.197918891906738, pred_loss=[0.15154128, 0.2995463, 1.9463105]\n",
      "epoch=94_train_batch=82, total_loss=12.755236625671387, pred_loss=[0.27661335, 0.23578885, 0.44317484]\n",
      "epoch=94_train_batch=83, total_loss=13.836915969848633, pred_loss=[0.0745275, 1.127617, 0.8359574]\n",
      "epoch=94_train_batch=84, total_loss=12.348576545715332, pred_loss=[0.096136704, 0.16417016, 0.29030013]\n",
      "epoch=94_train_batch=85, total_loss=12.769402503967285, pred_loss=[0.1401913, 0.6212499, 0.21082719]\n",
      "epoch=94_train_batch=86, total_loss=14.293143272399902, pred_loss=[0.1804617, 0.16884479, 2.147535]\n",
      "epoch=94_train_batch=87, total_loss=12.122966766357422, pred_loss=[0.042596433, 0.2252089, 0.059691668]\n",
      "epoch=94_val_batch=0, total_val_loss=799.1506958007812, pred_val_loss[0.13465558, 67.62769, 719.59375]\n",
      "epoch=94_val_batch=1, total_val_loss=221.9812469482422, pred_val_loss[0.044869944, 114.72741, 95.414345]\n",
      "epoch=94_val_batch=2, total_val_loss=106.96988677978516, pred_val_loss[16.837162, 22.924856, 55.41323]\n",
      "epoch=94_val_batch=3, total_val_loss=135.54122924804688, pred_val_loss[5.7423563, 27.228796, 90.77544]\n",
      "epoch=94_val_batch=4, total_val_loss=103.46346282958984, pred_val_loss[5.2672143, 37.2143, 49.187305]\n",
      "epoch=94_val_batch=5, total_val_loss=63.313377380371094, pred_val_loss[17.001854, 7.519249, 26.997639]\n",
      "epoch=94_val_batch=6, total_val_loss=230.16009521484375, pred_val_loss[24.275503, 8.045919, 186.04404]\n",
      "epoch=94_val_batch=7, total_val_loss=162.2949676513672, pred_val_loss[0.49612615, 63.853924, 86.15028]\n",
      "epoch=94_val_batch=8, total_val_loss=53.017417907714844, pred_val_loss[0.1857649, 29.76916, 11.267856]\n",
      "epoch=94_val_batch=9, total_val_loss=118.16925811767578, pred_val_loss[2.6614213, 58.051662, 45.661537]\n",
      "epoch=94_val_batch=10, total_val_loss=153.37454223632812, pred_val_loss[43.98867, 6.1041594, 91.487076]\n",
      "epoch=94_val_batch=11, total_val_loss=166.49839782714844, pred_val_loss[13.2997875, 59.44376, 81.96021]\n",
      "epoch=94_val_batch=12, total_val_loss=30.57314682006836, pred_val_loss[1.2702831, 10.233612, 7.274615]\n",
      "epoch=94_val_batch=13, total_val_loss=106.20598602294922, pred_val_loss[0.2661999, 42.85273, 51.29242]\n",
      "epoch=94_val_batch=14, total_val_loss=109.8185043334961, pred_val_loss[13.643011, 37.52158, 46.85928]\n",
      "epoch=94_val_batch=15, total_val_loss=85.13768768310547, pred_val_loss[29.952148, 0.5900653, 42.800835]\n",
      "epoch=94_val_batch=16, total_val_loss=218.42054748535156, pred_val_loss[13.416483, 78.53139, 114.67804]\n",
      "epoch=94_val_batch=17, total_val_loss=167.55319213867188, pred_val_loss[14.315769, 13.426033, 128.01675]\n",
      "epoch=94_val_batch=18, total_val_loss=149.82620239257812, pred_val_loss[6.792935, 26.48645, 104.75219]\n",
      "epoch=94, train: avg_loss=13.392111778259277, val: avg_val_loss=167.44580078125\n",
      "Saved checkpoint for step 105: ./tf_ckpts/ckpt-104\n",
      "epoch=95_train_batch=0, total_loss=13.608407974243164, pred_loss=[0.00300287, 0.44474745, 1.3660204]\n",
      "epoch=95_train_batch=1, total_loss=17.199966430664062, pred_loss=[0.100965455, 0.25948054, 5.0457153]\n",
      "epoch=95_train_batch=2, total_loss=14.679858207702637, pred_loss=[0.14705467, 1.9293354, 0.8104954]\n",
      "epoch=95_train_batch=3, total_loss=14.179876327514648, pred_loss=[1.31673, 0.24039713, 0.8306097]\n",
      "epoch=95_train_batch=4, total_loss=12.760793685913086, pred_loss=[0.10721585, 0.29444882, 0.5678483]\n",
      "epoch=95_train_batch=5, total_loss=13.10511589050293, pred_loss=[0.2271859, 0.22454289, 0.8629453]\n",
      "epoch=95_train_batch=6, total_loss=12.411057472229004, pred_loss=[0.21094573, 0.19155882, 0.2189403]\n",
      "epoch=95_train_batch=7, total_loss=15.129227638244629, pred_loss=[0.37688947, 1.4637733, 1.4997752]\n",
      "epoch=95_train_batch=8, total_loss=13.900297164916992, pred_loss=[0.2623412, 0.10708959, 1.7428955]\n",
      "epoch=95_train_batch=9, total_loss=12.631357192993164, pred_loss=[0.18355933, 0.39062676, 0.27001348]\n",
      "epoch=95_train_batch=10, total_loss=14.225876808166504, pred_loss=[0.3351299, 0.37631553, 1.7280831]\n",
      "epoch=95_train_batch=11, total_loss=12.279568672180176, pred_loss=[0.09967089, 0.35892314, 0.035429593]\n",
      "epoch=95_train_batch=12, total_loss=22.383920669555664, pred_loss=[0.12989233, 0.5107007, 9.958592]\n",
      "epoch=95_train_batch=13, total_loss=12.923850059509277, pred_loss=[0.05678317, 0.1563906, 0.92675257]\n",
      "epoch=95_train_batch=14, total_loss=13.161761283874512, pred_loss=[0.25781712, 0.20282562, 0.9180054]\n",
      "epoch=95_train_batch=15, total_loss=12.498604774475098, pred_loss=[0.1322999, 0.3107522, 0.2732494]\n",
      "epoch=95_train_batch=16, total_loss=13.700571060180664, pred_loss=[0.21833736, 0.07588088, 1.6248615]\n",
      "epoch=95_train_batch=17, total_loss=12.1548490524292, pred_loss=[0.25306705, 0.07185388, 0.049258344]\n",
      "epoch=95_train_batch=18, total_loss=12.773956298828125, pred_loss=[0.05497282, 0.42534795, 0.51379275]\n",
      "epoch=95_train_batch=19, total_loss=12.547163963317871, pred_loss=[0.13433117, 0.2747634, 0.35906392]\n",
      "epoch=95_train_batch=20, total_loss=12.283875465393066, pred_loss=[0.07224806, 0.23064496, 0.20282505]\n",
      "epoch=95_train_batch=21, total_loss=12.68468952178955, pred_loss=[0.18764716, 0.35607472, 0.36366218]\n",
      "epoch=95_train_batch=22, total_loss=12.446845054626465, pred_loss=[0.24178895, 0.28748578, 0.14111885]\n",
      "epoch=95_train_batch=23, total_loss=12.415621757507324, pred_loss=[0.08327262, 0.3722694, 0.18448463]\n",
      "epoch=95_train_batch=24, total_loss=13.188481330871582, pred_loss=[0.31567132, 0.2568691, 0.841208]\n",
      "epoch=95_train_batch=25, total_loss=14.873922348022461, pred_loss=[0.28570384, 0.28113285, 2.5332212]\n",
      "epoch=95_train_batch=26, total_loss=12.468558311462402, pred_loss=[0.24907044, 0.3310201, 0.11547168]\n",
      "epoch=95_train_batch=27, total_loss=14.19868278503418, pred_loss=[0.34048748, 1.9760704, 0.10999526]\n",
      "epoch=95_train_batch=28, total_loss=12.6405668258667, pred_loss=[0.033875156, 0.5387045, 0.29670966]\n",
      "epoch=95_train_batch=29, total_loss=16.757144927978516, pred_loss=[0.03694152, 1.8135915, 3.1361675]\n",
      "epoch=95_train_batch=30, total_loss=12.19371223449707, pred_loss=[0.14959712, 0.16315776, 0.11132868]\n",
      "epoch=95_train_batch=31, total_loss=12.32517147064209, pred_loss=[0.07438856, 0.2824017, 0.199563]\n",
      "epoch=95_train_batch=32, total_loss=12.108154296875, pred_loss=[0.09186491, 0.17656434, 0.07171639]\n",
      "epoch=95_train_batch=33, total_loss=12.486922264099121, pred_loss=[0.055737913, 0.49755496, 0.16642867]\n",
      "epoch=95_train_batch=34, total_loss=12.508337020874023, pred_loss=[0.24064192, 0.36923608, 0.13206749]\n",
      "epoch=95_train_batch=35, total_loss=13.526461601257324, pred_loss=[0.047450803, 1.470391, 0.24303834]\n",
      "epoch=95_train_batch=36, total_loss=19.005264282226562, pred_loss=[0.13712046, 3.2625806, 3.84079]\n",
      "epoch=95_train_batch=37, total_loss=13.04343032836914, pred_loss=[0.069604814, 0.26855752, 0.94128823]\n",
      "epoch=95_train_batch=38, total_loss=12.67518424987793, pred_loss=[0.09489645, 0.20091929, 0.61617875]\n",
      "epoch=95_train_batch=39, total_loss=12.733911514282227, pred_loss=[0.5856849, 0.3080704, 0.077755906]\n",
      "epoch=95_train_batch=40, total_loss=12.656042098999023, pred_loss=[0.32733124, 0.1680131, 0.3991093]\n",
      "epoch=95_train_batch=41, total_loss=12.560357093811035, pred_loss=[0.18195505, 0.108583614, 0.50903773]\n",
      "epoch=95_train_batch=42, total_loss=12.870598793029785, pred_loss=[0.16774668, 0.7370095, 0.20587099]\n",
      "epoch=95_train_batch=43, total_loss=12.7242431640625, pred_loss=[0.15508083, 0.54738975, 0.26260957]\n",
      "epoch=95_train_batch=44, total_loss=12.448288917541504, pred_loss=[0.19892545, 0.2188618, 0.27215382]\n",
      "epoch=95_train_batch=45, total_loss=12.618904113769531, pred_loss=[0.100159675, 0.59640145, 0.16481367]\n",
      "epoch=95_train_batch=46, total_loss=12.7245512008667, pred_loss=[0.17169443, 0.22995275, 0.5661997]\n",
      "epoch=95_train_batch=47, total_loss=13.086393356323242, pred_loss=[0.15907705, 0.55745715, 0.61398387]\n",
      "epoch=95_train_batch=48, total_loss=12.273258209228516, pred_loss=[0.12715662, 0.21269484, 0.17836665]\n",
      "epoch=95_train_batch=49, total_loss=12.716361999511719, pred_loss=[0.025178917, 0.34236383, 0.59461725]\n",
      "epoch=95_train_batch=50, total_loss=12.237432479858398, pred_loss=[0.11370492, 0.26491284, 0.10545534]\n",
      "epoch=95_train_batch=51, total_loss=12.687186241149902, pred_loss=[0.03047008, 0.733365, 0.17083769]\n",
      "epoch=95_train_batch=52, total_loss=12.74278736114502, pred_loss=[0.15590645, 0.54440975, 0.29081464]\n",
      "epoch=95_train_batch=53, total_loss=12.512239456176758, pred_loss=[0.13207781, 0.49470982, 0.13465306]\n",
      "epoch=95_train_batch=54, total_loss=12.394462585449219, pred_loss=[0.05686506, 0.48939696, 0.09826013]\n",
      "epoch=95_train_batch=55, total_loss=12.511526107788086, pred_loss=[0.36315697, 0.30604416, 0.09324767]\n",
      "epoch=95_train_batch=56, total_loss=12.45238208770752, pred_loss=[0.2086148, 0.29454035, 0.20101495]\n",
      "epoch=95_train_batch=57, total_loss=12.676348686218262, pred_loss=[0.07078863, 0.14562367, 0.7125955]\n",
      "epoch=95_train_batch=58, total_loss=13.779645919799805, pred_loss=[0.025723578, 0.24103631, 1.7664208]\n",
      "epoch=95_train_batch=59, total_loss=12.399816513061523, pred_loss=[0.2500929, 0.27159402, 0.13254268]\n",
      "epoch=95_train_batch=60, total_loss=12.538877487182617, pred_loss=[0.2117064, 0.32817054, 0.2542923]\n",
      "epoch=95_train_batch=61, total_loss=14.579323768615723, pred_loss=[0.06457525, 0.322636, 2.4482808]\n",
      "epoch=95_train_batch=62, total_loss=13.385085105895996, pred_loss=[0.09309035, 0.2552179, 1.2938257]\n",
      "epoch=95_train_batch=63, total_loss=12.825911521911621, pred_loss=[0.33800378, 0.38771096, 0.3581307]\n",
      "epoch=95_train_batch=64, total_loss=19.374088287353516, pred_loss=[0.025380418, 5.72426, 1.8832741]\n",
      "epoch=95_train_batch=65, total_loss=12.43387508392334, pred_loss=[0.08240314, 0.35073632, 0.2604533]\n",
      "epoch=95_train_batch=66, total_loss=12.773807525634766, pred_loss=[0.09631617, 0.24943936, 0.6886378]\n",
      "epoch=95_train_batch=67, total_loss=12.302828788757324, pred_loss=[0.070140325, 0.1298924, 0.3642356]\n",
      "epoch=95_train_batch=68, total_loss=12.666476249694824, pred_loss=[0.0514379, 0.41887188, 0.45844966]\n",
      "epoch=95_train_batch=69, total_loss=12.640700340270996, pred_loss=[0.11690373, 0.35611638, 0.4308013]\n",
      "epoch=95_train_batch=70, total_loss=12.53852653503418, pred_loss=[0.02941558, 0.4971348, 0.2759319]\n",
      "epoch=95_train_batch=71, total_loss=12.944897651672363, pred_loss=[0.116088845, 0.5104743, 0.58312434]\n",
      "epoch=95_train_batch=72, total_loss=12.51014518737793, pred_loss=[0.34804887, 0.31602526, 0.11169802]\n",
      "epoch=95_train_batch=73, total_loss=12.449586868286133, pred_loss=[0.06886752, 0.18683952, 0.46035314]\n",
      "epoch=95_train_batch=74, total_loss=12.77285099029541, pred_loss=[0.07369235, 0.86577356, 0.10071172]\n",
      "epoch=95_train_batch=75, total_loss=12.388622283935547, pred_loss=[0.13112761, 0.3831581, 0.14251886]\n",
      "epoch=95_train_batch=76, total_loss=13.331511497497559, pred_loss=[0.13243157, 1.0178621, 0.45025516]\n",
      "epoch=95_train_batch=77, total_loss=12.643441200256348, pred_loss=[0.050244696, 0.664459, 0.19862665]\n",
      "epoch=95_train_batch=78, total_loss=12.381202697753906, pred_loss=[0.2171841, 0.2220551, 0.21270351]\n",
      "epoch=95_train_batch=79, total_loss=12.374955177307129, pred_loss=[0.17245962, 0.31945366, 0.1546323]\n",
      "epoch=95_train_batch=80, total_loss=12.709848403930664, pred_loss=[0.23397754, 0.06975854, 0.678557]\n",
      "epoch=95_train_batch=81, total_loss=12.874137878417969, pred_loss=[0.034996316, 0.84010935, 0.27233145]\n",
      "epoch=95_train_batch=82, total_loss=12.332188606262207, pred_loss=[0.1842077, 0.18472303, 0.23741671]\n",
      "epoch=95_train_batch=83, total_loss=13.120405197143555, pred_loss=[0.07720553, 0.33357352, 0.9846492]\n",
      "epoch=95_train_batch=84, total_loss=12.864836692810059, pred_loss=[0.0016535483, 0.34947532, 0.7895998]\n",
      "epoch=95_train_batch=85, total_loss=12.922327995300293, pred_loss=[0.12813321, 0.28280333, 0.78815824]\n",
      "epoch=95_train_batch=86, total_loss=12.651576042175293, pred_loss=[0.22847615, 0.16229238, 0.5384547]\n",
      "epoch=95_train_batch=87, total_loss=12.059572219848633, pred_loss=[0.025278283, 0.24133293, 0.07149579]\n",
      "epoch=95_val_batch=0, total_val_loss=765.74365234375, pred_val_loss[0.08709342, 65.55239, 688.3836]\n",
      "epoch=95_val_batch=1, total_val_loss=215.56332397460938, pred_val_loss[0.06285869, 111.795685, 91.98421]\n",
      "epoch=95_val_batch=2, total_val_loss=93.3362808227539, pred_val_loss[15.736836, 13.896811, 51.982056]\n",
      "epoch=95_val_batch=3, total_val_loss=125.34395599365234, pred_val_loss[3.813351, 26.58151, 83.22852]\n",
      "epoch=95_val_batch=4, total_val_loss=110.59290313720703, pred_val_loss[4.2879205, 45.396103, 49.18831]\n",
      "epoch=95_val_batch=5, total_val_loss=59.10723876953125, pred_val_loss[16.631067, 8.167265, 22.588333]\n",
      "epoch=95_val_batch=6, total_val_loss=223.32717895507812, pred_val_loss[21.619255, 5.2673655, 184.71997]\n",
      "epoch=95_val_batch=7, total_val_loss=157.21087646484375, pred_val_loss[0.48860335, 63.11415, 81.88754]\n",
      "epoch=95_val_batch=8, total_val_loss=53.90245056152344, pred_val_loss[0.21688192, 29.120657, 12.8443365]\n",
      "epoch=95_val_batch=9, total_val_loss=115.23597717285156, pred_val_loss[2.1970873, 60.032284, 41.286034]\n",
      "epoch=95_val_batch=10, total_val_loss=149.81716918945312, pred_val_loss[40.78036, 8.601292, 88.71493]\n",
      "epoch=95_val_batch=11, total_val_loss=177.38018798828125, pred_val_loss[11.373216, 65.05201, 89.23438]\n",
      "epoch=95_val_batch=12, total_val_loss=28.073049545288086, pred_val_loss[1.0963318, 7.5099845, 7.7461586]\n",
      "epoch=95_val_batch=13, total_val_loss=97.69629669189453, pred_val_loss[0.1984227, 32.43593, 53.34137]\n",
      "epoch=95_val_batch=14, total_val_loss=115.05059814453125, pred_val_loss[12.042971, 46.081192, 45.205864]\n",
      "epoch=95_val_batch=15, total_val_loss=87.16374969482422, pred_val_loss[27.99289, 1.459053, 45.99123]\n",
      "epoch=95_val_batch=16, total_val_loss=205.42019653320312, pred_val_loss[12.733294, 67.055336, 113.91098]\n",
      "epoch=95_val_batch=17, total_val_loss=169.29974365234375, pred_val_loss[12.4597025, 20.723175, 124.39629]\n",
      "epoch=95_val_batch=18, total_val_loss=148.23797607421875, pred_val_loss[5.99314, 30.58123, 99.94302]\n",
      "epoch=95, train: avg_loss=13.196427345275879, val: avg_val_loss=163.02647399902344\n",
      "Saved checkpoint for step 106: ./tf_ckpts/ckpt-105\n",
      "epoch=96_train_batch=0, total_loss=13.242984771728516, pred_loss=[0.119602345, 0.9485156, 0.45429105]\n",
      "epoch=96_train_batch=1, total_loss=12.642782211303711, pred_loss=[0.026999405, 0.781952, 0.11414842]\n",
      "epoch=96_train_batch=2, total_loss=13.199111938476562, pred_loss=[0.090625525, 1.1173939, 0.272309]\n",
      "epoch=96_train_batch=3, total_loss=12.999518394470215, pred_loss=[0.5478029, 0.58565867, 0.14816123]\n",
      "epoch=96_train_batch=4, total_loss=12.921008110046387, pred_loss=[0.1212503, 0.82603693, 0.2567044]\n",
      "epoch=96_train_batch=5, total_loss=13.862131118774414, pred_loss=[0.15539195, 0.48665595, 1.5039349]\n",
      "epoch=96_train_batch=6, total_loss=12.57526969909668, pred_loss=[0.055564962, 0.19021216, 0.61421955]\n",
      "epoch=96_train_batch=7, total_loss=12.604867935180664, pred_loss=[0.18723355, 0.3216266, 0.38160467]\n",
      "epoch=96_train_batch=8, total_loss=12.759146690368652, pred_loss=[0.042644598, 0.24315317, 0.7598138]\n",
      "epoch=96_train_batch=9, total_loss=12.579504013061523, pred_loss=[0.04619485, 0.3704141, 0.4502318]\n",
      "epoch=96_train_batch=10, total_loss=13.497537612915039, pred_loss=[0.26507157, 0.09414298, 1.4265295]\n",
      "epoch=96_train_batch=11, total_loss=13.608701705932617, pred_loss=[0.12108021, 0.8226415, 0.95405334]\n",
      "epoch=96_train_batch=12, total_loss=12.949850082397461, pred_loss=[0.083300985, 0.5868453, 0.5696533]\n",
      "epoch=96_train_batch=13, total_loss=13.037425994873047, pred_loss=[0.1466634, 0.5333749, 0.64820904]\n",
      "epoch=96_train_batch=14, total_loss=13.120306015014648, pred_loss=[0.04345285, 0.9031959, 0.4653486]\n",
      "epoch=96_train_batch=15, total_loss=12.541861534118652, pred_loss=[0.2006101, 0.5846261, 0.049189836]\n",
      "epoch=96_train_batch=16, total_loss=20.775882720947266, pred_loss=[0.12796982, 1.183076, 7.7582774]\n",
      "epoch=96_train_batch=17, total_loss=12.992300033569336, pred_loss=[0.09644514, 0.577932, 0.612236]\n",
      "epoch=96_train_batch=18, total_loss=12.381805419921875, pred_loss=[0.16100475, 0.41019446, 0.105791785]\n",
      "epoch=96_train_batch=19, total_loss=12.83602237701416, pred_loss=[0.034725673, 0.62436813, 0.47298703]\n",
      "epoch=96_train_batch=20, total_loss=18.367877960205078, pred_loss=[0.17780358, 1.3844113, 5.1026025]\n",
      "epoch=96_train_batch=21, total_loss=12.852964401245117, pred_loss=[0.075673215, 0.5133775, 0.56174874]\n",
      "epoch=96_train_batch=22, total_loss=16.261262893676758, pred_loss=[0.100415766, 0.37188852, 4.087686]\n",
      "epoch=96_train_batch=23, total_loss=12.832210540771484, pred_loss=[0.039932877, 0.4888608, 0.6030408]\n",
      "epoch=96_train_batch=24, total_loss=12.378680229187012, pred_loss=[0.116579846, 0.12578112, 0.43683818]\n",
      "epoch=96_train_batch=25, total_loss=12.484245300292969, pred_loss=[0.14791146, 0.18831384, 0.44943273]\n",
      "epoch=96_train_batch=26, total_loss=12.61690902709961, pred_loss=[0.09430699, 0.46616292, 0.35873717]\n",
      "epoch=96_train_batch=27, total_loss=12.636009216308594, pred_loss=[0.12097497, 0.6448205, 0.17339878]\n",
      "epoch=96_train_batch=28, total_loss=12.33237075805664, pred_loss=[0.05280077, 0.37539807, 0.20824575]\n",
      "epoch=96_train_batch=29, total_loss=12.517045021057129, pred_loss=[0.02419504, 0.4590755, 0.33873653]\n",
      "epoch=96_train_batch=30, total_loss=12.413169860839844, pred_loss=[0.12730604, 0.36628672, 0.2254281]\n",
      "epoch=96_train_batch=31, total_loss=12.529046058654785, pred_loss=[0.07010428, 0.32912803, 0.43655476]\n",
      "epoch=96_train_batch=32, total_loss=12.852093696594238, pred_loss=[0.004794023, 0.34841627, 0.8065151]\n",
      "epoch=96_train_batch=33, total_loss=12.579752922058105, pred_loss=[0.12779997, 0.52085525, 0.23962165]\n",
      "epoch=96_train_batch=34, total_loss=12.694767951965332, pred_loss=[0.18682796, 0.09168653, 0.7256658]\n",
      "epoch=96_train_batch=35, total_loss=12.860445976257324, pred_loss=[0.10637755, 0.39981753, 0.66454804]\n",
      "epoch=96_train_batch=36, total_loss=13.82106876373291, pred_loss=[0.09151542, 0.5086284, 1.5321078]\n",
      "epoch=96_train_batch=37, total_loss=12.629937171936035, pred_loss=[0.0019959512, 0.80330956, 0.13669953]\n",
      "epoch=96_train_batch=38, total_loss=12.870279312133789, pred_loss=[0.07464542, 0.96550524, 0.14308453]\n",
      "epoch=96_train_batch=39, total_loss=12.42785358428955, pred_loss=[0.06404787, 0.26746404, 0.41018608]\n",
      "epoch=96_train_batch=40, total_loss=13.304594039916992, pred_loss=[0.017507669, 0.571249, 1.0305755]\n",
      "epoch=96_train_batch=41, total_loss=12.753778457641602, pred_loss=[0.2051286, 0.43686366, 0.42741224]\n",
      "epoch=96_train_batch=42, total_loss=17.593994140625, pred_loss=[0.106791735, 2.7032998, 3.1004264]\n",
      "epoch=96_train_batch=43, total_loss=13.109894752502441, pred_loss=[0.02973116, 0.6572387, 0.7403439]\n",
      "epoch=96_train_batch=44, total_loss=12.759810447692871, pred_loss=[0.11828565, 0.6560391, 0.30380008]\n",
      "epoch=96_train_batch=45, total_loss=12.4073486328125, pred_loss=[0.114674196, 0.331613, 0.2802694]\n",
      "epoch=96_train_batch=46, total_loss=14.07954216003418, pred_loss=[0.011719849, 0.62350464, 1.7644202]\n",
      "epoch=96_train_batch=47, total_loss=13.035042762756348, pred_loss=[0.33061177, 0.14681506, 0.8786044]\n",
      "epoch=96_train_batch=48, total_loss=12.748943328857422, pred_loss=[0.16693453, 0.32994866, 0.5739352]\n",
      "epoch=96_train_batch=49, total_loss=13.022932052612305, pred_loss=[0.06361532, 0.41487718, 0.86720085]\n",
      "epoch=96_train_batch=50, total_loss=13.584600448608398, pred_loss=[1.3151466, 0.30984163, 0.2832631]\n",
      "epoch=96_train_batch=51, total_loss=13.163979530334473, pred_loss=[0.0741001, 0.14297259, 1.2714201]\n",
      "epoch=96_train_batch=52, total_loss=12.416533470153809, pred_loss=[0.26652092, 0.145733, 0.32965338]\n",
      "epoch=96_train_batch=53, total_loss=12.553865432739258, pred_loss=[0.09045237, 0.47490966, 0.3147206]\n",
      "epoch=96_train_batch=54, total_loss=12.654207229614258, pred_loss=[0.21377888, 0.20558879, 0.56189615]\n",
      "epoch=96_train_batch=55, total_loss=12.491594314575195, pred_loss=[0.1245932, 0.28359085, 0.4113043]\n",
      "epoch=96_train_batch=56, total_loss=13.11461067199707, pred_loss=[0.114083454, 0.486951, 0.8423121]\n",
      "epoch=96_train_batch=57, total_loss=12.3297758102417, pred_loss=[0.053757764, 0.33614433, 0.26944846]\n",
      "epoch=96_train_batch=58, total_loss=12.089469909667969, pred_loss=[0.17434965, 0.20923318, 0.03630344]\n",
      "epoch=96_train_batch=59, total_loss=13.199183464050293, pred_loss=[0.05617012, 0.51029277, 0.9639928]\n",
      "epoch=96_train_batch=60, total_loss=12.608487129211426, pred_loss=[0.1993596, 0.46027192, 0.28099006]\n",
      "epoch=96_train_batch=61, total_loss=14.198751449584961, pred_loss=[0.110997245, 0.7246395, 1.6961151]\n",
      "epoch=96_train_batch=62, total_loss=16.663354873657227, pred_loss=[0.1533818, 4.7890167, 0.05482741]\n",
      "epoch=96_train_batch=63, total_loss=12.559244155883789, pred_loss=[0.0794431, 0.30101922, 0.5135356]\n",
      "epoch=96_train_batch=64, total_loss=12.607696533203125, pred_loss=[0.04311296, 0.24212568, 0.65806353]\n",
      "epoch=96_train_batch=65, total_loss=12.851934432983398, pred_loss=[0.083010785, 0.44149774, 0.66386175]\n",
      "epoch=96_train_batch=66, total_loss=12.627341270446777, pred_loss=[0.055209514, 0.6082177, 0.3011657]\n",
      "epoch=96_train_batch=67, total_loss=12.640316009521484, pred_loss=[0.26480728, 0.14208108, 0.5714879]\n",
      "epoch=96_train_batch=68, total_loss=12.422659873962402, pred_loss=[0.111436255, 0.37079385, 0.2792849]\n",
      "epoch=96_train_batch=69, total_loss=13.300847053527832, pred_loss=[0.046694994, 0.786306, 0.8074903]\n",
      "epoch=96_train_batch=70, total_loss=14.364864349365234, pred_loss=[0.072779626, 1.9548578, 0.6776583]\n",
      "epoch=96_train_batch=71, total_loss=12.76785659790039, pred_loss=[0.08480811, 0.60067976, 0.4235946]\n",
      "epoch=96_train_batch=72, total_loss=12.338146209716797, pred_loss=[0.23717663, 0.18062341, 0.2623731]\n",
      "epoch=96_train_batch=73, total_loss=13.843162536621094, pred_loss=[0.07876342, 1.8753667, 0.23186831]\n",
      "epoch=96_train_batch=74, total_loss=12.813614845275879, pred_loss=[0.24594483, 0.3787529, 0.53255755]\n",
      "epoch=96_train_batch=75, total_loss=12.647298812866211, pred_loss=[0.3169506, 0.44316274, 0.23163792]\n",
      "epoch=96_train_batch=76, total_loss=12.343064308166504, pred_loss=[0.13120876, 0.48671678, 0.07041113]\n",
      "epoch=96_train_batch=77, total_loss=12.402524948120117, pred_loss=[0.18682864, 0.23035315, 0.33144242]\n",
      "epoch=96_train_batch=78, total_loss=13.783923149108887, pred_loss=[0.95415604, 1.0657948, 0.110903636]\n",
      "epoch=96_train_batch=79, total_loss=20.359355926513672, pred_loss=[0.13974124, 8.491667, 0.07570551]\n",
      "epoch=96_train_batch=80, total_loss=13.68917465209961, pred_loss=[0.16098905, 1.6528304, 0.22389354]\n",
      "epoch=96_train_batch=81, total_loss=12.268954277038574, pred_loss=[0.33090165, 0.0591682, 0.22815585]\n",
      "epoch=96_train_batch=82, total_loss=12.362161636352539, pred_loss=[0.081991106, 0.42433327, 0.20582138]\n",
      "epoch=96_train_batch=83, total_loss=12.637079238891602, pred_loss=[0.058457516, 0.46811774, 0.46119243]\n",
      "epoch=96_train_batch=84, total_loss=12.303165435791016, pred_loss=[0.14501515, 0.3768253, 0.13271838]\n",
      "epoch=96_train_batch=85, total_loss=14.109960556030273, pred_loss=[0.035997313, 2.0513294, 0.37474388]\n",
      "epoch=96_train_batch=86, total_loss=17.484235763549805, pred_loss=[0.024196323, 5.6399546, 0.17293812]\n",
      "epoch=96_train_batch=87, total_loss=15.431222915649414, pred_loss=[0.10855038, 3.554813, 0.12149702]\n",
      "epoch=96_val_batch=0, total_val_loss=768.4129638671875, pred_val_loss[0.09415395, 70.03542, 686.6378]\n",
      "epoch=96_val_batch=1, total_val_loss=232.3231658935547, pred_val_loss[0.061503407, 126.131, 94.48508]\n",
      "epoch=96_val_batch=2, total_val_loss=97.62528991699219, pred_val_loss[16.297283, 16.702713, 52.979713]\n",
      "epoch=96_val_batch=3, total_val_loss=132.6946258544922, pred_val_loss[4.516959, 31.15929, 85.372795]\n",
      "epoch=96_val_batch=4, total_val_loss=105.45303344726562, pred_val_loss[4.56406, 40.198166, 49.045223]\n",
      "epoch=96_val_batch=5, total_val_loss=68.394287109375, pred_val_loss[18.763123, 14.616476, 23.369104]\n",
      "epoch=96_val_batch=6, total_val_loss=219.42552185058594, pred_val_loss[21.74461, 4.9311447, 181.10419]\n",
      "epoch=96_val_batch=7, total_val_loss=161.73690795898438, pred_val_loss[0.40609553, 65.16084, 84.52438]\n",
      "epoch=96_val_batch=8, total_val_loss=50.20924758911133, pred_val_loss[0.19401088, 30.35953, 8.010123]\n",
      "epoch=96_val_batch=9, total_val_loss=123.3297119140625, pred_val_loss[2.315892, 65.33237, 44.03587]\n",
      "epoch=96_val_batch=10, total_val_loss=146.9597930908203, pred_val_loss[38.174656, 7.718376, 89.42118]\n",
      "epoch=96_val_batch=11, total_val_loss=167.27537536621094, pred_val_loss[11.758217, 62.30836, 81.563225]\n",
      "epoch=96_val_batch=12, total_val_loss=32.34687805175781, pred_val_loss[1.2097248, 11.387016, 8.104553]\n",
      "epoch=96_val_batch=13, total_val_loss=101.75578308105469, pred_val_loss[0.19324106, 36.559235, 53.357727]\n",
      "epoch=96_val_batch=14, total_val_loss=111.48977661132812, pred_val_loss[11.843924, 44.906273, 43.09399]\n",
      "epoch=96_val_batch=15, total_val_loss=85.27555847167969, pred_val_loss[28.321426, 1.7656281, 43.542915]\n",
      "epoch=96_val_batch=16, total_val_loss=212.3735809326172, pred_val_loss[12.180352, 73.4583, 115.089355]\n",
      "epoch=96_val_batch=17, total_val_loss=166.17535400390625, pred_val_loss[10.387353, 16.237892, 127.904526]\n",
      "epoch=96_val_batch=18, total_val_loss=146.68028259277344, pred_val_loss[5.251812, 30.50234, 99.280556]\n",
      "epoch=96, train: avg_loss=13.328753471374512, val: avg_val_loss=164.7335205078125\n",
      "Saved checkpoint for step 107: ./tf_ckpts/ckpt-106\n",
      "epoch=97_train_batch=0, total_loss=13.503301620483398, pred_loss=[0.22978072, 1.5259625, 0.10197361]\n",
      "epoch=97_train_batch=1, total_loss=13.233237266540527, pred_loss=[0.15153557, 1.3080443, 0.1288203]\n",
      "epoch=97_train_batch=2, total_loss=12.203937530517578, pred_loss=[0.11809546, 0.35325426, 0.088482894]\n",
      "epoch=97_train_batch=3, total_loss=15.190731048583984, pred_loss=[0.012355294, 1.2255195, 2.309473]\n",
      "epoch=97_train_batch=4, total_loss=12.645147323608398, pred_loss=[0.06987444, 0.71502936, 0.21757485]\n",
      "epoch=97_train_batch=5, total_loss=13.939593315124512, pred_loss=[0.17739886, 0.6181162, 1.5021201]\n",
      "epoch=97_train_batch=6, total_loss=12.793910026550293, pred_loss=[0.311106, 0.5569887, 0.28456846]\n",
      "epoch=97_train_batch=7, total_loss=12.813838958740234, pred_loss=[0.04910284, 0.8254063, 0.2987769]\n",
      "epoch=97_train_batch=8, total_loss=12.823037147521973, pred_loss=[0.09578616, 0.4681697, 0.6192279]\n",
      "epoch=97_train_batch=9, total_loss=14.159614562988281, pred_loss=[0.09036538, 2.0192728, 0.41083273]\n",
      "epoch=97_train_batch=10, total_loss=12.93757438659668, pred_loss=[0.10832893, 0.9538974, 0.23693512]\n",
      "epoch=97_train_batch=11, total_loss=12.420968055725098, pred_loss=[0.1661904, 0.16689014, 0.45021695]\n",
      "epoch=97_train_batch=12, total_loss=12.71276569366455, pred_loss=[0.19579394, 0.8044892, 0.07556861]\n",
      "epoch=97_train_batch=13, total_loss=12.071115493774414, pred_loss=[0.11472099, 0.18394674, 0.13629921]\n",
      "epoch=97_train_batch=14, total_loss=14.520065307617188, pred_loss=[1.4944826, 0.65414727, 0.73605996]\n",
      "epoch=97_train_batch=15, total_loss=13.958160400390625, pred_loss=[0.0605779, 1.4953212, 0.7676694]\n",
      "epoch=97_train_batch=16, total_loss=14.50896167755127, pred_loss=[0.37933904, 0.4158886, 2.0799127]\n",
      "epoch=97_train_batch=17, total_loss=13.749959945678711, pred_loss=[0.08283285, 1.443386, 0.5906913]\n",
      "epoch=97_train_batch=18, total_loss=12.2620267868042, pred_loss=[0.07705691, 0.46616575, 0.086520396]\n",
      "epoch=97_train_batch=19, total_loss=12.950433731079102, pred_loss=[0.22923952, 0.58849657, 0.5011778]\n",
      "epoch=97_train_batch=20, total_loss=12.743149757385254, pred_loss=[0.04159507, 0.8661157, 0.20468651]\n",
      "epoch=97_train_batch=21, total_loss=16.786518096923828, pred_loss=[0.034467652, 2.5214663, 2.600611]\n",
      "epoch=97_train_batch=22, total_loss=13.04876708984375, pred_loss=[0.18615603, 0.57891446, 0.65450144]\n",
      "epoch=97_train_batch=23, total_loss=17.00397300720215, pred_loss=[0.34144247, 2.1647503, 2.8693676]\n",
      "epoch=97_train_batch=24, total_loss=12.803205490112305, pred_loss=[0.023910975, 0.43453962, 0.7171219]\n",
      "epoch=97_train_batch=25, total_loss=15.442304611206055, pred_loss=[0.0147856595, 0.74400973, 3.0566614]\n",
      "epoch=97_train_batch=26, total_loss=12.239246368408203, pred_loss=[0.084843785, 0.31600282, 0.21232063]\n",
      "epoch=97_train_batch=27, total_loss=12.70465087890625, pred_loss=[0.08631464, 0.81126046, 0.18175279]\n",
      "epoch=97_train_batch=28, total_loss=12.901932716369629, pred_loss=[0.06896913, 0.48211816, 0.72627264]\n",
      "epoch=97_train_batch=29, total_loss=13.177189826965332, pred_loss=[0.0808136, 1.0324936, 0.44006926]\n",
      "epoch=97_train_batch=30, total_loss=12.818268775939941, pred_loss=[0.03839935, 0.46664476, 0.690176]\n",
      "epoch=97_train_batch=31, total_loss=14.545909881591797, pred_loss=[0.0016404667, 0.65524054, 2.2667513]\n",
      "epoch=97_train_batch=32, total_loss=14.146615028381348, pred_loss=[0.012523048, 0.45983917, 2.0527606]\n",
      "epoch=97_train_batch=33, total_loss=12.866398811340332, pred_loss=[0.20379026, 0.98604083, 0.055872817]\n",
      "epoch=97_train_batch=34, total_loss=13.45702838897705, pred_loss=[0.11923616, 0.96978533, 0.7481127]\n",
      "epoch=97_train_batch=35, total_loss=12.216911315917969, pred_loss=[0.081508234, 0.33955985, 0.17675804]\n",
      "epoch=97_train_batch=36, total_loss=12.904105186462402, pred_loss=[0.20804244, 0.8566471, 0.22114469]\n",
      "epoch=97_train_batch=37, total_loss=12.960814476013184, pred_loss=[0.2348428, 0.93807817, 0.1704457]\n",
      "epoch=97_train_batch=38, total_loss=12.090540885925293, pred_loss=[0.16181824, 0.20844854, 0.10365615]\n",
      "epoch=97_train_batch=39, total_loss=13.200983047485352, pred_loss=[0.21001422, 0.19681232, 1.1783661]\n",
      "epoch=97_train_batch=40, total_loss=13.438961029052734, pred_loss=[0.0315796, 1.564489, 0.22793797]\n",
      "epoch=97_train_batch=41, total_loss=13.120485305786133, pred_loss=[0.112924576, 0.4084255, 0.98501796]\n",
      "epoch=97_train_batch=42, total_loss=12.844253540039062, pred_loss=[0.12967137, 0.3692351, 0.73206794]\n",
      "epoch=97_train_batch=43, total_loss=12.533055305480957, pred_loss=[0.17405215, 0.3166209, 0.42994773]\n",
      "epoch=97_train_batch=44, total_loss=12.79444408416748, pred_loss=[0.30157992, 0.23893374, 0.6423413]\n",
      "epoch=97_train_batch=45, total_loss=13.71986198425293, pred_loss=[0.056321632, 1.2136462, 0.83915716]\n",
      "epoch=97_train_batch=46, total_loss=12.773723602294922, pred_loss=[0.07145096, 0.6322771, 0.46012896]\n",
      "epoch=97_train_batch=47, total_loss=13.81260871887207, pred_loss=[0.077568844, 1.8942065, 0.23183575]\n",
      "epoch=97_train_batch=48, total_loss=12.258281707763672, pred_loss=[0.06592437, 0.21907632, 0.36515182]\n",
      "epoch=97_train_batch=49, total_loss=13.330162048339844, pred_loss=[0.053881306, 0.32793415, 1.341087]\n",
      "epoch=97_train_batch=50, total_loss=12.839229583740234, pred_loss=[0.231044, 0.9142852, 0.08751291]\n",
      "epoch=97_train_batch=51, total_loss=13.93840217590332, pred_loss=[0.19540603, 1.3041763, 0.83329254]\n",
      "epoch=97_train_batch=52, total_loss=13.516281127929688, pred_loss=[0.1804164, 1.4407074, 0.2904771]\n",
      "epoch=97_train_batch=53, total_loss=12.538057327270508, pred_loss=[0.37448263, 0.303529, 0.2562086]\n",
      "epoch=97_train_batch=54, total_loss=12.629395484924316, pred_loss=[0.20329875, 0.5889612, 0.23412342]\n",
      "epoch=97_train_batch=55, total_loss=19.880653381347656, pred_loss=[0.09115499, 3.4184618, 4.7688465]\n",
      "epoch=97_train_batch=56, total_loss=12.901579856872559, pred_loss=[0.14808643, 0.4255441, 0.72657555]\n",
      "epoch=97_train_batch=57, total_loss=12.457679748535156, pred_loss=[0.20646381, 0.466781, 0.18387145]\n",
      "epoch=97_train_batch=58, total_loss=12.627691268920898, pred_loss=[0.14744364, 0.64626884, 0.23422748]\n",
      "epoch=97_train_batch=59, total_loss=12.90922737121582, pred_loss=[0.03978738, 0.8075011, 0.46300203]\n",
      "epoch=97_train_batch=60, total_loss=12.194270133972168, pred_loss=[0.22686085, 0.20080858, 0.16848186]\n",
      "epoch=97_train_batch=61, total_loss=12.285992622375488, pred_loss=[0.10107048, 0.26999652, 0.3176206]\n",
      "epoch=97_train_batch=62, total_loss=12.148582458496094, pred_loss=[0.14438891, 0.21087107, 0.19683406]\n",
      "epoch=97_train_batch=63, total_loss=14.727529525756836, pred_loss=[0.0013795666, 2.0692797, 1.0612113]\n",
      "epoch=97_train_batch=64, total_loss=11.97977066040039, pred_loss=[0.0969468, 0.24052568, 0.04746386]\n",
      "epoch=97_train_batch=65, total_loss=15.573108673095703, pred_loss=[0.03459368, 1.821761, 2.1227496]\n",
      "epoch=97_train_batch=66, total_loss=13.784412384033203, pred_loss=[0.002477138, 0.916608, 1.2721562]\n",
      "epoch=97_train_batch=67, total_loss=12.770303726196289, pred_loss=[0.13494669, 0.94025594, 0.10277479]\n",
      "epoch=97_train_batch=68, total_loss=12.376838684082031, pred_loss=[0.12675437, 0.42204326, 0.23655666]\n",
      "epoch=97_train_batch=69, total_loss=12.778203010559082, pred_loss=[0.28195813, 0.58977085, 0.31582597]\n",
      "epoch=97_train_batch=70, total_loss=11.953814506530762, pred_loss=[0.011982773, 0.24913752, 0.10289359]\n",
      "epoch=97_train_batch=71, total_loss=12.41809368133545, pred_loss=[0.030679459, 0.4000311, 0.3984272]\n",
      "epoch=97_train_batch=72, total_loss=12.767515182495117, pred_loss=[0.13050386, 0.7565859, 0.29232067]\n",
      "epoch=97_train_batch=73, total_loss=13.34592342376709, pred_loss=[0.041340146, 0.51935756, 1.197969]\n",
      "epoch=97_train_batch=74, total_loss=12.667869567871094, pred_loss=[0.12444134, 0.7772104, 0.17981356]\n",
      "epoch=97_train_batch=75, total_loss=12.729080200195312, pred_loss=[0.22420567, 0.45433512, 0.46499306]\n",
      "epoch=97_train_batch=76, total_loss=13.863826751708984, pred_loss=[0.05516836, 1.2814034, 0.94257236]\n",
      "epoch=97_train_batch=77, total_loss=13.563891410827637, pred_loss=[0.059973698, 1.4877415, 0.432366]\n",
      "epoch=97_train_batch=78, total_loss=12.459691047668457, pred_loss=[0.22982104, 0.3642203, 0.28271824]\n",
      "epoch=97_train_batch=79, total_loss=12.265342712402344, pred_loss=[0.0964817, 0.49625042, 0.09055866]\n",
      "epoch=97_train_batch=80, total_loss=12.759452819824219, pred_loss=[0.111105986, 0.31247988, 0.7547002]\n",
      "epoch=97_train_batch=81, total_loss=12.37243366241455, pred_loss=[0.15617958, 0.067234315, 0.56874585]\n",
      "epoch=97_train_batch=82, total_loss=12.872928619384766, pred_loss=[0.2285125, 0.90784883, 0.15718928]\n",
      "epoch=97_train_batch=83, total_loss=12.675500869750977, pred_loss=[0.007776728, 0.7490892, 0.34015688]\n",
      "epoch=97_train_batch=84, total_loss=12.483684539794922, pred_loss=[0.022481268, 0.5328199, 0.35081086]\n",
      "epoch=97_train_batch=85, total_loss=12.639883995056152, pred_loss=[0.03652267, 0.8431122, 0.18358256]\n",
      "epoch=97_train_batch=86, total_loss=13.863120079040527, pred_loss=[0.067369334, 0.2074424, 2.012534]\n",
      "epoch=97_train_batch=87, total_loss=12.439016342163086, pred_loss=[0.001999468, 0.5205107, 0.34162757]\n",
      "epoch=97_val_batch=0, total_val_loss=763.2134399414062, pred_val_loss[0.06261895, 71.81795, 679.7589]\n",
      "epoch=97_val_batch=1, total_val_loss=209.13636779785156, pred_val_loss[0.039826673, 111.39964, 86.122925]\n",
      "epoch=97_val_batch=2, total_val_loss=106.85489654541016, pred_val_loss[16.092539, 21.477032, 57.711346]\n",
      "epoch=97_val_batch=3, total_val_loss=129.0146026611328, pred_val_loss[4.5728507, 27.291697, 85.57607]\n",
      "epoch=97_val_batch=4, total_val_loss=98.86116790771484, pred_val_loss[4.2144217, 36.94714, 46.125626]\n",
      "epoch=97_val_batch=5, total_val_loss=62.150657653808594, pred_val_loss[17.456316, 9.071289, 24.049074]\n",
      "epoch=97_val_batch=6, total_val_loss=219.41806030273438, pred_val_loss[22.645157, 6.9965096, 178.20242]\n",
      "epoch=97_val_batch=7, total_val_loss=165.42739868164062, pred_val_loss[0.36939585, 67.777374, 85.70665]\n",
      "epoch=97_val_batch=8, total_val_loss=51.51824188232422, pred_val_loss[0.12985592, 33.389725, 6.4246836]\n",
      "epoch=97_val_batch=9, total_val_loss=117.03099822998047, pred_val_loss[3.068716, 56.374416, 46.01389]\n",
      "epoch=97_val_batch=10, total_val_loss=147.91464233398438, pred_val_loss[41.7586, 5.668146, 88.91393]\n",
      "epoch=97_val_batch=11, total_val_loss=166.5726318359375, pred_val_loss[12.601698, 62.722374, 79.674576]\n",
      "epoch=97_val_batch=12, total_val_loss=31.015766143798828, pred_val_loss[1.6219753, 6.896459, 10.923354]\n",
      "epoch=97_val_batch=13, total_val_loss=105.01435089111328, pred_val_loss[0.19549906, 37.985924, 55.25894]\n",
      "epoch=97_val_batch=14, total_val_loss=104.09273529052734, pred_val_loss[10.8915615, 41.06961, 40.55758]\n",
      "epoch=97_val_batch=15, total_val_loss=82.50519561767578, pred_val_loss[29.729609, 1.4866037, 39.715]\n",
      "epoch=97_val_batch=16, total_val_loss=208.37710571289062, pred_val_loss[12.944576, 75.15428, 108.70428]\n",
      "epoch=97_val_batch=17, total_val_loss=164.52725219726562, pred_val_loss[10.748602, 14.549822, 127.65486]\n",
      "epoch=97_val_batch=18, total_val_loss=141.11801147460938, pred_val_loss[5.0630865, 29.795029, 94.68593]\n",
      "epoch=97, train: avg_loss=13.21683120727539, val: avg_val_loss=161.7770538330078\n",
      "Saved checkpoint for step 108: ./tf_ckpts/ckpt-107\n",
      "epoch=98_train_batch=0, total_loss=13.11535358428955, pred_loss=[0.051116962, 0.32024956, 1.1700078]\n",
      "epoch=98_train_batch=1, total_loss=13.836082458496094, pred_loss=[1.1012498, 0.39091215, 0.77084184]\n",
      "epoch=98_train_batch=2, total_loss=13.015871047973633, pred_loss=[0.29482362, 0.45150504, 0.6973773]\n",
      "epoch=98_train_batch=3, total_loss=12.244961738586426, pred_loss=[0.051836886, 0.3668867, 0.254975]\n",
      "epoch=98_train_batch=4, total_loss=12.445531845092773, pred_loss=[0.1278244, 0.3162534, 0.4310828]\n",
      "epoch=98_train_batch=5, total_loss=12.951918601989746, pred_loss=[0.072157815, 0.8619206, 0.4483593]\n",
      "epoch=98_train_batch=6, total_loss=12.377151489257812, pred_loss=[0.03935798, 0.3340526, 0.4351516]\n",
      "epoch=98_train_batch=7, total_loss=12.493951797485352, pred_loss=[0.17614476, 0.17682624, 0.57328427]\n",
      "epoch=98_train_batch=8, total_loss=12.911309242248535, pred_loss=[0.0017898865, 0.15109363, 1.1916326]\n",
      "epoch=98_train_batch=9, total_loss=12.526955604553223, pred_loss=[0.09856869, 0.27404985, 0.58844894]\n",
      "epoch=98_train_batch=10, total_loss=12.400344848632812, pred_loss=[0.44037384, 0.11702606, 0.27796063]\n",
      "epoch=98_train_batch=11, total_loss=12.118229866027832, pred_loss=[0.12240861, 0.1201023, 0.31164527]\n",
      "epoch=98_train_batch=12, total_loss=12.431984901428223, pred_loss=[0.11148688, 0.40338233, 0.35394603]\n",
      "epoch=98_train_batch=13, total_loss=13.79598617553711, pred_loss=[0.020299098, 1.1313894, 1.0820305]\n",
      "epoch=98_train_batch=14, total_loss=14.140320777893066, pred_loss=[1.7498953, 0.50228614, 0.32677388]\n",
      "epoch=98_train_batch=15, total_loss=12.43843936920166, pred_loss=[0.2204814, 0.054077018, 0.60328853]\n",
      "epoch=98_train_batch=16, total_loss=12.629131317138672, pred_loss=[0.055956233, 0.9175135, 0.09582979]\n",
      "epoch=98_train_batch=17, total_loss=12.558030128479004, pred_loss=[0.037021358, 0.29896352, 0.6629706]\n",
      "epoch=98_train_batch=18, total_loss=12.059761047363281, pred_loss=[0.069905244, 0.2464112, 0.18512672]\n",
      "epoch=98_train_batch=19, total_loss=12.2529296875, pred_loss=[0.16441645, 0.33620167, 0.19475299]\n",
      "epoch=98_train_batch=20, total_loss=12.647159576416016, pred_loss=[0.20966086, 0.61168164, 0.26902246]\n",
      "epoch=98_train_batch=21, total_loss=12.224226951599121, pred_loss=[0.18880127, 0.39255244, 0.08685856]\n",
      "epoch=98_train_batch=22, total_loss=13.196453094482422, pred_loss=[0.040217616, 0.4336638, 1.1673448]\n",
      "epoch=98_train_batch=23, total_loss=12.593831062316895, pred_loss=[0.12542121, 0.39911053, 0.5148686]\n",
      "epoch=98_train_batch=24, total_loss=12.433394432067871, pred_loss=[0.040722102, 0.17799036, 0.66105974]\n",
      "epoch=98_train_batch=25, total_loss=11.958168029785156, pred_loss=[0.08036988, 0.16680694, 0.15818436]\n",
      "epoch=98_train_batch=26, total_loss=13.049837112426758, pred_loss=[0.10410388, 0.98638475, 0.40736687]\n",
      "epoch=98_train_batch=27, total_loss=13.282787322998047, pred_loss=[0.13978064, 1.070839, 0.52100986]\n",
      "epoch=98_train_batch=28, total_loss=13.091127395629883, pred_loss=[0.07818946, 0.4002408, 1.0623722]\n",
      "epoch=98_train_batch=29, total_loss=14.011792182922363, pred_loss=[0.23118061, 0.7882017, 1.4429274]\n",
      "epoch=98_train_batch=30, total_loss=12.19486141204834, pred_loss=[0.21209097, 0.22980854, 0.20431426]\n",
      "epoch=98_train_batch=31, total_loss=12.451729774475098, pred_loss=[0.17325045, 0.14382116, 0.5868567]\n",
      "epoch=98_train_batch=32, total_loss=12.146748542785645, pred_loss=[0.07853082, 0.2710901, 0.25017792]\n",
      "epoch=98_train_batch=33, total_loss=12.572392463684082, pred_loss=[0.106906116, 0.5200229, 0.39937136]\n",
      "epoch=98_train_batch=34, total_loss=12.007804870605469, pred_loss=[0.12205209, 0.24970675, 0.09081599]\n",
      "epoch=98_train_batch=35, total_loss=12.769213676452637, pred_loss=[0.19592087, 0.78122294, 0.24771446]\n",
      "epoch=98_train_batch=36, total_loss=12.482760429382324, pred_loss=[0.0230026, 0.1839633, 0.73232025]\n",
      "epoch=98_train_batch=37, total_loss=11.914791107177734, pred_loss=[0.044580355, 0.25591713, 0.07170423]\n",
      "epoch=98_train_batch=38, total_loss=12.72708511352539, pred_loss=[0.10619873, 0.5430223, 0.53616536]\n",
      "epoch=98_train_batch=39, total_loss=12.789636611938477, pred_loss=[0.06406037, 0.6096628, 0.5751115]\n",
      "epoch=98_train_batch=40, total_loss=12.076726913452148, pred_loss=[0.039255228, 0.3352128, 0.16236073]\n",
      "epoch=98_train_batch=41, total_loss=12.37684440612793, pred_loss=[0.080106884, 0.23068315, 0.527065]\n",
      "epoch=98_train_batch=42, total_loss=12.544509887695312, pred_loss=[0.054758087, 0.46362555, 0.48805183]\n",
      "epoch=98_train_batch=43, total_loss=12.347516059875488, pred_loss=[0.2739871, 0.156692, 0.37968624]\n",
      "epoch=98_train_batch=44, total_loss=12.247467994689941, pred_loss=[0.24156822, 0.21484146, 0.25483298]\n",
      "epoch=98_train_batch=45, total_loss=11.934054374694824, pred_loss=[0.08554304, 0.14937873, 0.16384676]\n",
      "epoch=98_train_batch=46, total_loss=13.586343765258789, pred_loss=[1.3129836, 0.63907295, 0.09994208]\n",
      "epoch=98_train_batch=47, total_loss=13.106318473815918, pred_loss=[0.2263405, 0.2921235, 1.0544453]\n",
      "epoch=98_train_batch=48, total_loss=19.114229202270508, pred_loss=[0.08369744, 2.537481, 4.960554]\n",
      "epoch=98_train_batch=49, total_loss=12.079437255859375, pred_loss=[0.15054932, 0.059112452, 0.33817774]\n",
      "epoch=98_train_batch=50, total_loss=12.317703247070312, pred_loss=[0.32727677, 0.28946176, 0.17024495]\n",
      "epoch=98_train_batch=51, total_loss=11.9470853805542, pred_loss=[0.23416442, 0.14863893, 0.034429345]\n",
      "epoch=98_train_batch=52, total_loss=12.992120742797852, pred_loss=[0.050073173, 0.81308675, 0.59996957]\n",
      "epoch=98_train_batch=53, total_loss=12.280519485473633, pred_loss=[0.11433218, 0.31490928, 0.32313842]\n",
      "epoch=98_train_batch=54, total_loss=12.488883018493652, pred_loss=[0.06927713, 0.628778, 0.26353845]\n",
      "epoch=98_train_batch=55, total_loss=12.353466033935547, pred_loss=[0.30990094, 0.23507825, 0.28204337]\n",
      "epoch=98_train_batch=56, total_loss=12.194781303405762, pred_loss=[0.19357383, 0.1757794, 0.29984492]\n",
      "epoch=98_train_batch=57, total_loss=16.176837921142578, pred_loss=[0.08870432, 1.7754984, 2.7879176]\n",
      "epoch=98_train_batch=58, total_loss=12.077247619628906, pred_loss=[0.24525541, 0.26022857, 0.04791212]\n",
      "epoch=98_train_batch=59, total_loss=12.525638580322266, pred_loss=[0.19716893, 0.6106629, 0.19481882]\n",
      "epoch=98_train_batch=60, total_loss=12.190299034118652, pred_loss=[0.08839859, 0.5059911, 0.0737911]\n",
      "epoch=98_train_batch=61, total_loss=15.918971061706543, pred_loss=[0.17272004, 2.32341, 1.9015952]\n",
      "epoch=98_train_batch=62, total_loss=12.148942947387695, pred_loss=[0.025251172, 0.25197595, 0.351332]\n",
      "epoch=98_train_batch=63, total_loss=13.57717227935791, pred_loss=[0.24029692, 0.19861938, 1.6187327]\n",
      "epoch=98_train_batch=64, total_loss=12.355557441711426, pred_loss=[0.028566279, 0.3484392, 0.4598922]\n",
      "epoch=98_train_batch=65, total_loss=13.505356788635254, pred_loss=[0.28347483, 0.34365243, 1.3604307]\n",
      "epoch=98_train_batch=66, total_loss=12.540847778320312, pred_loss=[0.13347545, 0.32296205, 0.56746376]\n",
      "epoch=98_train_batch=67, total_loss=12.236644744873047, pred_loss=[0.036794875, 0.544824, 0.13894197]\n",
      "epoch=98_train_batch=68, total_loss=12.755437850952148, pred_loss=[0.09579575, 0.12157038, 1.022857]\n",
      "epoch=98_train_batch=69, total_loss=12.720111846923828, pred_loss=[0.29360157, 0.7724688, 0.13970119]\n",
      "epoch=98_train_batch=70, total_loss=11.921366691589355, pred_loss=[0.16773278, 0.12823494, 0.11193349]\n",
      "epoch=98_train_batch=71, total_loss=12.932440757751465, pred_loss=[0.00253827, 0.80841285, 0.60890365]\n",
      "epoch=98_train_batch=72, total_loss=12.531332015991211, pred_loss=[0.08688548, 0.41391465, 0.5188331]\n",
      "epoch=98_train_batch=73, total_loss=12.727642059326172, pred_loss=[0.112255886, 0.757024, 0.34755847]\n",
      "epoch=98_train_batch=74, total_loss=12.731623649597168, pred_loss=[0.092244625, 0.14868233, 0.98079854]\n",
      "epoch=98_train_batch=75, total_loss=12.418025970458984, pred_loss=[0.27145815, 0.29615545, 0.341422]\n",
      "epoch=98_train_batch=76, total_loss=12.395071029663086, pred_loss=[0.099593125, 0.47519535, 0.31220382]\n",
      "epoch=98_train_batch=77, total_loss=12.577221870422363, pred_loss=[0.18348524, 0.6116276, 0.27493986]\n",
      "epoch=98_train_batch=78, total_loss=12.785429000854492, pred_loss=[0.08213098, 0.22394848, 0.9730892]\n",
      "epoch=98_train_batch=79, total_loss=12.075902938842773, pred_loss=[0.0046098595, 0.31213507, 0.25380826]\n",
      "epoch=98_train_batch=80, total_loss=12.217107772827148, pred_loss=[0.25237888, 0.39098242, 0.06931145]\n",
      "epoch=98_train_batch=81, total_loss=13.940841674804688, pred_loss=[0.05346645, 0.27940804, 2.1044598]\n",
      "epoch=98_train_batch=82, total_loss=13.00291633605957, pred_loss=[0.13612884, 0.84436953, 0.51983464]\n",
      "epoch=98_train_batch=83, total_loss=13.170368194580078, pred_loss=[0.09977239, 0.3888364, 1.1801045]\n",
      "epoch=98_train_batch=84, total_loss=12.172966957092285, pred_loss=[0.058706947, 0.4273246, 0.18621074]\n",
      "epoch=98_train_batch=85, total_loss=12.309014320373535, pred_loss=[0.059898652, 0.22691238, 0.52241135]\n",
      "epoch=98_train_batch=86, total_loss=12.316585540771484, pred_loss=[0.017278438, 0.33824855, 0.46219563]\n",
      "epoch=98_train_batch=87, total_loss=11.801953315734863, pred_loss=[0.06280835, 0.21146514, 0.029743964]\n",
      "epoch=98_val_batch=0, total_val_loss=787.8601684570312, pred_val_loss[0.098418385, 68.36164, 707.9031]\n",
      "epoch=98_val_batch=1, total_val_loss=214.2254180908203, pred_val_loss[0.090619266, 115.805664, 86.83212]\n",
      "epoch=98_val_batch=2, total_val_loss=97.87657928466797, pred_val_loss[14.601268, 18.86059, 52.917713]\n",
      "epoch=98_val_batch=3, total_val_loss=129.7517547607422, pred_val_loss[4.488098, 28.89547, 84.871185]\n",
      "epoch=98_val_batch=4, total_val_loss=98.47293090820312, pred_val_loss[5.0668893, 36.215675, 45.69336]\n",
      "epoch=98_val_batch=5, total_val_loss=55.827552795410156, pred_val_loss[15.43317, 5.6184053, 23.27897]\n",
      "epoch=98_val_batch=6, total_val_loss=231.24118041992188, pred_val_loss[21.543844, 6.001552, 192.19878]\n",
      "epoch=98_val_batch=7, total_val_loss=166.0248565673828, pred_val_loss[0.39394367, 69.17094, 84.96297]\n",
      "epoch=98_val_batch=8, total_val_loss=50.3460807800293, pred_val_loss[0.16888855, 31.558018, 7.1221657]\n",
      "epoch=98_val_batch=9, total_val_loss=113.74425506591797, pred_val_loss[2.6163604, 55.48215, 44.148735]\n",
      "epoch=98_val_batch=10, total_val_loss=143.64431762695312, pred_val_loss[38.86461, 5.8457236, 87.43697]\n",
      "epoch=98_val_batch=11, total_val_loss=169.1708984375, pred_val_loss[11.035252, 63.13199, 83.50665]\n",
      "epoch=98_val_batch=12, total_val_loss=27.925079345703125, pred_val_loss[0.76953214, 6.2231245, 9.435415]\n",
      "epoch=98_val_batch=13, total_val_loss=101.9026107788086, pred_val_loss[0.16037577, 36.380047, 53.865177]\n",
      "epoch=98_val_batch=14, total_val_loss=114.80784606933594, pred_val_loss[13.127586, 42.392952, 47.790295]\n",
      "epoch=98_val_batch=15, total_val_loss=85.04774475097656, pred_val_loss[28.375412, 1.3456948, 43.829624]\n",
      "epoch=98_val_batch=16, total_val_loss=206.25457763671875, pred_val_loss[11.527435, 72.850174, 110.37996]\n",
      "epoch=98_val_batch=17, total_val_loss=161.45556640625, pred_val_loss[10.687084, 15.603667, 123.6678]\n",
      "epoch=98_val_batch=18, total_val_loss=145.4888916015625, pred_val_loss[4.2818, 30.709223, 99.000854]\n",
      "epoch=98, train: avg_loss=12.750396728515625, val: avg_val_loss=163.21412658691406\n",
      "Saved checkpoint for step 109: ./tf_ckpts/ckpt-108\n",
      "epoch=99_train_batch=0, total_loss=14.07253360748291, pred_loss=[0.07615709, 0.770864, 1.7285044]\n",
      "epoch=99_train_batch=1, total_loss=12.41206169128418, pred_loss=[0.025680885, 0.23893636, 0.65136284]\n",
      "epoch=99_train_batch=2, total_loss=12.76925277709961, pred_loss=[0.31576824, 0.029799245, 0.9285323]\n",
      "epoch=99_train_batch=3, total_loss=14.282367706298828, pred_loss=[2.0735319, 0.37321034, 0.3414071]\n",
      "epoch=99_train_batch=4, total_loss=12.569846153259277, pred_loss=[0.08829231, 0.32768524, 0.6605139]\n",
      "epoch=99_train_batch=5, total_loss=12.094891548156738, pred_loss=[0.12121718, 0.18750378, 0.293668]\n",
      "epoch=99_train_batch=6, total_loss=11.989426612854004, pred_loss=[0.18833235, 0.09476821, 0.21466848]\n",
      "epoch=99_train_batch=7, total_loss=12.06026840209961, pred_loss=[0.065565854, 0.4221961, 0.08169896]\n",
      "epoch=99_train_batch=8, total_loss=12.799335479736328, pred_loss=[0.12272643, 0.38816226, 0.7984929]\n",
      "epoch=99_train_batch=9, total_loss=26.021869659423828, pred_loss=[0.016078997, 1.6693469, 12.847345]\n",
      "epoch=99_train_batch=10, total_loss=12.15330696105957, pred_loss=[0.1581184, 0.13155517, 0.3753844]\n",
      "epoch=99_train_batch=11, total_loss=11.810322761535645, pred_loss=[0.10676858, 0.08398702, 0.13217223]\n",
      "epoch=99_train_batch=12, total_loss=12.01039981842041, pred_loss=[0.01923158, 0.3112048, 0.19342132]\n",
      "epoch=99_train_batch=13, total_loss=11.865131378173828, pred_loss=[0.04852022, 0.1439312, 0.18699405]\n",
      "epoch=99_train_batch=14, total_loss=12.139195442199707, pred_loss=[0.0738686, 0.066689074, 0.5138111]\n",
      "epoch=99_train_batch=15, total_loss=12.31189250946045, pred_loss=[0.18400723, 0.6152139, 0.0287162]\n",
      "epoch=99_train_batch=16, total_loss=12.299391746520996, pred_loss=[0.06874356, 0.45429587, 0.29327387]\n",
      "epoch=99_train_batch=17, total_loss=14.676963806152344, pred_loss=[0.1400477, 0.59404653, 2.4606798]\n",
      "epoch=99_train_batch=18, total_loss=12.214459419250488, pred_loss=[0.01581946, 0.10738625, 0.60995066]\n",
      "epoch=99_train_batch=19, total_loss=12.095849990844727, pred_loss=[0.063798554, 0.34717995, 0.20445971]\n",
      "epoch=99_train_batch=20, total_loss=12.317117691040039, pred_loss=[0.028888633, 0.1674941, 0.64122134]\n",
      "epoch=99_train_batch=21, total_loss=11.976861000061035, pred_loss=[0.057864178, 0.2950617, 0.14532526]\n",
      "epoch=99_train_batch=22, total_loss=11.932685852050781, pred_loss=[0.13216221, 0.22168738, 0.10113269]\n",
      "epoch=99_train_batch=23, total_loss=12.5657958984375, pred_loss=[0.0499481, 0.24378006, 0.7952849]\n",
      "epoch=99_train_batch=24, total_loss=13.646925926208496, pred_loss=[0.2892335, 0.268237, 1.6135974]\n",
      "epoch=99_train_batch=25, total_loss=12.764748573303223, pred_loss=[0.18240438, 0.7645441, 0.34287763]\n",
      "epoch=99_train_batch=26, total_loss=12.055710792541504, pred_loss=[0.14194667, 0.09878021, 0.3410009]\n",
      "epoch=99_train_batch=27, total_loss=12.440668106079102, pred_loss=[0.18833223, 0.1539219, 0.6253699]\n",
      "epoch=99_train_batch=28, total_loss=12.251978874206543, pred_loss=[0.14264369, 0.35372892, 0.28350228]\n",
      "epoch=99_train_batch=29, total_loss=12.130631446838379, pred_loss=[0.065399334, 0.12607947, 0.46799976]\n",
      "epoch=99_train_batch=30, total_loss=12.482574462890625, pred_loss=[0.060199723, 0.31837028, 0.6338024]\n",
      "epoch=99_train_batch=31, total_loss=11.890726089477539, pred_loss=[0.18347368, 0.058835797, 0.17916712]\n",
      "epoch=99_train_batch=32, total_loss=12.056097984313965, pred_loss=[0.07572605, 0.09146189, 0.42061722]\n",
      "epoch=99_train_batch=33, total_loss=13.169782638549805, pred_loss=[0.079458356, 0.35578734, 1.2671957]\n",
      "epoch=99_train_batch=34, total_loss=15.374592781066895, pred_loss=[1.9561901, 0.9265377, 1.0254779]\n",
      "epoch=99_train_batch=35, total_loss=12.006241798400879, pred_loss=[0.07745728, 0.27140588, 0.19192363]\n",
      "epoch=99_train_batch=36, total_loss=12.141722679138184, pred_loss=[0.08042315, 0.28333068, 0.3133868]\n",
      "epoch=99_train_batch=37, total_loss=14.017091751098633, pred_loss=[0.05484741, 1.3179775, 1.180522]\n",
      "epoch=99_train_batch=38, total_loss=12.654193878173828, pred_loss=[0.12738186, 0.77933383, 0.28454795]\n",
      "epoch=99_train_batch=39, total_loss=14.65516185760498, pred_loss=[0.051783103, 0.94299394, 2.1982546]\n",
      "epoch=99_train_batch=40, total_loss=14.494129180908203, pred_loss=[0.32227898, 0.9209466, 1.7895626]\n",
      "epoch=99_train_batch=41, total_loss=13.876997947692871, pred_loss=[1.8554459, 0.3702503, 0.19073713]\n",
      "epoch=99_train_batch=42, total_loss=13.780696868896484, pred_loss=[0.0012273267, 1.6608436, 0.65882784]\n",
      "epoch=99_train_batch=43, total_loss=13.295513153076172, pred_loss=[0.026130581, 0.8618548, 0.9484641]\n",
      "epoch=99_train_batch=44, total_loss=12.45132064819336, pred_loss=[0.09132071, 0.48125666, 0.42039084]\n",
      "epoch=99_train_batch=45, total_loss=12.12112808227539, pred_loss=[0.17642716, 0.27010927, 0.2169407]\n",
      "epoch=99_train_batch=46, total_loss=12.218528747558594, pred_loss=[0.13569428, 0.28957242, 0.3363047]\n",
      "epoch=99_train_batch=47, total_loss=13.245107650756836, pred_loss=[0.15316442, 1.1251774, 0.5105034]\n",
      "epoch=99_train_batch=48, total_loss=12.306056022644043, pred_loss=[0.08680503, 0.518602, 0.24508052]\n",
      "epoch=99_train_batch=49, total_loss=12.61559009552002, pred_loss=[0.11862771, 0.51057845, 0.5315206]\n",
      "epoch=99_train_batch=50, total_loss=11.834444999694824, pred_loss=[0.08549808, 0.21564117, 0.07916342]\n",
      "epoch=99_train_batch=51, total_loss=12.239701271057129, pred_loss=[0.019992158, 0.39005655, 0.3762416]\n",
      "epoch=99_train_batch=52, total_loss=12.110054016113281, pred_loss=[0.092164, 0.50947654, 0.05575331]\n",
      "epoch=99_train_batch=53, total_loss=13.644577026367188, pred_loss=[0.12465649, 0.93974614, 1.1282798]\n",
      "epoch=99_train_batch=54, total_loss=12.100152969360352, pred_loss=[0.34911138, 0.253316, 0.04661175]\n",
      "epoch=99_train_batch=55, total_loss=12.902108192443848, pred_loss=[0.018582104, 0.87245584, 0.5607475]\n",
      "epoch=99_train_batch=56, total_loss=12.90013599395752, pred_loss=[0.36549106, 0.73383915, 0.3512807]\n",
      "epoch=99_train_batch=57, total_loss=12.561392784118652, pred_loss=[0.020118985, 0.31336278, 0.7791995]\n",
      "epoch=99_train_batch=58, total_loss=12.35025405883789, pred_loss=[0.18467766, 0.14942418, 0.5682567]\n",
      "epoch=99_train_batch=59, total_loss=12.774554252624512, pred_loss=[0.13998355, 0.9619802, 0.22551408]\n",
      "epoch=99_train_batch=60, total_loss=12.398085594177246, pred_loss=[0.2808817, 0.44754523, 0.22340614]\n",
      "epoch=99_train_batch=61, total_loss=12.7710599899292, pred_loss=[0.22943142, 0.41341713, 0.68278545]\n",
      "epoch=99_train_batch=62, total_loss=15.33780574798584, pred_loss=[0.3392431, 3.3259294, 0.22803697]\n",
      "epoch=99_train_batch=63, total_loss=12.109338760375977, pred_loss=[0.028774126, 0.43666363, 0.2001721]\n",
      "epoch=99_train_batch=64, total_loss=11.906278610229492, pred_loss=[0.07964992, 0.19856389, 0.1851782]\n",
      "epoch=99_train_batch=65, total_loss=11.943037033081055, pred_loss=[0.10997247, 0.15421031, 0.23679337]\n",
      "epoch=99_train_batch=66, total_loss=12.304303169250488, pred_loss=[0.0870073, 0.5272269, 0.24882606]\n",
      "epoch=99_train_batch=67, total_loss=13.383874893188477, pred_loss=[0.018988956, 0.51451504, 1.4099404]\n",
      "epoch=99_train_batch=68, total_loss=12.822176933288574, pred_loss=[0.30043113, 0.49306017, 0.58906347]\n",
      "epoch=99_train_batch=69, total_loss=12.364555358886719, pred_loss=[0.15023611, 0.11895004, 0.6565657]\n",
      "epoch=99_train_batch=70, total_loss=12.610219955444336, pred_loss=[0.07984528, 0.24383305, 0.84856015]\n",
      "epoch=99_train_batch=71, total_loss=12.778890609741211, pred_loss=[0.047442935, 0.8662376, 0.42805138]\n",
      "epoch=99_train_batch=72, total_loss=11.761727333068848, pred_loss=[0.08249706, 0.2007295, 0.042176414]\n",
      "epoch=99_train_batch=73, total_loss=13.256758689880371, pred_loss=[0.19218192, 0.16680455, 1.4622893]\n",
      "epoch=99_train_batch=74, total_loss=11.965938568115234, pred_loss=[0.047052763, 0.21500453, 0.26924694]\n",
      "epoch=99_train_batch=75, total_loss=12.111902236938477, pred_loss=[0.08804407, 0.38997704, 0.20009772]\n",
      "epoch=99_train_batch=76, total_loss=13.207734107971191, pred_loss=[0.3115586, 0.99417794, 0.46906626]\n",
      "epoch=99_train_batch=77, total_loss=12.324745178222656, pred_loss=[0.04370593, 0.5967395, 0.2522118]\n",
      "epoch=99_train_batch=78, total_loss=12.080119132995605, pred_loss=[0.08707589, 0.10792977, 0.45387316]\n",
      "epoch=99_train_batch=79, total_loss=12.06457805633545, pred_loss=[0.08481273, 0.18758343, 0.36179692]\n",
      "epoch=99_train_batch=80, total_loss=13.462228775024414, pred_loss=[0.08913039, 0.33397922, 1.6095963]\n",
      "epoch=99_train_batch=81, total_loss=12.246041297912598, pred_loss=[0.028714214, 0.45190316, 0.3367656]\n",
      "epoch=99_train_batch=82, total_loss=12.440183639526367, pred_loss=[0.010988425, 0.8519486, 0.1494582]\n",
      "epoch=99_train_batch=83, total_loss=12.338691711425781, pred_loss=[0.10281767, 0.5431264, 0.26583847]\n",
      "epoch=99_train_batch=84, total_loss=12.23643970489502, pred_loss=[0.059814714, 0.29548737, 0.45511454]\n",
      "epoch=99_train_batch=85, total_loss=11.908287048339844, pred_loss=[0.06955691, 0.15226781, 0.2613318]\n",
      "epoch=99_train_batch=86, total_loss=14.782617568969727, pred_loss=[0.09536176, 1.4044108, 1.8586113]\n",
      "epoch=99_train_batch=87, total_loss=11.766881942749023, pred_loss=[0.03994633, 0.22713736, 0.076461524]\n",
      "epoch=99_val_batch=0, total_val_loss=792.7229614257812, pred_val_loss[0.09542217, 63.80681, 717.3983]\n",
      "epoch=99_val_batch=1, total_val_loss=212.8773651123047, pred_val_loss[0.14192618, 111.59718, 89.71581]\n",
      "epoch=99_val_batch=2, total_val_loss=102.07463073730469, pred_val_loss[16.353813, 20.287214, 54.011166]\n",
      "epoch=99_val_batch=3, total_val_loss=132.3682403564453, pred_val_loss[4.6241426, 25.746212, 90.575455]\n",
      "epoch=99_val_batch=4, total_val_loss=99.90374755859375, pred_val_loss[4.0570726, 36.191296, 48.232944]\n",
      "epoch=99_val_batch=5, total_val_loss=54.4560432434082, pred_val_loss[15.887086, 4.6653333, 22.48119]\n",
      "epoch=99_val_batch=6, total_val_loss=226.59898376464844, pred_val_loss[19.063457, 6.4382033, 189.67488]\n",
      "epoch=99_val_batch=7, total_val_loss=161.3325653076172, pred_val_loss[0.35070994, 64.434944, 85.12448]\n",
      "epoch=99_val_batch=8, total_val_loss=51.498023986816406, pred_val_loss[0.16346756, 32.149616, 7.7625046]\n",
      "epoch=99_val_batch=9, total_val_loss=113.86286926269531, pred_val_loss[1.5171406, 53.079376, 47.843914]\n",
      "epoch=99_val_batch=10, total_val_loss=146.65618896484375, pred_val_loss[35.24975, 10.294521, 89.68948]\n",
      "epoch=99_val_batch=11, total_val_loss=172.09844970703125, pred_val_loss[13.339551, 63.52403, 83.81243]\n",
      "epoch=99_val_batch=12, total_val_loss=27.949914932250977, pred_val_loss[0.8583473, 6.6317415, 9.03739]\n",
      "epoch=99_val_batch=13, total_val_loss=104.83758544921875, pred_val_loss[0.17338043, 36.43815, 56.80361]\n",
      "epoch=99_val_batch=14, total_val_loss=107.42576599121094, pred_val_loss[14.106031, 38.670433, 43.226868]\n",
      "epoch=99_val_batch=15, total_val_loss=86.40107727050781, pred_val_loss[28.77183, 2.4212298, 43.78558]\n",
      "epoch=99_val_batch=16, total_val_loss=210.14340209960938, pred_val_loss[10.849122, 73.91974, 113.9521]\n",
      "epoch=99_val_batch=17, total_val_loss=163.68226623535156, pred_val_loss[8.545305, 15.365475, 128.34904]\n",
      "epoch=99_val_batch=18, total_val_loss=137.49851989746094, pred_val_loss[4.51782, 26.404287, 95.15398]\n",
      "epoch=99, train: avg_loss=12.814627647399902, val: avg_val_loss=163.38888549804688\n",
      "Saved checkpoint for step 110: ./tf_ckpts/ckpt-109\n",
      "epoch=100_train_batch=0, total_loss=11.9098539352417, pred_loss=[0.21088491, 0.20602301, 0.07051035]\n",
      "epoch=100_train_batch=1, total_loss=12.78035831451416, pred_loss=[0.2594659, 0.83037496, 0.268988]\n",
      "epoch=100_train_batch=2, total_loss=12.020750045776367, pred_loss=[0.16342111, 0.27733243, 0.15936378]\n",
      "epoch=100_train_batch=3, total_loss=12.448099136352539, pred_loss=[0.111167476, 0.4380988, 0.4791007]\n",
      "epoch=100_train_batch=4, total_loss=11.98299789428711, pred_loss=[0.10084576, 0.15571092, 0.3076064]\n",
      "epoch=100_train_batch=5, total_loss=11.753231048583984, pred_loss=[0.06272094, 0.13963127, 0.1329497]\n",
      "epoch=100_train_batch=6, total_loss=12.306276321411133, pred_loss=[0.15324444, 0.6256076, 0.110407606]\n",
      "epoch=100_train_batch=7, total_loss=12.0333251953125, pred_loss=[0.016050387, 0.49220374, 0.10897249]\n",
      "epoch=100_train_batch=8, total_loss=13.47079849243164, pred_loss=[1.690428, 0.28642112, 0.07877309]\n",
      "epoch=100_train_batch=9, total_loss=12.653215408325195, pred_loss=[0.07286562, 0.20811008, 0.958076]\n",
      "epoch=100_train_batch=10, total_loss=11.748645782470703, pred_loss=[0.029729843, 0.112457536, 0.1932438]\n",
      "epoch=100_train_batch=11, total_loss=11.921051025390625, pred_loss=[0.23846921, 0.22823083, 0.042044766]\n",
      "epoch=100_train_batch=12, total_loss=12.021018981933594, pred_loss=[0.13905291, 0.1003022, 0.3702329]\n",
      "epoch=100_train_batch=13, total_loss=12.377546310424805, pred_loss=[0.06991615, 0.2198498, 0.6772023]\n",
      "epoch=100_train_batch=14, total_loss=12.411163330078125, pred_loss=[0.0047022346, 0.49615532, 0.5005717]\n",
      "epoch=100_train_batch=15, total_loss=12.701379776000977, pred_loss=[0.069209844, 0.414253, 0.80902135]\n",
      "epoch=100_train_batch=16, total_loss=11.809163093566895, pred_loss=[0.071271256, 0.14148796, 0.18834156]\n",
      "epoch=100_train_batch=17, total_loss=12.331099510192871, pred_loss=[0.23072971, 0.23964809, 0.45349288]\n",
      "epoch=100_train_batch=18, total_loss=12.105405807495117, pred_loss=[0.13041633, 0.24734917, 0.32124326]\n",
      "epoch=100_train_batch=19, total_loss=11.92880916595459, pred_loss=[0.100927465, 0.10030833, 0.32201505]\n",
      "epoch=100_train_batch=20, total_loss=11.84061050415039, pred_loss=[0.028256211, 0.19215453, 0.2154879]\n",
      "epoch=100_train_batch=21, total_loss=12.777079582214355, pred_loss=[0.06182394, 0.72301114, 0.58838314]\n",
      "epoch=100_train_batch=22, total_loss=12.811830520629883, pred_loss=[0.17471862, 0.1813947, 1.052717]\n",
      "epoch=100_train_batch=23, total_loss=12.74660873413086, pred_loss=[0.48508513, 0.2887975, 0.57059354]\n",
      "epoch=100_train_batch=24, total_loss=14.02775764465332, pred_loss=[0.030318232, 1.6378835, 0.9582743]\n",
      "epoch=100_train_batch=25, total_loss=11.972654342651367, pred_loss=[0.08047843, 0.35223278, 0.13951616]\n",
      "epoch=100_train_batch=26, total_loss=12.156749725341797, pred_loss=[0.40765652, 0.070861675, 0.27866477]\n",
      "epoch=100_train_batch=27, total_loss=12.08929443359375, pred_loss=[0.104368486, 0.28690535, 0.29931238]\n",
      "epoch=100_train_batch=28, total_loss=13.276910781860352, pred_loss=[0.13843173, 0.2012823, 1.5393491]\n",
      "epoch=100_train_batch=29, total_loss=13.047225952148438, pred_loss=[0.02392587, 0.27950877, 1.3468132]\n",
      "epoch=100_train_batch=30, total_loss=12.659112930297852, pred_loss=[0.9331608, 0.14795798, 0.18189135]\n",
      "epoch=100_train_batch=31, total_loss=11.825660705566406, pred_loss=[0.07332549, 0.28409237, 0.07296738]\n",
      "epoch=100_train_batch=32, total_loss=13.550975799560547, pred_loss=[0.0421531, 0.76113105, 1.3532467]\n",
      "epoch=100_train_batch=33, total_loss=11.944194793701172, pred_loss=[0.071645476, 0.32418802, 0.15474777]\n",
      "epoch=100_train_batch=34, total_loss=11.957542419433594, pred_loss=[0.08010241, 0.4124038, 0.07226721]\n",
      "epoch=100_train_batch=35, total_loss=15.184465408325195, pred_loss=[0.003930976, 1.3404799, 2.448137]\n",
      "epoch=100_train_batch=36, total_loss=15.415023803710938, pred_loss=[0.09892021, 0.10452709, 3.820514]\n",
      "epoch=100_train_batch=37, total_loss=11.979559898376465, pred_loss=[0.12500371, 0.07823121, 0.386119]\n",
      "epoch=100_train_batch=38, total_loss=12.027179718017578, pred_loss=[0.112780124, 0.3402149, 0.1848338]\n",
      "epoch=100_train_batch=39, total_loss=12.546150207519531, pred_loss=[0.07836487, 0.8353031, 0.24398446]\n",
      "epoch=100_train_batch=40, total_loss=12.122315406799316, pred_loss=[0.059130933, 0.30900943, 0.3665352]\n",
      "epoch=100_train_batch=41, total_loss=13.053433418273926, pred_loss=[0.2845779, 0.16484359, 1.2172369]\n",
      "epoch=100_train_batch=42, total_loss=12.437094688415527, pred_loss=[0.2560103, 0.35079023, 0.44438604]\n",
      "epoch=100_train_batch=43, total_loss=13.710891723632812, pred_loss=[0.1253778, 0.38518018, 1.8152972]\n",
      "epoch=100_train_batch=44, total_loss=12.216272354125977, pred_loss=[0.28488147, 0.2101792, 0.33704793]\n",
      "epoch=100_train_batch=45, total_loss=11.707311630249023, pred_loss=[0.19325176, 0.10135349, 0.02941965]\n",
      "epoch=100_train_batch=46, total_loss=12.838655471801758, pred_loss=[0.08589731, 0.72811496, 0.6422451]\n",
      "epoch=100_train_batch=47, total_loss=12.144485473632812, pred_loss=[0.0590003, 0.5670203, 0.13696119]\n",
      "epoch=100_train_batch=48, total_loss=13.424121856689453, pred_loss=[0.15353549, 0.20164296, 1.6883376]\n",
      "epoch=100_train_batch=49, total_loss=14.738607406616211, pred_loss=[0.08181738, 0.34784365, 2.9292395]\n",
      "epoch=100_train_batch=50, total_loss=12.706881523132324, pred_loss=[0.052215442, 0.40284073, 0.8729875]\n",
      "epoch=100_train_batch=51, total_loss=11.905616760253906, pred_loss=[0.09247787, 0.31525722, 0.11988497]\n",
      "epoch=100_train_batch=52, total_loss=13.215993881225586, pred_loss=[0.19712074, 0.2047587, 1.4369419]\n",
      "epoch=100_train_batch=53, total_loss=12.032076835632324, pred_loss=[0.014925039, 0.12689084, 0.5139045]\n",
      "epoch=100_train_batch=54, total_loss=11.88701057434082, pred_loss=[0.18485776, 0.2027983, 0.12380906]\n",
      "epoch=100_train_batch=55, total_loss=13.707742691040039, pred_loss=[0.09961665, 0.27506065, 1.9583302]\n",
      "epoch=100_train_batch=56, total_loss=23.5568904876709, pred_loss=[0.02362165, 2.7664444, 9.392902]\n",
      "epoch=100_train_batch=57, total_loss=15.960746765136719, pred_loss=[0.32190812, 0.16959892, 4.0961227]\n",
      "epoch=100_train_batch=58, total_loss=12.385326385498047, pred_loss=[0.26737982, 0.09980938, 0.64583874]\n",
      "epoch=100_train_batch=59, total_loss=11.90321159362793, pred_loss=[0.07365255, 0.39435595, 0.06372774]\n",
      "epoch=100_train_batch=60, total_loss=13.094996452331543, pred_loss=[0.075971976, 0.29089683, 1.3574694]\n",
      "epoch=100_train_batch=61, total_loss=12.756937026977539, pred_loss=[0.021812987, 0.5327003, 0.8325875]\n",
      "epoch=100_train_batch=62, total_loss=13.377941131591797, pred_loss=[0.11658129, 0.8165062, 1.0758433]\n",
      "epoch=100_train_batch=63, total_loss=12.851175308227539, pred_loss=[0.073400535, 0.56732976, 0.84226]\n",
      "epoch=100_train_batch=64, total_loss=12.22386646270752, pred_loss=[0.071510434, 0.40072384, 0.38427642]\n",
      "epoch=100_train_batch=65, total_loss=13.413305282592773, pred_loss=[0.21651429, 1.7345128, 0.095753886]\n",
      "epoch=100_train_batch=66, total_loss=12.722204208374023, pred_loss=[0.040102314, 0.93084705, 0.3855419]\n",
      "epoch=100_train_batch=67, total_loss=15.252622604370117, pred_loss=[0.018996676, 0.63049984, 3.2382176]\n",
      "epoch=100_train_batch=68, total_loss=12.12543773651123, pred_loss=[0.12258401, 0.2600686, 0.37867913]\n",
      "epoch=100_train_batch=69, total_loss=12.361266136169434, pred_loss=[0.3109351, 0.36190534, 0.32512015]\n",
      "epoch=100_train_batch=70, total_loss=13.285825729370117, pred_loss=[0.09440544, 0.84422153, 0.9847038]\n",
      "epoch=100_train_batch=71, total_loss=15.204724311828613, pred_loss=[0.04575764, 2.2372048, 1.5600789]\n",
      "epoch=100_train_batch=72, total_loss=12.08600902557373, pred_loss=[0.21974735, 0.15870206, 0.34668106]\n",
      "epoch=100_train_batch=73, total_loss=11.775110244750977, pred_loss=[0.22099358, 0.06539573, 0.12863694]\n",
      "epoch=100_train_batch=74, total_loss=12.09048843383789, pred_loss=[0.076506324, 0.3745343, 0.28015494]\n",
      "epoch=100_train_batch=75, total_loss=13.058097839355469, pred_loss=[0.102716886, 0.47051287, 1.1263603]\n",
      "epoch=100_train_batch=76, total_loss=14.885817527770996, pred_loss=[0.038889807, 0.41574812, 3.0734513]\n",
      "epoch=100_train_batch=77, total_loss=12.828685760498047, pred_loss=[0.08252315, 0.6002991, 0.7889202]\n",
      "epoch=100_train_batch=78, total_loss=12.692486763000488, pred_loss=[0.03235667, 0.3748267, 0.92914873]\n",
      "epoch=100_train_batch=79, total_loss=13.917823791503906, pred_loss=[0.12937912, 1.0974586, 1.3356264]\n",
      "epoch=100_train_batch=80, total_loss=12.075313568115234, pred_loss=[0.28497696, 0.32919624, 0.10658633]\n",
      "epoch=100_train_batch=81, total_loss=12.437058448791504, pred_loss=[0.013035381, 0.5293635, 0.5409164]\n",
      "epoch=100_train_batch=82, total_loss=12.035552024841309, pred_loss=[0.1356093, 0.17607489, 0.37094295]\n",
      "epoch=100_train_batch=83, total_loss=11.889678955078125, pred_loss=[0.06994197, 0.4175732, 0.050071515]\n",
      "epoch=100_train_batch=84, total_loss=13.279126167297363, pred_loss=[0.019862698, 0.2596805, 1.6483316]\n",
      "epoch=100_train_batch=85, total_loss=12.927298545837402, pred_loss=[0.15159777, 0.19152787, 1.2337717]\n",
      "epoch=100_train_batch=86, total_loss=12.397245407104492, pred_loss=[0.03476608, 0.40223554, 0.61070377]\n",
      "epoch=100_train_batch=87, total_loss=12.216401100158691, pred_loss=[0.04262885, 0.104632884, 0.720472]\n",
      "epoch=100_val_batch=0, total_val_loss=778.2872314453125, pred_val_loss[0.062443275, 69.01745, 697.85956]\n",
      "epoch=100_val_batch=1, total_val_loss=215.0570068359375, pred_val_loss[0.20003876, 116.006485, 87.50271]\n",
      "epoch=100_val_batch=2, total_val_loss=107.97169494628906, pred_val_loss[16.072058, 25.409174, 55.142677]\n",
      "epoch=100_val_batch=3, total_val_loss=130.90660095214844, pred_val_loss[4.416275, 30.330894, 84.811646]\n",
      "epoch=100_val_batch=4, total_val_loss=92.65245056152344, pred_val_loss[3.4324205, 37.333046, 40.5392]\n",
      "epoch=100_val_batch=5, total_val_loss=59.51311492919922, pred_val_loss[16.390005, 7.468078, 24.307243]\n",
      "epoch=100_val_batch=6, total_val_loss=222.19854736328125, pred_val_loss[21.84712, 6.522271, 182.48137]\n",
      "epoch=100_val_batch=7, total_val_loss=162.498046875, pred_val_loss[0.3854417, 68.51829, 82.24654]\n",
      "epoch=100_val_batch=8, total_val_loss=55.79417419433594, pred_val_loss[0.19908844, 33.329704, 10.917595]\n",
      "epoch=100_val_batch=9, total_val_loss=120.98800659179688, pred_val_loss[3.363826, 59.452057, 46.824337]\n",
      "epoch=100_val_batch=10, total_val_loss=144.44534301757812, pred_val_loss[41.8519, 5.9365177, 85.30915]\n",
      "epoch=100_val_batch=11, total_val_loss=177.75143432617188, pred_val_loss[12.723231, 59.233776, 94.44665]\n",
      "epoch=100_val_batch=12, total_val_loss=29.630300521850586, pred_val_loss[1.8466307, 6.9535418, 9.482343]\n",
      "epoch=100_val_batch=13, total_val_loss=104.38739776611328, pred_val_loss[0.18718216, 36.26857, 56.583855]\n",
      "epoch=100_val_batch=14, total_val_loss=103.17952728271484, pred_val_loss[11.540417, 40.450127, 39.841198]\n",
      "epoch=100_val_batch=15, total_val_loss=83.13809967041016, pred_val_loss[29.71367, 1.1102116, 40.966427]\n",
      "epoch=100_val_batch=16, total_val_loss=226.88963317871094, pred_val_loss[12.263382, 79.89494, 123.38353]\n",
      "epoch=100_val_batch=17, total_val_loss=175.48590087890625, pred_val_loss[12.098031, 13.905662, 138.13443]\n",
      "epoch=100_val_batch=18, total_val_loss=135.3839569091797, pred_val_loss[4.964456, 28.723665, 90.34805]\n",
      "epoch=100, train: avg_loss=12.834863662719727, val: avg_val_loss=164.53466796875\n",
      "Saved checkpoint for step 111: ./tf_ckpts/ckpt-110\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# flags.DEFINE_integer('size', 416, 'image size')\n",
    "# flags.DEFINE_integer('epochs', 2, 'number of epochs')\n",
    "# flags.DEFINE_integer('batch_size', 8, 'batch size')\n",
    "# flags.DEFINE_float('learning_rate', 1e-3, 'learning rate')\n",
    "# flags.DEFINE_integer('num_classes', 80, 'number of classes in the model')\n",
    "# flags.DEFINE_integer('weights_num_classes', None, 'specify num class for `weights` file if different, '\n",
    "#                                                   'useful in transfer learning with different number of classes')\n",
    "\n",
    "\n",
    "\n",
    "model = YoloV3(size, training=True, classes=weights_num_classes)\n",
    "anchors = yolo_anchors\n",
    "anchor_masks = yolo_anchor_masks\n",
    "\n",
    "\n",
    "model_pretrained = YoloV3(size, training=True, classes=num_classes)\n",
    "model_pretrained.load_weights(weights)\n",
    "\n",
    "model.get_layer('yolo_darknet').set_weights(model_pretrained.get_layer('yolo_darknet').get_weights())\n",
    "freeze_all(model.get_layer('yolo_darknet'))\n",
    "# for l in model.layers:\n",
    "#   if not l.name.startswith('yolo_output'):\n",
    "#     l.set_weights(model_pretrained.get_layer(l.name).get_weights())\n",
    "#     freeze_all(l)\n",
    "# model.get_layer('yolo_darknet').trainable = False\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
    "loss = [YoloLoss(anchors[mask], classes=weights_num_classes) for mask in anchor_masks]\n",
    "\n",
    "avg_loss = tf.keras.metrics.Mean('loss', dtype=tf.float32)\n",
    "avg_val_loss = tf.keras.metrics.Mean('val_loss', dtype=tf.float32)\n",
    "\n",
    "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=optimizer, model=model)\n",
    "manager = tf.train.CheckpointManager(ckpt, './tf_ckpts', max_to_keep=3)\n",
    "ckpt.restore(manager.latest_checkpoint)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    for batch, (images, labels) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = model(images, training=True)\n",
    "            regularization_loss = tf.reduce_sum(model.losses)\n",
    "            pred_loss = []\n",
    "            for output, label, loss_fn in zip(outputs, labels, loss):\n",
    "                pred_loss.append(loss_fn(label, output))\n",
    "            total_loss = tf.reduce_sum(pred_loss) + regularization_loss\n",
    "\n",
    "        grads = tape.gradient(total_loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(\n",
    "            zip(grads, model.trainable_variables))\n",
    "\n",
    "        print(\"epoch={}_train_batch={}, total_loss={}, pred_loss={}\".format(\n",
    "            epoch, batch, total_loss.numpy(),\n",
    "            list(map(lambda x: np.sum(x.numpy()), pred_loss))))\n",
    "        avg_loss.update_state(total_loss)\n",
    "\n",
    "    for batch, (images, labels) in enumerate(val_dataset):\n",
    "        outputs = model(images)\n",
    "        regularization_loss = tf.reduce_sum(model.losses)\n",
    "        pred_loss = []\n",
    "        for output, label, loss_fn in zip(outputs, labels, loss):\n",
    "            pred_loss.append(loss_fn(label, output))\n",
    "        total_loss = tf.reduce_sum(pred_loss) + regularization_loss\n",
    "\n",
    "        print(\"epoch={}_val_batch={}, total_val_loss={}, pred_val_loss{}\".format(\n",
    "            epoch, batch, total_loss.numpy(),\n",
    "            list(map(lambda x: np.sum(x.numpy()), pred_loss))))\n",
    "        avg_val_loss.update_state(total_loss)\n",
    "\n",
    "    print(\"epoch={}, train: avg_loss={}, val: avg_val_loss={}\".format(\n",
    "        epoch,\n",
    "        avg_loss.result().numpy(),\n",
    "        avg_val_loss.result().numpy()))\n",
    "\n",
    "    avg_loss.reset_states()\n",
    "    avg_val_loss.reset_states()\n",
    "    ckpt.step.assign_add(1)\n",
    "    save_path = manager.save()\n",
    "    print(\"Saved checkpoint for step {}: {}\".format(int(ckpt.step), save_path))\n",
    "    # model.save_weights('./new_checkpoints/yolov3_train_{}.tf'.format(epoch))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "4HCKWLcB4NIj",
    "outputId": "67ef3397-0d81-4b26-ae51-9cda2aabee7e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2020-09-02 17:52:06--  https://static01.nyt.com/images/2020/02/17/opinion/13Lynteris4/13Lynteris4-jumbo.jpg\n",
      "Resolving static01.nyt.com (static01.nyt.com)... 151.101.153.164\n",
      "Connecting to static01.nyt.com (static01.nyt.com)|151.101.153.164|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 179376 (175K) [image/jpeg]\n",
      "Saving to: '13Lynteris4-jumbo.jpg'\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 28%  847K 0s\n",
      "    50K .......... .......... .......... .......... .......... 57%  816K 0s\n",
      "   100K .......... .......... .......... .......... .......... 85%  815K 0s\n",
      "   150K .......... .......... .....                           100%  793K=0.2s\n",
      "\n",
      "2020-09-02 17:52:08 (821 KB/s) - '13Lynteris4-jumbo.jpg' saved [179376/179376]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://static01.nyt.com/images/2020/02/17/opinion/13Lynteris4/13Lynteris4-jumbo.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r-93wk974NIm"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = cv2.imread('./13Lynteris4-jumbo.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z5WVK82Sgw2_"
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yyhNLd5VMq8L",
    "outputId": "97272294-0e3c-42b7-dffa-1845d10cdcd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0949687957763672\n"
     ]
    }
   ],
   "source": [
    "yolo = YoloV3(classes=weights_num_classes)\n",
    "# yolo.load_weights('./tf_ckpts/ckpt-8').expect_partial()\n",
    "optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
    "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=optimizer, model=yolo)\n",
    "manager = tf.train.CheckpointManager(ckpt, './tf_ckpts', max_to_keep=3)\n",
    "latest = tf.train.latest_checkpoint('./tf_ckpts/')\n",
    "ckpt.restore(latest)\n",
    "model = ckpt.model\n",
    "for l in model.layers:\n",
    "  yolo.get_layer(l.name).set_weights(model.get_layer(l.name).get_weights())\n",
    "class_names = [c.strip() for c in open('./data/faceMask.names').readlines()]\n",
    "\n",
    "img_in = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img_in = tf.expand_dims(img_in, 0)\n",
    "img_in = transform_images(img_in, 416)\n",
    "\n",
    "t1 = time.time()\n",
    "boxes, scores, classes, nums = yolo(img_in)\n",
    "t2 = time.time()\n",
    "\n",
    "img = draw_outputs(img, (boxes, scores, classes, nums), class_names)\n",
    "print(t2 - t1)\n",
    "# img = cv2.putText(img, \"Time: {:.2f}ms\".format(sum(times) / len(times) * 1000), (0, 30),cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 765
    },
    "colab_type": "code",
    "id": "hRr2tV_3TIzF",
    "outputId": "5632456a-608f-439d-a59f-ec1acba782bf"
   },
   "outputs": [],
   "source": [
    "# from google.colab.patches import cv2_imshow\n",
    "# cv2.imshow(\"test\", img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R7UceJT26b5d"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "YoloFaceMaskDetector.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}